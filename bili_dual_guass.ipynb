{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08754bb9-9ddc-4664-987a-93eb9735a69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import add_self_loops\n",
    "from sklearn.model_selection import train_test_split                                                                                                   \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.amp import autocast\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts\n",
    "from sklearn.metrics import r2_score as sklearn_r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import sys\n",
    "sys.path.append('/home/jovyan/work/GNO/GNN/GNNShap')\n",
    "from gnnshap.explainer import GNNShapExplainer\n",
    "import uuid\n",
    "\n",
    "# 导入Blitz库\n",
    "from blitz.modules import BayesianLinear                 \n",
    "from blitz.utils import variational_estimator\n",
    "\n",
    "# 设备配置\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 自定义数据集类\n",
    "class HydroDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, graphs):\n",
    "        self.graphs = graphs\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.graphs[idx]\n",
    "\n",
    "class BlitzSTConv(MessagePassing):\n",
    "    \"\"\"\n",
    "    使用Blitz实现的贝叶斯时空卷积层，增强鲁棒性\n",
    "    \"\"\"\n",
    "    def __init__(self, spatial_dim, prior_sigma_1=0.1, prior_sigma_2=0.002, posterior_mu_init=0.0, posterior_rho_init=-3.0, dropout=0.1):\n",
    "        super().__init__(aggr='mean')\n",
    "        # 使用标准的PyTorch层进行初始化处理\n",
    "        self.pre_msg = nn.Linear(2 * spatial_dim + 3, spatial_dim)\n",
    "        \n",
    "        # 然后使用Blitz层进行贝叶斯推断\n",
    "        self.bayes_msg = nn.Sequential(\n",
    "            BayesianLinear(spatial_dim, spatial_dim,\n",
    "                        prior_sigma_1=prior_sigma_1, \n",
    "                        prior_sigma_2=prior_sigma_2,\n",
    "                        posterior_mu_init=posterior_mu_init,\n",
    "                        posterior_rho_init=posterior_rho_init),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.LayerNorm(spatial_dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        # 同样的模式用于gate网络\n",
    "        self.pre_gate = nn.Linear(3 * spatial_dim, spatial_dim)\n",
    "        self.bayes_gate = nn.Sequential(\n",
    "            BayesianLinear(spatial_dim, spatial_dim,\n",
    "                        prior_sigma_1=prior_sigma_1, \n",
    "                        prior_sigma_2=prior_sigma_2,\n",
    "                        posterior_mu_init=posterior_mu_init,\n",
    "                        posterior_rho_init=posterior_rho_init),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # 残差处理\n",
    "        self.pre_res = nn.Linear(spatial_dim, spatial_dim)\n",
    "        self.bayes_res = BayesianLinear(spatial_dim, spatial_dim,\n",
    "                                     prior_sigma_1=prior_sigma_1/2, \n",
    "                                     prior_sigma_2=prior_sigma_2/2,\n",
    "                                     posterior_mu_init=posterior_mu_init,\n",
    "                                     posterior_rho_init=posterior_rho_init)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        try:\n",
    "            # 添加调试信息\n",
    "            # 确保edge_attr是浮点类型\n",
    "            edge_attr = edge_attr.float()\n",
    "            \n",
    "            # 尝试传播消息\n",
    "            out = self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "            \n",
    "            # Gate机制\n",
    "            combined = torch.cat([x, out, x - out], dim=-1)\n",
    "            gate_pre = self.pre_gate(combined)\n",
    "            gate = self.bayes_gate(gate_pre)\n",
    "            \n",
    "            # 残差连接\n",
    "            res_pre = self.pre_res(x)\n",
    "            res = self.bayes_res(res_pre)\n",
    "            \n",
    "            return x + gate * out + 0.1 * res\n",
    "        except Exception as e:\n",
    "            print(f\"Error in BlitzSTConv.forward: {e}\")\n",
    "            # 提供更详细的错误信息\n",
    "            print(f\"x shape: {x.shape}, dtype: {x.dtype}\")\n",
    "            print(f\"edge_index shape: {edge_index.shape}, dtype: {edge_index.dtype}\")\n",
    "            print(f\"edge_attr shape: {edge_attr.shape}, dtype: {edge_attr.dtype}\")\n",
    "            raise\n",
    "\n",
    "    def message(self, x_i, x_j, edge_attr):\n",
    "        try:\n",
    "            # 添加调试信息\n",
    "            edge_attr = edge_attr.to(x_i.dtype).to(x_i.device)\n",
    "            \n",
    "            # 先使用标准层，然后使用贝叶斯层\n",
    "            combined = torch.cat([x_i, x_j, edge_attr], dim=-1)\n",
    "            pre_msg = self.pre_msg(combined)\n",
    "            return self.bayes_msg(pre_msg)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in BlitzSTConv.message: {e}\")\n",
    "            # 提供更详细的错误信息\n",
    "            print(f\"x_i shape: {x_i.shape}, dtype: {x_i.dtype}\")\n",
    "            print(f\"x_j shape: {x_j.shape}, dtype: {x_j.dtype}\")\n",
    "            print(f\"edge_attr shape: {edge_attr.shape}, dtype: {edge_attr.dtype}\")\n",
    "            raise\n",
    "\n",
    "class BlitzBoundaryProcessor(nn.Module):\n",
    "    \"\"\"\n",
    "    使用Blitz实现的贝叶斯边界处理器\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, prior_sigma_1=0.1, prior_sigma_2=0.002, posterior_mu_init=0.0, posterior_rho_init=-3.0):\n",
    "        super().__init__()\n",
    "        self.boundary_net = nn.Sequential(\n",
    "            BayesianLinear(dim + 1, dim,\n",
    "                        prior_sigma_1=prior_sigma_1, \n",
    "                        prior_sigma_2=prior_sigma_2,\n",
    "                        posterior_mu_init=posterior_mu_init,\n",
    "                        posterior_rho_init=posterior_rho_init),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.river_net = nn.Sequential(\n",
    "            BayesianLinear(dim + 2, dim,\n",
    "                        prior_sigma_1=prior_sigma_1, \n",
    "                        prior_sigma_2=prior_sigma_2,\n",
    "                        posterior_mu_init=posterior_mu_init,\n",
    "                        posterior_rho_init=posterior_rho_init),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.well_net = BayesianLinear(dim + 1, dim,\n",
    "                                    prior_sigma_1=prior_sigma_1, \n",
    "                                    prior_sigma_2=prior_sigma_2,\n",
    "                                    posterior_mu_init=posterior_mu_init,\n",
    "                                    posterior_rho_init=posterior_rho_init)\n",
    "        \n",
    "        self.gate = nn.Sequential(\n",
    "            BayesianLinear(2 * dim, dim,\n",
    "                        prior_sigma_1=prior_sigma_1/2, \n",
    "                        prior_sigma_2=prior_sigma_2/2,\n",
    "                        posterior_mu_init=posterior_mu_init,\n",
    "                        posterior_rho_init=posterior_rho_init),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.chd_enforcer = BayesianLinear(dim, dim,\n",
    "                                        prior_sigma_1=prior_sigma_1/2, \n",
    "                                        prior_sigma_2=prior_sigma_2/2,\n",
    "                                        posterior_mu_init=posterior_mu_init,\n",
    "                                        posterior_rho_init=posterior_rho_init)\n",
    "    \n",
    "    def forward(self, x, bc_mask):\n",
    "        boundary_feat = self.boundary_net(\n",
    "            torch.cat([x, bc_mask[:, 0:1]], dim=-1)\n",
    "        ) * bc_mask[:, 0:1]\n",
    "        \n",
    "        river_feat = self.river_net(\n",
    "            torch.cat([x, bc_mask[:, 1:3]], dim=-1)\n",
    "        ) * bc_mask[:, 1:2]\n",
    "        \n",
    "        well_feat = self.well_net(\n",
    "            torch.cat([x, bc_mask[:, 3:4]], dim=-1)\n",
    "        ) * bc_mask[:, 4:5]\n",
    "        \n",
    "        combined = boundary_feat + river_feat + well_feat\n",
    "        gate = self.gate(torch.cat([x, combined], dim=-1))\n",
    "        out = x * (1 - gate) + combined * gate\n",
    "        \n",
    "        chd_mask = bc_mask[:, 0] > 0\n",
    "        if chd_mask.sum() > 0:\n",
    "            chd_out = self.chd_enforcer(out[chd_mask]).to(out.dtype)\n",
    "            out[chd_mask] = chd_out\n",
    "            \n",
    "        return out\n",
    "\n",
    "@variational_estimator\n",
    "class BlitzHeadGNN(nn.Module):\n",
    "    \"\"\"\n",
    "    使用Blitz实现的贝叶斯水头预测GNN，加入前一时间步的水头和浓度特征\n",
    "    \"\"\"\n",
    "    def __init__(self, node_features=16, max_time_steps=40, spatial_dim=64, \n",
    "                temporal_dim=64, output_dim=1, prior_sigma_1=0.05, prior_sigma_2=0.001,\n",
    "                posterior_mu_init=0.0, posterior_rho_init=-3.0, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.spatial_dim = spatial_dim\n",
    "        self.time_embed = nn.Embedding(max_time_steps + 1, temporal_dim)\n",
    "        \n",
    "        # 节点编码器 - 注意这里的输入维度变为node_features + temporal_dim\n",
    "        # 节点编码器 - 更保守的设计\n",
    "        self.node_enc = nn.Sequential(\n",
    "            nn.Linear(node_features + temporal_dim, spatial_dim),\n",
    "            nn.BatchNorm1d(spatial_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(spatial_dim, spatial_dim),\n",
    "            nn.BatchNorm1d(spatial_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        # 卷积层\n",
    "        self.conv_layers = nn.ModuleList([\n",
    "            BlitzSTConv(spatial_dim, prior_sigma_1, prior_sigma_2, \n",
    "                     posterior_mu_init, posterior_rho_init, dropout) \n",
    "            for _ in range(4)\n",
    "        ])\n",
    "        \n",
    "        # 边界处理器\n",
    "        self.bc_processor = BlitzBoundaryProcessor(\n",
    "            spatial_dim, prior_sigma_1, prior_sigma_2, \n",
    "            posterior_mu_init, posterior_rho_init\n",
    "        )\n",
    "        \n",
    "        # 确定性路径 - 增强权重\n",
    "        self.deterministic_path = nn.Sequential(\n",
    "            nn.Linear(spatial_dim, spatial_dim // 2),\n",
    "            nn.BatchNorm1d(spatial_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(spatial_dim // 2, spatial_dim // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(spatial_dim // 4, output_dim),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "        \n",
    "        # 贝叶斯路径 - 降低复杂度\n",
    "        self.bayesian_path = nn.Sequential(\n",
    "            BayesianLinear(spatial_dim, spatial_dim // 2,\n",
    "                          prior_sigma_1=prior_sigma_1, \n",
    "                          prior_sigma_2=prior_sigma_2,\n",
    "                          posterior_mu_init=posterior_mu_init,\n",
    "                          posterior_rho_init=posterior_rho_init),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            BayesianLinear(spatial_dim // 2, output_dim,\n",
    "                          prior_sigma_1=prior_sigma_1/2, \n",
    "                          prior_sigma_2=prior_sigma_2/2,\n",
    "                          posterior_mu_init=posterior_mu_init,\n",
    "                          posterior_rho_init=posterior_rho_init),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "        \n",
    "        # 注意力机制用于特征选择\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(spatial_dim, spatial_dim // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(spatial_dim // 4, spatial_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr.to(torch.float32)\n",
    "        \n",
    "        # 特征工程\n",
    "        if hasattr(self, 'feature_engineering'):\n",
    "            x = self.feature_engineering(x)\n",
    "        \n",
    "        # 时间嵌入\n",
    "        time_emb = self.time_embed(data.time_step)\n",
    "        node_feat = torch.cat([x, time_emb], dim=-1)\n",
    "        \n",
    "        # 节点编码\n",
    "        h = self.node_enc(node_feat)\n",
    "        \n",
    "        # 简化的图卷积\n",
    "        for conv in self.conv_layers:\n",
    "            h_new = conv(h, edge_index, edge_attr)\n",
    "            h = h + 0.1 * h_new  # 残差连接\n",
    "        \n",
    "        # 注意力加权\n",
    "        attention_weights = self.attention(h)\n",
    "        h = h * attention_weights\n",
    "        \n",
    "        # 边界处理\n",
    "        h = self.bc_processor(h, data.bc_mask)\n",
    "        \n",
    "        # 双路径预测，增加确定性路径权重\n",
    "        det_pred = self.deterministic_path(h.detach())\n",
    "        bayes_pred = self.bayesian_path(h)\n",
    "        \n",
    "        # 自适应权重组合\n",
    "        return det_pred * 0.7 + bayes_pred * 0.3\n",
    "\n",
    "class ImprovedPhysicsInformedLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    改进的物理信息损失函数，无需显式计算KL散度（Blitz内部处理）\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha=0.5, kl_weight=1e-4):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.kl_weight = kl_weight  # 在Blitz中，KL权重在sample_elbo中传入\n",
    "        \n",
    "    def forward(self, pred, data, model=None):  # 添加model参数使接口一致，但不使用\n",
    "        # 基础MSE损失\n",
    "        mse_loss = F.mse_loss(pred, data.head_y.unsqueeze(1))\n",
    "        \n",
    "        # 物理约束损失\n",
    "        time_steps = data.time_step.unique(sorted=True)\n",
    "        flux_loss = 0\n",
    "        for t in time_steps[:-1]:\n",
    "            mask_t = (data.time_step == t)\n",
    "            mask_next = (data.time_step == t + 1)\n",
    "            if mask_t.sum() > 0 and mask_next.sum() > 0:\n",
    "                flux_diff = torch.mean((pred[mask_next] - pred[mask_t]) ** 2)\n",
    "                flux_loss += flux_diff\n",
    "        flux_loss /= len(time_steps) - 1 if len(time_steps) > 1 else 1\n",
    "        \n",
    "        # 边界条件损失\n",
    "        bc_mask = data.bc_mask[:, 0] > 0\n",
    "        bc_loss = F.l1_loss(pred[bc_mask], data.head_y[bc_mask].unsqueeze(1)) if bc_mask.sum() > 0 else torch.tensor(0.0, device=pred.device)\n",
    "        \n",
    "        # 井条件损失\n",
    "        well_mask = data.bc_mask[:, 4] > 0\n",
    "        well_loss = F.l1_loss(pred[well_mask], data.head_y[well_mask].unsqueeze(1)) if well_mask.sum() > 0 else torch.tensor(0.0, device=pred.device)\n",
    "        \n",
    "        # 总损失 - 不包含KL散度，KL散度由Blitz内部处理\n",
    "        total_loss = (1 - self.alpha) * mse_loss + self.alpha * (flux_loss + bc_loss + well_loss)\n",
    "        \n",
    "        return total_loss, (mse_loss.item(), flux_loss.item(), bc_loss.item(), well_loss.item(), 0.0)  # 返回0.0表示KL损失，但实际上由Blitz处理\n",
    "\n",
    "\n",
    "@variational_estimator\n",
    "class BlitzConcGNN(nn.Module):\n",
    "    \"\"\"\n",
    "    简化的贝叶斯浓度预测GNN，直接使用18维输入特征\n",
    "    \"\"\"\n",
    "    def __init__(self, node_features=19, max_time_steps=40, spatial_dim=128,\n",
    "                temporal_dim=64, output_dim=1, prior_sigma_1=0.1, prior_sigma_2=0.01,\n",
    "                posterior_mu_init=0.0, posterior_rho_init=-3.0, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.spatial_dim = spatial_dim\n",
    "        self.time_embed = nn.Embedding(max_time_steps + 1, temporal_dim)\n",
    "        \n",
    "        # 简化的节点编码器 - 直接处理18维特征\n",
    "        self.node_enc_scale1 = nn.Sequential(\n",
    "            nn.Linear(node_features + temporal_dim, spatial_dim),  # 18 + 64 = 82 -> 128\n",
    "            nn.BatchNorm1d(spatial_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout * 0.5)\n",
    "        )\n",
    "        \n",
    "        self.node_enc = nn.Sequential(\n",
    "            BayesianLinear(spatial_dim, spatial_dim,\n",
    "                        prior_sigma_1=prior_sigma_1, \n",
    "                        prior_sigma_2=prior_sigma_2,\n",
    "                        posterior_mu_init=posterior_mu_init,\n",
    "                        posterior_rho_init=posterior_rho_init),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.LayerNorm(spatial_dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        # 卷积层\n",
    "        self.conv_layers = nn.ModuleList([\n",
    "            BlitzSTConv(spatial_dim, prior_sigma_1, prior_sigma_2, \n",
    "                     posterior_mu_init, posterior_rho_init, dropout) \n",
    "            for _ in range(4)\n",
    "        ])\n",
    "        \n",
    "        # 边界处理器\n",
    "        self.bc_processor = BlitzBoundaryProcessor(\n",
    "            spatial_dim, prior_sigma_1, prior_sigma_2, \n",
    "            posterior_mu_init, posterior_rho_init\n",
    "        )\n",
    "        \n",
    "        # 注意力机制\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(spatial_dim, spatial_dim // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(spatial_dim // 4, spatial_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # 贝叶斯分支解码器\n",
    "        self.decoder = nn.Sequential(\n",
    "            BayesianLinear(spatial_dim, 128,\n",
    "                        prior_sigma_1=prior_sigma_1/2, \n",
    "                        prior_sigma_2=prior_sigma_2/2,\n",
    "                        posterior_mu_init=posterior_mu_init,\n",
    "                        posterior_rho_init=posterior_rho_init),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            BayesianLinear(128, 64,\n",
    "                        prior_sigma_1=prior_sigma_1/2, \n",
    "                        prior_sigma_2=prior_sigma_2/2,\n",
    "                        posterior_mu_init=posterior_mu_init,\n",
    "                        posterior_rho_init=posterior_rho_init),\n",
    "            nn.ReLU(),\n",
    "            BayesianLinear(64, output_dim,\n",
    "                        prior_sigma_1=prior_sigma_1/4, \n",
    "                        prior_sigma_2=prior_sigma_2/4,\n",
    "                        posterior_mu_init=posterior_mu_init,\n",
    "                        posterior_rho_init=posterior_rho_init),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "        \n",
    "        # 确定性分支解码器\n",
    "        self.decoder_det = nn.Sequential(\n",
    "            nn.Linear(spatial_dim, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, output_dim),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "        \n",
    "        # 自适应分支权重\n",
    "        self.branch_weight = nn.Parameter(torch.tensor(0.3))\n",
    "\n",
    "    def forward(self, data, pred_head=None):\n",
    "        # 直接使用conc_x作为输入（18维特征）\n",
    "        x = data.conc_x\n",
    "        edge_index, edge_attr = data.edge_index, data.edge_attr\n",
    "        \n",
    "        # 确保所有张量在同一设备\n",
    "        if edge_attr is not None:\n",
    "            edge_attr = edge_attr.to(torch.float32).to(x.device)\n",
    "        \n",
    "        # 时间嵌入\n",
    "        time_step = data.time_step.to(x.device)\n",
    "        time_emb = self.time_embed(time_step)\n",
    "        \n",
    "        # 节点特征与时间嵌入结合\n",
    "        node_feat = torch.cat([x, time_emb], dim=-1)  # (18 + 64) = 82维\n",
    "        \n",
    "        # 节点编码\n",
    "        h_scale1 = self.node_enc_scale1(node_feat)\n",
    "        h = self.node_enc(h_scale1)\n",
    "        \n",
    "        # 图卷积层\n",
    "        for conv in self.conv_layers:\n",
    "            h_new = conv(h, edge_index, edge_attr)\n",
    "            h = h + 0.1 * h_new  # 残差连接\n",
    "        \n",
    "        # 注意力加权\n",
    "        attention_weights = self.attention(h)\n",
    "        h = h * attention_weights\n",
    "        \n",
    "        # 边界处理\n",
    "        bc_mask = data.bc_mask.to(x.device) if hasattr(data, 'bc_mask') else None\n",
    "        h = self.bc_processor(h, bc_mask)\n",
    "        \n",
    "        # 双分支输出\n",
    "        bayes_output = self.decoder(h)\n",
    "        det_output = self.decoder_det(h.detach())\n",
    "        \n",
    "        # 自适应权重组合\n",
    "        combined_output = (\n",
    "            torch.sigmoid(self.branch_weight) * bayes_output + \n",
    "            (1 - torch.sigmoid(self.branch_weight)) * det_output\n",
    "        )\n",
    "        \n",
    "        return combined_output\n",
    "\n",
    "class ImprovedConcLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    改进的浓度预测损失函数，优化L1正则化\n",
    "    \"\"\"\n",
    "    def __init__(self, kl_weight=5e-5, l1_weight=1e-8):  # 大幅降低L1权重\n",
    "        super().__init__()\n",
    "        self.kl_weight = kl_weight\n",
    "        self.l1_weight = l1_weight  # L1正则化权重降低1000倍\n",
    "        \n",
    "    def forward(self, pred, data, model=None):\n",
    "        # 使用MSE损失\n",
    "        mse_loss = F.mse_loss(pred, data.y.unsqueeze(1))\n",
    "        \n",
    "        # 只对贝叶斯层应用L1正则化\n",
    "        l1_reg = torch.tensor(0., device=pred.device)\n",
    "        if model is not None and self.l1_weight > 0:\n",
    "            for name, param in model.named_parameters():\n",
    "                # 只对贝叶斯层的权重应用L1正则化\n",
    "                if 'weight' in name and ('bayesian' in name.lower() or 'bayes' in name.lower()):\n",
    "                    l1_reg += torch.norm(param, 1)\n",
    "        \n",
    "        # 总损失\n",
    "        total_loss = mse_loss + self.l1_weight * l1_reg\n",
    "        \n",
    "        return total_loss, (mse_loss.item(), 0.0, l1_reg.item())\n",
    "\n",
    "def generate_spatial_edges(model_df):\n",
    "    \"\"\"生成空间边和边属性\"\"\"\n",
    "    spatial_edges = []\n",
    "    time_steps = model_df['time_step'].unique()\n",
    "    for t in time_steps:\n",
    "        time_df = model_df[model_df['time_step'] == t]\n",
    "        coord_to_idx = {(r, c): idx for idx, r, c in zip(time_df['local_index'], time_df['row'], time_df['col'])}\n",
    "        for idx, row, col in zip(time_df['local_index'], time_df['row'], time_df['col']):\n",
    "            right_coord = (row, col + 1)\n",
    "            if right_coord in coord_to_idx:\n",
    "                spatial_edges.append([idx, coord_to_idx[right_coord]])\n",
    "            upper_coord = (row + 1, col)\n",
    "            if upper_coord in coord_to_idx:\n",
    "                spatial_edges.append([idx, coord_to_idx[upper_coord]])\n",
    "    return np.array(spatial_edges), np.full((len(spatial_edges), 3), [1.0, 0, 0], dtype=np.float32)\n",
    "\n",
    "def generate_temporal_edges(model_df):\n",
    "    \"\"\"生成时间边和边属性\"\"\"\n",
    "    temporal_edges = []\n",
    "    groups = model_df.groupby(['row', 'col'], sort=False)\n",
    "    for (row, col), group in groups:\n",
    "        time_series = group.sort_values('time_step')\n",
    "        for i in range(len(time_series) - 1):\n",
    "            global_src = time_series['local_index'].iloc[i]\n",
    "            global_dst = time_series['local_index'].iloc[i + 1]\n",
    "            temporal_edges.append([global_src, global_dst])\n",
    "    return np.array(temporal_edges), np.full((len(temporal_edges), 3), [0.0, 1.0, 0], dtype=np.float32)\n",
    "\n",
    "def build_bc_mask(model_df):\n",
    "    \"\"\"构建边界条件掩码\"\"\"\n",
    "    bc_mask = np.zeros((len(model_df), 5), dtype=np.float32)\n",
    "    bc_mask[:, 0] = model_df['chd_mask'].values.astype(np.float32)\n",
    "    bc_mask[:, 1] = (model_df['river_cond'] > 0).astype(np.float32)\n",
    "    bc_mask[:, 2] = model_df['river_stage'].values.astype(np.float32)\n",
    "    bc_mask[:, 3] = model_df['well_rate'].values.astype(np.float32)\n",
    "    bc_mask[:, 4] = model_df['well_mask'].values.astype(np.float32)\n",
    "    return bc_mask\n",
    "def build_spatiotemporal_graph(df):\n",
    "    \"\"\"构建时空图，将所有特征整合到一个输入中\"\"\"\n",
    "    print(f\"\\n▶ Started building spatiotemporal graphs\")\n",
    "    print(f\"▷ Total models to process: {len(df['model_name'].unique())}\")\n",
    "    graphs = []\n",
    "    \n",
    "    # 修正：添加 lytyp 字段的类型定义\n",
    "    df = df.astype({\n",
    "        'x': np.float32, 'y': np.float32, 'top': np.float32, \n",
    "        'bottom': np.float32, 'K': np.float32, 'recharge': np.float32,\n",
    "        'ET': np.float32, 'river_stage': np.float32, 'river_cond': np.float32,\n",
    "        'river_rbot': np.float32, 'well_rate': np.float32, 'well_mask': np.uint8,\n",
    "        'chd_mask': np.uint8, 'lytyp': np.uint8, 'head': np.float32, \n",
    "        'concentration': np.float32,'conc_mask': np.uint8\n",
    "    })\n",
    "    \n",
    "    time_min = df['time_step'].min()\n",
    "    df['time_step'] = df['time_step'] - time_min\n",
    "    \n",
    "    model_groups = list(df.groupby('model_name', sort=False))\n",
    "    total_models = len(model_groups)\n",
    "    \n",
    "    for model_idx, (model_name, model_df) in enumerate(model_groups, 1):\n",
    "        model_df = model_df.reset_index(drop=True).copy()\n",
    "        model_df['local_index'] = model_df.index\n",
    "        print(f\"\\n▣ Processing model {model_idx}/{total_models}: {model_name}\")\n",
    "        \n",
    "        model_df = model_df.sort_values(['row', 'col', 'time_step'])\n",
    "        \n",
    "        # 基础特征列（14维）\n",
    "        feature_cols = [\n",
    "            'x', 'y', 'top', 'bottom', 'K', 'recharge', 'ET',\n",
    "            'river_stage', 'river_cond', 'river_rbot', 'well_rate', 'well_mask',\n",
    "            'chd_mask', 'lytyp'\n",
    "        ]\n",
    "        node_feats = model_df[feature_cols].values.astype(np.float32)\n",
    "        col_types = df[feature_cols].dtypes.to_dict()\n",
    "        float_indices = [i for i, col in enumerate(feature_cols) if col_types[col] != np.uint8]\n",
    "        float_feats = node_feats[:, float_indices]\n",
    "        scaler = StandardScaler()\n",
    "        float_feats_scaled = scaler.fit_transform(float_feats)\n",
    "        node_feats[:, float_indices] = float_feats_scaled\n",
    "        conc_feature_cols = [\n",
    "            'x', 'y', 'top', 'bottom', 'K', 'recharge', 'ET',\n",
    "            'river_stage', 'river_cond', 'river_rbot', 'well_rate', 'well_mask',\n",
    "            'chd_mask', 'lytyp','conc_mask'\n",
    "        ]\n",
    "        conc_node_feats = model_df[conc_feature_cols].values.astype(np.float32)\n",
    "        col_types = df[conc_feature_cols].dtypes.to_dict()\n",
    "        float_indices = [i for i, col in enumerate(conc_feature_cols) if col_types[col] != np.uint8]\n",
    "        conc_float_feats = conc_node_feats[:, float_indices]\n",
    "        scaler = StandardScaler()\n",
    "        conc_float_feats_scaled = scaler.fit_transform(conc_float_feats)\n",
    "        conc_node_feats[:, float_indices] = conc_float_feats_scaled\n",
    "        # 计算前一时间步和前两个时间步的水头和浓度\n",
    "        prev_head = np.zeros(len(model_df), dtype=np.float32)\n",
    "        prev2_head = np.zeros(len(model_df), dtype=np.float32)\n",
    "        prev_conc = np.zeros(len(model_df), dtype=np.float32)\n",
    "        prev2_conc = np.zeros(len(model_df), dtype=np.float32)\n",
    "        \n",
    "        groups = model_df.groupby(['row', 'col'], sort=False)\n",
    "        for (row, col), group in groups:\n",
    "            time_series = group.sort_values('time_step')\n",
    "            prev_head[time_series.index] = np.roll(time_series['head'].values, 1)\n",
    "            prev2_head[time_series.index] = np.roll(time_series['head'].values, 2)\n",
    "            prev_conc[time_series.index] = np.roll(time_series['concentration'].values, 1)\n",
    "            prev2_conc[time_series.index] = np.roll(time_series['concentration'].values, 2)\n",
    "            \n",
    "            first_idx = time_series.index[0]\n",
    "            if len(time_series) > 1:\n",
    "                second_idx = time_series.index[1]\n",
    "                # 水头特征处理\n",
    "                prev_head[first_idx] = time_series['head'].values[0]\n",
    "                prev2_head[first_idx] = time_series['head'].values[0]\n",
    "                prev2_head[second_idx] = time_series['head'].values[0]\n",
    "                \n",
    "                # 浓度特征处理\n",
    "                prev_conc[first_idx] = time_series['concentration'].values[0]\n",
    "                prev2_conc[first_idx] = time_series['concentration'].values[0]\n",
    "                prev2_conc[second_idx] = time_series['concentration'].values[0]\n",
    "            else:\n",
    "                prev_head[first_idx] = 0.0\n",
    "                prev2_head[first_idx] = 0.0\n",
    "                prev_conc[first_idx] = 0.0\n",
    "                prev2_conc[first_idx] = 0.0\n",
    "\n",
    "        # 为水头模型：基础特征 + 前一/前二时间步水头（16维）\n",
    "        head_feats = np.concatenate([\n",
    "            node_feats,           # 14维基础特征\n",
    "            prev_head[:, None],   # 1维前一时间步水头\n",
    "            prev2_head[:, None]   # 1维前二时间步水头\n",
    "        ], axis=1)\n",
    "        \n",
    "        # 为浓度模型：基础特征 + 前一/前二时间步水头 + 前一/前二时间步浓度（18维）\n",
    "        conc_feats = np.concatenate([\n",
    "            conc_node_feats,           # 14维基础特征\n",
    "            prev_head[:, None],   # 1维前一时间步水头\n",
    "            prev2_head[:, None],  # 1维前二时间步水头\n",
    "            prev_conc[:, None],   # 1维前一时间步浓度\n",
    "            prev2_conc[:, None]   # 1维前二时间步浓度\n",
    "        ], axis=1)\n",
    "        \n",
    "        if np.any(np.isnan(head_feats)) or np.any(np.isinf(head_feats)):\n",
    "            print(f\"Warning: head_feats contains NaN or Inf for model {model_name}\")\n",
    "            head_feats = np.nan_to_num(head_feats, nan=0.0, posinf=1e6, neginf=-1e6)\n",
    "        \n",
    "        if np.any(np.isnan(conc_feats)) or np.any(np.isinf(conc_feats)):\n",
    "            print(f\"Warning: conc_feats contains NaN or Inf for model {model_name}\")\n",
    "            conc_feats = np.nan_to_num(conc_feats, nan=0.0, posinf=1e6, neginf=-1e6)\n",
    "        \n",
    "        conc = model_df['concentration'].values.astype(np.float32)\n",
    "        head = model_df['head'].values.astype(np.float32)\n",
    "        spatial_edges, spatial_attrs = generate_spatial_edges(model_df)\n",
    "        temporal_edges, temporal_attrs = generate_temporal_edges(model_df)\n",
    "        edges = np.concatenate([spatial_edges, temporal_edges], axis=0)\n",
    "        edge_attr = np.concatenate([spatial_attrs, temporal_attrs], axis=0)\n",
    "        bc_mask = build_bc_mask(model_df)\n",
    "        \n",
    "        assert bc_mask.shape == (len(model_df), 5), \\\n",
    "            f\"Invalid bc_mask shape: {bc_mask.shape} for model {model_name}\"\n",
    "        \n",
    "        graph = Data(\n",
    "            x=torch.from_numpy(head_feats),      # 水头模型特征（16维）\n",
    "            conc_x=torch.from_numpy(conc_feats), # 浓度模型特征（18维）\n",
    "            edge_index=torch.tensor(edges.T, dtype=torch.long),\n",
    "            edge_attr=torch.from_numpy(edge_attr),\n",
    "            y=torch.from_numpy(conc),\n",
    "            head_y=torch.from_numpy(head),\n",
    "            bc_mask=torch.from_numpy(bc_mask),\n",
    "            time_step=torch.from_numpy(model_df['time_step'].values).long(),\n",
    "            time_steps=model_df['time_step'].nunique(),\n",
    "            model_name=str(model_name),\n",
    "            row=torch.from_numpy(model_df['row'].values).long(),\n",
    "            col=torch.from_numpy(model_df['col'].values).long(),\n",
    "        )\n",
    "        graphs.append(graph)\n",
    "    \n",
    "    print(f\"\\n✅ All models processed! Total graphs created: {len(graphs):,}\")\n",
    "    return graphs\n",
    "\n",
    "\n",
    "def prepare_data(data, batch_size=4):\n",
    "    \"\"\"准备数据加载器\"\"\"\n",
    "    print('正在处理数据...')\n",
    "    all_graphs = build_spatiotemporal_graph(data)\n",
    "    print('数据处理完成！')\n",
    "    train_graphs, val_graphs = train_test_split(\n",
    "        all_graphs, test_size=0.3, random_state=42\n",
    "    )\n",
    "    train_dataset = HydroDataset(train_graphs)\n",
    "    val_dataset = HydroDataset(val_graphs)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "# Training configuration\n",
    "config = {\n",
    "    'head_input_dim': 16,\n",
    "    'conc_input_dim': 19,\n",
    "    'hidden_dim': 96,  # 增大隐藏维度\n",
    "    'num_epochs': 500,\n",
    "    'lr': 1e-3,  # 降低学习率以提高稳定性\n",
    "    'weight_decay': 1e-4,\n",
    "    'patience': 30,\n",
    "    'save_path': './saved_models/blitz_bayesian_gnn_dual_guass',\n",
    "    'mc_samples': 10,\n",
    "    'head_prior_sigma_1': 0.01,  # Blitz先验参数\n",
    "    'head_prior_sigma_2': 0.002,\n",
    "    'conc_prior_sigma_1': 0.05,  # 浓度模型使用较小的先验\n",
    "    'conc_prior_sigma_2': 0.002,\n",
    "    'kl_weight': 1e-4  # Blitz中的KL散度权重\n",
    "}\n",
    "\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    \"\"\"计算评估指标\"\"\"\n",
    "    if isinstance(y_true, torch.Tensor):\n",
    "        y_true = y_true.detach().cpu().numpy()\n",
    "    if isinstance(y_pred, torch.Tensor):\n",
    "        y_pred = y_pred.detach().cpu().numpy()\n",
    "\n",
    "    y_true = y_true.flatten()\n",
    "    y_pred = y_pred.flatten()\n",
    "\n",
    "    mask = ~np.isnan(y_true) & ~np.isinf(y_true) & ~np.isnan(y_pred) & ~np.isinf(y_pred)\n",
    "    y_true = y_true[mask]\n",
    "    y_pred = y_pred[mask]\n",
    "\n",
    "    mse = np.mean((y_true - y_pred) ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "    r2 = sklearn_r2_score(y_true, y_pred)\n",
    "\n",
    "    return {\n",
    "        'mse': mse,\n",
    "        'rmse': rmse,\n",
    "        'mae': mae,\n",
    "        'r2': r2\n",
    "    }\n",
    "\n",
    "def compute_uncertainty(model, data, mc_samples=10):\n",
    "    \"\"\"\n",
    "    为Blitz模型计算预测和不确定性\n",
    "    \"\"\"\n",
    "    model.train()  # Blitz在训练模式下采样权重\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(mc_samples):\n",
    "            pred = model(data)\n",
    "            predictions.append(pred)\n",
    "    \n",
    "    predictions = torch.stack(predictions, dim=0)\n",
    "    mean_pred = predictions.mean(dim=0)\n",
    "    std_pred = predictions.std(dim=0)\n",
    "    \n",
    "    return mean_pred, std_pred\n",
    "\n",
    "def compute_feature_shap_values_improved(model, data, n_samples=20, num_samples=10):\n",
    "    \"\"\"\n",
    "    计算模型对输入特征的重要性，使用Blitz贝叶斯网络\n",
    "    \"\"\"\n",
    "    model.train()  # 使用训练模式以启用贝叶斯采样\n",
    "    data = data.to(next(model.parameters()).device)\n",
    "    \n",
    "    print(f\"[FeatureSHAP] 开始特征重要性分析，抽样{n_samples}个节点...\")\n",
    "    \n",
    "    # 确保数据有必要的属性\n",
    "    if not hasattr(data, 'x') or not torch.is_tensor(data.x):\n",
    "        print(\"[FeatureSHAP] 错误: 数据缺少节点特征 (data.x)\")\n",
    "        return None, 0.0\n",
    "    \n",
    "    try:\n",
    "        # 获取当前时间步的节点\n",
    "        current_time_step = data.time_step.unique()[0].item() if hasattr(data, 'time_step') else 0\n",
    "        time_mask = data.time_step == current_time_step if hasattr(data, 'time_step') else torch.ones(data.num_nodes, dtype=torch.bool, device=data.x.device)\n",
    "        candidate_nodes = torch.where(time_mask)[0]\n",
    "        \n",
    "        if len(candidate_nodes) == 0:\n",
    "            print(\"[FeatureSHAP] 错误: 找不到满足条件的节点\")\n",
    "            return None, 0.0\n",
    "        \n",
    "        # 调整样本数\n",
    "        actual_n_samples = min(n_samples, len(candidate_nodes))\n",
    "        if actual_n_samples < n_samples:\n",
    "            print(f\"[FeatureSHAP] 警告: 候选节点数({len(candidate_nodes)})少于请求的样本数({n_samples})，调整为{actual_n_samples}\")\n",
    "        \n",
    "        # 随机抽样节点\n",
    "        sampled_indices = torch.randperm(len(candidate_nodes))[:actual_n_samples]\n",
    "        sampled_nodes = candidate_nodes[sampled_indices]\n",
    "        \n",
    "        # 特征数量\n",
    "        num_features = data.x.size(1)\n",
    "        \n",
    "        # 初始化SHAP值存储\n",
    "        all_shap_values = torch.zeros(actual_n_samples, num_features, device=data.x.device)\n",
    "        all_expected_values = torch.zeros(actual_n_samples, device=data.x.device)\n",
    "        \n",
    "        # 生成基准预测\n",
    "        baseline_preds = []\n",
    "        for _ in range(num_samples):\n",
    "            with torch.no_grad():\n",
    "                pred = model(data)\n",
    "                baseline_preds.append(pred)\n",
    "        baseline_pred = torch.stack(baseline_preds, dim=0).mean(dim=0)\n",
    "        \n",
    "        # 对每个抽样节点计算特征重要性\n",
    "        for i, node_idx in enumerate(sampled_nodes):\n",
    "            node_idx = node_idx.item()\n",
    "            original_value = baseline_pred[node_idx].item()\n",
    "            all_expected_values[i] = original_value\n",
    "            \n",
    "            # 对每个特征计算重要性\n",
    "            for feat_idx in range(num_features):\n",
    "                # 保存原始特征值\n",
    "                original_feat = data.x[:, feat_idx].clone()\n",
    "                \n",
    "                # 计算特征的平均值\n",
    "                feat_mean = original_feat.mean()\n",
    "                \n",
    "                # 掩码该特征（使用平均值替换）\n",
    "                data.x[:, feat_idx] = feat_mean\n",
    "                \n",
    "                # 蒙特卡洛采样以获取更稳定的结果\n",
    "                masked_preds = []\n",
    "                for _ in range(num_samples):\n",
    "                    with torch.no_grad():\n",
    "                        masked_pred = model(data)\n",
    "                        masked_preds.append(masked_pred)\n",
    "                \n",
    "                # 计算掩码后的平均预测\n",
    "                masked_pred = torch.stack(masked_preds, dim=0).mean(dim=0)\n",
    "                \n",
    "                # 计算特征重要性（原始预测与掩码后预测的差异）\n",
    "                shap_value = abs(original_value - masked_pred[node_idx].item())\n",
    "                all_shap_values[i, feat_idx] = shap_value\n",
    "                \n",
    "                # 恢复原始特征值\n",
    "                data.x[:, feat_idx] = original_feat\n",
    "            \n",
    "            # 每5个节点输出一次进度\n",
    "            if (i + 1) % 5 == 0 or i == len(sampled_nodes) - 1:\n",
    "                print(f\"[FeatureSHAP] 已完成 {i+1}/{len(sampled_nodes)} 个节点的分析\")\n",
    "        \n",
    "        # 计算平均SHAP值\n",
    "        avg_shap_values = all_shap_values.mean(dim=0)\n",
    "        avg_expected_value = all_expected_values.mean().item()\n",
    "        \n",
    "        # 归一化SHAP值\n",
    "        if avg_shap_values.sum() > 0:\n",
    "            avg_shap_values = avg_shap_values / avg_shap_values.sum()\n",
    "        \n",
    "        print(\"[FeatureSHAP] 特征重要性分析完成\")\n",
    "        return avg_shap_values.cpu().numpy(), avg_expected_value\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"[FeatureSHAP] 特征重要性分析出错: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, 0.0\n",
    "# 为Blitz的sample_elbo函数创建适配器损失函数\n",
    "class BlitzHeadLossAdapter(nn.Module):\n",
    "    def __init__(self, base_criterion, data, kl_weight=1e-4):\n",
    "        super().__init__()\n",
    "        self.base_criterion = base_criterion\n",
    "        self.data = data  # 保存数据对象\n",
    "        self.kl_weight = kl_weight\n",
    "    \n",
    "    def forward(self, pred, labels):\n",
    "        # 调用原始损失函数，但传入完整的data对象\n",
    "        loss, _ = self.base_criterion(pred, self.data)\n",
    "        return loss\n",
    "\n",
    "class BlitzConcLossAdapter(nn.Module):\n",
    "    def __init__(self, base_criterion, data, kl_weight=5e-5):\n",
    "        super().__init__()\n",
    "        self.base_criterion = base_criterion\n",
    "        self.data = data  # 保存数据对象\n",
    "        self.kl_weight = kl_weight\n",
    "    \n",
    "    def forward(self, pred, labels):\n",
    "        # 调用原始损失函数，但传入完整的data对象\n",
    "        loss, _ = self.base_criterion(pred, self.data)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b9c6b21-5934-4b67-a39a-17292d00b3bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_dual_model_improved(train_loader, val_loader, evaluation_criterion='r2'):\n",
    "    \"\"\"\n",
    "    改进的双模型训练，同时保存基于损失和R2的最佳模型\n",
    "    \n",
    "    Args:\n",
    "        train_loader: 训练数据加载器\n",
    "        val_loader: 验证数据加载器\n",
    "        evaluation_criterion: 最终评估使用的标准 ('loss' 或 'r2')\n",
    "    \"\"\"\n",
    "    try:\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"CUDA缓存已成功清除\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"无法清除CUDA缓存: {e}\")\n",
    "        return None, None, None\n",
    "    \n",
    "    # ===============================\n",
    "    # 第一阶段：训练水头模型\n",
    "    # ===============================\n",
    "    print(\"=\" * 80)\n",
    "    print(\"第一阶段：开始训练水头模型\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 根据实际数据更新特征维度\n",
    "    head_input_dim = 16  # 14个基本特征 + 2个前一时间步的水头\n",
    "    \n",
    "    # 初始化水头模型\n",
    "    head_model = BlitzHeadGNN(\n",
    "        node_features=head_input_dim,\n",
    "        spatial_dim=config['hidden_dim'],\n",
    "        temporal_dim=config['hidden_dim'],\n",
    "        prior_sigma_1=config['head_prior_sigma_1'],\n",
    "        prior_sigma_2=config['head_prior_sigma_2'],\n",
    "        dropout=0.1\n",
    "    ).to(device)\n",
    "    \n",
    "    # 损失函数 - 只需要水头损失\n",
    "    criterion_head = ImprovedPhysicsInformedLoss(alpha=0.1, kl_weight=config['kl_weight'])\n",
    "    \n",
    "    # 优化器 - 只优化水头模型参数\n",
    "    head_params = list(head_model.parameters())\n",
    "    head_optimizer = torch.optim.AdamW(head_params, lr=config['lr'], weight_decay=config['weight_decay'])\n",
    "    \n",
    "    # 学习率调度器\n",
    "    head_scheduler = CosineAnnealingWarmRestarts(\n",
    "        head_optimizer, T_0=20, T_mult=2, eta_min=1e-5\n",
    "    )\n",
    "    \n",
    "    # 跟踪变量 - 分别跟踪损失和R2\n",
    "    best_head_val_loss = float('inf')\n",
    "    best_head_r2 = float('-inf')\n",
    "    head_early_stop_counter = 0\n",
    "    head_losses = {'train': [], 'val': []}\n",
    "    \n",
    "    # 创建保存目录\n",
    "    os.makedirs(config['save_path'], exist_ok=True)\n",
    "    \n",
    "    print(\"开始训练水头模型\")\n",
    "    print(f\"水头模型参数数量: {sum(p.numel() for p in head_model.parameters() if p.requires_grad)}\")\n",
    "    \n",
    "    # 水头模型训练循环\n",
    "    for epoch in range(config['num_epochs']):\n",
    "        head_model.train()\n",
    "        train_loss = 0.0\n",
    "        train_batches = 0\n",
    "        \n",
    "        # 训练阶段\n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            try:\n",
    "                # 准备数据\n",
    "                batch = batch.to(device)\n",
    "                if hasattr(batch, 'edge_attr') and batch.edge_attr is not None:\n",
    "                    batch.edge_attr = batch.edge_attr.float()\n",
    "                \n",
    "                # 重置梯度\n",
    "                head_optimizer.zero_grad()\n",
    "                \n",
    "                # 前向传播\n",
    "                pred_head = head_model(batch)\n",
    "                \n",
    "                # 计算损失\n",
    "                criterion_output = criterion_head(pred_head, batch)\n",
    "                \n",
    "                # 处理损失函数的返回值\n",
    "                if isinstance(criterion_output, tuple):\n",
    "                    head_criterion_loss = criterion_output[0]\n",
    "                    if len(criterion_output) > 1:\n",
    "                        physics_loss = criterion_output[1]\n",
    "                        if isinstance(physics_loss, tuple):\n",
    "                            physics_loss_value = sum([p.item() if hasattr(p, 'item') else p for p in physics_loss])\n",
    "                        else:\n",
    "                            physics_loss_value = physics_loss.item() if hasattr(physics_loss, 'item') else physics_loss\n",
    "                    else:\n",
    "                        physics_loss_value = 0.0\n",
    "                else:\n",
    "                    head_criterion_loss = criterion_output\n",
    "                    physics_loss_value = 0.0\n",
    "                \n",
    "                kl_loss = head_model.nn_kl_divergence() * config['kl_weight']\n",
    "                total_loss = head_criterion_loss + kl_loss\n",
    "                \n",
    "                # 反向传播\n",
    "                total_loss.backward()\n",
    "                \n",
    "                # 梯度裁剪\n",
    "                torch.nn.utils.clip_grad_norm_(head_params, max_norm=1.0)\n",
    "                \n",
    "                # 更新参数\n",
    "                head_optimizer.step()\n",
    "                \n",
    "                # 记录损失\n",
    "                train_loss += total_loss.item()\n",
    "                train_batches += 1\n",
    "                \n",
    "                # 每50个批次输出一次详细信息\n",
    "                if batch_idx % 50 == 0:\n",
    "                    print(f\"水头模型 Epoch {epoch+1}, Batch {batch_idx}: \"\n",
    "                          f\"Total Loss: {total_loss.item():.4f}, \"\n",
    "                          f\"Criterion Loss: {head_criterion_loss.item():.4f}, \"\n",
    "                          f\"Physics Loss: {physics_loss_value:.4f}, \"\n",
    "                          f\"KL Loss: {kl_loss.item():.4f}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"水头模型训练批次 {batch_idx} 出错: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # 检查训练批次\n",
    "        if train_batches == 0:\n",
    "            print(\"警告: 水头模型本轮训练没有成功处理任何批次，跳过本轮\")\n",
    "            continue\n",
    "            \n",
    "        # 计算平均训练损失\n",
    "        avg_train_loss = train_loss / train_batches\n",
    "        \n",
    "        # 验证阶段\n",
    "        head_model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_metrics = {'mse': 0.0, 'rmse': 0.0, 'mae': 0.0, 'r2': 0.0}\n",
    "        val_batches = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch in enumerate(val_loader):\n",
    "                try:\n",
    "                    # 准备数据\n",
    "                    batch = batch.to(device)\n",
    "                    if hasattr(batch, 'edge_attr') and batch.edge_attr is not None:\n",
    "                        batch.edge_attr = batch.edge_attr.float()\n",
    "                    \n",
    "                    # 使用不确定性估计进行预测\n",
    "                    head_model.train()  # 开启dropout进行MC采样\n",
    "                    pred_head, head_std = compute_uncertainty(head_model, batch, mc_samples=config['mc_samples'])\n",
    "                    \n",
    "                    # 计算验证损失\n",
    "                    criterion_output = criterion_head(pred_head, batch)\n",
    "                    \n",
    "                    # 处理损失函数的返回值\n",
    "                    if isinstance(criterion_output, tuple):\n",
    "                        head_criterion_loss = criterion_output[0]\n",
    "                    else:\n",
    "                        head_criterion_loss = criterion_output\n",
    "                    \n",
    "                    # 计算指标\n",
    "                    metrics = compute_metrics(batch.head_y, pred_head)\n",
    "                    \n",
    "                    for k in metrics:\n",
    "                        val_metrics[k] += metrics[k]\n",
    "                    \n",
    "                    val_loss += head_criterion_loss.item()\n",
    "                    val_batches += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"水头模型验证批次 {batch_idx} 出错: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        # 计算平均验证损失和指标\n",
    "        if val_batches > 0:\n",
    "            avg_val_loss = val_loss / val_batches\n",
    "            for k in val_metrics:\n",
    "                val_metrics[k] /= val_batches\n",
    "        else:\n",
    "            print(\"警告: 水头模型本轮验证没有成功处理任何批次\")\n",
    "            avg_val_loss = float('inf')\n",
    "        \n",
    "        # 记录损失\n",
    "        head_losses['train'].append(avg_train_loss)\n",
    "        head_losses['val'].append({\n",
    "            'loss': avg_val_loss,\n",
    "            'metrics': val_metrics\n",
    "        })\n",
    "        \n",
    "        # 更新学习率\n",
    "        head_scheduler.step()\n",
    "        current_lr = head_scheduler.get_last_lr()[0]\n",
    "        \n",
    "        # 输出训练状态\n",
    "        print(f\"水头模型 Epoch {epoch+1:03d}/{config['num_epochs']} | \"\n",
    "              f\"训练损失: {avg_train_loss:.4f} | 验证损失: {avg_val_loss:.4f} | \"\n",
    "              f\"LR: {current_lr:.6f}\")\n",
    "        print(f\"水头验证指标 - MSE: {val_metrics['mse']:.4f}, \"\n",
    "              f\"RMSE: {val_metrics['rmse']:.4f}, \"\n",
    "              f\"MAE: {val_metrics['mae']:.4f}, \"\n",
    "              f\"R2: {val_metrics['r2']:.4f}\")\n",
    "        \n",
    "        # 保存基于损失的最佳模型\n",
    "        if avg_val_loss < best_head_val_loss:\n",
    "            best_head_val_loss = avg_val_loss\n",
    "            try:\n",
    "                torch.save({\n",
    "                    'model_state_dict': head_model.state_dict(),\n",
    "                    'epoch': epoch,\n",
    "                    'train_loss': avg_train_loss,\n",
    "                    'val_loss': avg_val_loss,\n",
    "                    'val_metrics': val_metrics,\n",
    "                    'config': config,\n",
    "                    'criterion': 'loss'\n",
    "                }, os.path.join(config['save_path'], 'best_head_model_loss.pth'))\n",
    "                print(f\"保存基于损失的最佳水头模型，验证损失: {best_head_val_loss:.4f}\")\n",
    "            except Exception as e:\n",
    "                print(f\"保存水头模型失败: {e}\")\n",
    "        \n",
    "        # 保存基于R2的最佳模型\n",
    "        if val_metrics['r2'] > best_head_r2:\n",
    "            best_head_r2 = val_metrics['r2']\n",
    "            head_early_stop_counter = 0  # 基于R2重置早停计数器\n",
    "            try:\n",
    "                torch.save({\n",
    "                    'model_state_dict': head_model.state_dict(),\n",
    "                    'epoch': epoch,\n",
    "                    'train_loss': avg_train_loss,\n",
    "                    'val_loss': avg_val_loss,\n",
    "                    'val_metrics': val_metrics,\n",
    "                    'config': config,\n",
    "                    'criterion': 'r2'\n",
    "                }, os.path.join(config['save_path'], 'best_head_model_r2.pth'))\n",
    "                print(f\"保存基于R2的最佳水头模型，R2: {best_head_r2:.4f}\")\n",
    "            except Exception as e:\n",
    "                print(f\"保存水头模型失败: {e}\")\n",
    "        else:\n",
    "            head_early_stop_counter += 1\n",
    "        \n",
    "        # 早停检查（基于R2）\n",
    "        if head_early_stop_counter >= config['patience']:\n",
    "            print(f\"水头模型早停触发! 在第{epoch+1}个epoch停止训练\")\n",
    "            break\n",
    "        \n",
    "        # 清理GPU内存\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"\\n水头模型训练完成!\")\n",
    "    print(f\"基于损失的最佳验证损失: {best_head_val_loss:.4f}\")\n",
    "    print(f\"基于R2的最佳R2分数: {best_head_r2:.4f}\")\n",
    "    \n",
    "    # ===============================\n",
    "    # 第二阶段：训练浓度模型\n",
    "    # ===============================\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"第二阶段：开始训练浓度模型\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 根据评估标准选择水头模型\n",
    "    head_model_file = f'best_head_model_{evaluation_criterion}.pth'\n",
    "    try:\n",
    "        checkpoint = torch.load(os.path.join(config['save_path'], head_model_file),weights_only=False)\n",
    "        head_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        print(f\"成功加载基于{evaluation_criterion}的最佳水头模型\")\n",
    "    except Exception as e:\n",
    "        print(f\"加载水头模型失败，使用当前模型: {e}\")\n",
    "    \n",
    "    # 固定水头模型参数\n",
    "    for param in head_model.parameters():\n",
    "        param.requires_grad = False\n",
    "    head_model.eval()\n",
    "    \n",
    "    # 初始化浓度模型\n",
    "    conc_input_dim = 19  # 基础特征14 + 前一/前二时间步水头2 + 前一/前二时间步浓度2\n",
    "    conc_model = BlitzConcGNN(\n",
    "        node_features=conc_input_dim,  # 18维\n",
    "        spatial_dim=config['hidden_dim'],\n",
    "        temporal_dim=config['hidden_dim'],\n",
    "        prior_sigma_1=0.1,\n",
    "        prior_sigma_2=0.01,\n",
    "        dropout=0.1,\n",
    "        posterior_mu_init=0.0,\n",
    "        posterior_rho_init=-3.0\n",
    "    ).to(device)\n",
    "    \n",
    "    # 浓度模型损失函数\n",
    "    criterion_conc = ImprovedConcLoss(kl_weight=config['kl_weight'], l1_weight=1e-5)\n",
    "    \n",
    "    # 浓度模型优化器\n",
    "    conc_params = list(conc_model.parameters())\n",
    "    conc_optimizer = torch.optim.AdamW(conc_params, lr=config['lr'] * 0.8, weight_decay=config['weight_decay'])\n",
    "    \n",
    "    # 浓度模型学习率调度器\n",
    "    conc_scheduler = CosineAnnealingWarmRestarts(\n",
    "        conc_optimizer, T_0=15, T_mult=2, eta_min=1e-6\n",
    "    )\n",
    "    \n",
    "    # 浓度模型跟踪变量 - 分别跟踪损失和R2\n",
    "    best_conc_val_loss = float('inf')\n",
    "    best_conc_r2 = float('-inf')\n",
    "    conc_early_stop_counter = 0\n",
    "    conc_losses = {'train': [], 'val': []}\n",
    "    \n",
    "    print(f\"浓度模型参数数量: {sum(p.numel() for p in conc_model.parameters() if p.requires_grad)}\")\n",
    "    \n",
    "    # 浓度模型训练循环\n",
    "    for epoch in range(config['num_epochs']):\n",
    "        conc_model.train()\n",
    "        train_loss = 0.0\n",
    "        train_batches = 0\n",
    "        \n",
    "        # 训练阶段\n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            try:\n",
    "                # 准备数据\n",
    "                batch = batch.to(device)\n",
    "                if hasattr(batch, 'edge_attr') and batch.edge_attr is not None:\n",
    "                    batch.edge_attr = batch.edge_attr.float()\n",
    "                \n",
    "                # 使用固定的水头模型预测水头\n",
    "                with torch.no_grad():\n",
    "                    pred_head = head_model(batch)\n",
    "                \n",
    "                # 重置梯度\n",
    "                conc_optimizer.zero_grad()\n",
    "                \n",
    "                # 浓度模型前向传播，使用预测的水头\n",
    "                pred_conc = conc_model(batch, pred_head)\n",
    "                \n",
    "                # 计算损失\n",
    "                criterion_output = criterion_conc(pred_conc, batch, conc_model)\n",
    "                \n",
    "                # 处理损失函数的返回值\n",
    "                if isinstance(criterion_output, tuple):\n",
    "                    conc_criterion_loss = criterion_output[0]\n",
    "                    if len(criterion_output) > 1:\n",
    "                        loss_components = criterion_output[1]\n",
    "                        if isinstance(loss_components, tuple) and len(loss_components) >= 3:\n",
    "                            mse_loss, kl_loss_val, l1_reg = loss_components[:3]\n",
    "                        else:\n",
    "                            mse_loss, kl_loss_val, l1_reg = 0.0, 0.0, 0.0\n",
    "                    else:\n",
    "                        mse_loss, kl_loss_val, l1_reg = 0.0, 0.0, 0.0\n",
    "                else:\n",
    "                    conc_criterion_loss = criterion_output\n",
    "                    mse_loss, kl_loss_val, l1_reg = 0.0, 0.0, 0.0\n",
    "                \n",
    "                kl_loss = conc_model.nn_kl_divergence() * config['kl_weight']\n",
    "                total_loss = conc_criterion_loss + kl_loss\n",
    "                \n",
    "                # 反向传播\n",
    "                total_loss.backward()\n",
    "                \n",
    "                # 梯度裁剪\n",
    "                torch.nn.utils.clip_grad_norm_(conc_params, max_norm=1.0)\n",
    "                \n",
    "                # 更新参数\n",
    "                conc_optimizer.step()\n",
    "                \n",
    "                # 记录损失\n",
    "                train_loss += total_loss.item()\n",
    "                train_batches += 1\n",
    "                \n",
    "                # 每50个批次输出一次详细信息\n",
    "                if batch_idx % 50 == 0:\n",
    "                    print(f\"浓度模型 Epoch {epoch+1}, Batch {batch_idx}: \"\n",
    "                          f\"Total Loss: {total_loss.item():.4f}, \"\n",
    "                          f\"Criterion Loss: {conc_criterion_loss.item():.4f}, \"\n",
    "                          f\"MSE: {mse_loss:.4f}, \"\n",
    "                          f\"KL Loss: {kl_loss.item():.4f}, \"\n",
    "                          f\"L1 Reg: {l1_reg:.4f}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"浓度模型训练批次 {batch_idx} 出错: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # 检查训练批次\n",
    "        if train_batches == 0:\n",
    "            print(\"警告: 浓度模型本轮训练没有成功处理任何批次，跳过本轮\")\n",
    "            continue\n",
    "            \n",
    "        # 计算平均训练损失\n",
    "        avg_train_loss = train_loss / train_batches\n",
    "        \n",
    "        # 验证阶段\n",
    "        conc_model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_metrics = {'mse': 0.0, 'rmse': 0.0, 'mae': 0.0, 'r2': 0.0}\n",
    "        val_batches = 0\n",
    "        \n",
    "        # 用于存储预测和真实值\n",
    "        all_conc_predictions = []\n",
    "        all_conc_targets = []\n",
    "        all_conc_uncertainties = []\n",
    "        all_head_predictions = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch in enumerate(val_loader):\n",
    "                try:\n",
    "                    # 准备数据\n",
    "                    batch = batch.to(device)\n",
    "                    if hasattr(batch, 'edge_attr') and batch.edge_attr is not None:\n",
    "                        batch.edge_attr = batch.edge_attr.float()\n",
    "                    \n",
    "                    # 使用水头模型预测水头\n",
    "                    pred_head = head_model(batch)\n",
    "                    \n",
    "                    # 使用不确定性估计进行浓度预测\n",
    "                    conc_model.train()  # 开启dropout进行MC采样\n",
    "                    pred_conc, conc_std = compute_uncertainty(conc_model, batch, mc_samples=config['mc_samples'])\n",
    "                    \n",
    "                    # 计算验证损失\n",
    "                    criterion_output = criterion_conc(pred_conc, batch, conc_model)\n",
    "                    \n",
    "                    # 处理损失函数的返回值\n",
    "                    if isinstance(criterion_output, tuple):\n",
    "                        conc_criterion_loss = criterion_output[0]\n",
    "                    else:\n",
    "                        conc_criterion_loss = criterion_output\n",
    "                    \n",
    "                    # 计算指标\n",
    "                    metrics = compute_metrics(batch.y, pred_conc)\n",
    "                    \n",
    "                    for k in metrics:\n",
    "                        val_metrics[k] += metrics[k]\n",
    "                    \n",
    "                    val_loss += conc_criterion_loss.item()\n",
    "                    val_batches += 1\n",
    "                    \n",
    "                    # 收集预测结果用于后续分析\n",
    "                    all_conc_predictions.append(pred_conc.cpu().numpy())\n",
    "                    all_conc_targets.append(batch.y.cpu().numpy())\n",
    "                    all_conc_uncertainties.append(conc_std.cpu().numpy())\n",
    "                    all_head_predictions.append(pred_head.cpu().numpy())\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"浓度模型验证批次 {batch_idx} 出错: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        # 计算平均验证损失和指标\n",
    "        if val_batches > 0:\n",
    "            avg_val_loss = val_loss / val_batches\n",
    "            for k in val_metrics:\n",
    "                val_metrics[k] /= val_batches\n",
    "        else:\n",
    "            print(\"警告: 浓度模型本轮验证没有成功处理任何批次\")\n",
    "            avg_val_loss = float('inf')\n",
    "        \n",
    "        # 记录损失\n",
    "        conc_losses['train'].append(avg_train_loss)\n",
    "        conc_losses['val'].append({\n",
    "            'loss': avg_val_loss,\n",
    "            'metrics': val_metrics\n",
    "        })\n",
    "        \n",
    "        # 更新学习率\n",
    "        conc_scheduler.step()\n",
    "        current_lr = conc_scheduler.get_last_lr()[0]\n",
    "        \n",
    "        # 输出训练状态\n",
    "        print(f\"浓度模型 Epoch {epoch+1:03d}/{config['num_epochs']} | \"\n",
    "              f\"训练损失: {avg_train_loss:.4f} | 验证损失: {avg_val_loss:.4f} | \"\n",
    "              f\"LR: {current_lr:.6f}\")\n",
    "        print(f\"浓度验证指标 - MSE: {val_metrics['mse']:.4f}, \"\n",
    "              f\"RMSE: {val_metrics['rmse']:.4f}, \"\n",
    "              f\"MAE: {val_metrics['mae']:.4f}, \"\n",
    "              f\"R2: {val_metrics['r2']:.4f}\")\n",
    "        \n",
    "        # 保存基于损失的最佳浓度模型\n",
    "        if avg_val_loss < best_conc_val_loss:\n",
    "            best_conc_val_loss = avg_val_loss\n",
    "            try:\n",
    "                torch.save({\n",
    "                    'model_state_dict': conc_model.state_dict(),\n",
    "                    'epoch': epoch,\n",
    "                    'train_loss': avg_train_loss,\n",
    "                    'val_loss': avg_val_loss,\n",
    "                    'val_metrics': val_metrics,\n",
    "                    'config': config,\n",
    "                    'criterion': 'loss'\n",
    "                }, os.path.join(config['save_path'], 'best_conc_model_loss.pth'))\n",
    "                \n",
    "                # 保存预测结果\n",
    "                if all_conc_predictions:\n",
    "                    np.save(os.path.join(config['save_path'], 'best_conc_predictions_loss.npy'), \n",
    "                           np.concatenate(all_conc_predictions, axis=0))\n",
    "                    np.save(os.path.join(config['save_path'], 'best_conc_targets_loss.npy'), \n",
    "                           np.concatenate(all_conc_targets, axis=0))\n",
    "                    np.save(os.path.join(config['save_path'], 'best_conc_uncertainties_loss.npy'), \n",
    "                           np.concatenate(all_conc_uncertainties, axis=0))\n",
    "                \n",
    "                print(f\"保存基于损失的最佳浓度模型，验证损失: {best_conc_val_loss:.4f}\")\n",
    "            except Exception as e:\n",
    "                print(f\"保存浓度模型失败: {e}\")\n",
    "        \n",
    "        # 保存基于R2的最佳浓度模型\n",
    "        if val_metrics['r2'] > best_conc_r2:\n",
    "            best_conc_r2 = val_metrics['r2']\n",
    "            conc_early_stop_counter = 0  # 基于R2重置早停计数器\n",
    "            try:\n",
    "                torch.save({\n",
    "                    'model_state_dict': conc_model.state_dict(),\n",
    "                    'epoch': epoch,\n",
    "                    'train_loss': avg_train_loss,\n",
    "                    'val_loss': avg_val_loss,\n",
    "                    'val_metrics': val_metrics,\n",
    "                    'config': config,\n",
    "                    'criterion': 'r2'\n",
    "                }, os.path.join(config['save_path'], 'best_conc_model_r2.pth'))\n",
    "                \n",
    "                # 保存预测结果\n",
    "                if all_conc_predictions:\n",
    "                    np.save(os.path.join(config['save_path'], 'best_conc_predictions_r2.npy'), \n",
    "                           np.concatenate(all_conc_predictions, axis=0))\n",
    "                    np.save(os.path.join(config['save_path'], 'best_conc_targets_r2.npy'), \n",
    "                           np.concatenate(all_conc_targets, axis=0))\n",
    "                    np.save(os.path.join(config['save_path'], 'best_conc_uncertainties_r2.npy'), \n",
    "                           np.concatenate(all_conc_uncertainties, axis=0))\n",
    "                \n",
    "                print(f\"保存基于R2的最佳浓度模型，R2: {best_conc_r2:.4f}\")\n",
    "            except Exception as e:\n",
    "                print(f\"保存浓度模型失败: {e}\")\n",
    "        else:\n",
    "            conc_early_stop_counter += 1\n",
    "        \n",
    "        # 早停检查（基于R2）\n",
    "        if conc_early_stop_counter >= config['patience']:\n",
    "            print(f\"浓度模型早停触发! 在第{epoch+1}个epoch停止训练\")\n",
    "            break\n",
    "        \n",
    "        # 清理GPU内存\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"\\n浓度模型训练完成!\")\n",
    "    print(f\"基于损失的最佳验证损失: {best_conc_val_loss:.4f}\")\n",
    "    print(f\"基于R2的最佳R2分数: {best_conc_r2:.4f}\")\n",
    "    \n",
    "    # ===============================\n",
    "    # 保存训练历史和可视化\n",
    "    # ===============================\n",
    "    try:\n",
    "        # 保存水头模型训练历史\n",
    "        head_history_data = []\n",
    "        for i, (train_loss, val_data) in enumerate(zip(head_losses['train'], head_losses['val'])):\n",
    "            head_history_data.append({\n",
    "                'epoch': i + 1,\n",
    "                'train_loss': train_loss,\n",
    "                'val_loss': val_data['loss'],\n",
    "                'val_mse': val_data['metrics']['mse'],\n",
    "                'val_rmse': val_data['metrics']['rmse'],\n",
    "                'val_mae': val_data['metrics']['mae'],\n",
    "                'val_r2': val_data['metrics']['r2']\n",
    "            })\n",
    "        \n",
    "        if head_history_data:\n",
    "            head_history_df = pd.DataFrame(head_history_data)\n",
    "            head_history_df.to_csv(os.path.join(config['save_path'], 'head_training_history.csv'), index=False)\n",
    "        \n",
    "        # 保存浓度模型训练历史\n",
    "        conc_history_data = []\n",
    "        for i, (train_loss, val_data) in enumerate(zip(conc_losses['train'], conc_losses['val'])):\n",
    "            conc_history_data.append({\n",
    "                'epoch': i + 1,\n",
    "                'train_loss': train_loss,\n",
    "                'val_loss': val_data['loss'],\n",
    "                'val_mse': val_data['metrics']['mse'],\n",
    "                'val_rmse': val_data['metrics']['rmse'],\n",
    "                'val_mae': val_data['metrics']['mae'],\n",
    "                'val_r2': val_data['metrics']['r2']\n",
    "            })\n",
    "        \n",
    "        if conc_history_data:\n",
    "            conc_history_df = pd.DataFrame(conc_history_data)\n",
    "            conc_history_df.to_csv(os.path.join(config['save_path'], 'conc_training_history.csv'), index=False)\n",
    "        \n",
    "        # 绘制双模型训练曲线，包含最佳点标记\n",
    "        if head_history_data and conc_history_data:\n",
    "            plt.figure(figsize=(20, 12))\n",
    "            \n",
    "            # 水头模型曲线\n",
    "            plt.subplot(2, 4, 1)\n",
    "            plt.plot(head_history_df['epoch'], head_history_df['train_loss'], 'b-', label='Head Train Loss')\n",
    "            plt.plot(head_history_df['epoch'], head_history_df['val_loss'], 'r-', label='Head Val Loss')\n",
    "            # 标记最佳损失点\n",
    "            best_loss_epoch = head_history_df.loc[head_history_df['val_loss'].idxmin(), 'epoch']\n",
    "            best_loss_value = head_history_df['val_loss'].min()\n",
    "            plt.scatter(best_loss_epoch, best_loss_value, color='red', s=100, marker='*', \n",
    "                       label=f'Best Loss (E{best_loss_epoch})')\n",
    "            plt.title('Head Model: Training and Validation Loss')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            \n",
    "            plt.subplot(2, 4, 2)\n",
    "            plt.plot(head_history_df['epoch'], head_history_df['val_r2'], 'g-', label='Head R2')\n",
    "            # 标记最佳R2点\n",
    "            best_r2_epoch = head_history_df.loc[head_history_df['val_r2'].idxmax(), 'epoch']\n",
    "            best_r2_value = head_history_df['val_r2'].max()\n",
    "            plt.scatter(best_r2_epoch, best_r2_value, color='green', s=100, marker='*', \n",
    "                       label=f'Best R2 (E{best_r2_epoch})')\n",
    "            plt.title('Head Model: Validation R2 Score')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('R2')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            \n",
    "            plt.subplot(2, 4, 3)\n",
    "            plt.plot(head_history_df['epoch'], head_history_df['val_mse'], 'orange', label='Head MSE')\n",
    "            plt.title('Head Model: Validation MSE')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('MSE')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            \n",
    "            plt.subplot(2, 4, 4)\n",
    "            plt.plot(head_history_df['epoch'], head_history_df['val_rmse'], 'purple', label='Head RMSE')\n",
    "            plt.title('Head Model: Validation RMSE')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('RMSE')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            \n",
    "            # 浓度模型曲线\n",
    "            plt.subplot(2, 4, 5)\n",
    "            plt.plot(conc_history_df['epoch'], conc_history_df['train_loss'], 'b--', label='Conc Train Loss')\n",
    "            plt.plot(conc_history_df['epoch'], conc_history_df['val_loss'], 'r--', label='Conc Val Loss')\n",
    "            # 标记最佳损失点\n",
    "            best_loss_epoch = conc_history_df.loc[conc_history_df['val_loss'].idxmin(), 'epoch']\n",
    "            best_loss_value = conc_history_df['val_loss'].min()\n",
    "            plt.scatter(best_loss_epoch, best_loss_value, color='red', s=100, marker='*', \n",
    "                       label=f'Best Loss (E{best_loss_epoch})')\n",
    "            plt.title('Conc Model: Training and Validation Loss')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            \n",
    "            plt.subplot(2, 4, 6)\n",
    "            plt.plot(conc_history_df['epoch'], conc_history_df['val_r2'], 'g--', label='Conc R2')\n",
    "            # 标记最佳R2点\n",
    "            best_r2_epoch = conc_history_df.loc[conc_history_df['val_r2'].idxmax(), 'epoch']\n",
    "            best_r2_value = conc_history_df['val_r2'].max()\n",
    "            plt.scatter(best_r2_epoch, best_r2_value, color='green', s=100, marker='*', \n",
    "                       label=f'Best R2 (E{best_r2_epoch})')\n",
    "            plt.title('Conc Model: Validation R2 Score')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('R2')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            \n",
    "            plt.subplot(2, 4, 7)\n",
    "            plt.plot(conc_history_df['epoch'], conc_history_df['val_mse'], 'orange', linestyle='--', label='Conc MSE')\n",
    "            plt.title('Conc Model: Validation MSE')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('MSE')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            \n",
    "            plt.subplot(2, 4, 8)\n",
    "            plt.plot(conc_history_df['epoch'], conc_history_df['val_rmse'], 'purple', linestyle='--', label='Conc RMSE')\n",
    "            plt.title('Conc Model: Validation RMSE')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('RMSE')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(config['save_path'], 'dual_model_training_curves_improved.png'), \n",
    "                       dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            \n",
    "            print(f\"改进的双模型训练曲线已保存\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"保存训练历史或绘图失败: {e}\")\n",
    "    \n",
    "    # 重新启用水头模型的梯度计算（如果需要）\n",
    "    for param in head_model.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"双模型训练完成总结:\")\n",
    "    print(f\"水头模型 - 基于损失的最佳验证损失: {best_head_val_loss:.4f}\")\n",
    "    print(f\"水头模型 - 基于R2的最佳R2分数: {best_head_r2:.4f}\")\n",
    "    print(f\"浓度模型 - 基于损失的最佳验证损失: {best_conc_val_loss:.4f}\")\n",
    "    print(f\"浓度模型 - 基于R2的最佳R2分数: {best_conc_r2:.4f}\")\n",
    "    print(f\"评估将使用基于{evaluation_criterion}的模型\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    return head_model, conc_model, {'head': head_losses, 'conc': conc_losses}\n",
    "\n",
    "def compute_uncertainty_with_func(forward_func, data, mc_samples=30):\n",
    "    \"\"\"\n",
    "    计算模型预测的不确定性，支持自定义前向传播函数\n",
    "    \n",
    "    参数:\n",
    "        forward_func: 前向传播函数，接受data参数\n",
    "        data: 输入数据\n",
    "        mc_samples: Monte Carlo采样次数\n",
    "    \n",
    "    返回:\n",
    "        pred_mean: 预测的均值\n",
    "        pred_std: 预测的标准差（不确定性）\n",
    "    \"\"\"\n",
    "    all_preds = []\n",
    "    for _ in range(mc_samples):\n",
    "        with torch.no_grad():\n",
    "            # 使用传入的函数进行前向传播\n",
    "            pred = forward_func(data)\n",
    "            all_preds.append(pred)\n",
    "    \n",
    "    # 计算预测的均值和标准差\n",
    "    all_preds = torch.stack(all_preds, dim=0)\n",
    "    pred_mean = all_preds.mean(dim=0)\n",
    "    pred_std = all_preds.std(dim=0)\n",
    "    \n",
    "    return pred_mean, pred_std\n",
    "\n",
    "def evaluate_dual_model_improved(head_model, conc_model, val_loader, evaluation_criterion='loss'):\n",
    "    \"\"\"\n",
    "    改进的双模型评估，使用compute_uncertainty_with_func进行不确定性估计\n",
    "    \n",
    "    Args:\n",
    "        head_model: 水头预测模型\n",
    "        conc_model: 浓度预测模型\n",
    "        val_loader: 验证数据加载器\n",
    "        evaluation_criterion: 评估标准 ('loss' 或 'r2')\n",
    "    \"\"\"\n",
    "    print(f\"开始评估双模型性能（基于{evaluation_criterion}标准）...\")\n",
    "    \n",
    "    # 加载指定标准的最佳模型权重\n",
    "    try:\n",
    "        head_model_file = f'best_head_model_{evaluation_criterion}.pth'\n",
    "        head_checkpoint = torch.load(os.path.join(config['save_path'], head_model_file), weights_only=False)\n",
    "        head_model.load_state_dict(head_checkpoint['model_state_dict'])\n",
    "        \n",
    "        conc_model_file = f'best_conc_model_{evaluation_criterion}.pth'\n",
    "        conc_checkpoint = torch.load(os.path.join(config['save_path'], conc_model_file), weights_only=False)\n",
    "        conc_model.load_state_dict(conc_checkpoint['model_state_dict'])\n",
    "        \n",
    "        print(f\"成功加载基于{evaluation_criterion}的最佳模型权重\")\n",
    "        print(f\"水头模型来自epoch {head_checkpoint['epoch']}, 验证损失: {head_checkpoint['val_loss']:.4f}, R2: {head_checkpoint['val_metrics']['r2']:.4f}\")\n",
    "        print(f\"浓度模型来自epoch {conc_checkpoint['epoch']}, 验证损失: {conc_checkpoint['val_loss']:.4f}, R2: {conc_checkpoint['val_metrics']['r2']:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"加载模型权重失败，使用当前权重: {e}\")\n",
    "    \n",
    "    # 设置模型为训练模式以进行MC dropout\n",
    "    head_model.train()  \n",
    "    conc_model.train()\n",
    "    \n",
    "    # 确保结果目录存在\n",
    "    results_dir = os.path.join(config['save_path'], 'evaluation_results')\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    # 存储所有预测结果\n",
    "    all_head_preds = []\n",
    "    all_head_targets = []\n",
    "    all_head_uncertainties = []\n",
    "    all_conc_preds = []\n",
    "    all_conc_targets = []\n",
    "    all_conc_uncertainties = []\n",
    "    \n",
    "    # 存储详细预测结果\n",
    "    predictions = []\n",
    "    uncertainties = []\n",
    "    \n",
    "    # 定义前向传播函数\n",
    "    def head_forward_func(batch):\n",
    "        \"\"\"水头模型前向传播函数\"\"\"\n",
    "        return head_model(batch)\n",
    "    \n",
    "    def conc_forward_func(batch_with_head):\n",
    "        \"\"\"浓度模型前向传播函数\"\"\"\n",
    "        return conc_model(batch_with_head)\n",
    "    \n",
    "    print(\"开始处理验证数据...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(val_loader):\n",
    "            try:\n",
    "                batch = batch.to(device)\n",
    "                if hasattr(batch, 'edge_attr') and batch.edge_attr is not None:\n",
    "                    batch.edge_attr = batch.edge_attr.float()\n",
    "                \n",
    "                # 使用新的不确定性计算函数进行水头预测\n",
    "                head_pred, head_std = compute_uncertainty_with_func(\n",
    "                    head_forward_func, batch, mc_samples=config.get('mc_samples', 30)\n",
    "                )\n",
    "                \n",
    "                # 为浓度预测准备输入（包含预测的水头）\n",
    "                batch_conc = batch.clone()\n",
    "                # 假设需要将预测的水头添加到特征中\n",
    "                if hasattr(batch_conc, 'x'):\n",
    "                    # 将预测的水头添加到节点特征中\n",
    "                    batch_conc.x = torch.cat([batch.x, head_pred.detach()], dim=1)\n",
    "                else:\n",
    "                    # 如果没有x属性，创建一个包含预测水头的特征\n",
    "                    batch_conc.x = head_pred.detach()\n",
    "                \n",
    "                # 使用新的不确定性计算函数进行浓度预测\n",
    "                conc_pred, conc_std = compute_uncertainty_with_func(\n",
    "                    conc_forward_func, batch_conc, mc_samples=config.get('mc_samples', 30)\n",
    "                )\n",
    "                \n",
    "                # 收集结果\n",
    "                all_head_preds.append(head_pred.cpu().numpy())\n",
    "                all_head_targets.append(batch.head_y.cpu().numpy())\n",
    "                all_head_uncertainties.append(head_std.cpu().numpy())\n",
    "                all_conc_preds.append(conc_pred.cpu().numpy())\n",
    "                all_conc_targets.append(batch.y.cpu().numpy())\n",
    "                all_conc_uncertainties.append(conc_std.cpu().numpy())\n",
    "                \n",
    "                # 保存详细预测结果\n",
    "                batch_predictions = {\n",
    "                    'batch_idx': batch_idx,\n",
    "                    'pred_head': head_pred.cpu().numpy().flatten(),\n",
    "                    'true_head': batch.head_y.cpu().numpy().flatten(),\n",
    "                    'pred_conc': conc_pred.cpu().numpy().flatten(),\n",
    "                    'true_conc': batch.y.cpu().numpy().flatten()\n",
    "                }\n",
    "                \n",
    "                # 如果有空间信息，也保存\n",
    "                if hasattr(batch, 'row') and hasattr(batch, 'col'):\n",
    "                    batch_predictions['row'] = batch.row.cpu().numpy()\n",
    "                    batch_predictions['col'] = batch.col.cpu().numpy()\n",
    "                if hasattr(batch, 'time_step'):\n",
    "                    batch_predictions['time_step'] = batch.time_step.cpu().numpy()\n",
    "                \n",
    "                predictions.append(batch_predictions)\n",
    "                \n",
    "                # 保存不确定性估计\n",
    "                batch_uncertainties = {\n",
    "                    'batch_idx': batch_idx,\n",
    "                    'head_std': head_std.cpu().numpy().flatten(),\n",
    "                    'conc_std': conc_std.cpu().numpy().flatten()\n",
    "                }\n",
    "                \n",
    "                # 如果有空间信息，也保存\n",
    "                if hasattr(batch, 'row') and hasattr(batch, 'col'):\n",
    "                    batch_uncertainties['row'] = batch.row.cpu().numpy()\n",
    "                    batch_uncertainties['col'] = batch.col.cpu().numpy()\n",
    "                if hasattr(batch, 'time_step'):\n",
    "                    batch_uncertainties['time_step'] = batch.time_step.cpu().numpy()\n",
    "                \n",
    "                uncertainties.append(batch_uncertainties)\n",
    "                \n",
    "                # 每10个批次输出进度\n",
    "                if batch_idx % 10 == 0:\n",
    "                    print(f\"处理批次 {batch_idx}/{len(val_loader)}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"评估批次 {batch_idx} 出错: {e}\")\n",
    "                continue\n",
    "    \n",
    "    # 合并所有预测结果\n",
    "    all_head_preds = np.concatenate(all_head_preds, axis=0)\n",
    "    all_head_targets = np.concatenate(all_head_targets, axis=0)\n",
    "    all_head_uncertainties = np.concatenate(all_head_uncertainties, axis=0)\n",
    "    all_conc_preds = np.concatenate(all_conc_preds, axis=0)\n",
    "    all_conc_targets = np.concatenate(all_conc_targets, axis=0)\n",
    "    all_conc_uncertainties = np.concatenate(all_conc_uncertainties, axis=0)\n",
    "    \n",
    "    # 计算指标\n",
    "    head_metrics = compute_metrics(all_head_targets, all_head_preds)\n",
    "    conc_metrics = compute_metrics(all_conc_targets, all_conc_preds)\n",
    "    \n",
    "    print(f\"\\n水头模型评估结果（基于{evaluation_criterion}）:\")\n",
    "    for metric, value in head_metrics.items():\n",
    "        print(f\"  {metric.upper()}: {value:.4f}\")\n",
    "    \n",
    "    print(f\"\\n浓度模型评估结果（基于{evaluation_criterion}）:\")\n",
    "    for metric, value in conc_metrics.items():\n",
    "        print(f\"  {metric.upper()}: {value:.4f}\")\n",
    "    \n",
    "    # 生成可视化图表\n",
    "    print(\"生成可视化图表...\")\n",
    "    \n",
    "    # 1. 水头预测散点图（带不确定性）\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.errorbar(all_head_targets.flatten(), all_head_preds.flatten(), \n",
    "                yerr=all_head_uncertainties.flatten(), fmt='o', alpha=0.3, \n",
    "                ecolor='lightgray', elinewidth=0.5, capsize=0, markersize=2)\n",
    "    \n",
    "    min_val = min(np.min(all_head_targets), np.min(all_head_preds))\n",
    "    max_val = max(np.max(all_head_targets), np.max(all_head_preds))\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2)\n",
    "    \n",
    "    plt.xlabel('True Head Values', fontsize=14)\n",
    "    plt.ylabel('Predicted Head Values', fontsize=14)\n",
    "    plt.title(f'Head Predictions (R² = {head_metrics[\"r2\"]:.4f}, RMSE = {head_metrics[\"rmse\"]:.4f})', fontsize=16)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(results_dir, f'head_predictions_{evaluation_criterion}.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. 浓度预测散点图（带不确定性）\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.errorbar(all_conc_targets.flatten(), all_conc_preds.flatten(), \n",
    "                yerr=all_conc_uncertainties.flatten(), fmt='o', alpha=0.3,\n",
    "                ecolor='lightgray', elinewidth=0.5, capsize=0, markersize=2)\n",
    "    \n",
    "    min_val = min(np.min(all_conc_targets), np.min(all_conc_preds))\n",
    "    max_val = max(np.max(all_conc_targets), np.max(all_conc_preds))\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2)\n",
    "    \n",
    "    plt.xlabel('True Concentration Values', fontsize=14)\n",
    "    plt.ylabel('Predicted Concentration Values', fontsize=14)\n",
    "    plt.title(f'Concentration Predictions (R² = {conc_metrics[\"r2\"]:.4f}, RMSE = {conc_metrics[\"rmse\"]:.4f})', fontsize=16)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(results_dir, f'conc_predictions_{evaluation_criterion}.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 3. 不确定性分布图\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    ax1.hist(all_head_uncertainties.flatten(), bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
    "    ax1.set_xlabel('Head Uncertainty (Std)', fontsize=12)\n",
    "    ax1.set_ylabel('Frequency', fontsize=12)\n",
    "    ax1.set_title('Head Uncertainty Distribution', fontsize=14)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax2.hist(all_conc_uncertainties.flatten(), bins=50, alpha=0.7, color='green', edgecolor='black')\n",
    "    ax2.set_xlabel('Concentration Uncertainty (Std)', fontsize=12)\n",
    "    ax2.set_ylabel('Frequency', fontsize=12)\n",
    "    ax2.set_title('Concentration Uncertainty Distribution', fontsize=14)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(results_dir, f'uncertainty_distributions_{evaluation_criterion}.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 4. 不确定性 vs 误差关系图\n",
    "    head_errors = np.abs(all_head_preds.flatten() - all_head_targets.flatten())\n",
    "    conc_errors = np.abs(all_conc_preds.flatten() - all_conc_targets.flatten())\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    ax1.scatter(all_head_uncertainties.flatten(), head_errors, alpha=0.5, s=10)\n",
    "    head_corr = np.corrcoef(all_head_uncertainties.flatten(), head_errors)[0, 1]\n",
    "    ax1.set_xlabel('Head Uncertainty (Std)', fontsize=12)\n",
    "    ax1.set_ylabel('Head Absolute Error', fontsize=12)\n",
    "    ax1.set_title(f'Head: Uncertainty vs Error (r={head_corr:.3f})', fontsize=14)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax2.scatter(all_conc_uncertainties.flatten(), conc_errors, alpha=0.5, s=10)\n",
    "    conc_corr = np.corrcoef(all_conc_uncertainties.flatten(), conc_errors)[0, 1]\n",
    "    ax2.set_xlabel('Concentration Uncertainty (Std)', fontsize=12)\n",
    "    ax2.set_ylabel('Concentration Absolute Error', fontsize=12)\n",
    "    ax2.set_title(f'Concentration: Uncertainty vs Error (r={conc_corr:.3f})', fontsize=14)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(results_dir, f'uncertainty_vs_error_{evaluation_criterion}.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 保存评估结果\n",
    "    evaluation_results = {\n",
    "        'criterion': evaluation_criterion,\n",
    "        'head_metrics': head_metrics,\n",
    "        'conc_metrics': conc_metrics,\n",
    "        'head_predictions': all_head_preds,\n",
    "        'head_targets': all_head_targets,\n",
    "        'head_uncertainties': all_head_uncertainties,\n",
    "        'conc_predictions': all_conc_preds,\n",
    "        'conc_targets': all_conc_targets,\n",
    "        'conc_uncertainties': all_conc_uncertainties,\n",
    "        'detailed_predictions': predictions,\n",
    "        'detailed_uncertainties': uncertainties\n",
    "    }\n",
    "    \n",
    "    # 保存为文件\n",
    "    filename = f'dual_model_evaluation_{evaluation_criterion}.npy'\n",
    "    np.save(os.path.join(config['save_path'], filename), evaluation_results)\n",
    "    print(f\"\\n评估结果已保存到: {config['save_path']}/{filename}\")\n",
    "    \n",
    "    # 保存CSV格式的预测结果\n",
    "    if predictions:\n",
    "        pred_dfs = []\n",
    "        for pred_dict in predictions:\n",
    "            pred_df = pd.DataFrame({k: v for k, v in pred_dict.items() if not k.startswith('batch')})\n",
    "            pred_dfs.append(pred_df)\n",
    "        \n",
    "        if pred_dfs:\n",
    "            predictions_df = pd.concat(pred_dfs, ignore_index=True)\n",
    "            predictions_df.to_csv(os.path.join(results_dir, f'predictions_{evaluation_criterion}.csv'), index=False)\n",
    "            print(f\"预测结果CSV已保存到: {results_dir}/predictions_{evaluation_criterion}.csv\")\n",
    "    \n",
    "    # 保存CSV格式的不确定性结果\n",
    "    if uncertainties:\n",
    "        unc_dfs = []\n",
    "        for unc_dict in uncertainties:\n",
    "            unc_df = pd.DataFrame({k: v for k, v in unc_dict.items() if not k.startswith('batch')})\n",
    "            unc_dfs.append(unc_df)\n",
    "        \n",
    "        if unc_dfs:\n",
    "            uncertainties_df = pd.concat(unc_dfs, ignore_index=True)\n",
    "            uncertainties_df.to_csv(os.path.join(results_dir, f'uncertainties_{evaluation_criterion}.csv'), index=False)\n",
    "            print(f\"不确定性结果CSV已保存到: {results_dir}/uncertainties_{evaluation_criterion}.csv\")\n",
    "    \n",
    "    # 保存整体评估指标\n",
    "    metrics_summary = {\n",
    "        'evaluation_criterion': evaluation_criterion,\n",
    "        'head_mse': head_metrics['mse'],\n",
    "        'head_rmse': head_metrics['rmse'],\n",
    "        'head_mae': head_metrics['mae'],\n",
    "        'head_r2': head_metrics['r2'],\n",
    "        'conc_mse': conc_metrics['mse'],\n",
    "        'conc_rmse': conc_metrics['rmse'],\n",
    "        'conc_mae': conc_metrics['mae'],\n",
    "        'conc_r2': conc_metrics['r2'],\n",
    "        'head_uncertainty_mean': np.mean(all_head_uncertainties),\n",
    "        'head_uncertainty_std': np.std(all_head_uncertainties),\n",
    "        'conc_uncertainty_mean': np.mean(all_conc_uncertainties),\n",
    "        'conc_uncertainty_std': np.std(all_conc_uncertainties),\n",
    "        'head_error_uncertainty_correlation': head_corr,\n",
    "        'conc_error_uncertainty_correlation': conc_corr\n",
    "    }\n",
    "    \n",
    "    metrics_df = pd.DataFrame([metrics_summary])\n",
    "    metrics_df.to_csv(os.path.join(results_dir, f'evaluation_summary_{evaluation_criterion}.csv'), index=False)\n",
    "    \n",
    "    print(f\"\\n📊 评估完成!\")\n",
    "    print(f\"📈 水头模型 - R2: {head_metrics['r2']:.4f}, RMSE: {head_metrics['rmse']:.4f}\")\n",
    "    print(f\"📈 浓度模型 - R2: {conc_metrics['r2']:.4f}, RMSE: {conc_metrics['rmse']:.4f}\")\n",
    "    print(f\"📁 所有结果已保存到: {results_dir}\")\n",
    "    \n",
    "    return evaluation_results\n",
    "\n",
    "def compare_model_criteria(head_model, conc_model, val_loader):\n",
    "    \"\"\"\n",
    "    比较基于损失和基于R2的模型性能，使用改进的评估函数\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"比较不同选择标准的模型性能\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 分别评估两种标准的模型\n",
    "    loss_results = evaluate_dual_model_improved(head_model, conc_model, val_loader, 'loss')\n",
    "    r2_results = evaluate_dual_model_improved(head_model, conc_model, val_loader, 'r2')\n",
    "    \n",
    "    # 创建比较表格\n",
    "    comparison_data = []\n",
    "    \n",
    "    # 水头模型比较\n",
    "    comparison_data.append({\n",
    "        'Model': 'Head',\n",
    "        'Criterion': 'Loss',\n",
    "        'MSE': loss_results['head_metrics']['mse'],\n",
    "        'RMSE': loss_results['head_metrics']['rmse'],\n",
    "        'MAE': loss_results['head_metrics']['mae'],\n",
    "        'R2': loss_results['head_metrics']['r2'],\n",
    "        'Uncertainty_Mean': np.mean(loss_results['head_uncertainties']),\n",
    "        'Error_Uncertainty_Corr': np.corrcoef(\n",
    "            loss_results['head_uncertainties'].flatten(),\n",
    "            np.abs(loss_results['head_predictions'].flatten() - loss_results['head_targets'].flatten())\n",
    "        )[0, 1]\n",
    "    })\n",
    "    \n",
    "    comparison_data.append({\n",
    "        'Model': 'Head',\n",
    "        'Criterion': 'R2',\n",
    "        'MSE': r2_results['head_metrics']['mse'],\n",
    "        'RMSE': r2_results['head_metrics']['rmse'],\n",
    "        'MAE': r2_results['head_metrics']['mae'],\n",
    "        'R2': r2_results['head_metrics']['r2'],\n",
    "        'Uncertainty_Mean': np.mean(r2_results['head_uncertainties']),\n",
    "        'Error_Uncertainty_Corr': np.corrcoef(\n",
    "            r2_results['head_uncertainties'].flatten(),\n",
    "            np.abs(r2_results['head_predictions'].flatten() - r2_results['head_targets'].flatten())\n",
    "        )[0, 1]\n",
    "    })\n",
    "    \n",
    "    # 浓度模型比较\n",
    "    comparison_data.append({\n",
    "        'Model': 'Concentration',\n",
    "        'Criterion': 'Loss',\n",
    "        'MSE': loss_results['conc_metrics']['mse'],\n",
    "        'RMSE': loss_results['conc_metrics']['rmse'],\n",
    "        'MAE': loss_results['conc_metrics']['mae'],\n",
    "        'R2': loss_results['conc_metrics']['r2'],\n",
    "        'Uncertainty_Mean': np.mean(loss_results['conc_uncertainties']),\n",
    "        'Error_Uncertainty_Corr': np.corrcoef(\n",
    "            loss_results['conc_uncertainties'].flatten(),\n",
    "            np.abs(loss_results['conc_predictions'].flatten() - loss_results['conc_targets'].flatten())\n",
    "        )[0, 1]\n",
    "    })\n",
    "    \n",
    "    comparison_data.append({\n",
    "        'Model': 'Concentration',\n",
    "        'Criterion': 'R2',\n",
    "        'MSE': r2_results['conc_metrics']['mse'],\n",
    "        'RMSE': r2_results['conc_metrics']['rmse'],\n",
    "        'MAE': r2_results['conc_metrics']['mae'],\n",
    "        'R2': r2_results['conc_metrics']['r2'],\n",
    "        'Uncertainty_Mean': np.mean(r2_results['conc_uncertainties']),\n",
    "        'Error_Uncertainty_Corr': np.corrcoef(\n",
    "            r2_results['conc_uncertainties'].flatten(),\n",
    "            np.abs(r2_results['conc_predictions'].flatten() - r2_results['conc_targets'].flatten())\n",
    "        )[0, 1]\n",
    "    })\n",
    "    \n",
    "    # 创建比较DataFrame\n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    \n",
    "    # 保存比较结果\n",
    "    results_dir = os.path.join(config['save_path'], 'evaluation_results')\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    comparison_df.to_csv(os.path.join(results_dir, 'model_criteria_comparison.csv'), index=False)\n",
    "    \n",
    "    # 打印比较结果\n",
    "    print(\"\\n模型选择标准比较结果:\")\n",
    "    print(comparison_df.to_string(index=False, float_format='%.4f'))\n",
    "    \n",
    "    # 绘制扩展的比较图\n",
    "    plt.figure(figsize=(20, 12))\n",
    "    \n",
    "    # R2比较\n",
    "    plt.subplot(2, 4, 1)\n",
    "    head_r2 = [loss_results['head_metrics']['r2'], r2_results['head_metrics']['r2']]\n",
    "    conc_r2 = [loss_results['conc_metrics']['r2'], r2_results['conc_metrics']['r2']]\n",
    "    x = ['Loss-based', 'R2-based']\n",
    "    plt.bar([0, 1], head_r2, alpha=0.7, label='Head Model', width=0.35)\n",
    "    plt.bar([0.35, 1.35], conc_r2, alpha=0.7, label='Concentration Model', width=0.35)\n",
    "    plt.xlabel('Model Selection Criterion')\n",
    "    plt.ylabel('R2 Score')\n",
    "    plt.title('R2 Score Comparison')\n",
    "    plt.xticks([0.175, 1.175], x)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # MSE比较\n",
    "    plt.subplot(2, 4, 2)\n",
    "    head_mse = [loss_results['head_metrics']['mse'], r2_results['head_metrics']['mse']]\n",
    "    conc_mse = [loss_results['conc_metrics']['mse'], r2_results['conc_metrics']['mse']]\n",
    "    plt.bar([0, 1], head_mse, alpha=0.7, label='Head Model', width=0.35)\n",
    "    plt.bar([0.35, 1.35], conc_mse, alpha=0.7, label='Concentration Model', width=0.35)\n",
    "    plt.xlabel('Model Selection Criterion')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.title('MSE Comparison')\n",
    "    plt.xticks([0.175, 1.175], x)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 不确定性比较\n",
    "    plt.subplot(2, 4, 3)\n",
    "    head_unc = [np.mean(loss_results['head_uncertainties']), np.mean(r2_results['head_uncertainties'])]\n",
    "    conc_unc = [np.mean(loss_results['conc_uncertainties']), np.mean(r2_results['conc_uncertainties'])]\n",
    "    plt.bar([0, 1], head_unc, alpha=0.7, label='Head Model', width=0.35)\n",
    "    plt.bar([0.35, 1.35], conc_unc, alpha=0.7, label='Concentration Model', width=0.35)\n",
    "    plt.xlabel('Model Selection Criterion')\n",
    "    plt.ylabel('Mean Uncertainty')\n",
    "    plt.title('Uncertainty Comparison')\n",
    "    plt.xticks([0.175, 1.175], x)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 误差-不确定性相关性比较\n",
    "    plt.subplot(2, 4, 4)\n",
    "    head_corr = [comparison_data[0]['Error_Uncertainty_Corr'], comparison_data[1]['Error_Uncertainty_Corr']]\n",
    "    conc_corr = [comparison_data[2]['Error_Uncertainty_Corr'], comparison_data[3]['Error_Uncertainty_Corr']]\n",
    "    plt.bar([0, 1], head_corr, alpha=0.7, label='Head Model', width=0.35)\n",
    "    plt.bar([0.35, 1.35], conc_corr, alpha=0.7, label='Concentration Model', width=0.35)\n",
    "    plt.xlabel('Model Selection Criterion')\n",
    "    plt.ylabel('Error-Uncertainty Correlation')\n",
    "    plt.title('Calibration Quality Comparison')\n",
    "    plt.xticks([0.175, 1.175], x)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 预测散点图比较\n",
    "    plt.subplot(2, 4, 5)\n",
    "    plt.scatter(loss_results['head_targets'].flatten(), loss_results['head_predictions'].flatten(), \n",
    "               alpha=0.5, label='Loss-based', s=5)\n",
    "    plt.scatter(r2_results['head_targets'].flatten(), r2_results['head_predictions'].flatten(), \n",
    "               alpha=0.5, label='R2-based', s=5)\n",
    "    plt.plot([loss_results['head_targets'].min(), loss_results['head_targets'].max()], \n",
    "             [loss_results['head_targets'].min(), loss_results['head_targets'].max()], 'r--', alpha=0.8)\n",
    "    plt.xlabel('True Head Values')\n",
    "    plt.ylabel('Predicted Head Values')\n",
    "    plt.title('Head Model: True vs Predicted')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(2, 4, 6)\n",
    "    plt.scatter(loss_results['conc_targets'].flatten(), loss_results['conc_predictions'].flatten(), \n",
    "               alpha=0.5, label='Loss-based', s=5)\n",
    "    plt.scatter(r2_results['conc_targets'].flatten(), r2_results['conc_predictions'].flatten(), \n",
    "               alpha=0.5, label='R2-based', s=5)\n",
    "    plt.plot([loss_results['conc_targets'].min(), loss_results['conc_targets'].max()], \n",
    "             [loss_results['conc_targets'].min(), loss_results['conc_targets'].max()], 'r--', alpha=0.8)\n",
    "    plt.xlabel('True Concentration Values')\n",
    "    plt.ylabel('Predicted Concentration Values')\n",
    "    plt.title('Concentration Model: True vs Predicted')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 不确定性分布比较\n",
    "    plt.subplot(2, 4, 7)\n",
    "    plt.hist(loss_results['head_uncertainties'].flatten(), bins=30, alpha=0.5, label='Loss-based', density=True)\n",
    "    plt.hist(r2_results['head_uncertainties'].flatten(), bins=30, alpha=0.5, label='R2-based', density=True)\n",
    "    plt.xlabel('Head Uncertainty')\n",
    "    plt.ylabel('Density')\n",
    "    plt.title('Head Uncertainty Distribution')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(2, 4, 8)\n",
    "    plt.hist(loss_results['conc_uncertainties'].flatten(), bins=30, alpha=0.5, label='Loss-based', density=True)\n",
    "    plt.hist(r2_results['conc_uncertainties'].flatten(), bins=30, alpha=0.5, label='R2-based', density=True)\n",
    "    plt.xlabel('Concentration Uncertainty')\n",
    "    plt.ylabel('Density')\n",
    "    plt.title('Concentration Uncertainty Distribution')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(results_dir, 'model_criteria_comparison_comprehensive.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"\\n比较图表已保存到: {results_dir}/model_criteria_comparison_comprehensive.png\")\n",
    "    print(f\"比较数据已保存到: {results_dir}/model_criteria_comparison.csv\")\n",
    "    \n",
    "    return comparison_df, loss_results, r2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4f6bffe-e1b9-4222-98d0-f50e9dc5e3cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在处理数据...\n",
      "\n",
      "▶ Started building spatiotemporal graphs\n",
      "▷ Total models to process: 100\n",
      "\n",
      "▣ Processing model 1/100: dual_42\n",
      "\n",
      "▣ Processing model 2/100: dual_93\n",
      "\n",
      "▣ Processing model 3/100: dual_71\n",
      "\n",
      "▣ Processing model 4/100: dual_31\n",
      "\n",
      "▣ Processing model 5/100: dual_60\n",
      "\n",
      "▣ Processing model 6/100: dual_15\n",
      "\n",
      "▣ Processing model 7/100: dual_88\n",
      "\n",
      "▣ Processing model 8/100: dual_40\n",
      "\n",
      "▣ Processing model 9/100: dual_20\n",
      "\n",
      "▣ Processing model 10/100: dual_94\n",
      "\n",
      "▣ Processing model 11/100: dual_76\n",
      "\n",
      "▣ Processing model 12/100: dual_84\n",
      "\n",
      "▣ Processing model 13/100: dual_62\n",
      "\n",
      "▣ Processing model 14/100: dual_10\n",
      "\n",
      "▣ Processing model 15/100: dual_21\n",
      "\n",
      "▣ Processing model 16/100: dual_0\n",
      "\n",
      "▣ Processing model 17/100: dual_29\n",
      "\n",
      "▣ Processing model 18/100: dual_49\n",
      "\n",
      "▣ Processing model 19/100: dual_37\n",
      "\n",
      "▣ Processing model 20/100: dual_23\n",
      "\n",
      "▣ Processing model 21/100: dual_61\n",
      "\n",
      "▣ Processing model 22/100: dual_68\n",
      "\n",
      "▣ Processing model 23/100: dual_18\n",
      "\n",
      "▣ Processing model 24/100: dual_66\n",
      "\n",
      "▣ Processing model 25/100: dual_17\n",
      "\n",
      "▣ Processing model 26/100: dual_51\n",
      "\n",
      "▣ Processing model 27/100: dual_36\n",
      "\n",
      "▣ Processing model 28/100: dual_48\n",
      "\n",
      "▣ Processing model 29/100: dual_34\n",
      "\n",
      "▣ Processing model 30/100: dual_47\n",
      "\n",
      "▣ Processing model 31/100: dual_24\n",
      "\n",
      "▣ Processing model 32/100: dual_85\n",
      "\n",
      "▣ Processing model 33/100: dual_67\n",
      "\n",
      "▣ Processing model 34/100: dual_54\n",
      "\n",
      "▣ Processing model 35/100: dual_55\n",
      "\n",
      "▣ Processing model 36/100: dual_87\n",
      "\n",
      "▣ Processing model 37/100: dual_90\n",
      "\n",
      "▣ Processing model 38/100: dual_8\n",
      "\n",
      "▣ Processing model 39/100: dual_6\n",
      "\n",
      "▣ Processing model 40/100: dual_7\n",
      "\n",
      "▣ Processing model 41/100: dual_99\n",
      "\n",
      "▣ Processing model 42/100: dual_16\n",
      "\n",
      "▣ Processing model 43/100: dual_32\n",
      "\n",
      "▣ Processing model 44/100: dual_33\n",
      "\n",
      "▣ Processing model 45/100: dual_43\n",
      "\n",
      "▣ Processing model 46/100: dual_63\n",
      "\n",
      "▣ Processing model 47/100: dual_72\n",
      "\n",
      "▣ Processing model 48/100: dual_35\n",
      "\n",
      "▣ Processing model 49/100: dual_91\n",
      "\n",
      "▣ Processing model 50/100: dual_26\n",
      "\n",
      "▣ Processing model 51/100: dual_39\n",
      "\n",
      "▣ Processing model 52/100: dual_81\n",
      "\n",
      "▣ Processing model 53/100: dual_74\n",
      "\n",
      "▣ Processing model 54/100: dual_96\n",
      "\n",
      "▣ Processing model 55/100: dual_52\n",
      "\n",
      "▣ Processing model 56/100: dual_19\n",
      "\n",
      "▣ Processing model 57/100: dual_38\n",
      "\n",
      "▣ Processing model 58/100: dual_3\n",
      "\n",
      "▣ Processing model 59/100: dual_44\n",
      "\n",
      "▣ Processing model 60/100: dual_83\n",
      "\n",
      "▣ Processing model 61/100: dual_82\n",
      "\n",
      "▣ Processing model 62/100: dual_97\n",
      "\n",
      "▣ Processing model 63/100: dual_5\n",
      "\n",
      "▣ Processing model 64/100: dual_57\n",
      "\n",
      "▣ Processing model 65/100: dual_45\n",
      "\n",
      "▣ Processing model 66/100: dual_73\n",
      "\n",
      "▣ Processing model 67/100: dual_12\n",
      "\n",
      "▣ Processing model 68/100: dual_27\n",
      "\n",
      "▣ Processing model 69/100: dual_11\n",
      "\n",
      "▣ Processing model 70/100: dual_50\n",
      "\n",
      "▣ Processing model 71/100: dual_41\n",
      "\n",
      "▣ Processing model 72/100: dual_79\n",
      "\n",
      "▣ Processing model 73/100: dual_13\n",
      "\n",
      "▣ Processing model 74/100: dual_77\n",
      "\n",
      "▣ Processing model 75/100: dual_92\n",
      "\n",
      "▣ Processing model 76/100: dual_98\n",
      "\n",
      "▣ Processing model 77/100: dual_89\n",
      "\n",
      "▣ Processing model 78/100: dual_28\n",
      "\n",
      "▣ Processing model 79/100: dual_1\n",
      "\n",
      "▣ Processing model 80/100: dual_59\n",
      "\n",
      "▣ Processing model 81/100: dual_56\n",
      "\n",
      "▣ Processing model 82/100: dual_69\n",
      "\n",
      "▣ Processing model 83/100: dual_70\n",
      "\n",
      "▣ Processing model 84/100: dual_65\n",
      "\n",
      "▣ Processing model 85/100: dual_64\n",
      "\n",
      "▣ Processing model 86/100: dual_58\n",
      "\n",
      "▣ Processing model 87/100: dual_4\n",
      "\n",
      "▣ Processing model 88/100: dual_86\n",
      "\n",
      "▣ Processing model 89/100: dual_22\n",
      "\n",
      "▣ Processing model 90/100: dual_25\n",
      "\n",
      "▣ Processing model 91/100: dual_46\n",
      "\n",
      "▣ Processing model 92/100: dual_95\n",
      "\n",
      "▣ Processing model 93/100: dual_9\n",
      "\n",
      "▣ Processing model 94/100: dual_78\n",
      "\n",
      "▣ Processing model 95/100: dual_2\n",
      "\n",
      "▣ Processing model 96/100: dual_75\n",
      "\n",
      "▣ Processing model 97/100: dual_14\n",
      "\n",
      "▣ Processing model 98/100: dual_53\n",
      "\n",
      "▣ Processing model 99/100: dual_30\n",
      "\n",
      "▣ Processing model 100/100: dual_80\n",
      "\n",
      "✅ All models processed! Total graphs created: 100\n",
      "数据处理完成！\n",
      "CUDA缓存已成功清除\n",
      "================================================================================\n",
      "第一阶段：开始训练水头模型\n",
      "================================================================================\n",
      "开始训练水头模型\n",
      "水头模型参数数量: 949853\n",
      "水头模型 Epoch 1, Batch 0: Total Loss: 8702.8789, Criterion Loss: 8505.7959, Physics Loss: 9619.5307, KL Loss: 197.0830\n",
      "水头模型 Epoch 001/500 | 训练损失: 8653.5909 | 验证损失: 8339.5905 | LR: 0.000994\n",
      "水头验证指标 - MSE: 9245.3013, RMSE: 96.1499, MAE: 95.9786, R2: -291.3891\n",
      "保存基于损失的最佳水头模型，验证损失: 8339.5905\n",
      "保存基于R2的最佳水头模型，R2: -291.3891\n",
      "水头模型 Epoch 2, Batch 0: Total Loss: 8538.7305, Criterion Loss: 8346.0771, Physics Loss: 9440.8021, KL Loss: 192.6534\n",
      "水头模型 Epoch 002/500 | 训练损失: 8447.2088 | 验证损失: 7985.0488 | LR: 0.000976\n",
      "水头验证指标 - MSE: 8851.4414, RMSE: 94.0795, MAE: 93.8801, R2: -278.9374\n",
      "保存基于损失的最佳水头模型，验证损失: 7985.0488\n",
      "保存基于R2的最佳水头模型，R2: -278.9374\n",
      "水头模型 Epoch 3, Batch 0: Total Loss: 8145.4209, Criterion Loss: 7955.7061, Physics Loss: 9005.8783, KL Loss: 189.7148\n",
      "水头模型 Epoch 003/500 | 训练损失: 7860.4356 | 验证损失: 7130.3472 | LR: 0.000946\n",
      "水头验证指标 - MSE: 7902.6872, RMSE: 88.8946, MAE: 88.6623, R2: -248.9347\n",
      "保存基于损失的最佳水头模型，验证损失: 7130.3472\n",
      "保存基于R2的最佳水头模型，R2: -248.9347\n",
      "水头模型 Epoch 4, Batch 0: Total Loss: 7342.7642, Criterion Loss: 7154.0010, Physics Loss: 8110.7932, KL Loss: 188.7633\n",
      "水头模型 Epoch 004/500 | 训练损失: 6478.3865 | 验证损失: 5079.5067 | LR: 0.000905\n",
      "水头验证指标 - MSE: 5628.0443, RMSE: 75.0158, MAE: 74.7077, R2: -176.8665\n",
      "保存基于损失的最佳水头模型，验证损失: 5079.5067\n",
      "保存基于R2的最佳水头模型，R2: -176.8665\n",
      "水头模型 Epoch 5, Batch 0: Total Loss: 5426.9238, Criterion Loss: 5239.0620, Physics Loss: 5958.1712, KL Loss: 187.8617\n",
      "水头模型 Epoch 005/500 | 训练损失: 3524.6561 | 验证损失: 939.1629 | LR: 0.000855\n",
      "水头验证指标 - MSE: 1034.0729, RMSE: 32.1401, MAE: 31.3376, R2: -31.5614\n",
      "保存基于损失的最佳水头模型，验证损失: 939.1629\n",
      "保存基于R2的最佳水头模型，R2: -31.5614\n",
      "水头模型 Epoch 6, Batch 0: Total Loss: 1049.5161, Criterion Loss: 860.5239, Physics Loss: 1146.3602, KL Loss: 188.9922\n",
      "水头模型 Epoch 006/500 | 训练损失: 536.9620 | 验证损失: 60.2888 | LR: 0.000796\n",
      "水头验证指标 - MSE: 60.2198, RMSE: 7.7325, MAE: 6.0579, R2: -0.9142\n",
      "保存基于损失的最佳水头模型，验证损失: 60.2888\n",
      "保存基于R2的最佳水头模型，R2: -0.9142\n",
      "水头模型 Epoch 7, Batch 0: Total Loss: 366.5329, Criterion Loss: 178.4445, Physics Loss: 418.2321, KL Loss: 188.0884\n",
      "水头模型 Epoch 007/500 | 训练损失: 367.7004 | 验证损失: 46.7750 | LR: 0.000730\n",
      "水头验证指标 - MSE: 47.3750, RMSE: 6.8327, MAE: 5.3110, R2: -0.4773\n",
      "保存基于损失的最佳水头模型，验证损失: 46.7750\n",
      "保存基于R2的最佳水头模型，R2: -0.4773\n",
      "水头模型 Epoch 8, Batch 0: Total Loss: 373.5784, Criterion Loss: 186.8551, Physics Loss: 404.4518, KL Loss: 186.7233\n",
      "水头模型 Epoch 008/500 | 训练损失: 317.6382 | 验证损失: 37.5856 | LR: 0.000658\n",
      "水头验证指标 - MSE: 38.2154, RMSE: 6.1735, MAE: 5.0100, R2: -0.1983\n",
      "保存基于损失的最佳水头模型，验证损失: 37.5856\n",
      "保存基于R2的最佳水头模型，R2: -0.1983\n",
      "水头模型 Epoch 9, Batch 0: Total Loss: 305.9540, Criterion Loss: 121.6854, Physics Loss: 278.4179, KL Loss: 184.2686\n",
      "水头模型 Epoch 009/500 | 训练损失: 331.2271 | 验证损失: 34.1824 | LR: 0.000582\n",
      "水头验证指标 - MSE: 34.9506, RMSE: 5.8974, MAE: 4.6530, R2: -0.0974\n",
      "保存基于损失的最佳水头模型，验证损失: 34.1824\n",
      "保存基于R2的最佳水头模型，R2: -0.0974\n",
      "水头模型 Epoch 10, Batch 0: Total Loss: 279.5244, Criterion Loss: 97.6874, Physics Loss: 242.6097, KL Loss: 181.8370\n",
      "水头模型 Epoch 010/500 | 训练损失: 308.9717 | 验证损失: 29.7808 | LR: 0.000505\n",
      "水头验证指标 - MSE: 30.2373, RMSE: 5.4721, MAE: 4.3504, R2: 0.0670\n",
      "保存基于损失的最佳水头模型，验证损失: 29.7808\n",
      "保存基于R2的最佳水头模型，R2: 0.0670\n",
      "水头模型 Epoch 11, Batch 0: Total Loss: 294.8454, Criterion Loss: 113.7851, Physics Loss: 244.5064, KL Loss: 181.0603\n",
      "水头模型 Epoch 011/500 | 训练损失: 283.6511 | 验证损失: 32.7612 | LR: 0.000428\n",
      "水头验证指标 - MSE: 33.8251, RMSE: 5.7596, MAE: 4.6523, R2: -0.0620\n",
      "水头模型 Epoch 12, Batch 0: Total Loss: 282.3069, Criterion Loss: 103.4235, Physics Loss: 255.2175, KL Loss: 178.8834\n",
      "水头模型 Epoch 012/500 | 训练损失: 291.7483 | 验证损失: 33.1627 | LR: 0.000352\n",
      "水头验证指标 - MSE: 34.2820, RMSE: 5.7950, MAE: 4.6977, R2: -0.0638\n",
      "水头模型 Epoch 13, Batch 0: Total Loss: 300.0632, Criterion Loss: 122.2825, Physics Loss: 256.3377, KL Loss: 177.7807\n",
      "水头模型 Epoch 013/500 | 训练损失: 296.8679 | 验证损失: 24.3397 | LR: 0.000280\n",
      "水头验证指标 - MSE: 24.5614, RMSE: 4.9249, MAE: 3.9312, R2: 0.2411\n",
      "保存基于损失的最佳水头模型，验证损失: 24.3397\n",
      "保存基于R2的最佳水头模型，R2: 0.2411\n",
      "水头模型 Epoch 14, Batch 0: Total Loss: 287.0528, Criterion Loss: 110.1667, Physics Loss: 262.7774, KL Loss: 176.8861\n",
      "水头模型 Epoch 014/500 | 训练损失: 314.0484 | 验证损失: 29.4492 | LR: 0.000214\n",
      "水头验证指标 - MSE: 30.1800, RMSE: 5.4306, MAE: 4.3597, R2: 0.0732\n",
      "水头模型 Epoch 15, Batch 0: Total Loss: 256.5340, Criterion Loss: 80.6645, Physics Loss: 209.6166, KL Loss: 175.8695\n",
      "水头模型 Epoch 015/500 | 训练损失: 277.0501 | 验证损失: 23.2973 | LR: 0.000155\n",
      "水头验证指标 - MSE: 23.4220, RMSE: 4.8248, MAE: 3.8854, R2: 0.2616\n",
      "保存基于损失的最佳水头模型，验证损失: 23.2973\n",
      "保存基于R2的最佳水头模型，R2: 0.2616\n",
      "水头模型 Epoch 16, Batch 0: Total Loss: 259.8210, Criterion Loss: 84.2255, Physics Loss: 225.8354, KL Loss: 175.5955\n",
      "水头模型 Epoch 016/500 | 训练损失: 282.2270 | 验证损失: 20.4564 | LR: 0.000105\n",
      "水头验证指标 - MSE: 20.4175, RMSE: 4.5079, MAE: 3.6015, R2: 0.3616\n",
      "保存基于损失的最佳水头模型，验证损失: 20.4564\n",
      "保存基于R2的最佳水头模型，R2: 0.3616\n",
      "水头模型 Epoch 17, Batch 0: Total Loss: 268.7932, Criterion Loss: 93.8064, Physics Loss: 235.2205, KL Loss: 174.9869\n",
      "水头模型 Epoch 017/500 | 训练损失: 281.8197 | 验证损失: 24.5051 | LR: 0.000064\n",
      "水头验证指标 - MSE: 24.9272, RMSE: 4.9076, MAE: 3.9340, R2: 0.2404\n",
      "水头模型 Epoch 18, Batch 0: Total Loss: 258.3668, Criterion Loss: 83.6738, Physics Loss: 222.5802, KL Loss: 174.6929\n",
      "水头模型 Epoch 018/500 | 训练损失: 277.0281 | 验证损失: 24.2230 | LR: 0.000034\n",
      "水头验证指标 - MSE: 24.6637, RMSE: 4.9135, MAE: 3.9284, R2: 0.2334\n",
      "水头模型 Epoch 19, Batch 0: Total Loss: 277.8449, Criterion Loss: 103.8426, Physics Loss: 228.9565, KL Loss: 174.0024\n",
      "水头模型 Epoch 019/500 | 训练损失: 273.0897 | 验证损失: 22.4290 | LR: 0.000016\n",
      "水头验证指标 - MSE: 22.6695, RMSE: 4.7122, MAE: 3.7588, R2: 0.2970\n",
      "水头模型 Epoch 20, Batch 0: Total Loss: 278.5312, Criterion Loss: 104.4367, Physics Loss: 229.2637, KL Loss: 174.0944\n",
      "水头模型 Epoch 020/500 | 训练损失: 271.3066 | 验证损失: 20.6006 | LR: 0.001000\n",
      "水头验证指标 - MSE: 20.6621, RMSE: 4.5139, MAE: 3.6024, R2: 0.3563\n",
      "水头模型 Epoch 21, Batch 0: Total Loss: 283.5579, Criterion Loss: 109.2196, Physics Loss: 261.7847, KL Loss: 174.3383\n",
      "水头模型 Epoch 021/500 | 训练损失: 274.5856 | 验证损失: 22.1862 | LR: 0.000998\n",
      "水头验证指标 - MSE: 21.5842, RMSE: 4.6248, MAE: 3.7077, R2: 0.3294\n",
      "水头模型 Epoch 22, Batch 0: Total Loss: 285.7432, Criterion Loss: 114.5131, Physics Loss: 245.0990, KL Loss: 171.2301\n",
      "水头模型 Epoch 022/500 | 训练损失: 273.3163 | 验证损失: 29.8676 | LR: 0.000994\n",
      "水头验证指标 - MSE: 30.8856, RMSE: 5.4525, MAE: 4.4199, R2: 0.0697\n",
      "水头模型 Epoch 23, Batch 0: Total Loss: 256.5785, Criterion Loss: 87.8301, Physics Loss: 220.8492, KL Loss: 168.7484\n",
      "水头模型 Epoch 023/500 | 训练损失: 262.3240 | 验证损失: 19.5241 | LR: 0.000986\n",
      "水头验证指标 - MSE: 19.1962, RMSE: 4.3678, MAE: 3.4805, R2: 0.4025\n",
      "保存基于损失的最佳水头模型，验证损失: 19.5241\n",
      "保存基于R2的最佳水头模型，R2: 0.4025\n",
      "水头模型 Epoch 24, Batch 0: Total Loss: 284.9632, Criterion Loss: 117.8251, Physics Loss: 267.8438, KL Loss: 167.1382\n",
      "水头模型 Epoch 024/500 | 训练损失: 268.7697 | 验证损失: 39.6884 | LR: 0.000976\n",
      "水头验证指标 - MSE: 40.8621, RMSE: 6.2659, MAE: 5.2019, R2: -0.2462\n",
      "水头模型 Epoch 25, Batch 0: Total Loss: 305.2095, Criterion Loss: 139.8248, Physics Loss: 257.0233, KL Loss: 165.3848\n",
      "水头模型 Epoch 025/500 | 训练损失: 258.2307 | 验证损失: 27.4042 | LR: 0.000962\n",
      "水头验证指标 - MSE: 28.0765, RMSE: 5.2129, MAE: 4.2752, R2: 0.1062\n",
      "水头模型 Epoch 26, Batch 0: Total Loss: 236.5799, Criterion Loss: 73.1894, Physics Loss: 193.9080, KL Loss: 163.3905\n",
      "水头模型 Epoch 026/500 | 训练损失: 268.2022 | 验证损失: 21.3711 | LR: 0.000946\n",
      "水头验证指标 - MSE: 21.1873, RMSE: 4.5766, MAE: 3.6429, R2: 0.3398\n",
      "水头模型 Epoch 27, Batch 0: Total Loss: 269.9560, Criterion Loss: 107.9906, Physics Loss: 241.9544, KL Loss: 161.9654\n",
      "水头模型 Epoch 027/500 | 训练损失: 248.9502 | 验证损失: 28.5946 | LR: 0.000927\n",
      "水头验证指标 - MSE: 29.6081, RMSE: 5.3425, MAE: 4.3625, R2: 0.0902\n",
      "水头模型 Epoch 28, Batch 0: Total Loss: 229.4085, Criterion Loss: 68.7687, Physics Loss: 171.6873, KL Loss: 160.6398\n",
      "水头模型 Epoch 028/500 | 训练损失: 249.3851 | 验证损失: 16.8927 | LR: 0.000905\n",
      "水头验证指标 - MSE: 16.4092, RMSE: 4.0369, MAE: 3.2384, R2: 0.4884\n",
      "保存基于损失的最佳水头模型，验证损失: 16.8927\n",
      "保存基于R2的最佳水头模型，R2: 0.4884\n",
      "水头模型 Epoch 29, Batch 0: Total Loss: 241.0605, Criterion Loss: 82.4050, Physics Loss: 187.2268, KL Loss: 158.6556\n",
      "水头模型 Epoch 029/500 | 训练损失: 237.2480 | 验证损失: 32.8039 | LR: 0.000881\n",
      "水头验证指标 - MSE: 33.6666, RMSE: 5.6743, MAE: 4.7815, R2: -0.0898\n",
      "水头模型 Epoch 30, Batch 0: Total Loss: 231.5105, Criterion Loss: 74.5166, Physics Loss: 185.5753, KL Loss: 156.9939\n",
      "水头模型 Epoch 030/500 | 训练损失: 233.8926 | 验证损失: 23.2875 | LR: 0.000855\n",
      "水头验证指标 - MSE: 22.9496, RMSE: 4.7414, MAE: 3.8536, R2: 0.2703\n",
      "水头模型 Epoch 31, Batch 0: Total Loss: 240.2033, Criterion Loss: 84.5913, Physics Loss: 206.5372, KL Loss: 155.6120\n",
      "水头模型 Epoch 031/500 | 训练损失: 241.3032 | 验证损失: 15.9080 | LR: 0.000826\n",
      "水头验证指标 - MSE: 15.8933, RMSE: 3.9561, MAE: 3.1700, R2: 0.5067\n",
      "保存基于损失的最佳水头模型，验证损失: 15.9080\n",
      "保存基于R2的最佳水头模型，R2: 0.5067\n",
      "水头模型 Epoch 32, Batch 0: Total Loss: 226.7845, Criterion Loss: 72.7938, Physics Loss: 183.1267, KL Loss: 153.9907\n",
      "水头模型 Epoch 032/500 | 训练损失: 227.2330 | 验证损失: 21.3614 | LR: 0.000796\n",
      "水头验证指标 - MSE: 21.8638, RMSE: 4.5735, MAE: 3.7012, R2: 0.3284\n",
      "水头模型 Epoch 33, Batch 0: Total Loss: 212.4044, Criterion Loss: 59.7196, Physics Loss: 155.0527, KL Loss: 152.6848\n",
      "水头模型 Epoch 033/500 | 训练损失: 232.1272 | 验证损失: 42.9167 | LR: 0.000764\n",
      "水头验证指标 - MSE: 45.4274, RMSE: 6.5524, MAE: 5.5963, R2: -0.3549\n",
      "水头模型 Epoch 34, Batch 0: Total Loss: 230.0249, Criterion Loss: 78.9768, Physics Loss: 176.7485, KL Loss: 151.0482\n",
      "水头模型 Epoch 034/500 | 训练损失: 238.4377 | 验证损失: 15.6702 | LR: 0.000730\n",
      "水头验证指标 - MSE: 15.6040, RMSE: 3.9324, MAE: 3.1437, R2: 0.5156\n",
      "保存基于损失的最佳水头模型，验证损失: 15.6702\n",
      "保存基于R2的最佳水头模型，R2: 0.5156\n",
      "水头模型 Epoch 35, Batch 0: Total Loss: 258.2869, Criterion Loss: 108.0063, Physics Loss: 201.1617, KL Loss: 150.2806\n",
      "水头模型 Epoch 035/500 | 训练损失: 232.5657 | 验证损失: 20.5764 | LR: 0.000694\n",
      "水头验证指标 - MSE: 20.6465, RMSE: 4.5323, MAE: 3.5623, R2: 0.3482\n",
      "水头模型 Epoch 36, Batch 0: Total Loss: 220.6781, Criterion Loss: 71.2620, Physics Loss: 173.1968, KL Loss: 149.4161\n",
      "水头模型 Epoch 036/500 | 训练损失: 238.1579 | 验证损失: 26.1523 | LR: 0.000658\n",
      "水头验证指标 - MSE: 26.6575, RMSE: 5.1329, MAE: 4.2740, R2: 0.1501\n",
      "水头模型 Epoch 37, Batch 0: Total Loss: 258.2250, Criterion Loss: 109.2625, Physics Loss: 233.4011, KL Loss: 148.9624\n",
      "水头模型 Epoch 037/500 | 训练损失: 238.8182 | 验证损失: 17.3707 | LR: 0.000621\n",
      "水头验证指标 - MSE: 17.5961, RMSE: 4.1767, MAE: 3.3849, R2: 0.4436\n",
      "水头模型 Epoch 38, Batch 0: Total Loss: 209.1008, Criterion Loss: 60.8089, Physics Loss: 150.6498, KL Loss: 148.2919\n",
      "水头模型 Epoch 038/500 | 训练损失: 228.8662 | 验证损失: 34.7380 | LR: 0.000582\n",
      "水头验证指标 - MSE: 35.9711, RMSE: 5.9348, MAE: 5.0100, R2: -0.1095\n",
      "水头模型 Epoch 39, Batch 0: Total Loss: 244.2509, Criterion Loss: 96.7556, Physics Loss: 191.8882, KL Loss: 147.4953\n",
      "水头模型 Epoch 039/500 | 训练损失: 223.7210 | 验证损失: 21.4526 | LR: 0.000544\n",
      "水头验证指标 - MSE: 22.0026, RMSE: 4.6559, MAE: 3.8459, R2: 0.2942\n",
      "水头模型 Epoch 40, Batch 0: Total Loss: 248.5012, Criterion Loss: 101.9719, Physics Loss: 221.1973, KL Loss: 146.5293\n",
      "水头模型 Epoch 040/500 | 训练损失: 229.0627 | 验证损失: 17.0147 | LR: 0.000505\n",
      "水头验证指标 - MSE: 17.0212, RMSE: 4.0991, MAE: 3.2773, R2: 0.4764\n",
      "水头模型 Epoch 41, Batch 0: Total Loss: 208.6867, Criterion Loss: 62.3159, Physics Loss: 156.3503, KL Loss: 146.3707\n",
      "水头模型 Epoch 041/500 | 训练损失: 214.6127 | 验证损失: 14.8287 | LR: 0.000466\n",
      "水头验证指标 - MSE: 14.8386, RMSE: 3.8391, MAE: 3.0856, R2: 0.5371\n",
      "保存基于损失的最佳水头模型，验证损失: 14.8287\n",
      "保存基于R2的最佳水头模型，R2: 0.5371\n",
      "水头模型 Epoch 42, Batch 0: Total Loss: 221.8811, Criterion Loss: 75.8671, Physics Loss: 161.3326, KL Loss: 146.0140\n",
      "水头模型 Epoch 042/500 | 训练损失: 221.1405 | 验证损失: 16.2572 | LR: 0.000428\n",
      "水头验证指标 - MSE: 16.3729, RMSE: 4.0059, MAE: 3.1806, R2: 0.4922\n",
      "水头模型 Epoch 43, Batch 0: Total Loss: 202.2882, Criterion Loss: 57.3140, Physics Loss: 145.2618, KL Loss: 144.9742\n",
      "水头模型 Epoch 043/500 | 训练损失: 223.6657 | 验证损失: 17.3600 | LR: 0.000389\n",
      "水头验证指标 - MSE: 17.0536, RMSE: 4.1038, MAE: 3.2664, R2: 0.4703\n",
      "水头模型 Epoch 44, Batch 0: Total Loss: 235.7383, Criterion Loss: 91.5394, Physics Loss: 184.8652, KL Loss: 144.1989\n",
      "水头模型 Epoch 044/500 | 训练损失: 233.2879 | 验证损失: 16.2383 | LR: 0.000352\n",
      "水头验证指标 - MSE: 16.0818, RMSE: 3.9885, MAE: 3.1908, R2: 0.4993\n",
      "水头模型 Epoch 45, Batch 0: Total Loss: 205.4714, Criterion Loss: 61.1340, Physics Loss: 148.9733, KL Loss: 144.3374\n",
      "水头模型 Epoch 045/500 | 训练损失: 207.3334 | 验证损失: 16.7242 | LR: 0.000316\n",
      "水头验证指标 - MSE: 16.2548, RMSE: 4.0196, MAE: 3.1973, R2: 0.4934\n",
      "水头模型 Epoch 46, Batch 0: Total Loss: 206.8963, Criterion Loss: 63.1458, Physics Loss: 164.3404, KL Loss: 143.7505\n",
      "水头模型 Epoch 046/500 | 训练损失: 222.9969 | 验证损失: 16.5354 | LR: 0.000280\n",
      "水头验证指标 - MSE: 16.5352, RMSE: 4.0179, MAE: 3.1792, R2: 0.4978\n",
      "水头模型 Epoch 47, Batch 0: Total Loss: 199.6033, Criterion Loss: 56.5553, Physics Loss: 150.7616, KL Loss: 143.0480\n",
      "水头模型 Epoch 047/500 | 训练损失: 209.9183 | 验证损失: 15.1631 | LR: 0.000246\n",
      "水头验证指标 - MSE: 15.1158, RMSE: 3.8698, MAE: 3.1179, R2: 0.5239\n",
      "水头模型 Epoch 48, Batch 0: Total Loss: 199.0434, Criterion Loss: 56.3165, Physics Loss: 143.1316, KL Loss: 142.7269\n",
      "水头模型 Epoch 048/500 | 训练损失: 207.4138 | 验证损失: 23.6816 | LR: 0.000214\n",
      "水头验证指标 - MSE: 24.6198, RMSE: 4.8934, MAE: 3.9950, R2: 0.2487\n",
      "水头模型 Epoch 49, Batch 0: Total Loss: 306.5117, Criterion Loss: 164.0479, Physics Loss: 250.1336, KL Loss: 142.4639\n",
      "水头模型 Epoch 049/500 | 训练损失: 217.1489 | 验证损失: 15.3206 | LR: 0.000184\n",
      "水头验证指标 - MSE: 15.4155, RMSE: 3.8965, MAE: 3.1245, R2: 0.5266\n",
      "水头模型 Epoch 50, Batch 0: Total Loss: 219.2014, Criterion Loss: 76.5384, Physics Loss: 160.8999, KL Loss: 142.6630\n",
      "水头模型 Epoch 050/500 | 训练损失: 212.3465 | 验证损失: 23.1699 | LR: 0.000155\n",
      "水头验证指标 - MSE: 23.8776, RMSE: 4.7928, MAE: 3.9404, R2: 0.2716\n",
      "水头模型 Epoch 51, Batch 0: Total Loss: 202.0196, Criterion Loss: 59.6853, Physics Loss: 142.3474, KL Loss: 142.3344\n",
      "水头模型 Epoch 051/500 | 训练损失: 217.8411 | 验证损失: 15.1190 | LR: 0.000129\n",
      "水头验证指标 - MSE: 15.1639, RMSE: 3.8863, MAE: 3.1146, R2: 0.5216\n",
      "水头模型 Epoch 52, Batch 0: Total Loss: 226.9164, Criterion Loss: 84.9632, Physics Loss: 185.5730, KL Loss: 141.9532\n",
      "水头模型 Epoch 052/500 | 训练损失: 208.2583 | 验证损失: 13.2648 | LR: 0.000105\n",
      "水头验证指标 - MSE: 13.1537, RMSE: 3.6122, MAE: 2.8736, R2: 0.5910\n",
      "保存基于损失的最佳水头模型，验证损失: 13.2648\n",
      "保存基于R2的最佳水头模型，R2: 0.5910\n",
      "水头模型 Epoch 53, Batch 0: Total Loss: 197.7173, Criterion Loss: 55.7110, Physics Loss: 140.2124, KL Loss: 142.0064\n",
      "水头模型 Epoch 053/500 | 训练损失: 211.3492 | 验证损失: 15.0922 | LR: 0.000083\n",
      "水头验证指标 - MSE: 15.1752, RMSE: 3.8694, MAE: 3.0952, R2: 0.5244\n",
      "水头模型 Epoch 54, Batch 0: Total Loss: 200.1990, Criterion Loss: 58.5542, Physics Loss: 149.7485, KL Loss: 141.6447\n",
      "水头模型 Epoch 054/500 | 训练损失: 206.6042 | 验证损失: 13.3810 | LR: 0.000064\n",
      "水头验证指标 - MSE: 13.3008, RMSE: 3.6298, MAE: 2.8903, R2: 0.5894\n",
      "水头模型 Epoch 55, Batch 0: Total Loss: 201.1318, Criterion Loss: 59.2588, Physics Loss: 152.0215, KL Loss: 141.8730\n",
      "水头模型 Epoch 055/500 | 训练损失: 204.7071 | 验证损失: 14.1742 | LR: 0.000048\n",
      "水头验证指标 - MSE: 14.2037, RMSE: 3.7425, MAE: 2.9813, R2: 0.5623\n",
      "水头模型 Epoch 56, Batch 0: Total Loss: 215.1687, Criterion Loss: 74.0849, Physics Loss: 170.8619, KL Loss: 141.0838\n",
      "水头模型 Epoch 056/500 | 训练损失: 208.0020 | 验证损失: 13.8968 | LR: 0.000034\n",
      "水头验证指标 - MSE: 13.8554, RMSE: 3.6962, MAE: 2.9497, R2: 0.5739\n",
      "水头模型 Epoch 57, Batch 0: Total Loss: 271.0987, Criterion Loss: 129.4070, Physics Loss: 213.4988, KL Loss: 141.6916\n",
      "水头模型 Epoch 057/500 | 训练损失: 215.7301 | 验证损失: 14.0359 | LR: 0.000024\n",
      "水头验证指标 - MSE: 14.0449, RMSE: 3.7180, MAE: 2.9562, R2: 0.5665\n",
      "水头模型 Epoch 58, Batch 0: Total Loss: 196.1049, Criterion Loss: 54.4730, Physics Loss: 143.5653, KL Loss: 141.6319\n",
      "水头模型 Epoch 058/500 | 训练损失: 209.0549 | 验证损失: 14.7925 | LR: 0.000016\n",
      "水头验证指标 - MSE: 14.8701, RMSE: 3.8228, MAE: 3.0523, R2: 0.5379\n",
      "水头模型 Epoch 59, Batch 0: Total Loss: 225.9663, Criterion Loss: 84.5881, Physics Loss: 168.2367, KL Loss: 141.3782\n",
      "水头模型 Epoch 059/500 | 训练损失: 208.5339 | 验证损失: 13.2160 | LR: 0.000012\n",
      "水头验证指标 - MSE: 13.1334, RMSE: 3.6056, MAE: 2.8704, R2: 0.5945\n",
      "保存基于损失的最佳水头模型，验证损失: 13.2160\n",
      "保存基于R2的最佳水头模型，R2: 0.5945\n",
      "水头模型 Epoch 60, Batch 0: Total Loss: 197.6515, Criterion Loss: 56.0583, Physics Loss: 139.9576, KL Loss: 141.5932\n",
      "水头模型 Epoch 060/500 | 训练损失: 203.3472 | 验证损失: 14.3344 | LR: 0.001000\n",
      "水头验证指标 - MSE: 14.4027, RMSE: 3.7588, MAE: 3.0046, R2: 0.5598\n",
      "水头模型 Epoch 61, Batch 0: Total Loss: 202.9497, Criterion Loss: 61.4706, Physics Loss: 144.1422, KL Loss: 141.4791\n",
      "水头模型 Epoch 061/500 | 训练损失: 211.6367 | 验证损失: 50.6970 | LR: 0.001000\n",
      "水头验证指标 - MSE: 54.2418, RMSE: 7.2389, MAE: 6.3977, R2: -0.6614\n",
      "水头模型 Epoch 62, Batch 0: Total Loss: 220.2795, Criterion Loss: 79.9582, Physics Loss: 158.7378, KL Loss: 140.3213\n",
      "水头模型 Epoch 062/500 | 训练损失: 220.1429 | 验证损失: 23.2566 | LR: 0.000998\n",
      "水头验证指标 - MSE: 23.9160, RMSE: 4.8097, MAE: 3.8722, R2: 0.2729\n",
      "水头模型 Epoch 63, Batch 0: Total Loss: 200.8911, Criterion Loss: 60.8581, Physics Loss: 141.2492, KL Loss: 140.0330\n",
      "水头模型 Epoch 063/500 | 训练损失: 222.9512 | 验证损失: 16.6359 | LR: 0.000997\n",
      "水头验证指标 - MSE: 16.4914, RMSE: 4.0287, MAE: 3.1823, R2: 0.4937\n",
      "水头模型 Epoch 64, Batch 0: Total Loss: 201.8318, Criterion Loss: 62.3881, Physics Loss: 156.6792, KL Loss: 139.4436\n",
      "水头模型 Epoch 064/500 | 训练损失: 206.5965 | 验证损失: 31.0631 | LR: 0.000994\n",
      "水头验证指标 - MSE: 32.5567, RMSE: 5.6415, MAE: 4.8030, R2: -0.0410\n",
      "水头模型 Epoch 65, Batch 0: Total Loss: 201.5866, Criterion Loss: 62.8180, Physics Loss: 154.3338, KL Loss: 138.7686\n",
      "水头模型 Epoch 065/500 | 训练损失: 217.1653 | 验证损失: 18.5559 | LR: 0.000990\n",
      "水头验证指标 - MSE: 17.9179, RMSE: 4.2257, MAE: 3.3920, R2: 0.4296\n",
      "水头模型 Epoch 66, Batch 0: Total Loss: 209.7701, Criterion Loss: 71.5426, Physics Loss: 162.4733, KL Loss: 138.2275\n",
      "水头模型 Epoch 066/500 | 训练损失: 203.3519 | 验证损失: 18.0808 | LR: 0.000986\n",
      "水头验证指标 - MSE: 18.5023, RMSE: 4.2177, MAE: 3.4086, R2: 0.4413\n",
      "水头模型 Epoch 67, Batch 0: Total Loss: 234.2296, Criterion Loss: 97.1898, Physics Loss: 174.5987, KL Loss: 137.0398\n",
      "水头模型 Epoch 067/500 | 训练损失: 204.5665 | 验证损失: 31.5686 | LR: 0.000981\n",
      "水头验证指标 - MSE: 32.3672, RMSE: 5.6489, MAE: 4.7432, R2: -0.0493\n",
      "水头模型 Epoch 68, Batch 0: Total Loss: 211.4044, Criterion Loss: 75.3050, Physics Loss: 177.8901, KL Loss: 136.0995\n",
      "水头模型 Epoch 068/500 | 训练损失: 223.5282 | 验证损失: 15.7622 | LR: 0.000976\n",
      "水头验证指标 - MSE: 15.4355, RMSE: 3.9146, MAE: 3.1059, R2: 0.5213\n",
      "水头模型 Epoch 69, Batch 0: Total Loss: 205.3972, Criterion Loss: 69.3938, Physics Loss: 150.0705, KL Loss: 136.0034\n",
      "水头模型 Epoch 069/500 | 训练损失: 203.5492 | 验证损失: 14.8438 | LR: 0.000969\n",
      "水头验证指标 - MSE: 14.5231, RMSE: 3.7830, MAE: 3.0226, R2: 0.5464\n",
      "水头模型 Epoch 70, Batch 0: Total Loss: 200.4621, Criterion Loss: 64.9017, Physics Loss: 158.9147, KL Loss: 135.5603\n",
      "水头模型 Epoch 070/500 | 训练损失: 194.3165 | 验证损失: 17.5856 | LR: 0.000962\n",
      "水头验证指标 - MSE: 17.6655, RMSE: 4.1811, MAE: 3.3681, R2: 0.4381\n",
      "水头模型 Epoch 71, Batch 0: Total Loss: 185.3347, Criterion Loss: 50.8970, Physics Loss: 131.9942, KL Loss: 134.4377\n",
      "水头模型 Epoch 071/500 | 训练损失: 196.1762 | 验证损失: 20.9895 | LR: 0.000955\n",
      "水头验证指标 - MSE: 20.8543, RMSE: 4.5203, MAE: 3.5981, R2: 0.3601\n",
      "水头模型 Epoch 72, Batch 0: Total Loss: 190.1547, Criterion Loss: 56.6712, Physics Loss: 138.0041, KL Loss: 133.4835\n",
      "水头模型 Epoch 072/500 | 训练损失: 205.6832 | 验证损失: 25.0022 | LR: 0.000946\n",
      "水头验证指标 - MSE: 25.8525, RMSE: 5.0486, MAE: 4.2319, R2: 0.1660\n",
      "水头模型 Epoch 73, Batch 0: Total Loss: 179.5004, Criterion Loss: 47.0971, Physics Loss: 122.5348, KL Loss: 132.4033\n",
      "水头模型 Epoch 073/500 | 训练损失: 188.0763 | 验证损失: 15.3632 | LR: 0.000937\n",
      "水头验证指标 - MSE: 14.9868, RMSE: 3.8635, MAE: 3.0813, R2: 0.5308\n",
      "水头模型 Epoch 74, Batch 0: Total Loss: 181.8005, Criterion Loss: 49.9021, Physics Loss: 128.6831, KL Loss: 131.8984\n",
      "水头模型 Epoch 074/500 | 训练损失: 186.8567 | 验证损失: 18.5150 | LR: 0.000927\n",
      "水头验证指标 - MSE: 18.7460, RMSE: 4.2717, MAE: 3.4511, R2: 0.4237\n",
      "水头模型 Epoch 75, Batch 0: Total Loss: 180.4724, Criterion Loss: 49.2626, Physics Loss: 125.7698, KL Loss: 131.2098\n",
      "水头模型 Epoch 075/500 | 训练损失: 192.2823 | 验证损失: 26.6737 | LR: 0.000917\n",
      "水头验证指标 - MSE: 27.8381, RMSE: 5.2298, MAE: 4.3813, R2: 0.1184\n",
      "水头模型 Epoch 76, Batch 0: Total Loss: 175.3193, Criterion Loss: 45.0403, Physics Loss: 119.3565, KL Loss: 130.2791\n",
      "水头模型 Epoch 076/500 | 训练损失: 202.5086 | 验证损失: 30.7521 | LR: 0.000905\n",
      "水头验证指标 - MSE: 31.5311, RMSE: 5.5870, MAE: 4.6561, R2: -0.0181\n",
      "水头模型 Epoch 77, Batch 0: Total Loss: 194.8309, Criterion Loss: 65.3825, Physics Loss: 156.5923, KL Loss: 129.4485\n",
      "水头模型 Epoch 077/500 | 训练损失: 187.7080 | 验证损失: 18.1422 | LR: 0.000894\n",
      "水头验证指标 - MSE: 17.7714, RMSE: 4.2072, MAE: 3.3864, R2: 0.4363\n",
      "水头模型 Epoch 78, Batch 0: Total Loss: 182.1005, Criterion Loss: 53.3322, Physics Loss: 134.8789, KL Loss: 128.7683\n",
      "水头模型 Epoch 078/500 | 训练损失: 186.4270 | 验证损失: 41.9045 | LR: 0.000881\n",
      "水头验证指标 - MSE: 43.8404, RMSE: 6.5617, MAE: 5.5896, R2: -0.3542\n",
      "水头模型 Epoch 79, Batch 0: Total Loss: 208.3247, Criterion Loss: 80.0933, Physics Loss: 157.7009, KL Loss: 128.2315\n",
      "水头模型 Epoch 079/500 | 训练损失: 191.6145 | 验证损失: 21.9853 | LR: 0.000868\n",
      "水头验证指标 - MSE: 22.9528, RMSE: 4.7385, MAE: 3.8863, R2: 0.2963\n",
      "水头模型 Epoch 80, Batch 0: Total Loss: 172.9544, Criterion Loss: 45.3348, Physics Loss: 114.5888, KL Loss: 127.6196\n",
      "水头模型 Epoch 080/500 | 训练损失: 183.0938 | 验证损失: 24.4325 | LR: 0.000855\n",
      "水头验证指标 - MSE: 25.3632, RMSE: 4.9627, MAE: 4.1970, R2: 0.1689\n",
      "水头模型 Epoch 81, Batch 0: Total Loss: 191.3401, Criterion Loss: 64.0424, Physics Loss: 141.4797, KL Loss: 127.2977\n",
      "水头模型 Epoch 081/500 | 训练损失: 188.5372 | 验证损失: 17.3787 | LR: 0.000841\n",
      "水头验证指标 - MSE: 17.1290, RMSE: 4.1311, MAE: 3.1585, R2: 0.4645\n",
      "水头模型 Epoch 82, Batch 0: Total Loss: 178.4070, Criterion Loss: 51.6540, Physics Loss: 128.5134, KL Loss: 126.7530\n",
      "水头模型 Epoch 082/500 | 训练损失: 183.4891 | 验证损失: 21.9874 | LR: 0.000826\n",
      "水头验证指标 - MSE: 22.7676, RMSE: 4.7121, MAE: 3.8678, R2: 0.3035\n",
      "水头模型 Epoch 83, Batch 0: Total Loss: 167.6200, Criterion Loss: 41.8217, Physics Loss: 111.0258, KL Loss: 125.7983\n",
      "水头模型 Epoch 083/500 | 训练损失: 190.6943 | 验证损失: 24.4520 | LR: 0.000811\n",
      "水头验证指标 - MSE: 25.2311, RMSE: 4.9787, MAE: 4.1897, R2: 0.1863\n",
      "水头模型 Epoch 84, Batch 0: Total Loss: 178.4124, Criterion Loss: 52.9314, Physics Loss: 129.4001, KL Loss: 125.4810\n",
      "水头模型 Epoch 084/500 | 训练损失: 177.9484 | 验证损失: 23.4484 | LR: 0.000796\n",
      "水头验证指标 - MSE: 23.8434, RMSE: 4.8397, MAE: 4.0476, R2: 0.2375\n",
      "水头模型 Epoch 85, Batch 0: Total Loss: 168.5578, Criterion Loss: 43.4463, Physics Loss: 112.5525, KL Loss: 125.1115\n",
      "水头模型 Epoch 085/500 | 训练损失: 174.1735 | 验证损失: 13.1509 | LR: 0.000780\n",
      "水头验证指标 - MSE: 13.0326, RMSE: 3.5888, MAE: 2.8312, R2: 0.5991\n",
      "保存基于损失的最佳水头模型，验证损失: 13.1509\n",
      "保存基于R2的最佳水头模型，R2: 0.5991\n",
      "水头模型 Epoch 86, Batch 0: Total Loss: 163.6783, Criterion Loss: 39.8159, Physics Loss: 108.7815, KL Loss: 123.8624\n",
      "水头模型 Epoch 086/500 | 训练损失: 173.1071 | 验证损失: 22.2219 | LR: 0.000764\n",
      "水头验证指标 - MSE: 22.8757, RMSE: 4.7219, MAE: 3.8766, R2: 0.3014\n",
      "水头模型 Epoch 87, Batch 0: Total Loss: 191.1638, Criterion Loss: 67.7876, Physics Loss: 133.5604, KL Loss: 123.3762\n",
      "水头模型 Epoch 087/500 | 训练损失: 178.5582 | 验证损失: 14.3296 | LR: 0.000747\n",
      "水头验证指标 - MSE: 13.7863, RMSE: 3.6900, MAE: 2.9338, R2: 0.5752\n",
      "水头模型 Epoch 88, Batch 0: Total Loss: 166.7114, Criterion Loss: 43.8131, Physics Loss: 121.8053, KL Loss: 122.8983\n",
      "水头模型 Epoch 088/500 | 训练损失: 172.9577 | 验证损失: 12.4798 | LR: 0.000730\n",
      "水头验证指标 - MSE: 12.3271, RMSE: 3.5034, MAE: 2.8011, R2: 0.6121\n",
      "保存基于损失的最佳水头模型，验证损失: 12.4798\n",
      "保存基于R2的最佳水头模型，R2: 0.6121\n",
      "水头模型 Epoch 89, Batch 0: Total Loss: 161.6002, Criterion Loss: 39.5137, Physics Loss: 106.9783, KL Loss: 122.0865\n",
      "水头模型 Epoch 089/500 | 训练损失: 173.3874 | 验证损失: 18.6474 | LR: 0.000712\n",
      "水头验证指标 - MSE: 18.8512, RMSE: 4.2945, MAE: 3.5068, R2: 0.4084\n",
      "水头模型 Epoch 90, Batch 0: Total Loss: 166.4982, Criterion Loss: 45.7161, Physics Loss: 113.6910, KL Loss: 120.7822\n",
      "水头模型 Epoch 090/500 | 训练损失: 171.0210 | 验证损失: 15.2850 | LR: 0.000694\n",
      "水头验证指标 - MSE: 14.9612, RMSE: 3.8489, MAE: 3.0685, R2: 0.5376\n",
      "水头模型 Epoch 91, Batch 0: Total Loss: 171.6621, Criterion Loss: 51.1043, Physics Loss: 122.5903, KL Loss: 120.5578\n",
      "水头模型 Epoch 091/500 | 训练损失: 167.8076 | 验证损失: 15.2433 | LR: 0.000676\n",
      "水头验证指标 - MSE: 14.9684, RMSE: 3.8545, MAE: 3.0850, R2: 0.5304\n",
      "水头模型 Epoch 92, Batch 0: Total Loss: 164.6735, Criterion Loss: 44.5304, Physics Loss: 114.8904, KL Loss: 120.1432\n",
      "水头模型 Epoch 092/500 | 训练损失: 175.5073 | 验证损失: 18.7844 | LR: 0.000658\n",
      "水头验证指标 - MSE: 18.5488, RMSE: 4.2927, MAE: 3.3853, R2: 0.4129\n",
      "水头模型 Epoch 93, Batch 0: Total Loss: 164.0357, Criterion Loss: 44.4064, Physics Loss: 110.1963, KL Loss: 119.6292\n",
      "水头模型 Epoch 093/500 | 训练损失: 164.7824 | 验证损失: 11.9428 | LR: 0.000639\n",
      "水头验证指标 - MSE: 11.8591, RMSE: 3.4338, MAE: 2.7549, R2: 0.6288\n",
      "保存基于损失的最佳水头模型，验证损失: 11.9428\n",
      "保存基于R2的最佳水头模型，R2: 0.6288\n",
      "水头模型 Epoch 94, Batch 0: Total Loss: 162.7615, Criterion Loss: 43.5958, Physics Loss: 107.6696, KL Loss: 119.1658\n",
      "水头模型 Epoch 094/500 | 训练损失: 170.5142 | 验证损失: 17.9854 | LR: 0.000621\n",
      "水头验证指标 - MSE: 18.4149, RMSE: 4.2107, MAE: 3.4188, R2: 0.4447\n",
      "水头模型 Epoch 95, Batch 0: Total Loss: 156.6502, Criterion Loss: 38.4029, Physics Loss: 102.1803, KL Loss: 118.2473\n",
      "水头模型 Epoch 095/500 | 训练损失: 164.4566 | 验证损失: 12.2168 | LR: 0.000602\n",
      "水头验证指标 - MSE: 11.9163, RMSE: 3.4321, MAE: 2.7297, R2: 0.6317\n",
      "保存基于R2的最佳水头模型，R2: 0.6317\n",
      "水头模型 Epoch 96, Batch 0: Total Loss: 167.4707, Criterion Loss: 49.7237, Physics Loss: 111.2920, KL Loss: 117.7470\n",
      "水头模型 Epoch 096/500 | 训练损失: 165.6709 | 验证损失: 17.3343 | LR: 0.000582\n",
      "水头验证指标 - MSE: 17.0295, RMSE: 4.1144, MAE: 3.3011, R2: 0.4651\n",
      "水头模型 Epoch 97, Batch 0: Total Loss: 164.6694, Criterion Loss: 47.1244, Physics Loss: 122.3388, KL Loss: 117.5450\n",
      "水头模型 Epoch 097/500 | 训练损失: 162.4947 | 验证损失: 14.3708 | LR: 0.000563\n",
      "水头验证指标 - MSE: 14.5779, RMSE: 3.7652, MAE: 2.9971, R2: 0.5579\n",
      "水头模型 Epoch 98, Batch 0: Total Loss: 154.9107, Criterion Loss: 37.9257, Physics Loss: 104.3570, KL Loss: 116.9851\n",
      "水头模型 Epoch 098/500 | 训练损失: 166.4071 | 验证损失: 14.4490 | LR: 0.000544\n",
      "水头验证指标 - MSE: 14.4328, RMSE: 3.7873, MAE: 2.9928, R2: 0.5489\n",
      "水头模型 Epoch 99, Batch 0: Total Loss: 157.5322, Criterion Loss: 40.6545, Physics Loss: 106.7159, KL Loss: 116.8777\n",
      "水头模型 Epoch 099/500 | 训练损失: 166.3428 | 验证损失: 12.5203 | LR: 0.000524\n",
      "水头验证指标 - MSE: 12.4776, RMSE: 3.5107, MAE: 2.7791, R2: 0.6119\n",
      "水头模型 Epoch 100, Batch 0: Total Loss: 165.3539, Criterion Loss: 49.6764, Physics Loss: 118.9926, KL Loss: 115.6775\n",
      "水头模型 Epoch 100/500 | 训练损失: 162.9260 | 验证损失: 13.5436 | LR: 0.000505\n",
      "水头验证指标 - MSE: 13.4284, RMSE: 3.6475, MAE: 2.9187, R2: 0.5782\n",
      "水头模型 Epoch 101, Batch 0: Total Loss: 156.9759, Criterion Loss: 41.2287, Physics Loss: 110.0354, KL Loss: 115.7471\n",
      "水头模型 Epoch 101/500 | 训练损失: 166.8911 | 验证损失: 11.1354 | LR: 0.000486\n",
      "水头验证指标 - MSE: 11.0287, RMSE: 3.3100, MAE: 2.6255, R2: 0.6569\n",
      "保存基于损失的最佳水头模型，验证损失: 11.1354\n",
      "保存基于R2的最佳水头模型，R2: 0.6569\n",
      "水头模型 Epoch 102, Batch 0: Total Loss: 154.9617, Criterion Loss: 39.3272, Physics Loss: 100.3372, KL Loss: 115.6345\n",
      "水头模型 Epoch 102/500 | 训练损失: 159.3102 | 验证损失: 13.0298 | LR: 0.000466\n",
      "水头验证指标 - MSE: 13.0085, RMSE: 3.5645, MAE: 2.8462, R2: 0.6027\n",
      "水头模型 Epoch 103, Batch 0: Total Loss: 153.3003, Criterion Loss: 38.5120, Physics Loss: 101.1851, KL Loss: 114.7882\n",
      "水头模型 Epoch 103/500 | 训练损失: 161.3951 | 验证损失: 12.3512 | LR: 0.000447\n",
      "水头验证指标 - MSE: 12.0400, RMSE: 3.4608, MAE: 2.7685, R2: 0.6228\n",
      "水头模型 Epoch 104, Batch 0: Total Loss: 160.8772, Criterion Loss: 45.9388, Physics Loss: 119.8114, KL Loss: 114.9384\n",
      "水头模型 Epoch 104/500 | 训练损失: 158.3022 | 验证损失: 12.2835 | LR: 0.000428\n",
      "水头验证指标 - MSE: 11.6265, RMSE: 3.3948, MAE: 2.6829, R2: 0.6403\n",
      "水头模型 Epoch 105, Batch 0: Total Loss: 153.2141, Criterion Loss: 38.6869, Physics Loss: 103.8246, KL Loss: 114.5272\n",
      "水头模型 Epoch 105/500 | 训练损失: 156.6746 | 验证损失: 11.5638 | LR: 0.000408\n",
      "水头验证指标 - MSE: 11.4731, RMSE: 3.3729, MAE: 2.6822, R2: 0.6449\n",
      "水头模型 Epoch 106, Batch 0: Total Loss: 162.7633, Criterion Loss: 48.6631, Physics Loss: 109.5716, KL Loss: 114.1002\n",
      "水头模型 Epoch 106/500 | 训练损失: 158.4873 | 验证损失: 11.2861 | LR: 0.000389\n",
      "水头验证指标 - MSE: 11.1100, RMSE: 3.3205, MAE: 2.6318, R2: 0.6532\n",
      "水头模型 Epoch 107, Batch 0: Total Loss: 169.3699, Criterion Loss: 55.6325, Physics Loss: 130.2330, KL Loss: 113.7374\n",
      "水头模型 Epoch 107/500 | 训练损失: 159.5847 | 验证损失: 11.5572 | LR: 0.000371\n",
      "水头验证指标 - MSE: 11.4576, RMSE: 3.3558, MAE: 2.6769, R2: 0.6469\n",
      "水头模型 Epoch 108, Batch 0: Total Loss: 154.0394, Criterion Loss: 41.2716, Physics Loss: 106.0611, KL Loss: 112.7677\n",
      "水头模型 Epoch 108/500 | 训练损失: 156.9319 | 验证损失: 11.5626 | LR: 0.000352\n",
      "水头验证指标 - MSE: 11.4690, RMSE: 3.3780, MAE: 2.7026, R2: 0.6396\n",
      "水头模型 Epoch 109, Batch 0: Total Loss: 148.4678, Criterion Loss: 35.6975, Physics Loss: 98.6347, KL Loss: 112.7703\n",
      "水头模型 Epoch 109/500 | 训练损失: 155.4519 | 验证损失: 12.0142 | LR: 0.000334\n",
      "水头验证指标 - MSE: 12.0301, RMSE: 3.4326, MAE: 2.7210, R2: 0.6304\n",
      "水头模型 Epoch 110, Batch 0: Total Loss: 148.6480, Criterion Loss: 36.2199, Physics Loss: 95.5450, KL Loss: 112.4281\n",
      "水头模型 Epoch 110/500 | 训练损失: 157.2426 | 验证损失: 11.4966 | LR: 0.000316\n",
      "水头验证指标 - MSE: 11.4786, RMSE: 3.3684, MAE: 2.6904, R2: 0.6462\n",
      "水头模型 Epoch 111, Batch 0: Total Loss: 149.4942, Criterion Loss: 37.4075, Physics Loss: 98.6064, KL Loss: 112.0867\n",
      "水头模型 Epoch 111/500 | 训练损失: 153.5367 | 验证损失: 10.6801 | LR: 0.000298\n",
      "水头验证指标 - MSE: 10.4543, RMSE: 3.2252, MAE: 2.5549, R2: 0.6738\n",
      "保存基于损失的最佳水头模型，验证损失: 10.6801\n",
      "保存基于R2的最佳水头模型，R2: 0.6738\n",
      "水头模型 Epoch 112, Batch 0: Total Loss: 158.9755, Criterion Loss: 47.0338, Physics Loss: 110.4953, KL Loss: 111.9417\n",
      "水头模型 Epoch 112/500 | 训练损失: 156.6622 | 验证损失: 11.6573 | LR: 0.000280\n",
      "水头验证指标 - MSE: 11.5050, RMSE: 3.3731, MAE: 2.7117, R2: 0.6391\n",
      "水头模型 Epoch 113, Batch 0: Total Loss: 148.7424, Criterion Loss: 37.5420, Physics Loss: 102.8150, KL Loss: 111.2003\n",
      "水头模型 Epoch 113/500 | 训练损失: 152.8543 | 验证损失: 11.8390 | LR: 0.000263\n",
      "水头验证指标 - MSE: 11.6299, RMSE: 3.3890, MAE: 2.6876, R2: 0.6405\n",
      "水头模型 Epoch 114, Batch 0: Total Loss: 149.5759, Criterion Loss: 38.1747, Physics Loss: 99.9126, KL Loss: 111.4012\n",
      "水头模型 Epoch 114/500 | 训练损失: 151.7798 | 验证损失: 12.2793 | LR: 0.000246\n",
      "水头验证指标 - MSE: 12.1232, RMSE: 3.4696, MAE: 2.7839, R2: 0.6165\n",
      "水头模型 Epoch 115, Batch 0: Total Loss: 165.0837, Criterion Loss: 54.3175, Physics Loss: 113.5041, KL Loss: 110.7663\n",
      "水头模型 Epoch 115/500 | 训练损失: 158.5081 | 验证损失: 10.5546 | LR: 0.000230\n",
      "水头验证指标 - MSE: 10.4201, RMSE: 3.2217, MAE: 2.5727, R2: 0.6738\n",
      "保存基于损失的最佳水头模型，验证损失: 10.5546\n",
      "水头模型 Epoch 116, Batch 0: Total Loss: 154.0286, Criterion Loss: 43.2049, Physics Loss: 103.6229, KL Loss: 110.8238\n",
      "水头模型 Epoch 116/500 | 训练损失: 154.3617 | 验证损失: 11.3657 | LR: 0.000214\n",
      "水头验证指标 - MSE: 11.2151, RMSE: 3.3317, MAE: 2.6424, R2: 0.6517\n",
      "水头模型 Epoch 117, Batch 0: Total Loss: 152.5719, Criterion Loss: 42.4930, Physics Loss: 102.6210, KL Loss: 110.0790\n",
      "水头模型 Epoch 117/500 | 训练损失: 153.4820 | 验证损失: 10.3946 | LR: 0.000199\n",
      "水头验证指标 - MSE: 10.2658, RMSE: 3.1829, MAE: 2.5041, R2: 0.6838\n",
      "保存基于损失的最佳水头模型，验证损失: 10.3946\n",
      "保存基于R2的最佳水头模型，R2: 0.6838\n",
      "水头模型 Epoch 118, Batch 0: Total Loss: 157.9398, Criterion Loss: 47.6516, Physics Loss: 110.3818, KL Loss: 110.2882\n",
      "水头模型 Epoch 118/500 | 训练损失: 151.1987 | 验证损失: 12.0660 | LR: 0.000184\n",
      "水头验证指标 - MSE: 12.0257, RMSE: 3.4355, MAE: 2.7218, R2: 0.6312\n",
      "水头模型 Epoch 119, Batch 0: Total Loss: 155.4213, Criterion Loss: 45.3116, Physics Loss: 108.6544, KL Loss: 110.1097\n",
      "水头模型 Epoch 119/500 | 训练损失: 153.1233 | 验证损失: 10.8034 | LR: 0.000169\n",
      "水头验证指标 - MSE: 10.7118, RMSE: 3.2418, MAE: 2.5761, R2: 0.6732\n",
      "水头模型 Epoch 120, Batch 0: Total Loss: 151.4657, Criterion Loss: 41.5366, Physics Loss: 101.5060, KL Loss: 109.9291\n",
      "水头模型 Epoch 120/500 | 训练损失: 154.7139 | 验证损失: 13.7276 | LR: 0.000155\n",
      "水头验证指标 - MSE: 13.9638, RMSE: 3.6700, MAE: 2.9458, R2: 0.5760\n",
      "水头模型 Epoch 121, Batch 0: Total Loss: 145.1992, Criterion Loss: 35.8223, Physics Loss: 95.0272, KL Loss: 109.3769\n",
      "水头模型 Epoch 121/500 | 训练损失: 151.7555 | 验证损失: 11.6613 | LR: 0.000142\n",
      "水头验证指标 - MSE: 11.4286, RMSE: 3.3715, MAE: 2.6965, R2: 0.6426\n",
      "水头模型 Epoch 122, Batch 0: Total Loss: 149.9972, Criterion Loss: 40.0296, Physics Loss: 103.1016, KL Loss: 109.9676\n",
      "水头模型 Epoch 122/500 | 训练损失: 152.2845 | 验证损失: 11.6030 | LR: 0.000129\n",
      "水头验证指标 - MSE: 11.5596, RMSE: 3.3713, MAE: 2.6951, R2: 0.6461\n",
      "水头模型 Epoch 123, Batch 0: Total Loss: 160.9659, Criterion Loss: 51.8801, Physics Loss: 114.7837, KL Loss: 109.0859\n",
      "水头模型 Epoch 123/500 | 训练损失: 149.8426 | 验证损失: 11.8525 | LR: 0.000116\n",
      "水头验证指标 - MSE: 11.8293, RMSE: 3.4050, MAE: 2.7071, R2: 0.6387\n",
      "水头模型 Epoch 124, Batch 0: Total Loss: 150.2934, Criterion Loss: 41.2348, Physics Loss: 102.3942, KL Loss: 109.0586\n",
      "水头模型 Epoch 124/500 | 训练损失: 152.6513 | 验证损失: 10.3271 | LR: 0.000105\n",
      "水头验证指标 - MSE: 10.1472, RMSE: 3.1735, MAE: 2.5242, R2: 0.6840\n",
      "保存基于损失的最佳水头模型，验证损失: 10.3271\n",
      "保存基于R2的最佳水头模型，R2: 0.6840\n",
      "水头模型 Epoch 125, Batch 0: Total Loss: 145.1982, Criterion Loss: 36.1502, Physics Loss: 94.3094, KL Loss: 109.0480\n",
      "水头模型 Epoch 125/500 | 训练损失: 150.3795 | 验证损失: 10.6366 | LR: 0.000093\n",
      "水头验证指标 - MSE: 10.4523, RMSE: 3.2145, MAE: 2.5450, R2: 0.6756\n",
      "水头模型 Epoch 126, Batch 0: Total Loss: 157.6932, Criterion Loss: 48.5775, Physics Loss: 112.7705, KL Loss: 109.1156\n",
      "水头模型 Epoch 126/500 | 训练损失: 149.1775 | 验证损失: 11.5287 | LR: 0.000083\n",
      "水头验证指标 - MSE: 11.4626, RMSE: 3.3729, MAE: 2.7136, R2: 0.6346\n",
      "水头模型 Epoch 127, Batch 0: Total Loss: 147.1180, Criterion Loss: 37.5909, Physics Loss: 98.7382, KL Loss: 109.5271\n",
      "水头模型 Epoch 127/500 | 训练损失: 150.1887 | 验证损失: 11.7652 | LR: 0.000073\n",
      "水头验证指标 - MSE: 11.7062, RMSE: 3.3889, MAE: 2.7224, R2: 0.6321\n",
      "水头模型 Epoch 128, Batch 0: Total Loss: 164.7431, Criterion Loss: 55.5441, Physics Loss: 113.6746, KL Loss: 109.1989\n",
      "水头模型 Epoch 128/500 | 训练损失: 151.2089 | 验证损失: 10.8502 | LR: 0.000064\n",
      "水头验证指标 - MSE: 10.6500, RMSE: 3.2522, MAE: 2.5872, R2: 0.6682\n",
      "水头模型 Epoch 129, Batch 0: Total Loss: 142.5831, Criterion Loss: 34.0346, Physics Loss: 93.1685, KL Loss: 108.5484\n",
      "水头模型 Epoch 129/500 | 训练损失: 149.8010 | 验证损失: 11.9849 | LR: 0.000055\n",
      "水头验证指标 - MSE: 11.9633, RMSE: 3.4149, MAE: 2.7095, R2: 0.6366\n",
      "水头模型 Epoch 130, Batch 0: Total Loss: 154.6490, Criterion Loss: 45.8940, Physics Loss: 105.1668, KL Loss: 108.7550\n",
      "水头模型 Epoch 130/500 | 训练损失: 150.0247 | 验证损失: 10.6326 | LR: 0.000048\n",
      "水头验证指标 - MSE: 10.4770, RMSE: 3.2164, MAE: 2.5442, R2: 0.6771\n",
      "水头模型 Epoch 131, Batch 0: Total Loss: 154.3643, Criterion Loss: 45.5908, Physics Loss: 108.2762, KL Loss: 108.7735\n",
      "水头模型 Epoch 131/500 | 训练损失: 150.8489 | 验证损失: 10.7977 | LR: 0.000041\n",
      "水头验证指标 - MSE: 10.6651, RMSE: 3.2559, MAE: 2.5927, R2: 0.6652\n",
      "水头模型 Epoch 132, Batch 0: Total Loss: 143.7227, Criterion Loss: 35.3597, Physics Loss: 94.8198, KL Loss: 108.3630\n",
      "水头模型 Epoch 132/500 | 训练损失: 153.9385 | 验证损失: 10.3277 | LR: 0.000034\n",
      "水头验证指标 - MSE: 10.1774, RMSE: 3.1749, MAE: 2.5252, R2: 0.6834\n",
      "水头模型 Epoch 133, Batch 0: Total Loss: 145.1851, Criterion Loss: 36.6713, Physics Loss: 97.8300, KL Loss: 108.5138\n",
      "水头模型 Epoch 133/500 | 训练损失: 150.3404 | 验证损失: 10.3193 | LR: 0.000029\n",
      "水头验证指标 - MSE: 10.1210, RMSE: 3.1567, MAE: 2.4913, R2: 0.6892\n",
      "保存基于损失的最佳水头模型，验证损失: 10.3193\n",
      "保存基于R2的最佳水头模型，R2: 0.6892\n",
      "水头模型 Epoch 134, Batch 0: Total Loss: 151.7966, Criterion Loss: 43.0316, Physics Loss: 105.5481, KL Loss: 108.7650\n",
      "水头模型 Epoch 134/500 | 训练损失: 149.9359 | 验证损失: 10.1397 | LR: 0.000024\n",
      "水头验证指标 - MSE: 9.9482, RMSE: 3.1443, MAE: 2.4900, R2: 0.6910\n",
      "保存基于损失的最佳水头模型，验证损失: 10.1397\n",
      "保存基于R2的最佳水头模型，R2: 0.6910\n",
      "水头模型 Epoch 135, Batch 0: Total Loss: 148.1875, Criterion Loss: 39.3488, Physics Loss: 98.7483, KL Loss: 108.8387\n",
      "水头模型 Epoch 135/500 | 训练损失: 153.1605 | 验证损失: 10.3793 | LR: 0.000020\n",
      "水头验证指标 - MSE: 10.2303, RMSE: 3.1915, MAE: 2.5466, R2: 0.6778\n",
      "水头模型 Epoch 136, Batch 0: Total Loss: 145.8884, Criterion Loss: 37.2725, Physics Loss: 97.0810, KL Loss: 108.6159\n",
      "水头模型 Epoch 136/500 | 训练损失: 154.5750 | 验证损失: 10.8432 | LR: 0.000016\n",
      "水头验证指标 - MSE: 10.6881, RMSE: 3.2407, MAE: 2.5759, R2: 0.6726\n",
      "水头模型 Epoch 137, Batch 0: Total Loss: 143.3492, Criterion Loss: 35.0293, Physics Loss: 93.0906, KL Loss: 108.3199\n",
      "水头模型 Epoch 137/500 | 训练损失: 151.3460 | 验证损失: 10.7093 | LR: 0.000013\n",
      "水头验证指标 - MSE: 10.5444, RMSE: 3.2290, MAE: 2.5663, R2: 0.6750\n",
      "水头模型 Epoch 138, Batch 0: Total Loss: 146.0861, Criterion Loss: 37.9447, Physics Loss: 95.9721, KL Loss: 108.1414\n",
      "水头模型 Epoch 138/500 | 训练损失: 149.9565 | 验证损失: 10.1827 | LR: 0.000012\n",
      "水头验证指标 - MSE: 9.9982, RMSE: 3.1488, MAE: 2.4903, R2: 0.6906\n",
      "水头模型 Epoch 139, Batch 0: Total Loss: 144.6987, Criterion Loss: 35.6871, Physics Loss: 96.1782, KL Loss: 109.0116\n",
      "水头模型 Epoch 139/500 | 训练损失: 152.3075 | 验证损失: 10.3564 | LR: 0.000010\n",
      "水头验证指标 - MSE: 10.1935, RMSE: 3.1745, MAE: 2.5182, R2: 0.6863\n",
      "水头模型 Epoch 140, Batch 0: Total Loss: 146.4928, Criterion Loss: 37.8132, Physics Loss: 101.3899, KL Loss: 108.6796\n",
      "水头模型 Epoch 140/500 | 训练损失: 150.1053 | 验证损失: 10.7826 | LR: 0.001000\n",
      "水头验证指标 - MSE: 10.6663, RMSE: 3.2544, MAE: 2.5802, R2: 0.6681\n",
      "水头模型 Epoch 141, Batch 0: Total Loss: 146.2979, Criterion Loss: 37.7828, Physics Loss: 98.0125, KL Loss: 108.5151\n",
      "水头模型 Epoch 141/500 | 训练损失: 153.2059 | 验证损失: 17.5062 | LR: 0.001000\n",
      "水头验证指标 - MSE: 16.8750, RMSE: 4.0973, MAE: 3.1156, R2: 0.4734\n",
      "水头模型 Epoch 142, Batch 0: Total Loss: 162.5588, Criterion Loss: 54.5615, Physics Loss: 125.5297, KL Loss: 107.9974\n",
      "水头模型 Epoch 142/500 | 训练损失: 152.9867 | 验证损失: 12.8954 | LR: 0.001000\n",
      "水头验证指标 - MSE: 12.7333, RMSE: 3.5613, MAE: 2.8361, R2: 0.5994\n",
      "水头模型 Epoch 143, Batch 0: Total Loss: 156.7198, Criterion Loss: 48.8939, Physics Loss: 116.9395, KL Loss: 107.8259\n",
      "水头模型 Epoch 143/500 | 训练损失: 151.6251 | 验证损失: 15.2544 | LR: 0.000999\n",
      "水头验证指标 - MSE: 14.9952, RMSE: 3.8511, MAE: 3.0192, R2: 0.5356\n",
      "水头模型 Epoch 144, Batch 0: Total Loss: 151.8654, Criterion Loss: 44.2704, Physics Loss: 110.6008, KL Loss: 107.5950\n",
      "水头模型 Epoch 144/500 | 训练损失: 149.5814 | 验证损失: 12.4630 | LR: 0.000998\n",
      "水头验证指标 - MSE: 12.0910, RMSE: 3.4726, MAE: 2.7635, R2: 0.6209\n",
      "水头模型 Epoch 145, Batch 0: Total Loss: 148.8015, Criterion Loss: 41.9874, Physics Loss: 111.2468, KL Loss: 106.8140\n",
      "水头模型 Epoch 145/500 | 训练损失: 150.1121 | 验证损失: 12.5481 | LR: 0.000998\n",
      "水头验证指标 - MSE: 12.2685, RMSE: 3.4910, MAE: 2.7931, R2: 0.6132\n",
      "水头模型 Epoch 146, Batch 0: Total Loss: 148.8991, Criterion Loss: 42.6915, Physics Loss: 106.2521, KL Loss: 106.2076\n",
      "水头模型 Epoch 146/500 | 训练损失: 149.0205 | 验证损失: 12.2431 | LR: 0.000997\n",
      "水头验证指标 - MSE: 12.0763, RMSE: 3.4424, MAE: 2.7326, R2: 0.6310\n",
      "水头模型 Epoch 147, Batch 0: Total Loss: 148.5430, Criterion Loss: 42.2842, Physics Loss: 103.9448, KL Loss: 106.2588\n",
      "水头模型 Epoch 147/500 | 训练损失: 151.0219 | 验证损失: 14.6367 | LR: 0.000995\n",
      "水头验证指标 - MSE: 14.1794, RMSE: 3.6986, MAE: 2.8984, R2: 0.5737\n",
      "水头模型 Epoch 148, Batch 0: Total Loss: 164.9886, Criterion Loss: 59.3518, Physics Loss: 124.9316, KL Loss: 105.6368\n",
      "水头模型 Epoch 148/500 | 训练损失: 153.3569 | 验证损失: 14.3755 | LR: 0.000994\n",
      "水头验证指标 - MSE: 14.0213, RMSE: 3.7070, MAE: 2.9260, R2: 0.5713\n",
      "水头模型 Epoch 149, Batch 0: Total Loss: 146.2516, Criterion Loss: 41.1307, Physics Loss: 104.9845, KL Loss: 105.1210\n",
      "水头模型 Epoch 149/500 | 训练损失: 151.3601 | 验证损失: 20.0246 | LR: 0.000992\n",
      "水头验证指标 - MSE: 20.6589, RMSE: 4.5231, MAE: 3.7170, R2: 0.3547\n",
      "水头模型 Epoch 150, Batch 0: Total Loss: 159.3343, Criterion Loss: 54.7515, Physics Loss: 115.5359, KL Loss: 104.5828\n",
      "水头模型 Epoch 150/500 | 训练损失: 150.0303 | 验证损失: 12.7169 | LR: 0.000990\n",
      "水头验证指标 - MSE: 12.6622, RMSE: 3.5075, MAE: 2.7730, R2: 0.6162\n",
      "水头模型 Epoch 151, Batch 0: Total Loss: 164.4851, Criterion Loss: 60.1274, Physics Loss: 124.0534, KL Loss: 104.3577\n",
      "水头模型 Epoch 151/500 | 训练损失: 145.7974 | 验证损失: 17.1136 | LR: 0.000988\n",
      "水头验证指标 - MSE: 17.4323, RMSE: 4.1232, MAE: 3.4000, R2: 0.4319\n",
      "水头模型 Epoch 152, Batch 0: Total Loss: 160.8036, Criterion Loss: 56.9471, Physics Loss: 124.4282, KL Loss: 103.8566\n",
      "水头模型 Epoch 152/500 | 训练损失: 148.2735 | 验证损失: 12.0265 | LR: 0.000986\n",
      "水头验证指标 - MSE: 11.5623, RMSE: 3.3833, MAE: 2.7091, R2: 0.6324\n",
      "水头模型 Epoch 153, Batch 0: Total Loss: 146.0577, Criterion Loss: 42.8560, Physics Loss: 111.0264, KL Loss: 103.2017\n",
      "水头模型 Epoch 153/500 | 训练损失: 144.2940 | 验证损失: 11.3578 | LR: 0.000984\n",
      "水头验证指标 - MSE: 11.0563, RMSE: 3.3098, MAE: 2.6424, R2: 0.6568\n",
      "水头模型 Epoch 154, Batch 0: Total Loss: 140.2800, Criterion Loss: 37.7873, Physics Loss: 100.0088, KL Loss: 102.4926\n",
      "水头模型 Epoch 154/500 | 训练损失: 147.2692 | 验证损失: 12.8533 | LR: 0.000981\n",
      "水头验证指标 - MSE: 12.2117, RMSE: 3.4593, MAE: 2.7548, R2: 0.6273\n",
      "水头模型 Epoch 155, Batch 0: Total Loss: 140.6804, Criterion Loss: 38.7251, Physics Loss: 102.4182, KL Loss: 101.9553\n",
      "水头模型 Epoch 155/500 | 训练损失: 145.8459 | 验证损失: 12.3198 | LR: 0.000979\n",
      "水头验证指标 - MSE: 11.5306, RMSE: 3.3837, MAE: 2.7069, R2: 0.6416\n",
      "水头模型 Epoch 156, Batch 0: Total Loss: 141.0177, Criterion Loss: 39.6230, Physics Loss: 106.6369, KL Loss: 101.3948\n",
      "水头模型 Epoch 156/500 | 训练损失: 143.4987 | 验证损失: 13.3623 | LR: 0.000976\n",
      "水头验证指标 - MSE: 13.5562, RMSE: 3.6402, MAE: 2.8758, R2: 0.5871\n",
      "水头模型 Epoch 157, Batch 0: Total Loss: 144.5454, Criterion Loss: 43.5139, Physics Loss: 113.0296, KL Loss: 101.0315\n",
      "水头模型 Epoch 157/500 | 训练损失: 146.9479 | 验证损失: 11.3689 | LR: 0.000973\n",
      "水头验证指标 - MSE: 11.1553, RMSE: 3.3128, MAE: 2.6339, R2: 0.6575\n",
      "水头模型 Epoch 158, Batch 0: Total Loss: 140.8076, Criterion Loss: 40.4583, Physics Loss: 97.9938, KL Loss: 100.3493\n",
      "水头模型 Epoch 158/500 | 训练损失: 142.2654 | 验证损失: 10.9283 | LR: 0.000969\n",
      "水头验证指标 - MSE: 10.8407, RMSE: 3.2696, MAE: 2.5881, R2: 0.6658\n",
      "水头模型 Epoch 159, Batch 0: Total Loss: 133.3215, Criterion Loss: 33.4541, Physics Loss: 95.1672, KL Loss: 99.8674\n",
      "水头模型 Epoch 159/500 | 训练损失: 140.3811 | 验证损失: 11.4429 | LR: 0.000966\n",
      "水头验证指标 - MSE: 11.2114, RMSE: 3.3189, MAE: 2.6573, R2: 0.6539\n",
      "水头模型 Epoch 160, Batch 0: Total Loss: 134.5503, Criterion Loss: 35.6258, Physics Loss: 97.2854, KL Loss: 98.9245\n",
      "水头模型 Epoch 160/500 | 训练损失: 140.4445 | 验证损失: 18.9840 | LR: 0.000962\n",
      "水头验证指标 - MSE: 19.3316, RMSE: 4.3707, MAE: 3.6816, R2: 0.3790\n",
      "水头模型 Epoch 161, Batch 0: Total Loss: 141.6901, Criterion Loss: 42.7678, Physics Loss: 105.6652, KL Loss: 98.9223\n",
      "水头模型 Epoch 161/500 | 训练损失: 145.9450 | 验证损失: 13.7369 | LR: 0.000959\n",
      "水头验证指标 - MSE: 13.4113, RMSE: 3.6402, MAE: 2.9028, R2: 0.5871\n",
      "水头模型 Epoch 162, Batch 0: Total Loss: 142.9938, Criterion Loss: 44.3363, Physics Loss: 117.1009, KL Loss: 98.6575\n",
      "水头模型 Epoch 162/500 | 训练损失: 140.9761 | 验证损失: 15.8994 | LR: 0.000955\n",
      "水头验证指标 - MSE: 16.1049, RMSE: 3.9832, MAE: 3.3009, R2: 0.4804\n",
      "水头模型 Epoch 163, Batch 0: Total Loss: 137.6261, Criterion Loss: 39.7084, Physics Loss: 107.9387, KL Loss: 97.9177\n",
      "水头模型 Epoch 163/500 | 训练损失: 147.3137 | 验证损失: 14.0636 | LR: 0.000950\n",
      "水头验证指标 - MSE: 13.7954, RMSE: 3.7038, MAE: 2.9705, R2: 0.5595\n",
      "水头模型 Epoch 164, Batch 0: Total Loss: 142.5428, Criterion Loss: 45.1490, Physics Loss: 108.5872, KL Loss: 97.3938\n",
      "水头模型 Epoch 164/500 | 训练损失: 143.5266 | 验证损失: 12.4986 | LR: 0.000946\n",
      "水头验证指标 - MSE: 12.4395, RMSE: 3.4953, MAE: 2.8068, R2: 0.6178\n",
      "水头模型早停触发! 在第164个epoch停止训练\n",
      "\n",
      "水头模型训练完成!\n",
      "基于损失的最佳验证损失: 10.1397\n",
      "基于R2的最佳R2分数: 0.6910\n",
      "\n",
      "================================================================================\n",
      "第二阶段：开始训练浓度模型\n",
      "================================================================================\n",
      "成功加载基于r2的最佳水头模型\n",
      "浓度模型参数数量: 1057246\n",
      "浓度模型 Epoch 1, Batch 0: Total Loss: 41.5879, Criterion Loss: 15.3489, MSE: 8.5326, KL Loss: 26.2389, L1 Reg: 681638.6875\n",
      "浓度模型 Epoch 001/500 | 训练损失: 40.9936 | 验证损失: 15.5404 | LR: 0.000791\n",
      "浓度验证指标 - MSE: 8.7761, RMSE: 2.9608, MAE: 0.6552, R2: 0.0247\n",
      "保存基于损失的最佳浓度模型，验证损失: 15.5404\n",
      "保存基于R2的最佳浓度模型，R2: 0.0247\n",
      "浓度模型 Epoch 2, Batch 0: Total Loss: 36.7468, Criterion Loss: 14.6317, MSE: 7.8675, KL Loss: 22.1151, L1 Reg: 676424.4375\n",
      "浓度模型 Epoch 002/500 | 训练损失: 36.5963 | 验证损失: 14.2543 | LR: 0.000765\n",
      "浓度验证指标 - MSE: 7.5333, RMSE: 2.7430, MAE: 0.6023, R2: 0.1630\n",
      "保存基于损失的最佳浓度模型，验证损失: 14.2543\n",
      "保存基于R2的最佳浓度模型，R2: 0.1630\n",
      "浓度模型 Epoch 3, Batch 0: Total Loss: 33.3377, Criterion Loss: 14.3293, MSE: 7.6082, KL Loss: 19.0084, L1 Reg: 672104.2500\n",
      "浓度模型 Epoch 003/500 | 训练损失: 32.0322 | 验证损失: 11.0367 | LR: 0.000724\n",
      "浓度验证指标 - MSE: 4.3420, RMSE: 2.0809, MAE: 0.4666, R2: 0.5186\n",
      "保存基于损失的最佳浓度模型，验证损失: 11.0367\n",
      "保存基于R2的最佳浓度模型，R2: 0.5186\n",
      "浓度模型 Epoch 4, Batch 0: Total Loss: 28.4325, Criterion Loss: 11.1748, MSE: 4.4800, KL Loss: 17.2577, L1 Reg: 669471.7500\n",
      "浓度模型 Epoch 004/500 | 训练损失: 28.1353 | 验证损失: 9.8361 | LR: 0.000668\n",
      "浓度验证指标 - MSE: 3.1677, RMSE: 1.7774, MAE: 0.3159, R2: 0.6487\n",
      "保存基于损失的最佳浓度模型，验证损失: 9.8361\n",
      "保存基于R2的最佳浓度模型，R2: 0.6487\n",
      "浓度模型 Epoch 5, Batch 0: Total Loss: 26.1030, Criterion Loss: 10.3463, MSE: 3.6779, KL Loss: 15.7568, L1 Reg: 666831.1250\n",
      "浓度模型 Epoch 005/500 | 训练损失: 25.7365 | 验证损失: 9.3356 | LR: 0.000600\n",
      "浓度验证指标 - MSE: 2.6995, RMSE: 1.6408, MAE: 0.2909, R2: 0.7006\n",
      "保存基于损失的最佳浓度模型，验证损失: 9.3356\n",
      "保存基于R2的最佳浓度模型，R2: 0.7006\n",
      "浓度模型 Epoch 6, Batch 0: Total Loss: 23.3354, Criterion Loss: 9.3522, MSE: 2.7161, KL Loss: 13.9832, L1 Reg: 663610.6250\n",
      "浓度模型 Epoch 006/500 | 训练损失: 23.8775 | 验证损失: 9.0688 | LR: 0.000524\n",
      "浓度验证指标 - MSE: 2.4591, RMSE: 1.5650, MAE: 0.2448, R2: 0.7277\n",
      "保存基于损失的最佳浓度模型，验证损失: 9.0688\n",
      "保存基于R2的最佳浓度模型，R2: 0.7277\n",
      "浓度模型 Epoch 7, Batch 0: Total Loss: 21.8312, Criterion Loss: 9.1161, MSE: 2.5063, KL Loss: 12.7151, L1 Reg: 660977.0625\n",
      "浓度模型 Epoch 007/500 | 训练损失: 22.5206 | 验证损失: 9.2599 | LR: 0.000442\n",
      "浓度验证指标 - MSE: 2.6714, RMSE: 1.6311, MAE: 0.1968, R2: 0.7042\n",
      "浓度模型 Epoch 8, Batch 0: Total Loss: 21.5022, Criterion Loss: 9.8438, MSE: 3.2553, KL Loss: 11.6583, L1 Reg: 658856.0625\n",
      "浓度模型 Epoch 008/500 | 训练损失: 21.6577 | 验证损失: 8.9215 | LR: 0.000359\n",
      "浓度验证指标 - MSE: 2.3466, RMSE: 1.5281, MAE: 0.2128, R2: 0.7403\n",
      "保存基于损失的最佳浓度模型，验证损失: 8.9215\n",
      "保存基于R2的最佳浓度模型，R2: 0.7403\n",
      "浓度模型 Epoch 9, Batch 0: Total Loss: 20.5817, Criterion Loss: 9.5235, MSE: 2.9486, KL Loss: 11.0582, L1 Reg: 657485.8750\n",
      "浓度模型 Epoch 009/500 | 训练损失: 20.9337 | 验证损失: 8.6215 | LR: 0.000277\n",
      "浓度验证指标 - MSE: 2.0583, RMSE: 1.4315, MAE: 0.2136, R2: 0.7720\n",
      "保存基于损失的最佳浓度模型，验证损失: 8.6215\n",
      "保存基于R2的最佳浓度模型，R2: 0.7720\n",
      "浓度模型 Epoch 10, Batch 0: Total Loss: 19.5405, Criterion Loss: 8.9473, MSE: 2.3841, KL Loss: 10.5932, L1 Reg: 656314.5625\n",
      "浓度模型 Epoch 010/500 | 训练损失: 20.2854 | 验证损失: 8.4541 | LR: 0.000201\n",
      "浓度验证指标 - MSE: 1.9008, RMSE: 1.3753, MAE: 0.2170, R2: 0.7895\n",
      "保存基于损失的最佳浓度模型，验证损失: 8.4541\n",
      "保存基于R2的最佳浓度模型，R2: 0.7895\n",
      "浓度模型 Epoch 11, Batch 0: Total Loss: 18.8752, Criterion Loss: 8.6714, MSE: 2.1181, KL Loss: 10.2038, L1 Reg: 655330.8750\n",
      "浓度模型 Epoch 011/500 | 训练损失: 19.8262 | 验证损失: 8.4078 | LR: 0.000133\n",
      "浓度验证指标 - MSE: 1.8618, RMSE: 1.3612, MAE: 0.1968, R2: 0.7939\n",
      "保存基于损失的最佳浓度模型，验证损失: 8.4078\n",
      "保存基于R2的最佳浓度模型，R2: 0.7939\n",
      "浓度模型 Epoch 12, Batch 0: Total Loss: 18.5832, Criterion Loss: 8.6955, MSE: 2.1495, KL Loss: 9.8877, L1 Reg: 654600.5625\n",
      "浓度模型 Epoch 012/500 | 训练损失: 19.6042 | 验证损失: 8.4251 | LR: 0.000077\n",
      "浓度验证指标 - MSE: 1.8835, RMSE: 1.3672, MAE: 0.1911, R2: 0.7920\n",
      "浓度模型 Epoch 13, Batch 0: Total Loss: 18.8581, Criterion Loss: 9.1703, MSE: 2.6288, KL Loss: 9.6878, L1 Reg: 654155.8750\n",
      "浓度模型 Epoch 013/500 | 训练损失: 19.3837 | 验证损失: 8.3224 | LR: 0.000036\n",
      "浓度验证指标 - MSE: 1.7835, RMSE: 1.3317, MAE: 0.1986, R2: 0.8026\n",
      "保存基于损失的最佳浓度模型，验证损失: 8.3224\n",
      "保存基于R2的最佳浓度模型，R2: 0.8026\n",
      "浓度模型 Epoch 14, Batch 0: Total Loss: 18.2193, Criterion Loss: 8.6464, MSE: 2.1075, KL Loss: 9.5729, L1 Reg: 653891.2500\n",
      "浓度模型 Epoch 014/500 | 训练损失: 19.2297 | 验证损失: 8.2718 | LR: 0.000010\n",
      "浓度验证指标 - MSE: 1.7342, RMSE: 1.3135, MAE: 0.1976, R2: 0.8080\n",
      "保存基于损失的最佳浓度模型，验证损失: 8.2718\n",
      "保存基于R2的最佳浓度模型，R2: 0.8080\n",
      "浓度模型 Epoch 15, Batch 0: Total Loss: 18.3830, Criterion Loss: 8.7771, MSE: 2.2394, KL Loss: 9.6059, L1 Reg: 653769.3750\n",
      "浓度模型 Epoch 015/500 | 训练损失: 19.1949 | 验证损失: 8.2759 | LR: 0.000800\n",
      "浓度验证指标 - MSE: 1.7386, RMSE: 1.3151, MAE: 0.1965, R2: 0.8076\n",
      "浓度模型 Epoch 16, Batch 0: Total Loss: 17.8906, Criterion Loss: 8.2580, MSE: 1.7207, KL Loss: 9.6326, L1 Reg: 653731.0625\n",
      "浓度模型 Epoch 016/500 | 训练损失: 18.7330 | 验证损失: 8.1579 | LR: 0.000798\n",
      "浓度验证指标 - MSE: 1.6524, RMSE: 1.2813, MAE: 0.2018, R2: 0.8173\n",
      "保存基于损失的最佳浓度模型，验证损失: 8.1579\n",
      "保存基于R2的最佳浓度模型，R2: 0.8173\n",
      "浓度模型 Epoch 17, Batch 0: Total Loss: 16.8150, Criterion Loss: 8.4316, MSE: 1.9261, KL Loss: 8.3834, L1 Reg: 650555.3750\n",
      "浓度模型 Epoch 017/500 | 训练损失: 17.6520 | 验证损失: 8.3002 | LR: 0.000791\n",
      "浓度验证指标 - MSE: 1.8160, RMSE: 1.3423, MAE: 0.1796, R2: 0.7993\n",
      "浓度模型 Epoch 18, Batch 0: Total Loss: 16.7494, Criterion Loss: 9.0544, MSE: 2.5703, KL Loss: 7.6950, L1 Reg: 648415.6875\n",
      "浓度模型 Epoch 018/500 | 训练损失: 16.9853 | 验证损失: 8.0018 | LR: 0.000780\n",
      "浓度验证指标 - MSE: 1.5378, RMSE: 1.2357, MAE: 0.1868, R2: 0.8300\n",
      "保存基于损失的最佳浓度模型，验证损失: 8.0018\n",
      "保存基于R2的最佳浓度模型，R2: 0.8300\n",
      "浓度模型 Epoch 19, Batch 0: Total Loss: 15.4298, Criterion Loss: 8.3272, MSE: 1.8633, KL Loss: 7.1025, L1 Reg: 646395.3125\n",
      "浓度模型 Epoch 019/500 | 训练损失: 16.1645 | 验证损失: 7.8648 | LR: 0.000765\n",
      "浓度验证指标 - MSE: 1.4228, RMSE: 1.1894, MAE: 0.1919, R2: 0.8424\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.8648\n",
      "保存基于R2的最佳浓度模型，R2: 0.8424\n",
      "浓度模型 Epoch 20, Batch 0: Total Loss: 15.0234, Criterion Loss: 8.4812, MSE: 2.0392, KL Loss: 6.5423, L1 Reg: 644198.6250\n",
      "浓度模型 Epoch 020/500 | 训练损失: 15.4419 | 验证损失: 7.8386 | LR: 0.000746\n",
      "浓度验证指标 - MSE: 1.4182, RMSE: 1.1864, MAE: 0.1905, R2: 0.8432\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.8386\n",
      "保存基于R2的最佳浓度模型，R2: 0.8432\n",
      "浓度模型 Epoch 21, Batch 0: Total Loss: 25.0609, Criterion Loss: 19.0976, MSE: 12.6773, KL Loss: 5.9632, L1 Reg: 642031.9375\n",
      "浓度模型 Epoch 021/500 | 训练损失: 14.9822 | 验证损失: 7.7756 | LR: 0.000724\n",
      "浓度验证指标 - MSE: 1.3770, RMSE: 1.1694, MAE: 0.1996, R2: 0.8477\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.7756\n",
      "保存基于R2的最佳浓度模型，R2: 0.8477\n",
      "浓度模型 Epoch 22, Batch 0: Total Loss: 13.7964, Criterion Loss: 8.2760, MSE: 1.8774, KL Loss: 5.5204, L1 Reg: 639860.1250\n",
      "浓度模型 Epoch 022/500 | 训练损失: 14.3898 | 验证损失: 7.6833 | LR: 0.000697\n",
      "浓度验证指标 - MSE: 1.3067, RMSE: 1.1389, MAE: 0.2013, R2: 0.8555\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.6833\n",
      "保存基于R2的最佳浓度模型，R2: 0.8555\n",
      "浓度模型 Epoch 23, Batch 0: Total Loss: 13.0778, Criterion Loss: 7.9494, MSE: 1.5729, KL Loss: 5.1284, L1 Reg: 637655.8750\n",
      "浓度模型 Epoch 023/500 | 训练损失: 14.0293 | 验证损失: 7.7158 | LR: 0.000668\n",
      "浓度验证指标 - MSE: 1.3611, RMSE: 1.1629, MAE: 0.2294, R2: 0.8493\n",
      "浓度模型 Epoch 24, Batch 0: Total Loss: 13.1060, Criterion Loss: 8.3640, MSE: 2.0092, KL Loss: 4.7420, L1 Reg: 635474.1250\n",
      "浓度模型 Epoch 024/500 | 训练损失: 13.6405 | 验证损失: 7.6645 | LR: 0.000635\n",
      "浓度验证指标 - MSE: 1.3278, RMSE: 1.1479, MAE: 0.2178, R2: 0.8531\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.6645\n",
      "浓度模型 Epoch 25, Batch 0: Total Loss: 12.4968, Criterion Loss: 8.0050, MSE: 1.6683, KL Loss: 4.4918, L1 Reg: 633670.3750\n",
      "浓度模型 Epoch 025/500 | 训练损失: 13.2382 | 验证损失: 7.6124 | LR: 0.000600\n",
      "浓度验证指标 - MSE: 1.2944, RMSE: 1.1333, MAE: 0.2056, R2: 0.8569\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.6124\n",
      "保存基于R2的最佳浓度模型，R2: 0.8569\n",
      "浓度模型 Epoch 26, Batch 0: Total Loss: 12.5868, Criterion Loss: 8.4324, MSE: 2.1144, KL Loss: 4.1544, L1 Reg: 631802.8750\n",
      "浓度模型 Epoch 026/500 | 训练损失: 13.0506 | 验证损失: 7.6464 | LR: 0.000563\n",
      "浓度验证指标 - MSE: 1.3452, RMSE: 1.1558, MAE: 0.1977, R2: 0.8512\n",
      "浓度模型 Epoch 27, Batch 0: Total Loss: 11.8301, Criterion Loss: 7.8795, MSE: 1.5783, KL Loss: 3.9505, L1 Reg: 630117.0000\n",
      "浓度模型 Epoch 027/500 | 训练损失: 12.7472 | 验证损失: 7.8838 | LR: 0.000524\n",
      "浓度验证指标 - MSE: 1.5999, RMSE: 1.2607, MAE: 0.1983, R2: 0.8231\n",
      "浓度模型 Epoch 28, Batch 0: Total Loss: 11.7921, Criterion Loss: 8.0319, MSE: 1.7481, KL Loss: 3.7602, L1 Reg: 628385.0000\n",
      "浓度模型 Epoch 028/500 | 训练损失: 12.6592 | 验证损失: 7.6043 | LR: 0.000484\n",
      "浓度验证指标 - MSE: 1.3345, RMSE: 1.1505, MAE: 0.1942, R2: 0.8525\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.6043\n",
      "浓度模型 Epoch 29, Batch 0: Total Loss: 11.6354, Criterion Loss: 8.0073, MSE: 1.7375, KL Loss: 3.6281, L1 Reg: 626980.8125\n",
      "浓度模型 Epoch 029/500 | 训练损失: 12.6807 | 验证损失: 7.6049 | LR: 0.000442\n",
      "浓度验证指标 - MSE: 1.3487, RMSE: 1.1568, MAE: 0.1938, R2: 0.8510\n",
      "浓度模型 Epoch 30, Batch 0: Total Loss: 11.2378, Criterion Loss: 7.7650, MSE: 1.5088, KL Loss: 3.4729, L1 Reg: 625616.3125\n",
      "浓度模型 Epoch 030/500 | 训练损失: 12.2668 | 验证损失: 7.5819 | LR: 0.000401\n",
      "浓度验证指标 - MSE: 1.3368, RMSE: 1.1518, MAE: 0.1947, R2: 0.8522\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.5819\n",
      "浓度模型 Epoch 31, Batch 0: Total Loss: 11.2844, Criterion Loss: 7.9880, MSE: 1.7429, KL Loss: 3.2964, L1 Reg: 624502.6250\n",
      "浓度模型 Epoch 031/500 | 训练损失: 12.2311 | 验证损失: 7.6164 | LR: 0.000359\n",
      "浓度验证指标 - MSE: 1.3822, RMSE: 1.1706, MAE: 0.1914, R2: 0.8474\n",
      "浓度模型 Epoch 32, Batch 0: Total Loss: 11.2787, Criterion Loss: 8.0418, MSE: 1.8076, KL Loss: 3.2370, L1 Reg: 623415.7500\n",
      "浓度模型 Epoch 032/500 | 训练损失: 12.3323 | 验证损失: 7.5286 | LR: 0.000317\n",
      "浓度验证指标 - MSE: 1.3049, RMSE: 1.1370, MAE: 0.2147, R2: 0.8558\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.5286\n",
      "浓度模型 Epoch 33, Batch 0: Total Loss: 11.1929, Criterion Loss: 8.0445, MSE: 1.8208, KL Loss: 3.1484, L1 Reg: 622369.6250\n",
      "浓度模型 Epoch 033/500 | 训练损失: 11.9879 | 验证损失: 7.5538 | LR: 0.000277\n",
      "浓度验证指标 - MSE: 1.3381, RMSE: 1.1524, MAE: 0.1938, R2: 0.8521\n",
      "浓度模型 Epoch 34, Batch 0: Total Loss: 10.7374, Criterion Loss: 7.6567, MSE: 1.4409, KL Loss: 3.0807, L1 Reg: 621570.6875\n",
      "浓度模型 Epoch 034/500 | 训练损失: 11.8694 | 验证损失: 7.5409 | LR: 0.000238\n",
      "浓度验证指标 - MSE: 1.3333, RMSE: 1.1503, MAE: 0.2000, R2: 0.8527\n",
      "浓度模型 Epoch 35, Batch 0: Total Loss: 11.3732, Criterion Loss: 8.3559, MSE: 2.1483, KL Loss: 3.0172, L1 Reg: 620764.4375\n",
      "浓度模型 Epoch 035/500 | 训练损失: 11.8454 | 验证损失: 7.5900 | LR: 0.000201\n",
      "浓度验证指标 - MSE: 1.3883, RMSE: 1.1731, MAE: 0.1974, R2: 0.8467\n",
      "浓度模型 Epoch 36, Batch 0: Total Loss: 10.6967, Criterion Loss: 7.7295, MSE: 1.5278, KL Loss: 2.9672, L1 Reg: 620168.4375\n",
      "浓度模型 Epoch 036/500 | 训练损失: 11.7138 | 验证损失: 7.4868 | LR: 0.000166\n",
      "浓度验证指标 - MSE: 1.2902, RMSE: 1.1308, MAE: 0.2009, R2: 0.8576\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.4868\n",
      "保存基于R2的最佳浓度模型，R2: 0.8576\n",
      "浓度模型 Epoch 37, Batch 0: Total Loss: 10.9978, Criterion Loss: 8.0764, MSE: 1.8797, KL Loss: 2.9214, L1 Reg: 619661.9375\n",
      "浓度模型 Epoch 037/500 | 训练损失: 11.7434 | 验证损失: 7.5194 | LR: 0.000133\n",
      "浓度验证指标 - MSE: 1.3273, RMSE: 1.1467, MAE: 0.1975, R2: 0.8535\n",
      "浓度模型 Epoch 38, Batch 0: Total Loss: 10.9267, Criterion Loss: 8.0431, MSE: 1.8510, KL Loss: 2.8836, L1 Reg: 619211.6875\n",
      "浓度模型 Epoch 038/500 | 训练损失: 11.6018 | 验证损失: 7.4824 | LR: 0.000104\n",
      "浓度验证指标 - MSE: 1.2940, RMSE: 1.1327, MAE: 0.2037, R2: 0.8570\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.4824\n",
      "浓度模型 Epoch 39, Batch 0: Total Loss: 10.8168, Criterion Loss: 7.9436, MSE: 1.7552, KL Loss: 2.8732, L1 Reg: 618844.6250\n",
      "浓度模型 Epoch 039/500 | 训练损失: 11.5968 | 验证损失: 7.4846 | LR: 0.000077\n",
      "浓度验证指标 - MSE: 1.2992, RMSE: 1.1351, MAE: 0.1927, R2: 0.8565\n",
      "浓度模型 Epoch 40, Batch 0: Total Loss: 10.3939, Criterion Loss: 7.5752, MSE: 1.3897, KL Loss: 2.8187, L1 Reg: 618546.3125\n",
      "浓度模型 Epoch 040/500 | 训练损失: 11.5155 | 验证损失: 7.4974 | LR: 0.000055\n",
      "浓度验证指标 - MSE: 1.3144, RMSE: 1.1418, MAE: 0.1965, R2: 0.8548\n",
      "浓度模型 Epoch 41, Batch 0: Total Loss: 11.1224, Criterion Loss: 8.2667, MSE: 2.0837, KL Loss: 2.8557, L1 Reg: 618300.5000\n",
      "浓度模型 Epoch 041/500 | 训练损失: 11.6698 | 验证损失: 7.4590 | LR: 0.000036\n",
      "浓度验证指标 - MSE: 1.2776, RMSE: 1.1256, MAE: 0.1927, R2: 0.8589\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.4590\n",
      "保存基于R2的最佳浓度模型，R2: 0.8589\n",
      "浓度模型 Epoch 42, Batch 0: Total Loss: 10.7385, Criterion Loss: 7.9005, MSE: 1.7191, KL Loss: 2.8380, L1 Reg: 618141.2500\n",
      "浓度模型 Epoch 042/500 | 训练损失: 11.5942 | 验证损失: 7.4531 | LR: 0.000021\n",
      "浓度验证指标 - MSE: 1.2727, RMSE: 1.1228, MAE: 0.1932, R2: 0.8595\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.4531\n",
      "保存基于R2的最佳浓度模型，R2: 0.8595\n",
      "浓度模型 Epoch 43, Batch 0: Total Loss: 10.3239, Criterion Loss: 7.4933, MSE: 1.3128, KL Loss: 2.8307, L1 Reg: 618045.5625\n",
      "浓度模型 Epoch 043/500 | 训练损失: 11.5780 | 验证损失: 7.4476 | LR: 0.000010\n",
      "浓度验证指标 - MSE: 1.2677, RMSE: 1.1212, MAE: 0.1982, R2: 0.8599\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.4476\n",
      "保存基于R2的最佳浓度模型，R2: 0.8599\n",
      "浓度模型 Epoch 44, Batch 0: Total Loss: 10.7629, Criterion Loss: 7.9418, MSE: 1.7619, KL Loss: 2.8212, L1 Reg: 617989.5625\n",
      "浓度模型 Epoch 044/500 | 训练损失: 11.4781 | 验证损失: 7.4573 | LR: 0.000003\n",
      "浓度验证指标 - MSE: 1.2777, RMSE: 1.1253, MAE: 0.1962, R2: 0.8589\n",
      "浓度模型 Epoch 45, Batch 0: Total Loss: 10.3879, Criterion Loss: 7.5781, MSE: 1.3985, KL Loss: 2.8098, L1 Reg: 617960.8750\n",
      "浓度模型 Epoch 045/500 | 训练损失: 11.4702 | 验证损失: 7.4634 | LR: 0.000800\n",
      "浓度验证指标 - MSE: 1.2839, RMSE: 1.1287, MAE: 0.1870, R2: 0.8581\n",
      "浓度模型 Epoch 46, Batch 0: Total Loss: 11.0168, Criterion Loss: 8.2050, MSE: 2.0255, KL Loss: 2.8118, L1 Reg: 617950.8125\n",
      "浓度模型 Epoch 046/500 | 训练损失: 11.8986 | 验证损失: 7.5107 | LR: 0.000799\n",
      "浓度验证指标 - MSE: 1.3514, RMSE: 1.1571, MAE: 0.1978, R2: 0.8508\n",
      "浓度模型 Epoch 47, Batch 0: Total Loss: 10.3588, Criterion Loss: 7.6941, MSE: 1.5348, KL Loss: 2.6647, L1 Reg: 615925.5000\n",
      "浓度模型 Epoch 047/500 | 训练损失: 11.5383 | 验证损失: 7.4462 | LR: 0.000798\n",
      "浓度验证指标 - MSE: 1.3025, RMSE: 1.1368, MAE: 0.1984, R2: 0.8560\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.4462\n",
      "浓度模型 Epoch 48, Batch 0: Total Loss: 10.3098, Criterion Loss: 7.7098, MSE: 1.5661, KL Loss: 2.5999, L1 Reg: 614376.3125\n",
      "浓度模型 Epoch 048/500 | 训练损失: 11.2819 | 验证损失: 7.5870 | LR: 0.000795\n",
      "浓度验证指标 - MSE: 1.4620, RMSE: 1.2043, MAE: 0.1959, R2: 0.8386\n",
      "浓度模型 Epoch 49, Batch 0: Total Loss: 10.4646, Criterion Loss: 8.0127, MSE: 1.8877, KL Loss: 2.4520, L1 Reg: 612499.3750\n",
      "浓度模型 Epoch 049/500 | 训练损失: 11.1967 | 验证损失: 7.4937 | LR: 0.000791\n",
      "浓度验证指标 - MSE: 1.3874, RMSE: 1.1735, MAE: 0.1978, R2: 0.8467\n",
      "浓度模型 Epoch 50, Batch 0: Total Loss: 10.3396, Criterion Loss: 7.9620, MSE: 1.8556, KL Loss: 2.3776, L1 Reg: 610637.0625\n",
      "浓度模型 Epoch 050/500 | 训练损失: 11.0615 | 验证损失: 7.4202 | LR: 0.000786\n",
      "浓度验证指标 - MSE: 1.3339, RMSE: 1.1515, MAE: 0.1936, R2: 0.8524\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.4202\n",
      "浓度模型 Epoch 51, Batch 0: Total Loss: 10.3212, Criterion Loss: 8.0388, MSE: 1.9525, KL Loss: 2.2824, L1 Reg: 608632.6250\n",
      "浓度模型 Epoch 051/500 | 训练损失: 11.0324 | 验证损失: 7.5323 | LR: 0.000780\n",
      "浓度验证指标 - MSE: 1.4653, RMSE: 1.2053, MAE: 0.2000, R2: 0.8383\n",
      "浓度模型 Epoch 52, Batch 0: Total Loss: 20.3756, Criterion Loss: 18.1729, MSE: 12.1060, KL Loss: 2.2027, L1 Reg: 606692.0000\n",
      "浓度模型 Epoch 052/500 | 训练损失: 10.9668 | 验证损失: 7.3852 | LR: 0.000773\n",
      "浓度验证指标 - MSE: 1.3338, RMSE: 1.1499, MAE: 0.1934, R2: 0.8527\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.3852\n",
      "浓度模型 Epoch 53, Batch 0: Total Loss: 10.9279, Criterion Loss: 8.7860, MSE: 2.7345, KL Loss: 2.1419, L1 Reg: 605142.8125\n",
      "浓度模型 Epoch 053/500 | 训练损失: 10.9624 | 验证损失: 7.5730 | LR: 0.000765\n",
      "浓度验证指标 - MSE: 1.5350, RMSE: 1.2335, MAE: 0.1999, R2: 0.8306\n",
      "浓度模型 Epoch 54, Batch 0: Total Loss: 9.5013, Criterion Loss: 7.4351, MSE: 1.3972, KL Loss: 2.0662, L1 Reg: 603795.1250\n",
      "浓度模型 Epoch 054/500 | 训练损失: 10.6437 | 验证损失: 7.3016 | LR: 0.000756\n",
      "浓度验证指标 - MSE: 1.2833, RMSE: 1.1284, MAE: 0.1951, R2: 0.8581\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.3016\n",
      "浓度模型 Epoch 55, Batch 0: Total Loss: 9.6539, Criterion Loss: 7.6263, MSE: 1.6081, KL Loss: 2.0276, L1 Reg: 601827.3750\n",
      "浓度模型 Epoch 055/500 | 训练损失: 10.6384 | 验证损失: 7.3339 | LR: 0.000746\n",
      "浓度验证指标 - MSE: 1.3317, RMSE: 1.1491, MAE: 0.2008, R2: 0.8529\n",
      "浓度模型 Epoch 56, Batch 0: Total Loss: 9.5420, Criterion Loss: 7.5799, MSE: 1.5777, KL Loss: 1.9620, L1 Reg: 600220.0000\n",
      "浓度模型 Epoch 056/500 | 训练损失: 10.7026 | 验证损失: 7.6369 | LR: 0.000736\n",
      "浓度验证指标 - MSE: 1.6478, RMSE: 1.2780, MAE: 0.2014, R2: 0.8183\n",
      "浓度模型 Epoch 57, Batch 0: Total Loss: 9.4633, Criterion Loss: 7.5499, MSE: 1.5607, KL Loss: 1.9134, L1 Reg: 598915.1250\n",
      "浓度模型 Epoch 057/500 | 训练损失: 10.5232 | 验证损失: 7.2749 | LR: 0.000724\n",
      "浓度验证指标 - MSE: 1.2997, RMSE: 1.1358, MAE: 0.2020, R2: 0.8564\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.2749\n",
      "浓度模型 Epoch 58, Batch 0: Total Loss: 9.2734, Criterion Loss: 7.4070, MSE: 1.4319, KL Loss: 1.8664, L1 Reg: 597515.6250\n",
      "浓度模型 Epoch 058/500 | 训练损失: 10.2648 | 验证损失: 7.2532 | LR: 0.000711\n",
      "浓度验证指标 - MSE: 1.2982, RMSE: 1.1343, MAE: 0.2017, R2: 0.8565\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.2532\n",
      "浓度模型 Epoch 59, Batch 0: Total Loss: 19.6943, Criterion Loss: 17.8956, MSE: 11.9406, KL Loss: 1.7986, L1 Reg: 595498.0625\n",
      "浓度模型 Epoch 059/500 | 训练损失: 10.3551 | 验证损失: 7.1839 | LR: 0.000697\n",
      "浓度验证指标 - MSE: 1.2457, RMSE: 1.1115, MAE: 0.1872, R2: 0.8623\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.1839\n",
      "保存基于R2的最佳浓度模型，R2: 0.8623\n",
      "浓度模型 Epoch 60, Batch 0: Total Loss: 9.1997, Criterion Loss: 7.4595, MSE: 1.5214, KL Loss: 1.7401, L1 Reg: 593815.6250\n",
      "浓度模型 Epoch 060/500 | 训练损失: 10.2510 | 验证损失: 7.2712 | LR: 0.000683\n",
      "浓度验证指标 - MSE: 1.3474, RMSE: 1.1564, MAE: 0.1813, R2: 0.8511\n",
      "浓度模型 Epoch 61, Batch 0: Total Loss: 8.7310, Criterion Loss: 7.0083, MSE: 1.0845, KL Loss: 1.7226, L1 Reg: 592380.6875\n",
      "浓度模型 Epoch 061/500 | 训练损失: 10.1969 | 验证损失: 7.2483 | LR: 0.000668\n",
      "浓度验证指标 - MSE: 1.3411, RMSE: 1.1526, MAE: 0.1829, R2: 0.8520\n",
      "浓度模型 Epoch 62, Batch 0: Total Loss: 9.2101, Criterion Loss: 7.5586, MSE: 1.6515, KL Loss: 1.6515, L1 Reg: 590712.3750\n",
      "浓度模型 Epoch 062/500 | 训练损失: 10.2179 | 验证损失: 7.2491 | LR: 0.000652\n",
      "浓度验证指标 - MSE: 1.3587, RMSE: 1.1607, MAE: 0.1909, R2: 0.8500\n",
      "浓度模型 Epoch 63, Batch 0: Total Loss: 8.9624, Criterion Loss: 7.3361, MSE: 1.4457, KL Loss: 1.6263, L1 Reg: 589039.0000\n",
      "浓度模型 Epoch 063/500 | 训练损失: 10.1558 | 验证损失: 7.2326 | LR: 0.000635\n",
      "浓度验证指标 - MSE: 1.3565, RMSE: 1.1618, MAE: 0.2279, R2: 0.8496\n",
      "浓度模型 Epoch 64, Batch 0: Total Loss: 9.7518, Criterion Loss: 8.1954, MSE: 2.3194, KL Loss: 1.5564, L1 Reg: 587605.6250\n",
      "浓度模型 Epoch 064/500 | 训练损失: 10.0170 | 验证损失: 7.1675 | LR: 0.000618\n",
      "浓度验证指标 - MSE: 1.3076, RMSE: 1.1390, MAE: 0.1901, R2: 0.8555\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.1675\n",
      "浓度模型 Epoch 65, Batch 0: Total Loss: 9.0734, Criterion Loss: 7.5424, MSE: 1.6825, KL Loss: 1.5310, L1 Reg: 585990.0625\n",
      "浓度模型 Epoch 065/500 | 训练损失: 9.9204 | 验证损失: 7.1984 | LR: 0.000600\n",
      "浓度验证指标 - MSE: 1.3534, RMSE: 1.1590, MAE: 0.2101, R2: 0.8503\n",
      "浓度模型 Epoch 66, Batch 0: Total Loss: 9.3490, Criterion Loss: 7.8538, MSE: 2.0089, KL Loss: 1.4951, L1 Reg: 584495.5625\n",
      "浓度模型 Epoch 066/500 | 训练损失: 9.9169 | 验证损失: 7.0921 | LR: 0.000582\n",
      "浓度验证指标 - MSE: 1.2605, RMSE: 1.1188, MAE: 0.1950, R2: 0.8605\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.0921\n",
      "浓度模型 Epoch 67, Batch 0: Total Loss: 8.8218, Criterion Loss: 7.3518, MSE: 1.5202, KL Loss: 1.4700, L1 Reg: 583161.3125\n",
      "浓度模型 Epoch 067/500 | 训练损失: 9.7951 | 验证损失: 7.0873 | LR: 0.000563\n",
      "浓度验证指标 - MSE: 1.2699, RMSE: 1.1221, MAE: 0.2004, R2: 0.8596\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.0873\n",
      "浓度模型 Epoch 68, Batch 0: Total Loss: 8.9684, Criterion Loss: 7.5610, MSE: 1.7436, KL Loss: 1.4075, L1 Reg: 581735.8125\n",
      "浓度模型 Epoch 068/500 | 训练损失: 9.7750 | 验证损失: 7.0478 | LR: 0.000544\n",
      "浓度验证指标 - MSE: 1.2437, RMSE: 1.1102, MAE: 0.1827, R2: 0.8626\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.0478\n",
      "保存基于R2的最佳浓度模型，R2: 0.8626\n",
      "浓度模型 Epoch 69, Batch 0: Total Loss: 8.6970, Criterion Loss: 7.3165, MSE: 1.5124, KL Loss: 1.3806, L1 Reg: 580400.5625\n",
      "浓度模型 Epoch 069/500 | 训练损失: 9.7306 | 验证损失: 7.0760 | LR: 0.000524\n",
      "浓度验证指标 - MSE: 1.2847, RMSE: 1.1282, MAE: 0.1907, R2: 0.8582\n",
      "浓度模型 Epoch 70, Batch 0: Total Loss: 8.9582, Criterion Loss: 7.5748, MSE: 1.7835, KL Loss: 1.3833, L1 Reg: 579135.6250\n",
      "浓度模型 Epoch 070/500 | 训练损失: 9.7523 | 验证损失: 7.0243 | LR: 0.000504\n",
      "浓度验证指标 - MSE: 1.2440, RMSE: 1.1102, MAE: 0.1961, R2: 0.8626\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.0243\n",
      "保存基于R2的最佳浓度模型，R2: 0.8626\n",
      "浓度模型 Epoch 71, Batch 0: Total Loss: 9.0134, Criterion Loss: 7.6835, MSE: 1.9032, KL Loss: 1.3300, L1 Reg: 578027.1250\n",
      "浓度模型 Epoch 071/500 | 训练损失: 9.7127 | 验证损失: 7.0418 | LR: 0.000484\n",
      "浓度验证指标 - MSE: 1.2721, RMSE: 1.1231, MAE: 0.1904, R2: 0.8596\n",
      "浓度模型 Epoch 72, Batch 0: Total Loss: 8.5292, Criterion Loss: 7.2098, MSE: 1.4402, KL Loss: 1.3194, L1 Reg: 576960.8750\n",
      "浓度模型 Epoch 072/500 | 训练损失: 9.5550 | 验证损失: 7.0033 | LR: 0.000463\n",
      "浓度验证指标 - MSE: 1.2448, RMSE: 1.1105, MAE: 0.1855, R2: 0.8625\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.0033\n",
      "浓度模型 Epoch 73, Batch 0: Total Loss: 9.0167, Criterion Loss: 7.7443, MSE: 1.9858, KL Loss: 1.2724, L1 Reg: 575849.5000\n",
      "浓度模型 Epoch 073/500 | 训练损失: 9.5310 | 验证损失: 7.0333 | LR: 0.000442\n",
      "浓度验证指标 - MSE: 1.2868, RMSE: 1.1295, MAE: 0.1994, R2: 0.8579\n",
      "浓度模型 Epoch 74, Batch 0: Total Loss: 8.9970, Criterion Loss: 7.7457, MSE: 1.9993, KL Loss: 1.2513, L1 Reg: 574642.8125\n",
      "浓度模型 Epoch 074/500 | 训练损失: 9.5069 | 验证损失: 7.0387 | LR: 0.000421\n",
      "浓度验证指标 - MSE: 1.3049, RMSE: 1.1374, MAE: 0.1886, R2: 0.8559\n",
      "浓度模型 Epoch 75, Batch 0: Total Loss: 8.8721, Criterion Loss: 7.6304, MSE: 1.8966, KL Loss: 1.2416, L1 Reg: 573383.1875\n",
      "浓度模型 Epoch 075/500 | 训练损失: 9.4605 | 验证损失: 6.9630 | LR: 0.000401\n",
      "浓度验证指标 - MSE: 1.2388, RMSE: 1.1083, MAE: 0.1828, R2: 0.8632\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.9630\n",
      "保存基于R2的最佳浓度模型，R2: 0.8632\n",
      "浓度模型 Epoch 76, Batch 0: Total Loss: 8.3993, Criterion Loss: 7.2055, MSE: 1.4812, KL Loss: 1.1939, L1 Reg: 572427.7500\n",
      "浓度模型 Epoch 076/500 | 训练损失: 9.3933 | 验证损失: 6.9408 | LR: 0.000380\n",
      "浓度验证指标 - MSE: 1.2261, RMSE: 1.1027, MAE: 0.1860, R2: 0.8645\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.9408\n",
      "保存基于R2的最佳浓度模型，R2: 0.8645\n",
      "浓度模型 Epoch 77, Batch 0: Total Loss: 8.4894, Criterion Loss: 7.2844, MSE: 1.5697, KL Loss: 1.2050, L1 Reg: 571464.6250\n",
      "浓度模型 Epoch 077/500 | 训练损失: 9.4205 | 验证损失: 6.9504 | LR: 0.000359\n",
      "浓度验证指标 - MSE: 1.2457, RMSE: 1.1115, MAE: 0.1910, R2: 0.8623\n",
      "浓度模型 Epoch 78, Batch 0: Total Loss: 8.3440, Criterion Loss: 7.1831, MSE: 1.4784, KL Loss: 1.1608, L1 Reg: 570477.2500\n",
      "浓度模型 Epoch 078/500 | 训练损失: 9.4163 | 验证损失: 6.9196 | LR: 0.000338\n",
      "浓度验证指标 - MSE: 1.2232, RMSE: 1.1013, MAE: 0.1871, R2: 0.8649\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.9196\n",
      "保存基于R2的最佳浓度模型，R2: 0.8649\n",
      "浓度模型 Epoch 79, Batch 0: Total Loss: 8.2085, Criterion Loss: 7.0632, MSE: 1.3668, KL Loss: 1.1453, L1 Reg: 569640.8750\n",
      "浓度模型 Epoch 079/500 | 训练损失: 9.2888 | 验证损失: 6.9901 | LR: 0.000317\n",
      "浓度验证指标 - MSE: 1.3015, RMSE: 1.1361, MAE: 0.1909, R2: 0.8562\n",
      "浓度模型 Epoch 80, Batch 0: Total Loss: 8.1814, Criterion Loss: 7.0479, MSE: 1.3593, KL Loss: 1.1335, L1 Reg: 568861.8750\n",
      "浓度模型 Epoch 080/500 | 训练损失: 9.2636 | 验证损失: 6.8968 | LR: 0.000297\n",
      "浓度验证指标 - MSE: 1.2155, RMSE: 1.0972, MAE: 0.1882, R2: 0.8658\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.8968\n",
      "保存基于R2的最佳浓度模型，R2: 0.8658\n",
      "浓度模型 Epoch 81, Batch 0: Total Loss: 8.1225, Criterion Loss: 6.9816, MSE: 1.3003, KL Loss: 1.1409, L1 Reg: 568130.0625\n",
      "浓度模型 Epoch 081/500 | 训练损失: 9.1635 | 验证损失: 6.9073 | LR: 0.000277\n",
      "浓度验证指标 - MSE: 1.2339, RMSE: 1.1056, MAE: 0.1727, R2: 0.8638\n",
      "浓度模型 Epoch 82, Batch 0: Total Loss: 8.1471, Criterion Loss: 7.0574, MSE: 1.3840, KL Loss: 1.0898, L1 Reg: 567335.6250\n",
      "浓度模型 Epoch 082/500 | 训练损失: 9.2090 | 验证损失: 6.8936 | LR: 0.000257\n",
      "浓度验证指标 - MSE: 1.2287, RMSE: 1.1038, MAE: 0.1775, R2: 0.8643\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.8936\n",
      "浓度模型 Epoch 83, Batch 0: Total Loss: 8.1650, Criterion Loss: 7.0799, MSE: 1.4150, KL Loss: 1.0851, L1 Reg: 566489.6250\n",
      "浓度模型 Epoch 083/500 | 训练损失: 9.1451 | 验证损失: 6.8969 | LR: 0.000238\n",
      "浓度验证指标 - MSE: 1.2389, RMSE: 1.1087, MAE: 0.1694, R2: 0.8630\n",
      "浓度模型 Epoch 84, Batch 0: Total Loss: 14.7805, Criterion Loss: 13.6990, MSE: 8.0410, KL Loss: 1.0815, L1 Reg: 565796.2500\n",
      "浓度模型 Epoch 084/500 | 训练损失: 9.1737 | 验证损失: 6.8949 | LR: 0.000219\n",
      "浓度验证指标 - MSE: 1.2433, RMSE: 1.1107, MAE: 0.1828, R2: 0.8626\n",
      "浓度模型 Epoch 85, Batch 0: Total Loss: 8.3408, Criterion Loss: 7.2945, MSE: 1.6428, KL Loss: 1.0463, L1 Reg: 565161.5625\n",
      "浓度模型 Epoch 085/500 | 训练损失: 9.1663 | 验证损失: 6.8732 | LR: 0.000201\n",
      "浓度验证指标 - MSE: 1.2277, RMSE: 1.1032, MAE: 0.1733, R2: 0.8644\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.8732\n",
      "浓度模型 Epoch 86, Batch 0: Total Loss: 8.5600, Criterion Loss: 7.5069, MSE: 1.8613, KL Loss: 1.0532, L1 Reg: 564558.6875\n",
      "浓度模型 Epoch 086/500 | 训练损失: 9.1696 | 验证损失: 6.8724 | LR: 0.000183\n",
      "浓度验证指标 - MSE: 1.2320, RMSE: 1.1047, MAE: 0.1719, R2: 0.8640\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.8724\n",
      "浓度模型 Epoch 87, Batch 0: Total Loss: 8.3016, Criterion Loss: 7.2690, MSE: 1.6286, KL Loss: 1.0326, L1 Reg: 564043.6250\n",
      "浓度模型 Epoch 087/500 | 训练损失: 9.1964 | 验证损失: 6.9013 | LR: 0.000166\n",
      "浓度验证指标 - MSE: 1.2653, RMSE: 1.1197, MAE: 0.1740, R2: 0.8604\n",
      "浓度模型 Epoch 88, Batch 0: Total Loss: 8.0957, Criterion Loss: 7.0587, MSE: 1.4227, KL Loss: 1.0370, L1 Reg: 563599.8750\n",
      "浓度模型 Epoch 088/500 | 训练损失: 9.1623 | 验证损失: 6.8490 | LR: 0.000149\n",
      "浓度验证指标 - MSE: 1.2169, RMSE: 1.0981, MAE: 0.1789, R2: 0.8656\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.8490\n",
      "浓度模型 Epoch 89, Batch 0: Total Loss: 8.5137, Criterion Loss: 7.5065, MSE: 1.8744, KL Loss: 1.0072, L1 Reg: 563209.1875\n",
      "浓度模型 Epoch 089/500 | 训练损失: 9.7116 | 验证损失: 6.8782 | LR: 0.000133\n",
      "浓度验证指标 - MSE: 1.2499, RMSE: 1.1134, MAE: 0.1753, R2: 0.8619\n",
      "浓度模型 Epoch 90, Batch 0: Total Loss: 8.3067, Criterion Loss: 7.3017, MSE: 1.6734, KL Loss: 1.0050, L1 Reg: 562827.4375\n",
      "浓度模型 Epoch 090/500 | 训练损失: 9.0879 | 验证损失: 6.8289 | LR: 0.000118\n",
      "浓度验证指标 - MSE: 1.2036, RMSE: 1.0921, MAE: 0.1773, R2: 0.8671\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.8289\n",
      "保存基于R2的最佳浓度模型，R2: 0.8671\n",
      "浓度模型 Epoch 91, Batch 0: Total Loss: 8.2267, Criterion Loss: 7.2561, MSE: 1.6309, KL Loss: 0.9706, L1 Reg: 562521.0625\n",
      "浓度模型 Epoch 091/500 | 训练损失: 9.0475 | 验证损失: 6.8357 | LR: 0.000104\n",
      "浓度验证指标 - MSE: 1.2132, RMSE: 1.0968, MAE: 0.1760, R2: 0.8659\n",
      "浓度模型 Epoch 92, Batch 0: Total Loss: 7.8610, Criterion Loss: 6.8700, MSE: 1.2475, KL Loss: 0.9910, L1 Reg: 562248.1875\n",
      "浓度模型 Epoch 092/500 | 训练损失: 9.0196 | 验证损失: 6.8239 | LR: 0.000090\n",
      "浓度验证指标 - MSE: 1.2038, RMSE: 1.0921, MAE: 0.1734, R2: 0.8670\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.8239\n",
      "浓度模型 Epoch 93, Batch 0: Total Loss: 8.0395, Criterion Loss: 7.0452, MSE: 1.4252, KL Loss: 0.9943, L1 Reg: 562004.3750\n",
      "浓度模型 Epoch 093/500 | 训练损失: 9.0110 | 验证损失: 6.8159 | LR: 0.000077\n",
      "浓度验证指标 - MSE: 1.1979, RMSE: 1.0894, MAE: 0.1698, R2: 0.8676\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.8159\n",
      "保存基于R2的最佳浓度模型，R2: 0.8676\n",
      "浓度模型 Epoch 94, Batch 0: Total Loss: 8.6506, Criterion Loss: 7.6360, MSE: 2.0179, KL Loss: 1.0146, L1 Reg: 561804.5000\n",
      "浓度模型 Epoch 094/500 | 训练损失: 9.1039 | 验证损失: 6.8156 | LR: 0.000065\n",
      "浓度验证指标 - MSE: 1.1994, RMSE: 1.0901, MAE: 0.1751, R2: 0.8675\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.8156\n",
      "浓度模型 Epoch 95, Batch 0: Total Loss: 8.0575, Criterion Loss: 7.0629, MSE: 1.4468, KL Loss: 0.9945, L1 Reg: 561617.0625\n",
      "浓度模型 Epoch 095/500 | 训练损失: 9.1920 | 验证损失: 6.8122 | LR: 0.000055\n",
      "浓度验证指标 - MSE: 1.1977, RMSE: 1.0894, MAE: 0.1696, R2: 0.8677\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.8122\n",
      "保存基于R2的最佳浓度模型，R2: 0.8677\n",
      "浓度模型 Epoch 96, Batch 0: Total Loss: 8.4518, Criterion Loss: 7.4691, MSE: 1.8546, KL Loss: 0.9826, L1 Reg: 561453.7500\n",
      "浓度模型 Epoch 096/500 | 训练损失: 9.1678 | 验证损失: 6.8338 | LR: 0.000045\n",
      "浓度验证指标 - MSE: 1.2206, RMSE: 1.0998, MAE: 0.1729, R2: 0.8652\n",
      "浓度模型 Epoch 97, Batch 0: Total Loss: 7.8847, Criterion Loss: 6.9191, MSE: 1.3059, KL Loss: 0.9656, L1 Reg: 561317.0625\n",
      "浓度模型 Epoch 097/500 | 训练损失: 8.9547 | 验证损失: 6.8532 | LR: 0.000036\n",
      "浓度验证指标 - MSE: 1.2411, RMSE: 1.1093, MAE: 0.1729, R2: 0.8630\n",
      "浓度模型 Epoch 98, Batch 0: Total Loss: 8.1065, Criterion Loss: 7.1357, MSE: 1.5237, KL Loss: 0.9708, L1 Reg: 561205.5625\n",
      "浓度模型 Epoch 098/500 | 训练损失: 9.0385 | 验证损失: 6.8279 | LR: 0.000028\n",
      "浓度验证指标 - MSE: 1.2167, RMSE: 1.0978, MAE: 0.1735, R2: 0.8656\n",
      "浓度模型 Epoch 99, Batch 0: Total Loss: 8.1433, Criterion Loss: 7.1713, MSE: 1.5601, KL Loss: 0.9720, L1 Reg: 561120.8750\n",
      "浓度模型 Epoch 099/500 | 训练损失: 9.0144 | 验证损失: 6.8240 | LR: 0.000021\n",
      "浓度验证指标 - MSE: 1.2135, RMSE: 1.0964, MAE: 0.1738, R2: 0.8660\n",
      "浓度模型 Epoch 100, Batch 0: Total Loss: 8.2685, Criterion Loss: 7.3028, MSE: 1.6923, KL Loss: 0.9657, L1 Reg: 561052.0625\n",
      "浓度模型 Epoch 100/500 | 训练损失: 9.0018 | 验证损失: 6.8133 | LR: 0.000015\n",
      "浓度验证指标 - MSE: 1.2032, RMSE: 1.0916, MAE: 0.1716, R2: 0.8671\n",
      "浓度模型 Epoch 101, Batch 0: Total Loss: 7.8667, Criterion Loss: 6.9278, MSE: 1.3177, KL Loss: 0.9389, L1 Reg: 561004.1250\n",
      "浓度模型 Epoch 101/500 | 训练损失: 9.0624 | 验证损失: 6.8265 | LR: 0.000010\n",
      "浓度验证指标 - MSE: 1.2168, RMSE: 1.0981, MAE: 0.1722, R2: 0.8656\n",
      "浓度模型 Epoch 102, Batch 0: Total Loss: 7.8166, Criterion Loss: 6.8632, MSE: 1.2535, KL Loss: 0.9534, L1 Reg: 560968.9375\n",
      "浓度模型 Epoch 102/500 | 训练损失: 8.9494 | 验证损失: 6.8326 | LR: 0.000006\n",
      "浓度验证指标 - MSE: 1.2232, RMSE: 1.1014, MAE: 0.1711, R2: 0.8649\n",
      "浓度模型 Epoch 103, Batch 0: Total Loss: 9.3805, Criterion Loss: 8.4032, MSE: 2.7938, KL Loss: 0.9773, L1 Reg: 560941.4375\n",
      "浓度模型 Epoch 103/500 | 训练损失: 9.0717 | 验证损失: 6.8287 | LR: 0.000003\n",
      "浓度验证指标 - MSE: 1.2194, RMSE: 1.0992, MAE: 0.1732, R2: 0.8654\n",
      "浓度模型 Epoch 104, Batch 0: Total Loss: 7.8240, Criterion Loss: 6.8642, MSE: 1.2550, KL Loss: 0.9597, L1 Reg: 560926.3125\n",
      "浓度模型 Epoch 104/500 | 训练损失: 9.5452 | 验证损失: 6.8231 | LR: 0.000002\n",
      "浓度验证指标 - MSE: 1.2139, RMSE: 1.0968, MAE: 0.1758, R2: 0.8660\n",
      "浓度模型 Epoch 105, Batch 0: Total Loss: 9.6156, Criterion Loss: 8.6342, MSE: 3.0251, KL Loss: 0.9813, L1 Reg: 560917.6250\n",
      "浓度模型 Epoch 105/500 | 训练损失: 9.6793 | 验证损失: 6.8281 | LR: 0.000800\n",
      "浓度验证指标 - MSE: 1.2190, RMSE: 1.0990, MAE: 0.1731, R2: 0.8654\n",
      "浓度模型 Epoch 106, Batch 0: Total Loss: 8.2708, Criterion Loss: 7.3027, MSE: 1.6936, KL Loss: 0.9681, L1 Reg: 560913.7500\n",
      "浓度模型 Epoch 106/500 | 训练损失: 9.0042 | 验证损失: 6.9255 | LR: 0.000800\n",
      "浓度验证指标 - MSE: 1.3346, RMSE: 1.1507, MAE: 0.1987, R2: 0.8526\n",
      "浓度模型 Epoch 107, Batch 0: Total Loss: 7.7673, Criterion Loss: 6.8046, MSE: 1.2138, KL Loss: 0.9627, L1 Reg: 559083.9375\n",
      "浓度模型 Epoch 107/500 | 训练损失: 9.1433 | 验证损失: 7.0079 | LR: 0.000799\n",
      "浓度验证指标 - MSE: 1.4341, RMSE: 1.1920, MAE: 0.1771, R2: 0.8418\n",
      "浓度模型 Epoch 108, Batch 0: Total Loss: 7.9771, Criterion Loss: 7.0504, MSE: 1.4766, KL Loss: 0.9267, L1 Reg: 557381.6250\n",
      "浓度模型 Epoch 108/500 | 训练损失: 9.1629 | 验证损失: 6.9856 | LR: 0.000799\n",
      "浓度验证指标 - MSE: 1.4245, RMSE: 1.1881, MAE: 0.1720, R2: 0.8426\n",
      "浓度模型 Epoch 109, Batch 0: Total Loss: 8.1652, Criterion Loss: 7.2605, MSE: 1.6994, KL Loss: 0.9047, L1 Reg: 556113.6250\n",
      "浓度模型 Epoch 109/500 | 训练损失: 9.1759 | 验证损失: 6.8251 | LR: 0.000798\n",
      "浓度验证指标 - MSE: 1.2755, RMSE: 1.1246, MAE: 0.1802, R2: 0.8591\n",
      "浓度模型 Epoch 110, Batch 0: Total Loss: 8.5085, Criterion Loss: 7.6172, MSE: 2.0676, KL Loss: 0.8913, L1 Reg: 554962.1875\n",
      "浓度模型 Epoch 110/500 | 训练损失: 9.0259 | 验证损失: 6.9506 | LR: 0.000797\n",
      "浓度验证指标 - MSE: 1.4142, RMSE: 1.1840, MAE: 0.1979, R2: 0.8438\n",
      "浓度模型 Epoch 111, Batch 0: Total Loss: 8.7266, Criterion Loss: 7.8493, MSE: 2.3129, KL Loss: 0.8773, L1 Reg: 553643.0625\n",
      "浓度模型 Epoch 111/500 | 训练损失: 9.0241 | 验证损失: 6.8605 | LR: 0.000795\n",
      "浓度验证指标 - MSE: 1.3381, RMSE: 1.1520, MAE: 0.1797, R2: 0.8522\n",
      "浓度模型 Epoch 112, Batch 0: Total Loss: 7.8542, Criterion Loss: 6.9996, MSE: 1.4771, KL Loss: 0.8546, L1 Reg: 552245.2500\n",
      "浓度模型 Epoch 112/500 | 训练损失: 8.8272 | 验证损失: 6.7732 | LR: 0.000793\n",
      "浓度验证指标 - MSE: 1.2664, RMSE: 1.1199, MAE: 0.1890, R2: 0.8602\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.7732\n",
      "浓度模型 Epoch 113, Batch 0: Total Loss: 7.5948, Criterion Loss: 6.7539, MSE: 1.2471, KL Loss: 0.8409, L1 Reg: 550681.2500\n",
      "浓度模型 Epoch 113/500 | 训练损失: 8.8334 | 验证损失: 6.7693 | LR: 0.000791\n",
      "浓度验证指标 - MSE: 1.2791, RMSE: 1.1260, MAE: 0.1838, R2: 0.8586\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.7693\n",
      "浓度模型 Epoch 114, Batch 0: Total Loss: 8.7455, Criterion Loss: 7.9426, MSE: 2.4525, KL Loss: 0.8029, L1 Reg: 549013.7500\n",
      "浓度模型 Epoch 114/500 | 训练损失: 8.7799 | 验证损失: 6.8720 | LR: 0.000789\n",
      "浓度验证指标 - MSE: 1.3999, RMSE: 1.1781, MAE: 0.1737, R2: 0.8454\n",
      "浓度模型 Epoch 115, Batch 0: Total Loss: 7.7174, Criterion Loss: 6.9388, MSE: 1.4668, KL Loss: 0.7785, L1 Reg: 547203.8750\n",
      "浓度模型 Epoch 115/500 | 训练损失: 9.0953 | 验证损失: 6.8069 | LR: 0.000786\n",
      "浓度验证指标 - MSE: 1.3498, RMSE: 1.1564, MAE: 0.1808, R2: 0.8510\n",
      "浓度模型 Epoch 116, Batch 0: Total Loss: 8.3421, Criterion Loss: 7.5681, MSE: 2.1110, KL Loss: 0.7741, L1 Reg: 545704.6875\n",
      "浓度模型 Epoch 116/500 | 训练损失: 8.8539 | 验证损失: 6.8016 | LR: 0.000784\n",
      "浓度验证指标 - MSE: 1.3607, RMSE: 1.1615, MAE: 0.1742, R2: 0.8497\n",
      "浓度模型 Epoch 117, Batch 0: Total Loss: 7.4352, Criterion Loss: 6.7004, MSE: 1.2595, KL Loss: 0.7348, L1 Reg: 544089.3750\n",
      "浓度模型 Epoch 117/500 | 训练损失: 8.8151 | 验证损失: 6.7236 | LR: 0.000780\n",
      "浓度验证指标 - MSE: 1.3010, RMSE: 1.1367, MAE: 0.1950, R2: 0.8560\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.7236\n",
      "浓度模型 Epoch 118, Batch 0: Total Loss: 8.2115, Criterion Loss: 7.4823, MSE: 2.0597, KL Loss: 0.7293, L1 Reg: 542255.8750\n",
      "浓度模型 Epoch 118/500 | 训练损失: 8.6830 | 验证损失: 6.6482 | LR: 0.000777\n",
      "浓度验证指标 - MSE: 1.2407, RMSE: 1.1090, MAE: 0.1794, R2: 0.8629\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.6482\n",
      "浓度模型 Epoch 119, Batch 0: Total Loss: 7.9387, Criterion Loss: 7.2360, MSE: 1.8285, KL Loss: 0.7027, L1 Reg: 540752.9375\n",
      "浓度模型 Epoch 119/500 | 训练损失: 8.6147 | 验证损失: 6.6776 | LR: 0.000773\n",
      "浓度验证指标 - MSE: 1.2849, RMSE: 1.1284, MAE: 0.1698, R2: 0.8581\n",
      "浓度模型 Epoch 120, Batch 0: Total Loss: 8.2259, Criterion Loss: 7.5309, MSE: 2.1382, KL Loss: 0.6950, L1 Reg: 539269.8750\n",
      "浓度模型 Epoch 120/500 | 训练损失: 8.6900 | 验证损失: 6.6801 | LR: 0.000770\n",
      "浓度验证指标 - MSE: 1.3026, RMSE: 1.1365, MAE: 0.1810, R2: 0.8561\n",
      "浓度模型 Epoch 121, Batch 0: Total Loss: 7.9666, Criterion Loss: 7.2952, MSE: 1.9176, KL Loss: 0.6715, L1 Reg: 537753.1875\n",
      "浓度模型 Epoch 121/500 | 训练损失: 9.3150 | 验证损失: 6.8261 | LR: 0.000765\n",
      "浓度验证指标 - MSE: 1.4613, RMSE: 1.2040, MAE: 0.1720, R2: 0.8385\n",
      "浓度模型 Epoch 122, Batch 0: Total Loss: 7.4446, Criterion Loss: 6.8030, MSE: 1.4383, KL Loss: 0.6416, L1 Reg: 536473.3125\n",
      "浓度模型 Epoch 122/500 | 训练损失: 8.5529 | 验证损失: 6.6110 | LR: 0.000761\n",
      "浓度验证指标 - MSE: 1.2598, RMSE: 1.1183, MAE: 0.1740, R2: 0.8607\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.6110\n",
      "浓度模型 Epoch 123, Batch 0: Total Loss: 7.5196, Criterion Loss: 6.8812, MSE: 1.5300, KL Loss: 0.6384, L1 Reg: 535119.8750\n",
      "浓度模型 Epoch 123/500 | 训练损失: 8.5378 | 验证损失: 6.6647 | LR: 0.000756\n",
      "浓度验证指标 - MSE: 1.3306, RMSE: 1.1480, MAE: 0.1842, R2: 0.8532\n",
      "浓度模型 Epoch 124, Batch 0: Total Loss: 7.5094, Criterion Loss: 6.8878, MSE: 1.5537, KL Loss: 0.6216, L1 Reg: 533411.4375\n",
      "浓度模型 Epoch 124/500 | 训练损失: 8.7492 | 验证损失: 6.5648 | LR: 0.000752\n",
      "浓度验证指标 - MSE: 1.2470, RMSE: 1.1114, MAE: 0.1692, R2: 0.8624\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.5648\n",
      "浓度模型 Epoch 125, Batch 0: Total Loss: 7.6031, Criterion Loss: 6.9964, MSE: 1.6786, KL Loss: 0.6067, L1 Reg: 531781.1250\n",
      "浓度模型 Epoch 125/500 | 训练损失: 8.6856 | 验证损失: 6.5951 | LR: 0.000746\n",
      "浓度验证指标 - MSE: 1.2928, RMSE: 1.1321, MAE: 0.1969, R2: 0.8572\n",
      "浓度模型早停触发! 在第125个epoch停止训练\n",
      "\n",
      "浓度模型训练完成!\n",
      "基于损失的最佳验证损失: 6.5648\n",
      "基于R2的最佳R2分数: 0.8677\n",
      "改进的双模型训练曲线已保存\n",
      "\n",
      "================================================================================\n",
      "双模型训练完成总结:\n",
      "水头模型 - 基于损失的最佳验证损失: 10.1397\n",
      "水头模型 - 基于R2的最佳R2分数: 0.6910\n",
      "浓度模型 - 基于损失的最佳验证损失: 6.5648\n",
      "浓度模型 - 基于R2的最佳R2分数: 0.8677\n",
      "评估将使用基于r2的模型\n",
      "================================================================================\n",
      "开始评估双模型性能（基于loss标准）...\n",
      "成功加载基于loss的最佳模型权重\n",
      "水头模型来自epoch 133, 验证损失: 10.1397, R2: 0.6910\n",
      "浓度模型来自epoch 123, 验证损失: 6.5648, R2: 0.8624\n",
      "开始处理验证数据...\n",
      "处理批次 0/8\n",
      "\n",
      "水头模型评估结果（基于loss）:\n",
      "  MSE: 9.9774\n",
      "  RMSE: 3.1587\n",
      "  MAE: 2.5015\n",
      "  R2: 0.6957\n",
      "\n",
      "浓度模型评估结果（基于loss）:\n",
      "  MSE: 1.2444\n",
      "  RMSE: 1.1155\n",
      "  MAE: 0.1660\n",
      "  R2: 0.8626\n",
      "生成可视化图表...\n",
      "\n",
      "评估结果已保存到: ./saved_models/blitz_bayesian_gnn_dual_guass/dual_model_evaluation_loss.npy\n",
      "预测结果CSV已保存到: ./saved_models/blitz_bayesian_gnn_dual_guass/evaluation_results/predictions_loss.csv\n",
      "不确定性结果CSV已保存到: ./saved_models/blitz_bayesian_gnn_dual_guass/evaluation_results/uncertainties_loss.csv\n",
      "\n",
      "📊 评估完成!\n",
      "📈 水头模型 - R2: 0.6957, RMSE: 3.1587\n",
      "📈 浓度模型 - R2: 0.8626, RMSE: 1.1155\n",
      "📁 所有结果已保存到: ./saved_models/blitz_bayesian_gnn_dual_guass/evaluation_results\n",
      "================================================================================\n",
      "比较不同选择标准的模型性能\n",
      "================================================================================\n",
      "开始评估双模型性能（基于loss标准）...\n",
      "成功加载基于loss的最佳模型权重\n",
      "水头模型来自epoch 133, 验证损失: 10.1397, R2: 0.6910\n",
      "浓度模型来自epoch 123, 验证损失: 6.5648, R2: 0.8624\n",
      "开始处理验证数据...\n",
      "处理批次 0/8\n",
      "\n",
      "水头模型评估结果（基于loss）:\n",
      "  MSE: 10.4372\n",
      "  RMSE: 3.2307\n",
      "  MAE: 2.5564\n",
      "  R2: 0.6816\n",
      "\n",
      "浓度模型评估结果（基于loss）:\n",
      "  MSE: 1.2567\n",
      "  RMSE: 1.1210\n",
      "  MAE: 0.1716\n",
      "  R2: 0.8613\n",
      "生成可视化图表...\n",
      "\n",
      "评估结果已保存到: ./saved_models/blitz_bayesian_gnn_dual_guass/dual_model_evaluation_loss.npy\n",
      "预测结果CSV已保存到: ./saved_models/blitz_bayesian_gnn_dual_guass/evaluation_results/predictions_loss.csv\n",
      "不确定性结果CSV已保存到: ./saved_models/blitz_bayesian_gnn_dual_guass/evaluation_results/uncertainties_loss.csv\n",
      "\n",
      "📊 评估完成!\n",
      "📈 水头模型 - R2: 0.6816, RMSE: 3.2307\n",
      "📈 浓度模型 - R2: 0.8613, RMSE: 1.1210\n",
      "📁 所有结果已保存到: ./saved_models/blitz_bayesian_gnn_dual_guass/evaluation_results\n",
      "开始评估双模型性能（基于r2标准）...\n",
      "成功加载基于r2的最佳模型权重\n",
      "水头模型来自epoch 133, 验证损失: 10.1397, R2: 0.6910\n",
      "浓度模型来自epoch 94, 验证损失: 6.8122, R2: 0.8677\n",
      "开始处理验证数据...\n",
      "处理批次 0/8\n",
      "\n",
      "水头模型评估结果（基于r2）:\n",
      "  MSE: 10.4943\n",
      "  RMSE: 3.2395\n",
      "  MAE: 2.5673\n",
      "  R2: 0.6799\n",
      "\n",
      "浓度模型评估结果（基于r2）:\n",
      "  MSE: 1.2221\n",
      "  RMSE: 1.1055\n",
      "  MAE: 0.1702\n",
      "  R2: 0.8651\n",
      "生成可视化图表...\n",
      "\n",
      "评估结果已保存到: ./saved_models/blitz_bayesian_gnn_dual_guass/dual_model_evaluation_r2.npy\n",
      "预测结果CSV已保存到: ./saved_models/blitz_bayesian_gnn_dual_guass/evaluation_results/predictions_r2.csv\n",
      "不确定性结果CSV已保存到: ./saved_models/blitz_bayesian_gnn_dual_guass/evaluation_results/uncertainties_r2.csv\n",
      "\n",
      "📊 评估完成!\n",
      "📈 水头模型 - R2: 0.6799, RMSE: 3.2395\n",
      "📈 浓度模型 - R2: 0.8651, RMSE: 1.1055\n",
      "📁 所有结果已保存到: ./saved_models/blitz_bayesian_gnn_dual_guass/evaluation_results\n",
      "\n",
      "模型选择标准比较结果:\n",
      "        Model Criterion     MSE   RMSE    MAE     R2  Uncertainty_Mean  Error_Uncertainty_Corr\n",
      "         Head      Loss 10.4372 3.2307 2.5564 0.6816            5.3658                  0.0442\n",
      "         Head        R2 10.4943 3.2395 2.5673 0.6799            5.3722                  0.0346\n",
      "Concentration      Loss  1.2567 1.1210 0.1716 0.8613            0.1312                  0.6439\n",
      "Concentration        R2  1.2221 1.1055 0.1702 0.8651            0.1311                  0.6683\n",
      "\n",
      "比较图表已保存到: ./saved_models/blitz_bayesian_gnn_dual_guass/evaluation_results/model_criteria_comparison_comprehensive.png\n",
      "比较数据已保存到: ./saved_models/blitz_bayesian_gnn_dual_guass/evaluation_results/model_criteria_comparison.csv\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('conc_dual_guass.csv')  # 替换为您的数据文件\n",
    "train_loader, val_loader = prepare_data(data, batch_size=4)\n",
    "head_model, conc_model, training_losses = train_dual_model_improved(train_loader, val_loader)\n",
    "evaluation_results = evaluate_dual_model_improved(head_model, conc_model, val_loader)\n",
    "comparison_df, loss_results, r2_results=compare_model_criteria(head_model, conc_model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2769be0-cb85-4976-b15f-6d4c7940c954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功加载评估结果: dual_model_evaluation_r2.npy\n",
      "共有 888 个空间点\n",
      "网格尺寸: 30 rows x 50 cols\n",
      "空间范围: row [0, 29], col [0, 49]\n",
      "改进的水头模型空间2D结果图已保存\n",
      "改进的浓度模型空间2D结果图已保存\n",
      "改进的综合空间2D分析图已保存\n",
      "改进的空间2D拟合效果图绘制完成!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import seaborn as sns\n",
    "from scipy.interpolate import griddata\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import os\n",
    "\n",
    "def interpolate_and_smooth_field(field_2d, mask_2d, nrow, ncol, sigma=1.0):\n",
    "    \"\"\"\n",
    "    First interpolate missing values, then apply smoothing, but keep original grid structure\n",
    "    \"\"\"\n",
    "    # Copy original field\n",
    "    result = field_2d.copy()\n",
    "    \n",
    "    # Create coordinate grids\n",
    "    rows, cols = np.mgrid[0:nrow, 0:ncol]\n",
    "    \n",
    "    # Get active cells\n",
    "    active_mask = (mask_2d > 0) & (~np.isnan(field_2d))\n",
    "    \n",
    "    if np.any(active_mask):\n",
    "        # Get active points and values\n",
    "        points = np.column_stack((rows[active_mask], cols[active_mask]))\n",
    "        values = field_2d[active_mask]\n",
    "        \n",
    "        # Create all grid points\n",
    "        all_points = np.column_stack((rows.ravel(), cols.ravel()))\n",
    "        \n",
    "        # Interpolate to fill any gaps\n",
    "        try:\n",
    "            interpolated_values = griddata(points, values, all_points, \n",
    "                                         method='cubic', fill_value=np.nan)\n",
    "            interpolated_field = interpolated_values.reshape(nrow, ncol)\n",
    "            \n",
    "            # Replace NaN values in original field with interpolated values\n",
    "            nan_mask = np.isnan(result)\n",
    "            result[nan_mask] = interpolated_field[nan_mask]\n",
    "            \n",
    "            # Apply Gaussian smoothing to the entire field\n",
    "            # Only smooth where we have valid data\n",
    "            valid_mask = ~np.isnan(result)\n",
    "            if np.any(valid_mask):\n",
    "                # Create a temporary field for smoothing\n",
    "                temp_field = result.copy()\n",
    "                temp_field[~valid_mask] = np.nanmean(result[valid_mask])  # Fill with mean for smoothing\n",
    "                \n",
    "                # Apply smoothing\n",
    "                smoothed = gaussian_filter(temp_field, sigma=sigma)\n",
    "                \n",
    "                # Only use smoothed values where we originally had data\n",
    "                result = smoothed\n",
    "                result[mask_2d <= 0] = np.nan  # Restore inactive areas as NaN\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Interpolation failed: {e}, using original field with basic smoothing\")\n",
    "            # Fallback: just apply basic smoothing\n",
    "            valid_mask = ~np.isnan(result) & (mask_2d > 0)\n",
    "            if np.any(valid_mask):\n",
    "                temp_field = result.copy()\n",
    "                temp_field[~valid_mask] = np.nanmean(result[valid_mask])\n",
    "                result = gaussian_filter(temp_field, sigma=sigma)\n",
    "                result[mask_2d <= 0] = np.nan\n",
    "    \n",
    "    return result\n",
    "\n",
    "def create_2d_field_from_points(df, field_name, nrow, ncol):\n",
    "    \"\"\"\n",
    "    Create 2D field from point data with proper indexing\n",
    "    \"\"\"\n",
    "    field_2d = np.full((nrow, ncol), np.nan)\n",
    "    mask_2d = np.zeros((nrow, ncol))\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        r, c = int(row['row']), int(row['col'])\n",
    "        if 0 <= r < nrow and 0 <= c < ncol:\n",
    "            field_2d[r, c] = row[field_name]\n",
    "            mask_2d[r, c] = 1\n",
    "    \n",
    "    return field_2d, mask_2d\n",
    "\n",
    "def plot_spatial_2d_fitting_results_improved(evaluation_results, save_path, time_step=None, model_type='both', sigma=1.5):\n",
    "    \"\"\"\n",
    "    绘制改进的基于空间坐标(x,y)的二维拟合效果图，使用MODFLOW网格方向和平滑插值\n",
    "    \n",
    "    Args:\n",
    "        evaluation_results: 评估结果字典\n",
    "        save_path: 保存路径\n",
    "        time_step: 指定时间步（如果为None，使用所有时间步的平均）\n",
    "        model_type: 'head', 'conc', 或 'both'\n",
    "        sigma: 高斯平滑参数\n",
    "    \"\"\"\n",
    "    \n",
    "    # 检查是否有详细预测结果\n",
    "    if 'detailed_predictions' not in evaluation_results:\n",
    "        print(\"警告: 评估结果中没有详细的空间信息，尝试从保存的CSV文件中读取\")\n",
    "        return load_and_plot_from_csv_improved(save_path, model_type, sigma)\n",
    "    \n",
    "    # 提取空间坐标和预测结果\n",
    "    all_data = []\n",
    "    \n",
    "    for batch_data in evaluation_results['detailed_predictions']:\n",
    "        if 'row' in batch_data and 'col' in batch_data:\n",
    "            batch_df = pd.DataFrame({\n",
    "                'row': batch_data['row'].flatten() if hasattr(batch_data['row'], 'flatten') else batch_data['row'],\n",
    "                'col': batch_data['col'].flatten() if hasattr(batch_data['col'], 'flatten') else batch_data['col'],\n",
    "                'pred_head': batch_data['pred_head'],\n",
    "                'true_head': batch_data['true_head'],\n",
    "                'pred_conc': batch_data['pred_conc'],\n",
    "                'true_conc': batch_data['true_conc'],\n",
    "            })\n",
    "            \n",
    "            if 'time_step' in batch_data:\n",
    "                batch_df['time_step'] = batch_data['time_step'].flatten() if hasattr(batch_data['time_step'], 'flatten') else batch_data['time_step']\n",
    "            \n",
    "            all_data.append(batch_df)\n",
    "    \n",
    "    if not all_data:\n",
    "        print(\"错误: 无法提取空间坐标信息\")\n",
    "        return\n",
    "    \n",
    "    # 合并所有数据\n",
    "    df = pd.concat(all_data, ignore_index=True)\n",
    "    \n",
    "    # 如果指定了时间步，筛选数据\n",
    "    if time_step is not None and 'time_step' in df.columns:\n",
    "        df = df[df['time_step'] == time_step]\n",
    "        time_suffix = f'_t{time_step}'\n",
    "    else:\n",
    "        # 使用所有时间步的平均值\n",
    "        df = df.groupby(['row', 'col']).agg({\n",
    "            'pred_head': 'mean',\n",
    "            'true_head': 'mean',\n",
    "            'pred_conc': 'mean',\n",
    "            'true_conc': 'mean'\n",
    "        }).reset_index()\n",
    "        time_suffix = '_all_time_avg'\n",
    "    \n",
    "    # 计算误差\n",
    "    df['head_error'] = np.abs(df['pred_head'] - df['true_head'])\n",
    "    df['conc_error'] = np.abs(df['pred_conc'] - df['true_conc'])\n",
    "    df['head_relative_error'] = df['head_error'] / (np.abs(df['true_head']) + 1e-8) * 100\n",
    "    df['conc_relative_error'] = df['conc_error'] / (np.abs(df['true_conc']) + 1e-8) * 100\n",
    "    \n",
    "    # 确定网格尺寸\n",
    "    nrow = int(df['row'].max()) + 1\n",
    "    ncol = int(df['col'].max()) + 1\n",
    "    \n",
    "    print(f\"共有 {len(df)} 个空间点\")\n",
    "    print(f\"网格尺寸: {nrow} rows x {ncol} cols\")\n",
    "    print(f\"空间范围: row [0, {nrow-1}], col [0, {ncol-1}]\")\n",
    "    \n",
    "    # 绘制图表\n",
    "    if model_type in ['head', 'both']:\n",
    "        plot_head_2d_results_improved(df, nrow, ncol, save_path, time_suffix, sigma)\n",
    "    \n",
    "    if model_type in ['conc', 'both']:\n",
    "        plot_conc_2d_results_improved(df, nrow, ncol, save_path, time_suffix, sigma)\n",
    "    \n",
    "    # 绘制综合比较图\n",
    "    if model_type == 'both':\n",
    "        plot_combined_2d_results_improved(df, nrow, ncol, save_path, time_suffix, sigma)\n",
    "\n",
    "def plot_head_2d_results_improved(df, nrow, ncol, save_path, time_suffix, sigma):\n",
    "    \"\"\"绘制水头模型的改进二维结果\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(24, 16))\n",
    "    fig.suptitle(f'Head Model Spatial 2D Results{time_suffix}', fontsize=20)\n",
    "    \n",
    "    # 创建2D场\n",
    "    true_head_2d, mask_2d = create_2d_field_from_points(df, 'true_head', nrow, ncol)\n",
    "    pred_head_2d, _ = create_2d_field_from_points(df, 'pred_head', nrow, ncol)\n",
    "    head_error_2d, _ = create_2d_field_from_points(df, 'head_error', nrow, ncol)\n",
    "    head_rel_error_2d, _ = create_2d_field_from_points(df, 'head_relative_error', nrow, ncol)\n",
    "    head_residual_2d = pred_head_2d - true_head_2d\n",
    "    \n",
    "    # 应用插值和平滑\n",
    "    true_head_smooth = interpolate_and_smooth_field(true_head_2d, mask_2d, nrow, ncol, sigma)\n",
    "    pred_head_smooth = interpolate_and_smooth_field(pred_head_2d, mask_2d, nrow, ncol, sigma)\n",
    "    head_error_smooth = interpolate_and_smooth_field(head_error_2d, mask_2d, nrow, ncol, sigma)\n",
    "    head_rel_error_smooth = interpolate_and_smooth_field(head_rel_error_2d, mask_2d, nrow, ncol, sigma)\n",
    "    head_residual_smooth = interpolate_and_smooth_field(head_residual_2d, mask_2d, nrow, ncol, sigma)\n",
    "    \n",
    "    # 1. 真实水头值\n",
    "    ax = axes[0, 0]\n",
    "    ax.set_title('True Head Values', fontsize=16)\n",
    "    masked_true = np.ma.masked_where(mask_2d <= 0, true_head_smooth)\n",
    "    valid_true = masked_true.compressed()\n",
    "    vmin_true, vmax_true = np.nanmin(valid_true), np.nanmax(valid_true) if len(valid_true) > 0 else (0, 1)\n",
    "    \n",
    "    im1 = ax.imshow(masked_true, cmap='viridis', aspect='equal', \n",
    "                   extent=[0, ncol-1, nrow-1, 0], origin='upper', \n",
    "                   interpolation='bilinear', vmin=vmin_true, vmax=vmax_true)\n",
    "    \n",
    "    divider1 = make_axes_locatable(ax)\n",
    "    cax1 = divider1.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    cbar1 = plt.colorbar(im1, cax=cax1)\n",
    "    cbar1.set_label('Head (m)', fontsize=12)\n",
    "    \n",
    "    # 添加统计信息\n",
    "    stats_text = f\"Min: {vmin_true:.2f}\\nMax: {vmax_true:.2f}\\nMean: {np.nanmean(valid_true):.2f}\"\n",
    "    ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=10,\n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    ax.set_xlim(0, ncol-1)\n",
    "    ax.set_ylim(nrow-1, 0)\n",
    "    ax.set_xlabel('Columns')\n",
    "    ax.set_ylabel('Rows')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. 预测水头值\n",
    "    ax = axes[0, 1]\n",
    "    ax.set_title('Predicted Head Values', fontsize=16)\n",
    "    masked_pred = np.ma.masked_where(mask_2d <= 0, pred_head_smooth)\n",
    "    valid_pred = masked_pred.compressed()\n",
    "    vmin_pred, vmax_pred = np.nanmin(valid_pred), np.nanmax(valid_pred) if len(valid_pred) > 0 else (0, 1)\n",
    "    \n",
    "    im2 = ax.imshow(masked_pred, cmap='viridis', aspect='equal',\n",
    "                   extent=[0, ncol-1, nrow-1, 0], origin='upper',\n",
    "                   interpolation='bilinear', vmin=vmin_pred, vmax=vmax_pred)\n",
    "    \n",
    "    divider2 = make_axes_locatable(ax)\n",
    "    cax2 = divider2.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    cbar2 = plt.colorbar(im2, cax=cax2)\n",
    "    cbar2.set_label('Head (m)', fontsize=12)\n",
    "    \n",
    "    stats_text = f\"Min: {vmin_pred:.2f}\\nMax: {vmax_pred:.2f}\\nMean: {np.nanmean(valid_pred):.2f}\"\n",
    "    ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=10,\n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    ax.set_xlim(0, ncol-1)\n",
    "    ax.set_ylim(nrow-1, 0)\n",
    "    ax.set_xlabel('Columns')\n",
    "    ax.set_ylabel('Rows')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. 绝对误差\n",
    "    ax = axes[0, 2]\n",
    "    ax.set_title('Absolute Error', fontsize=16)\n",
    "    masked_error = np.ma.masked_where(mask_2d <= 0, head_error_smooth)\n",
    "    valid_error = masked_error.compressed()\n",
    "    vmin_error, vmax_error = 0, np.nanmax(valid_error) if len(valid_error) > 0 else 1\n",
    "    \n",
    "    im3 = ax.imshow(masked_error, cmap='Reds', aspect='equal',\n",
    "                   extent=[0, ncol-1, nrow-1, 0], origin='upper',\n",
    "                   interpolation='bilinear', vmin=vmin_error, vmax=vmax_error)\n",
    "    \n",
    "    divider3 = make_axes_locatable(ax)\n",
    "    cax3 = divider3.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    cbar3 = plt.colorbar(im3, cax=cax3)\n",
    "    cbar3.set_label('Error (m)', fontsize=12)\n",
    "    \n",
    "    stats_text = f\"Min: {vmin_error:.2f}\\nMax: {vmax_error:.2f}\\nMean: {np.nanmean(valid_error):.2f}\"\n",
    "    ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=10,\n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    ax.set_xlim(0, ncol-1)\n",
    "    ax.set_ylim(nrow-1, 0)\n",
    "    ax.set_xlabel('Columns')\n",
    "    ax.set_ylabel('Rows')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. 相对误差\n",
    "    ax = axes[1, 0]\n",
    "    ax.set_title('Relative Error (%)', fontsize=16)\n",
    "    masked_rel_error = np.ma.masked_where(mask_2d <= 0, head_rel_error_smooth)\n",
    "    valid_rel_error = masked_rel_error.compressed()\n",
    "    vmin_rel, vmax_rel = 0, np.nanmax(valid_rel_error) if len(valid_rel_error) > 0 else 100\n",
    "    \n",
    "    im4 = ax.imshow(masked_rel_error, cmap='Reds', aspect='equal',\n",
    "                   extent=[0, ncol-1, nrow-1, 0], origin='upper',\n",
    "                   interpolation='bilinear', vmin=vmin_rel, vmax=vmax_rel)\n",
    "    \n",
    "    divider4 = make_axes_locatable(ax)\n",
    "    cax4 = divider4.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    cbar4 = plt.colorbar(im4, cax=cax4)\n",
    "    cbar4.set_label('Relative Error (%)', fontsize=12)\n",
    "    \n",
    "    stats_text = f\"Min: {vmin_rel:.1f}%\\nMax: {vmax_rel:.1f}%\\nMean: {np.nanmean(valid_rel_error):.1f}%\"\n",
    "    ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=10,\n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    ax.set_xlim(0, ncol-1)\n",
    "    ax.set_ylim(nrow-1, 0)\n",
    "    ax.set_xlabel('Columns')\n",
    "    ax.set_ylabel('Rows')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 5. 预测 vs 真实值散点图（按空间位置着色）\n",
    "    ax = axes[1, 1]\n",
    "    ax.set_title('Prediction vs Truth (colored by row)', fontsize=16)\n",
    "    scatter = ax.scatter(df['true_head'], df['pred_head'], \n",
    "                        c=df['row'], s=20, cmap='plasma', alpha=0.7)\n",
    "    min_val = min(df['true_head'].min(), df['pred_head'].min())\n",
    "    max_val = max(df['true_head'].max(), df['pred_head'].max())\n",
    "    ax.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2)\n",
    "    ax.set_xlabel('True Head Values (m)')\n",
    "    ax.set_ylabel('Predicted Head Values (m)')\n",
    "    \n",
    "    divider5 = make_axes_locatable(ax)\n",
    "    cax5 = divider5.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    plt.colorbar(scatter, cax=cax5, label='Row Index')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 6. 残差图\n",
    "    ax = axes[1, 2]\n",
    "    ax.set_title('Residuals (Pred - True)', fontsize=16)\n",
    "    masked_residual = np.ma.masked_where(mask_2d <= 0, head_residual_smooth)\n",
    "    valid_residual = masked_residual.compressed()\n",
    "    abs_max = np.nanmax(np.abs(valid_residual)) if len(valid_residual) > 0 else 1\n",
    "    \n",
    "    im6 = ax.imshow(masked_residual, cmap='RdBu_r', aspect='equal',\n",
    "                   extent=[0, ncol-1, nrow-1, 0], origin='upper',\n",
    "                   interpolation='bilinear', vmin=-abs_max, vmax=abs_max)\n",
    "    \n",
    "    divider6 = make_axes_locatable(ax)\n",
    "    cax6 = divider6.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    cbar6 = plt.colorbar(im6, cax=cax6)\n",
    "    cbar6.set_label('Residual (m)', fontsize=12)\n",
    "    \n",
    "    stats_text = f\"Min: {np.nanmin(valid_residual):.2f}\\nMax: {np.nanmax(valid_residual):.2f}\\nMean: {np.nanmean(valid_residual):.2f}\"\n",
    "    ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=10,\n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    ax.set_xlim(0, ncol-1)\n",
    "    ax.set_ylim(nrow-1, 0)\n",
    "    ax.set_xlabel('Columns')\n",
    "    ax.set_ylabel('Rows')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_path, f'head_spatial_2d_results_improved{time_suffix}.png'), \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"改进的水头模型空间2D结果图已保存\")\n",
    "\n",
    "def plot_conc_2d_results_improved(df, nrow, ncol, save_path, time_suffix, sigma):\n",
    "    \"\"\"绘制浓度模型的改进二维结果\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(24, 16))\n",
    "    fig.suptitle(f'Concentration Model Spatial 2D Results{time_suffix}', fontsize=20)\n",
    "    \n",
    "    # 创建2D场\n",
    "    true_conc_2d, mask_2d = create_2d_field_from_points(df, 'true_conc', nrow, ncol)\n",
    "    pred_conc_2d, _ = create_2d_field_from_points(df, 'pred_conc', nrow, ncol)\n",
    "    conc_error_2d, _ = create_2d_field_from_points(df, 'conc_error', nrow, ncol)\n",
    "    conc_rel_error_2d, _ = create_2d_field_from_points(df, 'conc_relative_error', nrow, ncol)\n",
    "    conc_residual_2d = pred_conc_2d - true_conc_2d\n",
    "    \n",
    "    # 应用插值和平滑\n",
    "    true_conc_smooth = interpolate_and_smooth_field(true_conc_2d, mask_2d, nrow, ncol, sigma)\n",
    "    pred_conc_smooth = interpolate_and_smooth_field(pred_conc_2d, mask_2d, nrow, ncol, sigma)\n",
    "    conc_error_smooth = interpolate_and_smooth_field(conc_error_2d, mask_2d, nrow, ncol, sigma)\n",
    "    conc_rel_error_smooth = interpolate_and_smooth_field(conc_rel_error_2d, mask_2d, nrow, ncol, sigma)\n",
    "    conc_residual_smooth = interpolate_and_smooth_field(conc_residual_2d, mask_2d, nrow, ncol, sigma)\n",
    "    \n",
    "    # 1. 真实浓度值\n",
    "    ax = axes[0, 0]\n",
    "    ax.set_title('True Concentration Values', fontsize=16)\n",
    "    masked_true = np.ma.masked_where(mask_2d <= 0, true_conc_smooth)\n",
    "    valid_true = masked_true.compressed()\n",
    "    vmin_true, vmax_true = np.nanmin(valid_true), np.nanmax(valid_true) if len(valid_true) > 0 else (0, 1)\n",
    "    \n",
    "    im1 = ax.imshow(masked_true, cmap='plasma', aspect='equal',\n",
    "                   extent=[0, ncol-1, nrow-1, 0], origin='upper',\n",
    "                   interpolation='bilinear', vmin=vmin_true, vmax=vmax_true)\n",
    "    \n",
    "    divider1 = make_axes_locatable(ax)\n",
    "    cax1 = divider1.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    cbar1 = plt.colorbar(im1, cax=cax1)\n",
    "    cbar1.set_label('Concentration(mg/L)', fontsize=12)\n",
    "    \n",
    "    stats_text = f\"Min: {vmin_true:.3f}\\nMax: {vmax_true:.3f}\\nMean: {np.nanmean(valid_true):.3f}\"\n",
    "    ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=10,\n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    ax.set_xlim(0, ncol-1)\n",
    "    ax.set_ylim(nrow-1, 0)\n",
    "    ax.set_xlabel('Columns')\n",
    "    ax.set_ylabel('Rows')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. 预测浓度值\n",
    "    ax = axes[0, 1]\n",
    "    ax.set_title('Predicted Concentration Values', fontsize=16)\n",
    "    masked_pred = np.ma.masked_where(mask_2d <= 0, pred_conc_smooth)\n",
    "    valid_pred = masked_pred.compressed()\n",
    "    vmin_pred, vmax_pred = np.nanmin(valid_pred), np.nanmax(valid_pred) if len(valid_pred) > 0 else (0, 1)\n",
    "    \n",
    "    im2 = ax.imshow(masked_pred, cmap='plasma', aspect='equal',\n",
    "                   extent=[0, ncol-1, nrow-1, 0], origin='upper',\n",
    "                   interpolation='bilinear', vmin=vmin_pred, vmax=vmax_pred)\n",
    "    \n",
    "    divider2 = make_axes_locatable(ax)\n",
    "    cax2 = divider2.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    cbar2 = plt.colorbar(im2, cax=cax2)\n",
    "    cbar2.set_label('Concentration(mg/L)', fontsize=12)\n",
    "    \n",
    "    stats_text = f\"Min: {vmin_pred:.3f}\\nMax: {vmax_pred:.3f}\\nMean: {np.nanmean(valid_pred):.3f}\"\n",
    "    ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=10,\n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    ax.set_xlim(0, ncol-1)\n",
    "    ax.set_ylim(nrow-1, 0)\n",
    "    ax.set_xlabel('Columns')\n",
    "    ax.set_ylabel('Rows')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. 绝对误差\n",
    "    ax = axes[0, 2]\n",
    "    ax.set_title('Absolute Error', fontsize=16)\n",
    "    masked_error = np.ma.masked_where(mask_2d <= 0, conc_error_smooth)\n",
    "    valid_error = masked_error.compressed()\n",
    "    vmin_error, vmax_error = 0, np.nanmax(valid_error) if len(valid_error) > 0 else 1\n",
    "    \n",
    "    im3 = ax.imshow(masked_error, cmap='Reds', aspect='equal',\n",
    "                   extent=[0, ncol-1, nrow-1, 0], origin='upper',\n",
    "                   interpolation='bilinear', vmin=vmin_error, vmax=vmax_error)\n",
    "    \n",
    "    divider3 = make_axes_locatable(ax)\n",
    "    cax3 = divider3.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    cbar3 = plt.colorbar(im3, cax=cax3)\n",
    "    cbar3.set_label('Error', fontsize=12)\n",
    "    \n",
    "    stats_text = f\"Min: {vmin_error:.3f}\\nMax: {vmax_error:.3f}\\nMean: {np.nanmean(valid_error):.3f}\"\n",
    "    ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=10,\n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    ax.set_xlim(0, ncol-1)\n",
    "    ax.set_ylim(nrow-1, 0)\n",
    "    ax.set_xlabel('Columns')\n",
    "    ax.set_ylabel('Rows')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. 相对误差\n",
    "    ax = axes[1, 0]\n",
    "    ax.set_title('Relative Error (%)', fontsize=16)\n",
    "    masked_rel_error = np.ma.masked_where(mask_2d <= 0, conc_rel_error_smooth)\n",
    "    valid_rel_error = masked_rel_error.compressed()\n",
    "    vmin_rel, vmax_rel = 0, np.nanmax(valid_rel_error) if len(valid_rel_error) > 0 else 100\n",
    "    \n",
    "    im4 = ax.imshow(masked_rel_error, cmap='Reds', aspect='equal',\n",
    "                   extent=[0, ncol-1, nrow-1, 0], origin='upper',\n",
    "                   interpolation='bilinear', vmin=vmin_rel, vmax=vmax_rel)\n",
    "    \n",
    "    divider4 = make_axes_locatable(ax)\n",
    "    cax4 = divider4.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    cbar4 = plt.colorbar(im4, cax=cax4)\n",
    "    cbar4.set_label('Relative Error (%)', fontsize=12)\n",
    "    \n",
    "    stats_text = f\"Min: {vmin_rel:.1f}%\\nMax: {vmax_rel:.1f}%\\nMean: {np.nanmean(valid_rel_error):.1f}%\"\n",
    "    ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=10,\n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    ax.set_xlim(0, ncol-1)\n",
    "    ax.set_ylim(nrow-1, 0)\n",
    "    ax.set_xlabel('Columns')\n",
    "    ax.set_ylabel('Rows')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 5. 预测 vs 真实值散点图（按空间位置着色）\n",
    "    ax = axes[1, 1]\n",
    "    ax.set_title('Prediction vs Truth (colored by column)', fontsize=16)\n",
    "    scatter = ax.scatter(df['true_conc'], df['pred_conc'],\n",
    "                        c=df['col'], s=20, cmap='viridis', alpha=0.7)\n",
    "    min_val = min(df['true_conc'].min(), df['pred_conc'].min())\n",
    "    max_val = max(df['true_conc'].max(), df['pred_conc'].max())\n",
    "    ax.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2)\n",
    "    ax.set_xlabel('True Concentration Values')\n",
    "    ax.set_ylabel('Predicted Concentration Values')\n",
    "    \n",
    "    divider5 = make_axes_locatable(ax)\n",
    "    cax5 = divider5.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    plt.colorbar(scatter, cax=cax5, label='Column Index')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 6. 残差图\n",
    "    ax = axes[1, 2]\n",
    "    ax.set_title('Residuals (Pred - True)', fontsize=16)\n",
    "    masked_residual = np.ma.masked_where(mask_2d <= 0, conc_residual_smooth)\n",
    "    valid_residual = masked_residual.compressed()\n",
    "    abs_max = np.nanmax(np.abs(valid_residual)) if len(valid_residual) > 0 else 1\n",
    "    \n",
    "    im6 = ax.imshow(masked_residual, cmap='RdBu_r', aspect='equal',\n",
    "                   extent=[0, ncol-1, nrow-1, 0], origin='upper',\n",
    "                   interpolation='bilinear', vmin=-abs_max, vmax=abs_max)\n",
    "    \n",
    "    divider6 = make_axes_locatable(ax)\n",
    "    cax6 = divider6.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    cbar6 = plt.colorbar(im6, cax=cax6)\n",
    "    cbar6.set_label('Residual(mg/L)', fontsize=12)\n",
    "    \n",
    "    stats_text = f\"Min: {np.nanmin(valid_residual):.3f}\\nMax: {np.nanmax(valid_residual):.3f}\\nMean: {np.nanmean(valid_residual):.3f}\"\n",
    "    ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=10,\n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    ax.set_xlim(0, ncol-1)\n",
    "    ax.set_ylim(nrow-1, 0)\n",
    "    ax.set_xlabel('Columns')\n",
    "    ax.set_ylabel('Rows')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_path, f'conc_spatial_2d_results_improved{time_suffix}.png'),\n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"改进的浓度模型空间2D结果图已保存\")\n",
    "\n",
    "def plot_combined_2d_results_improved(df, nrow, ncol, save_path, time_suffix, sigma):\n",
    "    \"\"\"绘制水头和浓度模型的改进综合比较图\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(20, 16))\n",
    "    fig.suptitle(f'Combined Spatial 2D Analysis{time_suffix}', fontsize=20)\n",
    "    \n",
    "    # 创建2D场\n",
    "    head_error_2d, mask_2d = create_2d_field_from_points(df, 'head_error', nrow, ncol)\n",
    "    conc_error_2d, _ = create_2d_field_from_points(df, 'conc_error', nrow, ncol)\n",
    "    combined_rel_error = (df['head_relative_error'] + df['conc_relative_error']) / 2\n",
    "    combined_error_2d, _ = create_2d_field_from_points(\n",
    "        df.assign(combined_rel_error=combined_rel_error), \n",
    "        'combined_rel_error', nrow, ncol\n",
    "    )\n",
    "    \n",
    "    # 应用插值和平滑\n",
    "    head_error_smooth = interpolate_and_smooth_field(head_error_2d, mask_2d, nrow, ncol, sigma)\n",
    "    conc_error_smooth = interpolate_and_smooth_field(conc_error_2d, mask_2d, nrow, ncol, sigma)\n",
    "    combined_error_smooth = interpolate_and_smooth_field(combined_error_2d, mask_2d, nrow, ncol, sigma)\n",
    "    \n",
    "    # 1. 水头误差分布\n",
    "    ax = axes[0, 0]\n",
    "    ax.set_title('Head Model: Absolute Error Distribution', fontsize=16)\n",
    "    masked_head_error = np.ma.masked_where(mask_2d <= 0, head_error_smooth)\n",
    "    valid_head_error = masked_head_error.compressed()\n",
    "    vmax_head_error = np.nanmax(valid_head_error) if len(valid_head_error) > 0 else 1\n",
    "    \n",
    "    im1 = ax.imshow(masked_head_error, cmap='Reds', aspect='equal',\n",
    "                   extent=[0, ncol-1, nrow-1, 0], origin='upper',\n",
    "                   interpolation='bilinear', vmin=0, vmax=vmax_head_error)\n",
    "    \n",
    "    divider1 = make_axes_locatable(ax)\n",
    "    cax1 = divider1.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    plt.colorbar(im1, cax=cax1, label='Head Error (m)')\n",
    "    \n",
    "    ax.set_xlim(0, ncol-1)\n",
    "    ax.set_ylim(nrow-1, 0)\n",
    "    ax.set_xlabel('Columns')\n",
    "    ax.set_ylabel('Rows')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. 浓度误差分布\n",
    "    ax = axes[0, 1]\n",
    "    ax.set_title('Concentration Model: Absolute Error Distribution', fontsize=16)\n",
    "    masked_conc_error = np.ma.masked_where(mask_2d <= 0, conc_error_smooth)\n",
    "    valid_conc_error = masked_conc_error.compressed()\n",
    "    vmax_conc_error = np.nanmax(valid_conc_error) if len(valid_conc_error) > 0 else 1\n",
    "    \n",
    "    im2 = ax.imshow(masked_conc_error, cmap='Reds', aspect='equal',\n",
    "                   extent=[0, ncol-1, nrow-1, 0], origin='upper',\n",
    "                   interpolation='bilinear', vmin=0, vmax=vmax_conc_error)\n",
    "    \n",
    "    divider2 = make_axes_locatable(ax)\n",
    "    cax2 = divider2.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    plt.colorbar(im2, cax=cax2, label='Concentration Error')\n",
    "    \n",
    "    ax.set_xlim(0, ncol-1)\n",
    "    ax.set_ylim(nrow-1, 0)\n",
    "    ax.set_xlabel('Columns')\n",
    "    ax.set_ylabel('Rows')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. 误差相关性分析\n",
    "    ax = axes[1, 0]\n",
    "    ax.set_title('Error Correlation (colored by row)', fontsize=16)\n",
    "    scatter = ax.scatter(df['head_error'], df['conc_error'], c=df['row'],\n",
    "                        s=30, cmap='viridis', alpha=0.7, edgecolors='black', linewidth=0.3)\n",
    "    ax.set_xlabel('Head Absolute Error')\n",
    "    ax.set_ylabel('Concentration Absolute Error')\n",
    "    \n",
    "    divider3 = make_axes_locatable(ax)\n",
    "    cax3 = divider3.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    plt.colorbar(scatter, cax=cax3, label='Row Index')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. 综合误差分布\n",
    "    ax = axes[1, 1]\n",
    "    ax.set_title('Combined Relative Error (%)', fontsize=16)\n",
    "    masked_combined = np.ma.masked_where(mask_2d <= 0, combined_error_smooth)\n",
    "    valid_combined = masked_combined.compressed()\n",
    "    vmax_combined = np.nanmax(valid_combined) if len(valid_combined) > 0 else 100\n",
    "    \n",
    "    im4 = ax.imshow(masked_combined, cmap='Reds', aspect='equal',\n",
    "                   extent=[0, ncol-1, nrow-1, 0], origin='upper',\n",
    "                   interpolation='bilinear', vmin=0, vmax=vmax_combined)\n",
    "    \n",
    "    divider4 = make_axes_locatable(ax)\n",
    "    cax4 = divider4.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    plt.colorbar(im4, cax=cax4, label='Combined Error (%)')\n",
    "    \n",
    "    stats_text = f\"Min: {np.nanmin(valid_combined):.1f}%\\nMax: {vmax_combined:.1f}%\\nMean: {np.nanmean(valid_combined):.1f}%\"\n",
    "    ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=10,\n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    ax.set_xlim(0, ncol-1)\n",
    "    ax.set_ylim(nrow-1, 0)\n",
    "    ax.set_xlabel('Columns')\n",
    "    ax.set_ylabel('Rows')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_path, f'combined_spatial_2d_results_improved{time_suffix}.png'),\n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"改进的综合空间2D分析图已保存\")\n",
    "\n",
    "def load_and_plot_from_csv_improved(save_path, model_type, sigma):\n",
    "    \"\"\"从CSV文件加载数据并绘制改进版图表\"\"\"\n",
    "    try:\n",
    "        results_dir = os.path.join(save_path, 'evaluation_results')\n",
    "        csv_files = [f for f in os.listdir(results_dir) if f.endswith('.csv') and 'predictions' in f]\n",
    "        \n",
    "        if not csv_files:\n",
    "            print(\"未找到预测结果CSV文件\")\n",
    "            return\n",
    "        \n",
    "        csv_file = csv_files[0]\n",
    "        df = pd.read_csv(os.path.join(results_dir, csv_file))\n",
    "        \n",
    "        print(f\"从 {csv_file} 加载数据\")\n",
    "        print(f\"数据形状: {df.shape}\")\n",
    "        \n",
    "        # 检查必要的列\n",
    "        required_cols = ['row', 'col', 'pred_head', 'true_head', 'pred_conc', 'true_conc']\n",
    "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "        \n",
    "        if missing_cols:\n",
    "            print(f\"缺少必要的列: {missing_cols}\")\n",
    "            return\n",
    "        \n",
    "        # 计算误差\n",
    "        df['head_error'] = np.abs(df['pred_head'] - df['true_head'])\n",
    "        df['conc_error'] = np.abs(df['pred_conc'] - df['true_conc'])\n",
    "        df['head_relative_error'] = df['head_error'] / (np.abs(df['true_head']) + 1e-8) * 100\n",
    "        df['conc_relative_error'] = df['conc_error'] / (np.abs(df['true_conc']) + 1e-8) * 100\n",
    "        \n",
    "        # 如果有多个时间步，取平均\n",
    "        if 'time_step' in df.columns:\n",
    "            df = df.groupby(['row', 'col']).agg({\n",
    "                'pred_head': 'mean',\n",
    "                'true_head': 'mean',\n",
    "                'pred_conc': 'mean',\n",
    "                'true_conc': 'mean',\n",
    "                'head_error': 'mean',\n",
    "                'conc_error': 'mean',\n",
    "                'head_relative_error': 'mean',\n",
    "                'conc_relative_error': 'mean'\n",
    "            }).reset_index()\n",
    "        \n",
    "        # 确定网格尺寸\n",
    "        nrow = int(df['row'].max()) + 1\n",
    "        ncol = int(df['col'].max()) + 1\n",
    "        \n",
    "        time_suffix = '_from_csv'\n",
    "        \n",
    "        # 绘制图表\n",
    "        if model_type in ['head', 'both']:\n",
    "            plot_head_2d_results_improved(df, nrow, ncol, results_dir, time_suffix, sigma)\n",
    "        \n",
    "        if model_type in ['conc', 'both']:\n",
    "            plot_conc_2d_results_improved(df, nrow, ncol, results_dir, time_suffix, sigma)\n",
    "        \n",
    "        if model_type == 'both':\n",
    "            plot_combined_2d_results_improved(df, nrow, ncol, results_dir, time_suffix, sigma)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"从CSV加载数据失败: {e}\")\n",
    "\n",
    "# 主函数\n",
    "def main():\n",
    "    \"\"\"主函数示例\"\"\"\n",
    "    save_path = './saved_models/blitz_bayesian_gnn_dual_guass'\n",
    "    evaluation_criterion = 'r2'\n",
    "    \n",
    "    try:\n",
    "        filename = f'dual_model_evaluation_{evaluation_criterion}.npy'\n",
    "        filepath = os.path.join(save_path, filename)\n",
    "        evaluation_results = np.load(filepath, allow_pickle=True).item()\n",
    "        \n",
    "        print(f\"成功加载评估结果: {filename}\")\n",
    "        \n",
    "        # 绘制改进的空间2D拟合效果图\n",
    "        plot_spatial_2d_fitting_results_improved(\n",
    "            evaluation_results,\n",
    "            save_path,\n",
    "            time_step=None,  # 使用所有时间步的平均\n",
    "            model_type='both',  # 'head', 'conc', 或 'both'\n",
    "            sigma=1.5  # 平滑参数\n",
    "        )\n",
    "        \n",
    "        print(\"改进的空间2D拟合效果图绘制完成!\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"未找到评估结果文件，尝试从CSV文件绘制\")\n",
    "        load_and_plot_from_csv_improved(save_path, 'both', sigma=1.5)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"加载评估结果失败: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90acb9f7-09a5-4318-9793-4fa20851ce32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "🚀 开始完整的特征作用蜂群图分析\n",
      "==========================================================================================\n",
      "\n",
      "📊 分析评估标准: r2\n",
      "================================================================================\n",
      "🎯 特征作用蜂群图分析\n",
      "  横轴：特征对模型输出的作用（正向/负向）\n",
      "  颜色：特征重要性\n",
      "================================================================================\n",
      "\n",
      "🌊 分析Head模型特征作用...\n",
      "======================================================================\n",
      "🎯 HEAD模型特征作用分析\n",
      "======================================================================\n",
      "✅ 成功加载HEAD模型 (Epoch: 133, Val Loss: 10.1397)\n",
      "🎯 开始分析 300 个样本...\n",
      "📊 验证数据加载器总批次数: 8\n",
      "🔄 需要重复遍历数据加载器 38 次\n",
      "\n",
      "🔄 第 1/38 轮遍历...\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.739296\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 1/300 分析完成 (轮次1, 批次1)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.239906\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 2/300 分析完成 (轮次1, 批次2)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.078606\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 3/300 分析完成 (轮次1, 批次3)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 98.296501\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 4/300 分析完成 (轮次1, 批次4)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.062012\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 5/300 分析完成 (轮次1, 批次5)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.056854\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 6/300 分析完成 (轮次1, 批次6)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.523499\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 7/300 分析完成 (轮次1, 批次7)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.477478\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 8/300 分析完成 (轮次1, 批次8)\n",
      "\n",
      "🔄 第 2/38 轮遍历...\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.669281\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 9/300 分析完成 (轮次2, 批次1)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.031174\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 10/300 分析完成 (轮次2, 批次2)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 96.532104\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 11/300 分析完成 (轮次2, 批次3)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 96.946266\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 12/300 分析完成 (轮次2, 批次4)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.725525\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 13/300 分析完成 (轮次2, 批次5)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.709648\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 14/300 分析完成 (轮次2, 批次6)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 96.646843\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 15/300 分析完成 (轮次2, 批次7)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.842850\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 16/300 分析完成 (轮次2, 批次8)\n",
      "\n",
      "🔄 第 3/38 轮遍历...\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 96.927910\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 17/300 分析完成 (轮次3, 批次1)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.404510\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 18/300 分析完成 (轮次3, 批次2)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.548889\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 19/300 分析完成 (轮次3, 批次3)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.312042\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 20/300 分析完成 (轮次3, 批次4)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.007324\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 21/300 分析完成 (轮次3, 批次5)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 96.805420\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 22/300 分析完成 (轮次3, 批次6)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.271477\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 23/300 分析完成 (轮次3, 批次7)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.408417\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 24/300 分析完成 (轮次3, 批次8)\n",
      "\n",
      "🔄 第 4/38 轮遍历...\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 98.284630\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 25/300 分析完成 (轮次4, 批次1)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 98.109146\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 26/300 分析完成 (轮次4, 批次2)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.404419\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 27/300 分析完成 (轮次4, 批次3)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 96.737839\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 28/300 分析完成 (轮次4, 批次4)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.290047\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 29/300 分析完成 (轮次4, 批次5)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 98.319801\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 30/300 分析完成 (轮次4, 批次6)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.695145\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 31/300 分析完成 (轮次4, 批次7)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.369003\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 32/300 分析完成 (轮次4, 批次8)\n",
      "\n",
      "🔄 第 5/38 轮遍历...\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 96.816086\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 33/300 分析完成 (轮次5, 批次1)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.115898\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 34/300 分析完成 (轮次5, 批次2)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 98.101357\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 35/300 分析完成 (轮次5, 批次3)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.569115\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 36/300 分析完成 (轮次5, 批次4)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 96.539902\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 37/300 分析完成 (轮次5, 批次5)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.065071\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 38/300 分析完成 (轮次5, 批次6)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.722420\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 39/300 分析完成 (轮次5, 批次7)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.040169\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 40/300 分析完成 (轮次5, 批次8)\n",
      "\n",
      "🔄 第 6/38 轮遍历...\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.903801\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 41/300 分析完成 (轮次6, 批次1)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 96.780182\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 42/300 分析完成 (轮次6, 批次2)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.881157\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 43/300 分析完成 (轮次6, 批次3)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 98.229790\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 44/300 分析完成 (轮次6, 批次4)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 96.657417\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 45/300 分析完成 (轮次6, 批次5)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.644234\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 46/300 分析完成 (轮次6, 批次6)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 98.049751\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 47/300 分析完成 (轮次6, 批次7)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 96.520821\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 48/300 分析完成 (轮次6, 批次8)\n",
      "\n",
      "🔄 第 7/38 轮遍历...\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.482338\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 49/300 分析完成 (轮次7, 批次1)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 98.375534\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 50/300 分析完成 (轮次7, 批次2)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.824234\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 51/300 分析完成 (轮次7, 批次3)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 98.401955\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 52/300 分析完成 (轮次7, 批次4)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.362778\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 53/300 分析完成 (轮次7, 批次5)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.572189\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 54/300 分析完成 (轮次7, 批次6)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.454407\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 55/300 分析完成 (轮次7, 批次7)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 96.414551\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 56/300 分析完成 (轮次7, 批次8)\n",
      "\n",
      "🔄 第 8/38 轮遍历...\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.106300\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 57/300 分析完成 (轮次8, 批次1)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.317482\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 58/300 分析完成 (轮次8, 批次2)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.396866\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 59/300 分析完成 (轮次8, 批次3)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.409447\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 60/300 分析完成 (轮次8, 批次4)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.621002\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 61/300 分析完成 (轮次8, 批次5)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.477142\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 62/300 分析完成 (轮次8, 批次6)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.661301\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 63/300 分析完成 (轮次8, 批次7)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 96.878212\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 64/300 分析完成 (轮次8, 批次8)\n",
      "\n",
      "🔄 第 9/38 轮遍历...\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.690521\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 65/300 分析完成 (轮次9, 批次1)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.040466\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 66/300 分析完成 (轮次9, 批次2)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.271057\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 67/300 分析完成 (轮次9, 批次3)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.953590\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 68/300 分析完成 (轮次9, 批次4)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.484947\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 69/300 分析完成 (轮次9, 批次5)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 96.946739\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 70/300 分析完成 (轮次9, 批次6)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 98.058762\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 71/300 分析完成 (轮次9, 批次7)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 96.932037\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 72/300 分析完成 (轮次9, 批次8)\n",
      "\n",
      "🔄 第 10/38 轮遍历...\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 96.999634\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 73/300 分析完成 (轮次10, 批次1)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.238449\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 74/300 分析完成 (轮次10, 批次2)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.729263\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 75/300 分析完成 (轮次10, 批次3)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 96.786377\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 76/300 分析完成 (轮次10, 批次4)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.605080\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 77/300 分析完成 (轮次10, 批次5)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 98.090996\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 78/300 分析完成 (轮次10, 批次6)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 96.782959\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 79/300 分析完成 (轮次10, 批次7)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.528603\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 80/300 分析完成 (轮次10, 批次8)\n",
      "\n",
      "🔄 第 11/38 轮遍历...\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.439926\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 81/300 分析完成 (轮次11, 批次1)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 96.710388\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 82/300 分析完成 (轮次11, 批次2)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.186005\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 83/300 分析完成 (轮次11, 批次3)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.711166\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 84/300 分析完成 (轮次11, 批次4)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.935455\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 85/300 分析完成 (轮次11, 批次5)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.896599\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 86/300 分析完成 (轮次11, 批次6)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 96.520500\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 87/300 分析完成 (轮次11, 批次7)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.538788\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 88/300 分析完成 (轮次11, 批次8)\n",
      "\n",
      "🔄 第 12/38 轮遍历...\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.201164\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 89/300 分析完成 (轮次12, 批次1)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.298347\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 90/300 分析完成 (轮次12, 批次2)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 96.807510\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 91/300 分析完成 (轮次12, 批次3)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.923424\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 92/300 分析完成 (轮次12, 批次4)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.285652\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 93/300 分析完成 (轮次12, 批次5)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.544075\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 94/300 分析完成 (轮次12, 批次6)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.093704\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 95/300 分析完成 (轮次12, 批次7)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 96.993050\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 96/300 分析完成 (轮次12, 批次8)\n",
      "\n",
      "🔄 第 13/38 轮遍历...\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.472244\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 97/300 分析完成 (轮次13, 批次1)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.264511\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 98/300 分析完成 (轮次13, 批次2)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 96.970909\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 99/300 分析完成 (轮次13, 批次3)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 96.792747\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 100/300 分析完成 (轮次13, 批次4)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 96.633369\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 101/300 分析完成 (轮次13, 批次5)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.611115\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 102/300 分析完成 (轮次13, 批次6)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 96.837326\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 103/300 分析完成 (轮次13, 批次7)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.257095\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 104/300 分析完成 (轮次13, 批次8)\n",
      "\n",
      "🔄 第 14/38 轮遍历...\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 96.464180\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 105/300 分析完成 (轮次14, 批次1)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.882301\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 106/300 分析完成 (轮次14, 批次2)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 97.582062\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 107/300 分析完成 (轮次14, 批次3)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 98.363159\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 108/300 分析完成 (轮次14, 批次4)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 96.922737\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 109/300 分析完成 (轮次14, 批次5)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 98.050797\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 110/300 分析完成 (轮次14, 批次6)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 98.221962\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n",
      "      分析特征 14/16\n",
      "      分析特征 15/16\n",
      "      分析特征 16/16\n",
      "    ✅ 特征作用和重要性计算完成\n",
      "  ✅ 样本 111/300 分析完成 (轮次14, 批次7)\n",
      "  🔍 计算HEAD模型的特征作用和重要性...\n",
      "    📊 特征数量: 16\n",
      "    📈 基线预测均值: 96.885078\n",
      "      分析特征 1/16\n",
      "      分析特征 2/16\n",
      "      分析特征 3/16\n",
      "      分析特征 4/16\n",
      "      分析特征 5/16\n",
      "      分析特征 6/16\n",
      "      分析特征 7/16\n",
      "      分析特征 8/16\n",
      "      分析特征 9/16\n",
      "      分析特征 10/16\n",
      "      分析特征 11/16\n",
      "      分析特征 12/16\n",
      "      分析特征 13/16\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import gc\n",
    "from sklearn.metrics import r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def create_complete_data_copy(original_data, device):\n",
    "    \"\"\"创建包含所有必要属性的完整数据副本\"\"\"\n",
    "    try:\n",
    "        data_copy = original_data.clone().to(device)\n",
    "        \n",
    "        required_attrs = ['x', 'conc_x', 'edge_index', 'edge_attr', 'y', 'head_y', \n",
    "                         'time_step', 'bc_mask', 'row', 'col', 'model_name']\n",
    "        \n",
    "        for attr in required_attrs:\n",
    "            if hasattr(original_data, attr):\n",
    "                original_value = getattr(original_data, attr)\n",
    "                if original_value is not None:\n",
    "                    if torch.is_tensor(original_value):\n",
    "                        setattr(data_copy, attr, original_value.clone().to(device))\n",
    "                    else:\n",
    "                        setattr(data_copy, attr, original_value)\n",
    "            else:\n",
    "                if attr == 'bc_mask':\n",
    "                    if hasattr(data_copy, 'x') and data_copy.x is not None:\n",
    "                        num_nodes = data_copy.x.shape[0]\n",
    "                        setattr(data_copy, attr, torch.zeros(num_nodes, 5, dtype=torch.float32, device=device))\n",
    "                elif attr == 'time_step':\n",
    "                    if hasattr(data_copy, 'x') and data_copy.x is not None:\n",
    "                        num_nodes = data_copy.x.shape[0]\n",
    "                        setattr(data_copy, attr, torch.zeros(num_nodes, dtype=torch.long, device=device))\n",
    "        \n",
    "        return data_copy\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 创建数据副本失败: {e}\")\n",
    "        return None\n",
    "\n",
    "def compute_feature_effects_and_importance(model, data, model_type='head', mc_samples=20, perturbation_scale=0.1):\n",
    "    \"\"\"\n",
    "    计算特征对模型输出的作用（正向/负向）和重要性\n",
    "    \n",
    "    Args:\n",
    "        model: 要分析的模型\n",
    "        data: 输入数据\n",
    "        model_type: 模型类型 ('head' 或 'conc')\n",
    "        mc_samples: MC采样次数\n",
    "        perturbation_scale: 扰动强度\n",
    "    \n",
    "    Returns:\n",
    "        dict: 包含特征作用和重要性的字典\n",
    "    \"\"\"\n",
    "    model.train()  # Blitz模型需要训练模式进行MC采样\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    print(f\"  🔍 计算{model_type.upper()}模型的特征作用和重要性...\")\n",
    "    \n",
    "    try:\n",
    "        # 创建数据副本\n",
    "        data_copy = create_complete_data_copy(data, device)\n",
    "        if data_copy is None:\n",
    "            return {}\n",
    "        \n",
    "        # 确定特征集\n",
    "        if model_type == 'head':\n",
    "            if not hasattr(data_copy, 'x') or data_copy.x is None:\n",
    "                print(f\"    ❌ 水头模型缺少节点特征 x\")\n",
    "                return {}\n",
    "            feature_tensor = data_copy.x\n",
    "            feature_name = 'x'\n",
    "        else:  # conc\n",
    "            if not hasattr(data_copy, 'conc_x') or data_copy.conc_x is None:\n",
    "                print(f\"    ❌ 浓度模型缺少节点特征 conc_x\")\n",
    "                return {}\n",
    "            feature_tensor = data_copy.conc_x\n",
    "            feature_name = 'conc_x'\n",
    "        \n",
    "        num_features = feature_tensor.shape[1]\n",
    "        print(f\"    📊 特征数量: {num_features}\")\n",
    "        \n",
    "        # 获取基线预测\n",
    "        baseline_preds = []\n",
    "        for _ in range(mc_samples):\n",
    "            with torch.no_grad():\n",
    "                pred = model(data_copy)\n",
    "                baseline_preds.append(pred.detach())\n",
    "        \n",
    "        baseline_pred = torch.stack(baseline_preds, dim=0).mean(dim=0)\n",
    "        baseline_mean = baseline_pred.mean().item()\n",
    "        \n",
    "        print(f\"    📈 基线预测均值: {baseline_mean:.6f}\")\n",
    "        \n",
    "        # 存储每个特征的作用和重要性\n",
    "        feature_effects = np.zeros(num_features)  # 特征作用（正向/负向）\n",
    "        feature_importance = np.zeros(num_features)  # 特征重要性（绝对值）\n",
    "        \n",
    "        # 对每个特征进行扰动分析\n",
    "        for feat_idx in range(num_features):\n",
    "            print(f\"      分析特征 {feat_idx + 1}/{num_features}\")\n",
    "            \n",
    "            # 正向扰动\n",
    "            data_pos = data_copy.clone()\n",
    "            original_feature = getattr(data_pos, feature_name)[:, feat_idx].clone()\n",
    "            std_val = original_feature.std().item()\n",
    "            \n",
    "            # 正向扰动\n",
    "            getattr(data_pos, feature_name)[:, feat_idx] = original_feature + perturbation_scale * std_val\n",
    "            \n",
    "            pos_preds = []\n",
    "            for _ in range(mc_samples):\n",
    "                with torch.no_grad():\n",
    "                    pred = model(data_pos)\n",
    "                    pos_preds.append(pred.detach())\n",
    "            pos_pred = torch.stack(pos_preds, dim=0).mean(dim=0)\n",
    "            pos_effect = pos_pred.mean().item() - baseline_mean\n",
    "            \n",
    "            # 负向扰动\n",
    "            data_neg = data_copy.clone()\n",
    "            getattr(data_neg, feature_name)[:, feat_idx] = original_feature - perturbation_scale * std_val\n",
    "            \n",
    "            neg_preds = []\n",
    "            for _ in range(mc_samples):\n",
    "                with torch.no_grad():\n",
    "                    pred = model(data_neg)\n",
    "                    neg_preds.append(pred.detach())\n",
    "            neg_pred = torch.stack(neg_preds, dim=0).mean(dim=0)\n",
    "            neg_effect = neg_pred.mean().item() - baseline_mean\n",
    "            \n",
    "            # 计算平均作用（正向表示增加特征值会增加输出，负向相反）\n",
    "            avg_effect = (pos_effect - neg_effect) / 2\n",
    "            \n",
    "            # 计算重要性（绝对影响程度）\n",
    "            importance = abs(pos_effect) + abs(neg_effect)\n",
    "            \n",
    "            feature_effects[feat_idx] = avg_effect\n",
    "            feature_importance[feat_idx] = importance\n",
    "        \n",
    "        # 归一化重要性到0-1范围\n",
    "        if feature_importance.max() > 0:\n",
    "            feature_importance = feature_importance / feature_importance.max()\n",
    "        \n",
    "        print(f\"    ✅ 特征作用和重要性计算完成\")\n",
    "        \n",
    "        return {\n",
    "            'effects': feature_effects,\n",
    "            'importance': feature_importance,\n",
    "            'baseline': baseline_mean\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"    ❌ 特征作用计算失败: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return {}\n",
    "\n",
    "def prepare_single_graph_batch(batch):\n",
    "    \"\"\"从batch中提取单个图的数据\"\"\"\n",
    "    try:\n",
    "        if not hasattr(batch, 'batch') or batch.batch is None:\n",
    "            return batch\n",
    "        \n",
    "        unique_graphs = torch.unique(batch.batch)\n",
    "        if len(unique_graphs) <= 1:\n",
    "            return batch\n",
    "        \n",
    "        # 提取第一个图\n",
    "        first_graph_mask = batch.batch == unique_graphs[0]\n",
    "        new_batch = type(batch)()\n",
    "        \n",
    "        # 复制节点相关属性\n",
    "        node_attrs = ['x', 'conc_x', 'head_y', 'y', 'time_step', 'bc_mask', 'row', 'col']\n",
    "        for attr in node_attrs:\n",
    "            if hasattr(batch, attr) and getattr(batch, attr) is not None:\n",
    "                attr_value = getattr(batch, attr)\n",
    "                if torch.is_tensor(attr_value) and len(attr_value) == len(first_graph_mask):\n",
    "                    setattr(new_batch, attr, attr_value[first_graph_mask])\n",
    "        \n",
    "        # 处理边相关数据\n",
    "        if hasattr(batch, 'edge_index') and batch.edge_index is not None:\n",
    "            first_nodes = torch.where(first_graph_mask)[0]\n",
    "            edge_mask = torch.isin(batch.edge_index[0], first_nodes) & \\\n",
    "                       torch.isin(batch.edge_index[1], first_nodes)\n",
    "            \n",
    "            if edge_mask.sum() > 0:\n",
    "                node_mapping = {old.item(): new for new, old in enumerate(first_nodes)}\n",
    "                old_edges = batch.edge_index[:, edge_mask]\n",
    "                new_edges = torch.zeros_like(old_edges)\n",
    "                \n",
    "                for i in range(old_edges.shape[1]):\n",
    "                    new_edges[0, i] = node_mapping[old_edges[0, i].item()]\n",
    "                    new_edges[1, i] = node_mapping[old_edges[1, i].item()]\n",
    "                \n",
    "                new_batch.edge_index = new_edges\n",
    "                \n",
    "                if hasattr(batch, 'edge_attr') and batch.edge_attr is not None:\n",
    "                    new_batch.edge_attr = batch.edge_attr[edge_mask]\n",
    "            else:\n",
    "                new_batch.edge_index = torch.empty((2, 0), dtype=torch.long, device=batch.edge_index.device)\n",
    "        \n",
    "        # 复制其他属性\n",
    "        other_attrs = ['model_name', 'time_steps']\n",
    "        for attr in other_attrs:\n",
    "            if hasattr(batch, attr):\n",
    "                setattr(new_batch, attr, getattr(batch, attr))\n",
    "        \n",
    "        return new_batch\n",
    "    except Exception as e:\n",
    "        print(f\"准备单图batch失败: {e}\")\n",
    "        return batch\n",
    "\n",
    "def analyze_model_effects(model, val_loader, config, model_type='head', \n",
    "                         evaluation_criterion='loss', n_samples=300):\n",
    "    \"\"\"\n",
    "    分析模型的特征作用和重要性 - 修复采样逻辑\n",
    "    \"\"\"\n",
    "    print(f\"=\" * 70)\n",
    "    print(f\"🎯 {model_type.upper()}模型特征作用分析\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # 加载最佳模型\n",
    "    try:\n",
    "        model_file = f'best_{model_type}_model_{evaluation_criterion}.pth'\n",
    "        checkpoint = torch.load(os.path.join(config['save_path'], model_file), \n",
    "                              map_location='cpu', weights_only=False)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        print(f\"✅ 成功加载{model_type.upper()}模型 (Epoch: {checkpoint['epoch']}, Val Loss: {checkpoint['val_loss']:.4f})\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️  加载{model_type.upper()}模型权重失败: {e}\")\n",
    "    \n",
    "    device = next(model.parameters()).device\n",
    "    model.eval()\n",
    "    \n",
    "    # 特征名称\n",
    "    if model_type == 'head':\n",
    "        feature_names = [\n",
    "            'x', 'y', 'top', 'bottom', 'K', 'recharge', 'ET',\n",
    "            'river_stage', 'river_cond', 'river_rbot', 'well_rate', \n",
    "            'well_mask', 'chd_mask', 'lytyp', 'prev_head', 'prev2_head'\n",
    "        ]\n",
    "    else:  # conc\n",
    "        feature_names = [\n",
    "            'x', 'y', 'top', 'bottom', 'K', 'recharge', 'ET',\n",
    "            'river_stage', 'river_cond', 'river_rbot', 'well_rate', \n",
    "            'well_mask', 'chd_mask', 'lytyp', 'conc_mask',\n",
    "            'prev_head', 'prev2_head', 'prev_conc', 'prev2_conc'\n",
    "        ]\n",
    "    \n",
    "    # 收集所有样本的作用和重要性数据\n",
    "    all_effect_data = []\n",
    "    successful_samples = 0\n",
    "    total_batches = len(val_loader)\n",
    "    \n",
    "    print(f\"🎯 开始分析 {n_samples} 个样本...\")\n",
    "    print(f\"📊 验证数据加载器总批次数: {total_batches}\")\n",
    "    \n",
    "    # 计算需要重复遍历的次数\n",
    "    cycles_needed = max(1, (n_samples + total_batches - 1) // total_batches)\n",
    "    print(f\"🔄 需要重复遍历数据加载器 {cycles_needed} 次\")\n",
    "    \n",
    "    for cycle in range(cycles_needed):\n",
    "        print(f\"\\n🔄 第 {cycle + 1}/{cycles_needed} 轮遍历...\")\n",
    "        \n",
    "        for batch_idx, batch in enumerate(val_loader):\n",
    "            if successful_samples >= n_samples:\n",
    "                break\n",
    "            \n",
    "            try:\n",
    "                # 准备单图数据\n",
    "                single_batch = prepare_single_graph_batch(batch)\n",
    "                \n",
    "                # 分析特征作用和重要性\n",
    "                result = compute_feature_effects_and_importance(\n",
    "                    model, single_batch, model_type=model_type\n",
    "                )\n",
    "                \n",
    "                if result and 'effects' in result and 'importance' in result:\n",
    "                    effects = result['effects']\n",
    "                    importance = result['importance']\n",
    "                    baseline = result['baseline']\n",
    "                    \n",
    "                    # 将结果转换为DataFrame格式\n",
    "                    for i, (effect, imp) in enumerate(zip(effects, importance)):\n",
    "                        feature_name = feature_names[i] if i < len(feature_names) else f'Feature_{i}'\n",
    "                        all_effect_data.append({\n",
    "                            'Sample': successful_samples + 1,\n",
    "                            'Feature': feature_name,\n",
    "                            'Effect': effect,  # 对输出的作用（正向/负向）\n",
    "                            'Importance': imp,  # 重要性（用于颜色）\n",
    "                            'Feature_Index': i,\n",
    "                            'Baseline': baseline,\n",
    "                            'Cycle': cycle + 1,\n",
    "                            'Batch_in_Cycle': batch_idx + 1\n",
    "                        })\n",
    "                    \n",
    "                    successful_samples += 1\n",
    "                    print(f\"  ✅ 样本 {successful_samples}/{n_samples} 分析完成 (轮次{cycle+1}, 批次{batch_idx+1})\")\n",
    "                else:\n",
    "                    print(f\"  ❌ 样本分析失败 (轮次{cycle+1}, 批次{batch_idx+1})\")\n",
    "                \n",
    "                # 清理内存\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  ❌ 处理批次 {batch_idx} 失败: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if successful_samples >= n_samples:\n",
    "            break\n",
    "    \n",
    "    print(f\"\\n📊 {model_type.upper()}模型分析完成，成功分析 {successful_samples} 个样本\")\n",
    "    \n",
    "    if not all_effect_data:\n",
    "        print(\"❌ 没有收集到任何有效数据\")\n",
    "        return None, None\n",
    "    \n",
    "    # 转换为DataFrame\n",
    "    effect_df = pd.DataFrame(all_effect_data)\n",
    "    \n",
    "    # 计算统计信息\n",
    "    feature_stats = effect_df.groupby('Feature').agg({\n",
    "        'Effect': ['mean', 'std', 'min', 'max'],\n",
    "        'Importance': ['mean', 'std', 'min', 'max']\n",
    "    }).reset_index()\n",
    "    \n",
    "    # 扁平化列名\n",
    "    feature_stats.columns = ['Feature', 'Effect_Mean', 'Effect_Std', 'Effect_Min', 'Effect_Max',\n",
    "                            'Importance_Mean', 'Importance_Std', 'Importance_Min', 'Importance_Max']\n",
    "    \n",
    "    # 按重要性排序\n",
    "    feature_stats = feature_stats.sort_values('Importance_Mean', ascending=False)\n",
    "    \n",
    "    return effect_df, feature_stats\n",
    "\n",
    "def create_effect_swarm_plots(head_df, head_stats, conc_df, conc_stats, config, \n",
    "                             evaluation_criterion):\n",
    "    \"\"\"\n",
    "    创建基于特征作用的蜂群图（横轴是作用，颜色是重要性）\n",
    "    特征重要性从上到下排序\n",
    "    \"\"\"\n",
    "    print(\"🎨 生成特征作用蜂群图...\")\n",
    "\n",
    "    # 创建结果目录\n",
    "    results_dir = os.path.join(config['save_path'], 'effect_swarm_analysis')\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "    # 设置绘图风格\n",
    "    plt.style.use('default')\n",
    "\n",
    "    # 1. Head模型作用蜂群图\n",
    "    if head_df is not None:\n",
    "        plt.figure(figsize=(16, 12))\n",
    "        \n",
    "        # 按重要性均值从高到低排序\n",
    "        feature_order = head_stats.sort_values(\"Importance_Mean\", ascending=False)['Feature'].tolist()\n",
    "        \n",
    "        # y轴映射：特征在 feature_order 内的索引\n",
    "        y_mapping = {f: i for i, f in enumerate(feature_order)}\n",
    "\n",
    "        # 创建蜂群图，横轴是Effect，颜色表示Importance\n",
    "        scatter = plt.scatter(\n",
    "            head_df['Effect'], \n",
    "            head_df['Feature'].map(y_mapping), \n",
    "            c=head_df['Importance'], \n",
    "            cmap='viridis', \n",
    "            s=80, \n",
    "            alpha=0.7,\n",
    "            edgecolors='black',\n",
    "            linewidth=0.5\n",
    "        )\n",
    "        \n",
    "        # 添加颜色条\n",
    "        cbar = plt.colorbar(scatter)\n",
    "        cbar.set_label('Feature Importance', fontsize=12, fontweight='bold')\n",
    "\n",
    "        # 添加零线\n",
    "        plt.axvline(x=0, color='red', linestyle='--', alpha=0.8, linewidth=2, label='No Effect')\n",
    "\n",
    "        # 添加平均值标记\n",
    "        for i, feature in enumerate(feature_order):\n",
    "            mean_effect = head_stats[head_stats['Feature'] == feature]['Effect_Mean'].iloc[0]\n",
    "            plt.scatter(mean_effect, i, marker='D', s=100, color='red', \n",
    "                       edgecolors='black', linewidth=1, zorder=5)\n",
    "            # 添加数值标签\n",
    "            plt.text(mean_effect, i + 0.15, f'{mean_effect:.4f}', \n",
    "                    ha='center', va='bottom', fontsize=9, fontweight='bold', \n",
    "                    bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "\n",
    "        plt.yticks(range(len(feature_order)), feature_order)\n",
    "        plt.xlabel('Feature Effect on Model Output', fontsize=14, fontweight='bold')\n",
    "        plt.ylabel('Features (sorted by importance)', fontsize=14, fontweight='bold')\n",
    "        plt.title(f'Head Model: Feature Effects Distribution\\nCriterion: {evaluation_criterion}\\n(Red diamonds = mean effect)', \n",
    "                 fontsize=16, fontweight='bold', pad=20)\n",
    "        plt.grid(True, alpha=0.3, axis='x')\n",
    "        plt.legend()\n",
    "\n",
    "        # 调整布局\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(results_dir, f'head_effect_swarm_{evaluation_criterion}_sorted.png'), \n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        print(f\"  📊 Head模型作用蜂群图已保存（已按重要性排序）\")\n",
    "\n",
    "    # 2. Conc模型作用蜂群图\n",
    "    if conc_df is not None:\n",
    "        plt.figure(figsize=(16, 14))\n",
    "        \n",
    "        # 按重要性均值从高到低排序\n",
    "        feature_order = conc_stats.sort_values(\"Importance_Mean\", ascending=False)['Feature'].tolist()\n",
    "        y_mapping = {f: i for i, f in enumerate(feature_order)}\n",
    "\n",
    "        scatter = plt.scatter(\n",
    "            conc_df['Effect'], \n",
    "            conc_df['Feature'].map(y_mapping), \n",
    "            c=conc_df['Importance'], \n",
    "            cmap='viridis', \n",
    "            s=80, \n",
    "            alpha=0.7,\n",
    "            edgecolors='black',\n",
    "            linewidth=0.5\n",
    "        )\n",
    "\n",
    "        cbar = plt.colorbar(scatter)\n",
    "        cbar.set_label('Feature Importance', fontsize=12, fontweight='bold')\n",
    "\n",
    "        plt.axvline(x=0, color='red', linestyle='--', alpha=0.8, linewidth=2, label='No Effect')\n",
    "\n",
    "        for i, feature in enumerate(feature_order):\n",
    "            mean_effect = conc_stats[conc_stats['Feature'] == feature]['Effect_Mean'].iloc[0]\n",
    "            plt.scatter(mean_effect, i, marker='D', s=100, color='red', \n",
    "                       edgecolors='black', linewidth=1, zorder=5)\n",
    "            plt.text(mean_effect, i + 0.15, f'{mean_effect:.4f}', \n",
    "                    ha='center', va='bottom', fontsize=9, fontweight='bold',\n",
    "                    bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "\n",
    "        plt.yticks(range(len(feature_order)), feature_order)\n",
    "        plt.xlabel('Feature Effect on Model Output', fontsize=14, fontweight='bold')\n",
    "        plt.ylabel('Features (sorted by importance)', fontsize=14, fontweight='bold')\n",
    "        plt.title(f'Concentration Model: Feature Effects Distribution\\nCriterion: {evaluation_criterion}\\n(Red diamonds = mean effect)', \n",
    "                 fontsize=16, fontweight='bold', pad=20)\n",
    "        plt.grid(True, alpha=0.3, axis='x')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(results_dir, f'conc_effect_swarm_{evaluation_criterion}_sorted.png'), \n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        print(f\"  📊 Conc模型作用蜂群图已保存（已按重要性排序）\")\n",
    "\n",
    "    # 3. 对比图（只显示Top 10特征）\n",
    "    if head_df is not None and conc_df is not None:\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(28, 14))\n",
    "\n",
    "        # Head模型 Top 10（已排序）\n",
    "        top_head_features = head_stats.sort_values(\"Importance_Mean\", ascending=False).head(10)['Feature'].tolist()\n",
    "        head_top_df = head_df[head_df['Feature'].isin(top_head_features)]\n",
    "        y_mapping_head = {f: i for i, f in enumerate(top_head_features)}\n",
    "\n",
    "        ax1.scatter(\n",
    "            head_top_df['Effect'], \n",
    "            head_top_df['Feature'].map(y_mapping_head), \n",
    "            c=head_top_df['Importance'], \n",
    "            cmap='viridis', \n",
    "            s=100, \n",
    "            alpha=0.8,\n",
    "            edgecolors='black',\n",
    "            linewidth=0.5\n",
    "        )\n",
    "        ax1.axvline(x=0, color='red', linestyle='--', alpha=0.8, linewidth=2)\n",
    "        for i, feature in enumerate(top_head_features):\n",
    "            mean_effect = head_stats[head_stats['Feature'] == feature]['Effect_Mean'].iloc[0]\n",
    "            ax1.scatter(mean_effect, i, marker='D', s=120, color='red', \n",
    "                       edgecolors='black', linewidth=1, zorder=5)\n",
    "            ax1.text(mean_effect, i + 0.15, f'{mean_effect:.4f}', \n",
    "                    ha='center', va='bottom', fontsize=10, fontweight='bold',\n",
    "                    bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "\n",
    "        ax1.set_yticks(range(len(top_head_features)))\n",
    "        ax1.set_yticklabels(top_head_features)\n",
    "        ax1.set_xlabel('Feature Effect on Output', fontsize=12, fontweight='bold')\n",
    "        ax1.set_ylabel('Features (sorted by importance)', fontsize=12, fontweight='bold')\n",
    "        ax1.set_title('Head Model - Top 10 Features', fontsize=14, fontweight='bold')\n",
    "        ax1.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "        # Conc模型 Top 10（已排序）\n",
    "        top_conc_features = conc_stats.sort_values(\"Importance_Mean\", ascending=False).head(10)['Feature'].tolist()\n",
    "        conc_top_df = conc_df[conc_df['Feature'].isin(top_conc_features)]\n",
    "        y_mapping_conc = {f: i for i, f in enumerate(top_conc_features)}\n",
    "\n",
    "        ax2.scatter(\n",
    "            conc_top_df['Effect'], \n",
    "            conc_top_df['Feature'].map(y_mapping_conc), \n",
    "            c=conc_top_df['Importance'], \n",
    "            cmap='viridis', \n",
    "            s=100, \n",
    "            alpha=0.8,\n",
    "            edgecolors='black',\n",
    "            linewidth=0.5\n",
    "        )\n",
    "        ax2.axvline(x=0, color='red', linestyle='--', alpha=0.8, linewidth=2)\n",
    "        for i, feature in enumerate(top_conc_features):\n",
    "            mean_effect = conc_stats[conc_stats['Feature'] == feature]['Effect_Mean'].iloc[0]\n",
    "            ax2.scatter(mean_effect, i, marker='D', s=120, color='red', \n",
    "                       edgecolors='black', linewidth=1, zorder=5)\n",
    "            ax2.text(mean_effect, i + 0.15, f'{mean_effect:.4f}', \n",
    "                    ha='center', va='bottom', fontsize=10, fontweight='bold',\n",
    "                    bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "\n",
    "        ax2.set_yticks(range(len(top_conc_features)))\n",
    "        ax2.set_yticklabels(top_conc_features)\n",
    "        ax2.set_xlabel('Feature Effect on Output', fontsize=12, fontweight='bold')\n",
    "        ax2.set_ylabel('Features (sorted by importance)', fontsize=12, fontweight='bold')\n",
    "        ax2.set_title('Concentration Model - Top 10 Features', fontsize=14, fontweight='bold')\n",
    "        ax2.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "        # 添加共享的颜色条\n",
    "        fig.subplots_adjust(right=0.85)\n",
    "        cbar_ax = fig.add_axes([0.87, 0.15, 0.02, 0.7])\n",
    "        cbar = fig.colorbar(ax2.collections[0], cax=cbar_ax)\n",
    "        cbar.set_label('Feature Importance', fontsize=12, fontweight='bold')\n",
    "\n",
    "        plt.suptitle(f'Model Comparison: Feature Effects on Output\\nCriterion: {evaluation_criterion}', \n",
    "                    fontsize=16, fontweight='bold')\n",
    "        plt.savefig(os.path.join(results_dir, f'comparison_effect_swarm_{evaluation_criterion}_sorted.png'), \n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        print(f\"  📊 对比作用蜂群图已保存（已按重要性排序）\")\n",
    "\n",
    "    return results_dir\n",
    "\n",
    "def save_effect_results(head_df, head_stats, conc_df, conc_stats, results_dir, \n",
    "                       evaluation_criterion):\n",
    "    \"\"\"\n",
    "    保存特征作用分析结果\n",
    "    \"\"\"\n",
    "    print(\"💾 保存特征作用分析结果...\")\n",
    "    \n",
    "    # 保存原始数据\n",
    "    if head_df is not None:\n",
    "        head_df.to_csv(os.path.join(results_dir, f'head_effects_raw_{evaluation_criterion}.csv'), \n",
    "                      index=False)\n",
    "        head_stats.to_csv(os.path.join(results_dir, f'head_effects_stats_{evaluation_criterion}.csv'), \n",
    "                         index=False)\n",
    "    \n",
    "    if conc_df is not None:\n",
    "        conc_df.to_csv(os.path.join(results_dir, f'conc_effects_raw_{evaluation_criterion}.csv'), \n",
    "                      index=False)\n",
    "        conc_stats.to_csv(os.path.join(results_dir, f'conc_effects_stats_{evaluation_criterion}.csv'), \n",
    "                         index=False)\n",
    "    \n",
    "    # 创建总结报告\n",
    "    summary_data = []\n",
    "    \n",
    "    if head_stats is not None:\n",
    "        for _, row in head_stats.iterrows():\n",
    "            summary_data.append({\n",
    "                'Model': 'Head',\n",
    "                'Feature': row['Feature'],\n",
    "                'Mean_Effect': row['Effect_Mean'],\n",
    "                'Effect_Direction': 'Positive' if row['Effect_Mean'] > 0 else 'Negative' if row['Effect_Mean'] < 0 else 'Neutral',\n",
    "                'Mean_Importance': row['Importance_Mean'],\n",
    "                'Effect_Std': row['Effect_Std'],\n",
    "                'Importance_Std': row['Importance_Std']\n",
    "            })\n",
    "    \n",
    "    if conc_stats is not None:\n",
    "        for _, row in conc_stats.iterrows():\n",
    "            summary_data.append({\n",
    "                'Model': 'Concentration',\n",
    "                'Feature': row['Feature'],\n",
    "                'Mean_Effect': row['Effect_Mean'],\n",
    "                'Effect_Direction': 'Positive' if row['Effect_Mean'] > 0 else 'Negative' if row['Effect_Mean'] < 0 else 'Neutral',\n",
    "                'Mean_Importance': row['Importance_Mean'],\n",
    "                'Effect_Std': row['Effect_Std'],\n",
    "                'Importance_Std': row['Importance_Std']\n",
    "            })\n",
    "    \n",
    "    if summary_data:\n",
    "        summary_df = pd.DataFrame(summary_data)\n",
    "        summary_df.to_csv(os.path.join(results_dir, f'feature_effects_summary_{evaluation_criterion}.csv'), \n",
    "                         index=False)\n",
    "        \n",
    "        print(f\"  📄 总结报告已保存\")\n",
    "\n",
    "def run_effect_swarm_analysis(head_model, conc_model, val_loader, config, \n",
    "                             evaluation_criterion='loss', n_samples=300):\n",
    "    \"\"\"\n",
    "    运行基于特征作用的蜂群图分析\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"🎯 特征作用蜂群图分析\")\n",
    "    print(\"  横轴：特征对模型输出的作用（正向/负向）\")\n",
    "    print(\"  颜色：特征重要性\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 分析Head模型\n",
    "    print(\"\\n🌊 分析Head模型特征作用...\")\n",
    "    head_df, head_stats = analyze_model_effects(\n",
    "        head_model, val_loader, config, model_type='head', \n",
    "        evaluation_criterion=evaluation_criterion, n_samples=n_samples\n",
    "    )\n",
    "    \n",
    "    # 分析Conc模型\n",
    "    print(\"\\n🧪 分析Conc模型特征作用...\")\n",
    "    conc_df, conc_stats = analyze_model_effects(\n",
    "        conc_model, val_loader, config, model_type='conc', \n",
    "        evaluation_criterion=evaluation_criterion, n_samples=n_samples\n",
    "    )\n",
    "    \n",
    "    # 生成蜂群图\n",
    "    if head_df is not None or conc_df is not None:\n",
    "        results_dir = create_effect_swarm_plots(\n",
    "            head_df, head_stats, conc_df, conc_stats, \n",
    "            config, evaluation_criterion\n",
    "        )\n",
    "        \n",
    "        # 保存详细结果\n",
    "        save_effect_results(\n",
    "            head_df, head_stats, conc_df, conc_stats, \n",
    "            results_dir, evaluation_criterion\n",
    "        )\n",
    "        \n",
    "        print(f\"\\n🎉 特征作用蜂群图分析完成!\")\n",
    "        print(f\"📁 结果保存至: {results_dir}\")\n",
    "        \n",
    "        # 打印Top 5特征作用\n",
    "        if head_stats is not None:\n",
    "            print(f\"\\n🏆 Head模型 Top 5 重要特征作用:\")\n",
    "            for i, row in head_stats.head(5).iterrows():\n",
    "                direction = \"正向\" if row['Effect_Mean'] > 0 else \"负向\" if row['Effect_Mean'] < 0 else \"中性\"\n",
    "                print(f\"  {i+1}. {row['Feature']}: 作用 {row['Effect_Mean']:.6f} ({direction}), 重要性 {row['Importance_Mean']:.6f}\")\n",
    "        \n",
    "        if conc_stats is not None:\n",
    "            print(f\"\\n🏆 Conc模型 Top 5 重要特征作用:\")\n",
    "            for i, row in conc_stats.head(5).iterrows():\n",
    "                direction = \"正向\" if row['Effect_Mean'] > 0 else \"负向\" if row['Effect_Mean'] < 0 else \"中性\"\n",
    "                print(f\"  {i+1}. {row['Feature']}: 作用 {row['Effect_Mean']:.6f} ({direction}), 重要性 {row['Importance_Mean']:.6f}\")\n",
    "        \n",
    "        return {\n",
    "            'head_df': head_df,\n",
    "            'head_stats': head_stats,\n",
    "            'conc_df': conc_df,\n",
    "            'conc_stats': conc_stats,\n",
    "            'results_dir': results_dir\n",
    "        }\n",
    "    else:\n",
    "        print(\"❌ 没有成功分析任何模型\")\n",
    "        return None\n",
    "\n",
    "# 运行完整分析\n",
    "def run_complete_effect_analysis(head_model, conc_model, val_loader, config):\n",
    "    \"\"\"\n",
    "    运行完整的特征作用分析（包括不同评估标准）\n",
    "    \"\"\"\n",
    "    print(\"=\" * 90)\n",
    "    print(\"🚀 开始完整的特征作用蜂群图分析\")\n",
    "    print(\"=\" * 90)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # 分析不同评估标准\n",
    "    for criterion in ['r2']:\n",
    "        print(f\"\\n📊 分析评估标准: {criterion}\")\n",
    "        \n",
    "        result = run_effect_swarm_analysis(\n",
    "            head_model, conc_model, val_loader, config,\n",
    "            evaluation_criterion=criterion, n_samples=300\n",
    "        )\n",
    "        \n",
    "        results[criterion] = result\n",
    "        \n",
    "        # 清理内存\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    \n",
    "    print(f\"\\n✅ 完整的特征作用蜂群图分析完成!\")\n",
    "    return results\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    # 运行完整分析\n",
    "    all_results = run_complete_effect_analysis(head_model, conc_model, val_loader, config)\n",
    "    \n",
    "    # 或者只运行单个分析\n",
    "    # results = run_effect_swarm_analysis(\n",
    "    #     head_model, conc_model, val_loader, config,\n",
    "    #     evaluation_criterion='loss', n_samples=8\n",
    "    # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa8bfc4-60c2-474d-8a0e-a1e47cc373c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80c4a7b-cb67-4c8f-857b-9b65eef7679d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
