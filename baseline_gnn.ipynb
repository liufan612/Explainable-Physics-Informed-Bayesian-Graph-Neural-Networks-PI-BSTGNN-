{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63b417c3-765e-40a2-82c4-a3f1332fd344",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import add_self_loops\n",
    "from sklearn.model_selection import train_test_split                                                                                                   \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.amp import autocast\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts\n",
    "from sklearn.metrics import r2_score as sklearn_r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import sys\n",
    "sys.path.append('/home/jovyan/work/GNO/GNN/GNNShap')\n",
    "from gnnshap.explainer import GNNShapExplainer\n",
    "import uuid\n",
    "\n",
    "# 导入Blitz库\n",
    "from blitz.modules import BayesianLinear                 \n",
    "from blitz.utils import variational_estimator\n",
    "\n",
    "# 设备配置\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 自定义数据集类\n",
    "class HydroDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, graphs):\n",
    "        self.graphs = graphs\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.graphs[idx]\n",
    "\n",
    "class BlitzSTConv(MessagePassing):\n",
    "    \"\"\"\n",
    "    使用Blitz实现的贝叶斯时空卷积层，增强鲁棒性\n",
    "    \"\"\"\n",
    "    def __init__(self, spatial_dim, prior_sigma_1=0.1, prior_sigma_2=0.002, posterior_mu_init=0.0, posterior_rho_init=-3.0, dropout=0.1):\n",
    "        super().__init__(aggr='mean')\n",
    "        # 使用标准的PyTorch层进行初始化处理\n",
    "        self.pre_msg = nn.Linear(2 * spatial_dim + 3, spatial_dim)\n",
    "        \n",
    "        # 然后使用Blitz层进行贝叶斯推断\n",
    "        self.bayes_msg = nn.Sequential(\n",
    "            BayesianLinear(spatial_dim, spatial_dim,\n",
    "                        prior_sigma_1=prior_sigma_1, \n",
    "                        prior_sigma_2=prior_sigma_2,\n",
    "                        posterior_mu_init=posterior_mu_init,\n",
    "                        posterior_rho_init=posterior_rho_init),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.LayerNorm(spatial_dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        # 同样的模式用于gate网络\n",
    "        self.pre_gate = nn.Linear(3 * spatial_dim, spatial_dim)\n",
    "        self.bayes_gate = nn.Sequential(\n",
    "            BayesianLinear(spatial_dim, spatial_dim,\n",
    "                        prior_sigma_1=prior_sigma_1, \n",
    "                        prior_sigma_2=prior_sigma_2,\n",
    "                        posterior_mu_init=posterior_mu_init,\n",
    "                        posterior_rho_init=posterior_rho_init),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # 残差处理\n",
    "        self.pre_res = nn.Linear(spatial_dim, spatial_dim)\n",
    "        self.bayes_res = BayesianLinear(spatial_dim, spatial_dim,\n",
    "                                     prior_sigma_1=prior_sigma_1/2, \n",
    "                                     prior_sigma_2=prior_sigma_2/2,\n",
    "                                     posterior_mu_init=posterior_mu_init,\n",
    "                                     posterior_rho_init=posterior_rho_init)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        try:\n",
    "            # 添加调试信息\n",
    "            # 确保edge_attr是浮点类型\n",
    "            edge_attr = edge_attr.float()\n",
    "            \n",
    "            # 尝试传播消息\n",
    "            out = self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "            \n",
    "            # Gate机制\n",
    "            combined = torch.cat([x, out, x - out], dim=-1)\n",
    "            gate_pre = self.pre_gate(combined)\n",
    "            gate = self.bayes_gate(gate_pre)\n",
    "            \n",
    "            # 残差连接\n",
    "            res_pre = self.pre_res(x)\n",
    "            res = self.bayes_res(res_pre)\n",
    "            \n",
    "            return x + gate * out + 0.1 * res\n",
    "        except Exception as e:\n",
    "            print(f\"Error in BlitzSTConv.forward: {e}\")\n",
    "            # 提供更详细的错误信息\n",
    "            print(f\"x shape: {x.shape}, dtype: {x.dtype}\")\n",
    "            print(f\"edge_index shape: {edge_index.shape}, dtype: {edge_index.dtype}\")\n",
    "            print(f\"edge_attr shape: {edge_attr.shape}, dtype: {edge_attr.dtype}\")\n",
    "            raise\n",
    "\n",
    "    def message(self, x_i, x_j, edge_attr):\n",
    "        try:\n",
    "            # 添加调试信息\n",
    "            edge_attr = edge_attr.to(x_i.dtype).to(x_i.device)\n",
    "            \n",
    "            # 先使用标准层，然后使用贝叶斯层\n",
    "            combined = torch.cat([x_i, x_j, edge_attr], dim=-1)\n",
    "            pre_msg = self.pre_msg(combined)\n",
    "            return self.bayes_msg(pre_msg)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in BlitzSTConv.message: {e}\")\n",
    "            # 提供更详细的错误信息\n",
    "            print(f\"x_i shape: {x_i.shape}, dtype: {x_i.dtype}\")\n",
    "            print(f\"x_j shape: {x_j.shape}, dtype: {x_j.dtype}\")\n",
    "            print(f\"edge_attr shape: {edge_attr.shape}, dtype: {edge_attr.dtype}\")\n",
    "            raise\n",
    "\n",
    "class BlitzBoundaryProcessor(nn.Module):\n",
    "    \"\"\"\n",
    "    使用Blitz实现的贝叶斯边界处理器\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, prior_sigma_1=0.1, prior_sigma_2=0.002, posterior_mu_init=0.0, posterior_rho_init=-3.0):\n",
    "        super().__init__()\n",
    "        self.boundary_net = nn.Sequential(\n",
    "            BayesianLinear(dim + 1, dim,\n",
    "                        prior_sigma_1=prior_sigma_1, \n",
    "                        prior_sigma_2=prior_sigma_2,\n",
    "                        posterior_mu_init=posterior_mu_init,\n",
    "                        posterior_rho_init=posterior_rho_init),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.river_net = nn.Sequential(\n",
    "            BayesianLinear(dim + 2, dim,\n",
    "                        prior_sigma_1=prior_sigma_1, \n",
    "                        prior_sigma_2=prior_sigma_2,\n",
    "                        posterior_mu_init=posterior_mu_init,\n",
    "                        posterior_rho_init=posterior_rho_init),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.well_net = BayesianLinear(dim + 1, dim,\n",
    "                                    prior_sigma_1=prior_sigma_1, \n",
    "                                    prior_sigma_2=prior_sigma_2,\n",
    "                                    posterior_mu_init=posterior_mu_init,\n",
    "                                    posterior_rho_init=posterior_rho_init)\n",
    "        \n",
    "        self.gate = nn.Sequential(\n",
    "            BayesianLinear(2 * dim, dim,\n",
    "                        prior_sigma_1=prior_sigma_1/2, \n",
    "                        prior_sigma_2=prior_sigma_2/2,\n",
    "                        posterior_mu_init=posterior_mu_init,\n",
    "                        posterior_rho_init=posterior_rho_init),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.chd_enforcer = BayesianLinear(dim, dim,\n",
    "                                        prior_sigma_1=prior_sigma_1/2, \n",
    "                                        prior_sigma_2=prior_sigma_2/2,\n",
    "                                        posterior_mu_init=posterior_mu_init,\n",
    "                                        posterior_rho_init=posterior_rho_init)\n",
    "    \n",
    "    def forward(self, x, bc_mask):\n",
    "        boundary_feat = self.boundary_net(\n",
    "            torch.cat([x, bc_mask[:, 0:1]], dim=-1)\n",
    "        ) * bc_mask[:, 0:1]\n",
    "        \n",
    "        river_feat = self.river_net(\n",
    "            torch.cat([x, bc_mask[:, 1:3]], dim=-1)\n",
    "        ) * bc_mask[:, 1:2]\n",
    "        \n",
    "        well_feat = self.well_net(\n",
    "            torch.cat([x, bc_mask[:, 3:4]], dim=-1)\n",
    "        ) * bc_mask[:, 4:5]\n",
    "        \n",
    "        combined = boundary_feat + river_feat + well_feat\n",
    "        gate = self.gate(torch.cat([x, combined], dim=-1))\n",
    "        out = x * (1 - gate) + combined * gate\n",
    "        \n",
    "        chd_mask = bc_mask[:, 0] > 0\n",
    "        if chd_mask.sum() > 0:\n",
    "            chd_out = self.chd_enforcer(out[chd_mask]).to(out.dtype)\n",
    "            out[chd_mask] = chd_out\n",
    "            \n",
    "        return out\n",
    "\n",
    "@variational_estimator\n",
    "class BlitzHeadGNN(nn.Module):\n",
    "    \"\"\"\n",
    "    使用Blitz实现的贝叶斯水头预测GNN，加入前一时间步的水头和浓度特征\n",
    "    \"\"\"\n",
    "    def __init__(self, node_features=16, max_time_steps=40, spatial_dim=64, \n",
    "                temporal_dim=64, output_dim=1, prior_sigma_1=0.05, prior_sigma_2=0.001,\n",
    "                posterior_mu_init=0.0, posterior_rho_init=-3.0, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.spatial_dim = spatial_dim\n",
    "        self.time_embed = nn.Embedding(max_time_steps + 1, temporal_dim)\n",
    "        \n",
    "        # 节点编码器 - 注意这里的输入维度变为node_features + temporal_dim\n",
    "        # 节点编码器 - 更保守的设计\n",
    "        self.node_enc = nn.Sequential(\n",
    "            nn.Linear(node_features + temporal_dim, spatial_dim),\n",
    "            nn.BatchNorm1d(spatial_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(spatial_dim, spatial_dim),\n",
    "            nn.BatchNorm1d(spatial_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        # 卷积层\n",
    "        self.conv_layers = nn.ModuleList([\n",
    "            BlitzSTConv(spatial_dim, prior_sigma_1, prior_sigma_2, \n",
    "                     posterior_mu_init, posterior_rho_init, dropout) \n",
    "            for _ in range(4)\n",
    "        ])\n",
    "        \n",
    "        # 边界处理器\n",
    "        self.bc_processor = BlitzBoundaryProcessor(\n",
    "            spatial_dim, prior_sigma_1, prior_sigma_2, \n",
    "            posterior_mu_init, posterior_rho_init\n",
    "        )\n",
    "        \n",
    "        # 确定性路径 - 增强权重\n",
    "        self.deterministic_path = nn.Sequential(\n",
    "            nn.Linear(spatial_dim, spatial_dim // 2),\n",
    "            nn.BatchNorm1d(spatial_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(spatial_dim // 2, spatial_dim // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(spatial_dim // 4, output_dim),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "        \n",
    "        # 贝叶斯路径 - 降低复杂度\n",
    "        self.bayesian_path = nn.Sequential(\n",
    "            BayesianLinear(spatial_dim, spatial_dim // 2,\n",
    "                          prior_sigma_1=prior_sigma_1, \n",
    "                          prior_sigma_2=prior_sigma_2,\n",
    "                          posterior_mu_init=posterior_mu_init,\n",
    "                          posterior_rho_init=posterior_rho_init),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            BayesianLinear(spatial_dim // 2, output_dim,\n",
    "                          prior_sigma_1=prior_sigma_1/2, \n",
    "                          prior_sigma_2=prior_sigma_2/2,\n",
    "                          posterior_mu_init=posterior_mu_init,\n",
    "                          posterior_rho_init=posterior_rho_init),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "        \n",
    "        # 注意力机制用于特征选择\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(spatial_dim, spatial_dim // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(spatial_dim // 4, spatial_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr.to(torch.float32)\n",
    "        \n",
    "        # 特征工程\n",
    "        if hasattr(self, 'feature_engineering'):\n",
    "            x = self.feature_engineering(x)\n",
    "        \n",
    "        # 时间嵌入\n",
    "        time_emb = self.time_embed(data.time_step)\n",
    "        node_feat = torch.cat([x, time_emb], dim=-1)\n",
    "        \n",
    "        # 节点编码\n",
    "        h = self.node_enc(node_feat)\n",
    "        \n",
    "        # 简化的图卷积\n",
    "        for conv in self.conv_layers:\n",
    "            h_new = conv(h, edge_index, edge_attr)\n",
    "            h = h + 0.1 * h_new  # 残差连接\n",
    "        \n",
    "        # 注意力加权\n",
    "        attention_weights = self.attention(h)\n",
    "        h = h * attention_weights\n",
    "        \n",
    "        # 边界处理\n",
    "        h = self.bc_processor(h, data.bc_mask)\n",
    "        \n",
    "        # 双路径预测，增加确定性路径权重\n",
    "        det_pred = self.deterministic_path(h.detach())\n",
    "        bayes_pred = self.bayesian_path(h)\n",
    "        \n",
    "        # 自适应权重组合\n",
    "        return det_pred * 0.7 + bayes_pred * 0.3\n",
    "\n",
    "class ImprovedPhysicsInformedLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    改进的物理信息损失函数，无需显式计算KL散度（Blitz内部处理）\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha=0.5, kl_weight=1e-4):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.kl_weight = kl_weight  # 在Blitz中，KL权重在sample_elbo中传入\n",
    "        \n",
    "    def forward(self, pred, data, model=None):  # 添加model参数使接口一致，但不使用\n",
    "        # 基础MSE损失\n",
    "        mse_loss = F.mse_loss(pred, data.head_y.unsqueeze(1))\n",
    "        \n",
    "        # 物理约束损失\n",
    "        time_steps = data.time_step.unique(sorted=True)\n",
    "        flux_loss = 0\n",
    "        for t in time_steps[:-1]:\n",
    "            mask_t = (data.time_step == t)\n",
    "            mask_next = (data.time_step == t + 1)\n",
    "            if mask_t.sum() > 0 and mask_next.sum() > 0:\n",
    "                flux_diff = torch.mean((pred[mask_next] - pred[mask_t]) ** 2)\n",
    "                flux_loss += flux_diff\n",
    "        flux_loss /= len(time_steps) - 1 if len(time_steps) > 1 else 1\n",
    "        \n",
    "        # 边界条件损失\n",
    "        bc_mask = data.bc_mask[:, 0] > 0\n",
    "        bc_loss = F.l1_loss(pred[bc_mask], data.head_y[bc_mask].unsqueeze(1)) if bc_mask.sum() > 0 else torch.tensor(0.0, device=pred.device)\n",
    "        \n",
    "        # 井条件损失\n",
    "        well_mask = data.bc_mask[:, 4] > 0\n",
    "        well_loss = F.l1_loss(pred[well_mask], data.head_y[well_mask].unsqueeze(1)) if well_mask.sum() > 0 else torch.tensor(0.0, device=pred.device)\n",
    "        \n",
    "        # 总损失 - 不包含KL散度，KL散度由Blitz内部处理\n",
    "        # total_loss = (1 - self.alpha) * mse_loss + self.alpha * (flux_loss + bc_loss + well_loss)\n",
    "        total_loss= mse_loss\n",
    "        return total_loss, (mse_loss.item(), flux_loss.item(), bc_loss.item(), well_loss.item(), 0.0)  # 返回0.0表示KL损失，但实际上由Blitz处理\n",
    "\n",
    "\n",
    "@variational_estimator\n",
    "class BlitzConcGNN(nn.Module):\n",
    "    \"\"\"\n",
    "    简化的贝叶斯浓度预测GNN，直接使用18维输入特征\n",
    "    \"\"\"\n",
    "    def __init__(self, node_features=19, max_time_steps=40, spatial_dim=128,\n",
    "                temporal_dim=64, output_dim=1, prior_sigma_1=0.1, prior_sigma_2=0.01,\n",
    "                posterior_mu_init=0.0, posterior_rho_init=-3.0, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.spatial_dim = spatial_dim\n",
    "        self.time_embed = nn.Embedding(max_time_steps + 1, temporal_dim)\n",
    "        \n",
    "        # 简化的节点编码器 - 直接处理18维特征\n",
    "        self.node_enc_scale1 = nn.Sequential(\n",
    "            nn.Linear(node_features + temporal_dim, spatial_dim),  # 18 + 64 = 82 -> 128\n",
    "            nn.BatchNorm1d(spatial_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout * 0.5)\n",
    "        )\n",
    "        \n",
    "        self.node_enc = nn.Sequential(\n",
    "            BayesianLinear(spatial_dim, spatial_dim,\n",
    "                        prior_sigma_1=prior_sigma_1, \n",
    "                        prior_sigma_2=prior_sigma_2,\n",
    "                        posterior_mu_init=posterior_mu_init,\n",
    "                        posterior_rho_init=posterior_rho_init),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.LayerNorm(spatial_dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        # 卷积层\n",
    "        self.conv_layers = nn.ModuleList([\n",
    "            BlitzSTConv(spatial_dim, prior_sigma_1, prior_sigma_2, \n",
    "                     posterior_mu_init, posterior_rho_init, dropout) \n",
    "            for _ in range(4)\n",
    "        ])\n",
    "        \n",
    "        # 边界处理器\n",
    "        self.bc_processor = BlitzBoundaryProcessor(\n",
    "            spatial_dim, prior_sigma_1, prior_sigma_2, \n",
    "            posterior_mu_init, posterior_rho_init\n",
    "        )\n",
    "        \n",
    "        # 注意力机制\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(spatial_dim, spatial_dim // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(spatial_dim // 4, spatial_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # 贝叶斯分支解码器\n",
    "        self.decoder = nn.Sequential(\n",
    "            BayesianLinear(spatial_dim, 128,\n",
    "                        prior_sigma_1=prior_sigma_1/2, \n",
    "                        prior_sigma_2=prior_sigma_2/2,\n",
    "                        posterior_mu_init=posterior_mu_init,\n",
    "                        posterior_rho_init=posterior_rho_init),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            BayesianLinear(128, 64,\n",
    "                        prior_sigma_1=prior_sigma_1/2, \n",
    "                        prior_sigma_2=prior_sigma_2/2,\n",
    "                        posterior_mu_init=posterior_mu_init,\n",
    "                        posterior_rho_init=posterior_rho_init),\n",
    "            nn.ReLU(),\n",
    "            BayesianLinear(64, output_dim,\n",
    "                        prior_sigma_1=prior_sigma_1/4, \n",
    "                        prior_sigma_2=prior_sigma_2/4,\n",
    "                        posterior_mu_init=posterior_mu_init,\n",
    "                        posterior_rho_init=posterior_rho_init),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "        \n",
    "        # 确定性分支解码器\n",
    "        self.decoder_det = nn.Sequential(\n",
    "            nn.Linear(spatial_dim, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, output_dim),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "        \n",
    "        # 自适应分支权重\n",
    "        self.branch_weight = nn.Parameter(torch.tensor(0.3))\n",
    "\n",
    "    def forward(self, data, pred_head=None):\n",
    "        # 直接使用conc_x作为输入（18维特征）\n",
    "        x = data.conc_x\n",
    "        edge_index, edge_attr = data.edge_index, data.edge_attr\n",
    "        \n",
    "        # 确保所有张量在同一设备\n",
    "        if edge_attr is not None:\n",
    "            edge_attr = edge_attr.to(torch.float32).to(x.device)\n",
    "        \n",
    "        # 时间嵌入\n",
    "        time_step = data.time_step.to(x.device)\n",
    "        time_emb = self.time_embed(time_step)\n",
    "        \n",
    "        # 节点特征与时间嵌入结合\n",
    "        node_feat = torch.cat([x, time_emb], dim=-1)  # (18 + 64) = 82维\n",
    "        \n",
    "        # 节点编码\n",
    "        h_scale1 = self.node_enc_scale1(node_feat)\n",
    "        h = self.node_enc(h_scale1)\n",
    "        \n",
    "        # 图卷积层\n",
    "        for conv in self.conv_layers:\n",
    "            h_new = conv(h, edge_index, edge_attr)\n",
    "            h = h + 0.1 * h_new  # 残差连接\n",
    "        \n",
    "        # 注意力加权\n",
    "        attention_weights = self.attention(h)\n",
    "        h = h * attention_weights\n",
    "        \n",
    "        # 边界处理\n",
    "        bc_mask = data.bc_mask.to(x.device) if hasattr(data, 'bc_mask') else None\n",
    "        h = self.bc_processor(h, bc_mask)\n",
    "        \n",
    "        # 双分支输出\n",
    "        bayes_output = self.decoder(h)\n",
    "        det_output = self.decoder_det(h.detach())\n",
    "        \n",
    "        # 自适应权重组合\n",
    "        combined_output = (\n",
    "            torch.sigmoid(self.branch_weight) * bayes_output + \n",
    "            (1 - torch.sigmoid(self.branch_weight)) * det_output\n",
    "        )\n",
    "        \n",
    "        return combined_output\n",
    "\n",
    "class ImprovedConcLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    改进的浓度预测损失函数，优化L1正则化\n",
    "    \"\"\"\n",
    "    def __init__(self, kl_weight=5e-5, l1_weight=1e-8):  # 大幅降低L1权重\n",
    "        super().__init__()\n",
    "        self.kl_weight = kl_weight\n",
    "        self.l1_weight = l1_weight  # L1正则化权重降低1000倍\n",
    "        \n",
    "    def forward(self, pred, data, model=None):\n",
    "        # 使用MSE损失\n",
    "        mse_loss = F.mse_loss(pred, data.y.unsqueeze(1))\n",
    "        \n",
    "        # 只对贝叶斯层应用L1正则化\n",
    "        l1_reg = torch.tensor(0., device=pred.device)\n",
    "        if model is not None and self.l1_weight > 0:\n",
    "            for name, param in model.named_parameters():\n",
    "                # 只对贝叶斯层的权重应用L1正则化\n",
    "                if 'weight' in name and ('bayesian' in name.lower() or 'bayes' in name.lower()):\n",
    "                    l1_reg += torch.norm(param, 1)\n",
    "        \n",
    "        # 总损失\n",
    "        total_loss = mse_loss + self.l1_weight * l1_reg\n",
    "        \n",
    "        return total_loss, (mse_loss.item(), 0.0, l1_reg.item())\n",
    "\n",
    "def generate_spatial_edges(model_df):\n",
    "    \"\"\"生成空间边和边属性\"\"\"\n",
    "    spatial_edges = []\n",
    "    time_steps = model_df['time_step'].unique()\n",
    "    for t in time_steps:\n",
    "        time_df = model_df[model_df['time_step'] == t]\n",
    "        coord_to_idx = {(r, c): idx for idx, r, c in zip(time_df['local_index'], time_df['row'], time_df['col'])}\n",
    "        for idx, row, col in zip(time_df['local_index'], time_df['row'], time_df['col']):\n",
    "            right_coord = (row, col + 1)\n",
    "            if right_coord in coord_to_idx:\n",
    "                spatial_edges.append([idx, coord_to_idx[right_coord]])\n",
    "            upper_coord = (row + 1, col)\n",
    "            if upper_coord in coord_to_idx:\n",
    "                spatial_edges.append([idx, coord_to_idx[upper_coord]])\n",
    "    return np.array(spatial_edges), np.full((len(spatial_edges), 3), [1.0, 0, 0], dtype=np.float32)\n",
    "\n",
    "def generate_temporal_edges(model_df):\n",
    "    \"\"\"生成时间边和边属性\"\"\"\n",
    "    temporal_edges = []\n",
    "    groups = model_df.groupby(['row', 'col'], sort=False)\n",
    "    for (row, col), group in groups:\n",
    "        time_series = group.sort_values('time_step')\n",
    "        for i in range(len(time_series) - 1):\n",
    "            global_src = time_series['local_index'].iloc[i]\n",
    "            global_dst = time_series['local_index'].iloc[i + 1]\n",
    "            temporal_edges.append([global_src, global_dst])\n",
    "    return np.array(temporal_edges), np.full((len(temporal_edges), 3), [0.0, 1.0, 0], dtype=np.float32)\n",
    "\n",
    "def build_bc_mask(model_df):\n",
    "    \"\"\"构建边界条件掩码\"\"\"\n",
    "    bc_mask = np.zeros((len(model_df), 5), dtype=np.float32)\n",
    "    bc_mask[:, 0] = model_df['chd_mask'].values.astype(np.float32)\n",
    "    bc_mask[:, 1] = (model_df['river_cond'] > 0).astype(np.float32)\n",
    "    bc_mask[:, 2] = model_df['river_stage'].values.astype(np.float32)\n",
    "    bc_mask[:, 3] = model_df['well_rate'].values.astype(np.float32)\n",
    "    bc_mask[:, 4] = model_df['well_mask'].values.astype(np.float32)\n",
    "    return bc_mask\n",
    "def build_spatiotemporal_graph(df):\n",
    "    \"\"\"构建时空图，将所有特征整合到一个输入中\"\"\"\n",
    "    print(f\"\\n▶ Started building spatiotemporal graphs\")\n",
    "    print(f\"▷ Total models to process: {len(df['model_name'].unique())}\")\n",
    "    graphs = []\n",
    "    \n",
    "    # 修正：添加 lytyp 字段的类型定义\n",
    "    df = df.astype({\n",
    "        'x': np.float32, 'y': np.float32, 'top': np.float32, \n",
    "        'bottom': np.float32, 'K': np.float32, 'recharge': np.float32,\n",
    "        'ET': np.float32, 'river_stage': np.float32, 'river_cond': np.float32,\n",
    "        'river_rbot': np.float32, 'well_rate': np.float32, 'well_mask': np.uint8,\n",
    "        'chd_mask': np.uint8, 'lytyp': np.uint8, 'head': np.float32, \n",
    "        'concentration': np.float32,'conc_mask': np.uint8\n",
    "    })\n",
    "    \n",
    "    time_min = df['time_step'].min()\n",
    "    df['time_step'] = df['time_step'] - time_min\n",
    "    \n",
    "    model_groups = list(df.groupby('model_name', sort=False))\n",
    "    total_models = len(model_groups)\n",
    "    \n",
    "    for model_idx, (model_name, model_df) in enumerate(model_groups, 1):\n",
    "        model_df = model_df.reset_index(drop=True).copy()\n",
    "        model_df['local_index'] = model_df.index\n",
    "        print(f\"\\n▣ Processing model {model_idx}/{total_models}: {model_name}\")\n",
    "        \n",
    "        model_df = model_df.sort_values(['row', 'col', 'time_step'])\n",
    "        \n",
    "        # 基础特征列（14维）\n",
    "        feature_cols = [\n",
    "            'x', 'y', 'top', 'bottom', 'K', 'recharge', 'ET',\n",
    "            'river_stage', 'river_cond', 'river_rbot', 'well_rate', 'well_mask',\n",
    "            'chd_mask', 'lytyp'\n",
    "        ]\n",
    "        node_feats = model_df[feature_cols].values.astype(np.float32)\n",
    "        col_types = df[feature_cols].dtypes.to_dict()\n",
    "        float_indices = [i for i, col in enumerate(feature_cols) if col_types[col] != np.uint8]\n",
    "        float_feats = node_feats[:, float_indices]\n",
    "        scaler = StandardScaler()\n",
    "        float_feats_scaled = scaler.fit_transform(float_feats)\n",
    "        node_feats[:, float_indices] = float_feats_scaled\n",
    "        conc_feature_cols = [\n",
    "            'x', 'y', 'top', 'bottom', 'K', 'recharge', 'ET',\n",
    "            'river_stage', 'river_cond', 'river_rbot', 'well_rate', 'well_mask',\n",
    "            'chd_mask', 'lytyp','conc_mask'\n",
    "        ]\n",
    "        conc_node_feats = model_df[conc_feature_cols].values.astype(np.float32)\n",
    "        col_types = df[conc_feature_cols].dtypes.to_dict()\n",
    "        float_indices = [i for i, col in enumerate(conc_feature_cols) if col_types[col] != np.uint8]\n",
    "        conc_float_feats = conc_node_feats[:, float_indices]\n",
    "        scaler = StandardScaler()\n",
    "        conc_float_feats_scaled = scaler.fit_transform(conc_float_feats)\n",
    "        conc_node_feats[:, float_indices] = conc_float_feats_scaled\n",
    "        # 计算前一时间步和前两个时间步的水头和浓度\n",
    "        prev_head = np.zeros(len(model_df), dtype=np.float32)\n",
    "        prev2_head = np.zeros(len(model_df), dtype=np.float32)\n",
    "        prev_conc = np.zeros(len(model_df), dtype=np.float32)\n",
    "        prev2_conc = np.zeros(len(model_df), dtype=np.float32)\n",
    "        \n",
    "        groups = model_df.groupby(['row', 'col'], sort=False)\n",
    "        for (row, col), group in groups:\n",
    "            time_series = group.sort_values('time_step')\n",
    "            prev_head[time_series.index] = np.roll(time_series['head'].values, 1)\n",
    "            prev2_head[time_series.index] = np.roll(time_series['head'].values, 2)\n",
    "            prev_conc[time_series.index] = np.roll(time_series['concentration'].values, 1)\n",
    "            prev2_conc[time_series.index] = np.roll(time_series['concentration'].values, 2)\n",
    "            \n",
    "            first_idx = time_series.index[0]\n",
    "            if len(time_series) > 1:\n",
    "                second_idx = time_series.index[1]\n",
    "                # 水头特征处理\n",
    "                prev_head[first_idx] = time_series['head'].values[0]\n",
    "                prev2_head[first_idx] = time_series['head'].values[0]\n",
    "                prev2_head[second_idx] = time_series['head'].values[0]\n",
    "                \n",
    "                # 浓度特征处理\n",
    "                prev_conc[first_idx] = time_series['concentration'].values[0]\n",
    "                prev2_conc[first_idx] = time_series['concentration'].values[0]\n",
    "                prev2_conc[second_idx] = time_series['concentration'].values[0]\n",
    "            else:\n",
    "                prev_head[first_idx] = 0.0\n",
    "                prev2_head[first_idx] = 0.0\n",
    "                prev_conc[first_idx] = 0.0\n",
    "                prev2_conc[first_idx] = 0.0\n",
    "\n",
    "        # 为水头模型：基础特征 + 前一/前二时间步水头（16维）\n",
    "        head_feats = np.concatenate([\n",
    "            node_feats,           # 14维基础特征\n",
    "            prev_head[:, None],   # 1维前一时间步水头\n",
    "            prev2_head[:, None]   # 1维前二时间步水头\n",
    "        ], axis=1)\n",
    "        \n",
    "        # 为浓度模型：基础特征 + 前一/前二时间步水头 + 前一/前二时间步浓度（18维）\n",
    "        conc_feats = np.concatenate([\n",
    "            conc_node_feats,           # 14维基础特征\n",
    "            prev_head[:, None],   # 1维前一时间步水头\n",
    "            prev2_head[:, None],  # 1维前二时间步水头\n",
    "            prev_conc[:, None],   # 1维前一时间步浓度\n",
    "            prev2_conc[:, None]   # 1维前二时间步浓度\n",
    "        ], axis=1)\n",
    "        \n",
    "        if np.any(np.isnan(head_feats)) or np.any(np.isinf(head_feats)):\n",
    "            print(f\"Warning: head_feats contains NaN or Inf for model {model_name}\")\n",
    "            head_feats = np.nan_to_num(head_feats, nan=0.0, posinf=1e6, neginf=-1e6)\n",
    "        \n",
    "        if np.any(np.isnan(conc_feats)) or np.any(np.isinf(conc_feats)):\n",
    "            print(f\"Warning: conc_feats contains NaN or Inf for model {model_name}\")\n",
    "            conc_feats = np.nan_to_num(conc_feats, nan=0.0, posinf=1e6, neginf=-1e6)\n",
    "        \n",
    "        conc = model_df['concentration'].values.astype(np.float32)\n",
    "        head = model_df['head'].values.astype(np.float32)\n",
    "        spatial_edges, spatial_attrs = generate_spatial_edges(model_df)\n",
    "        temporal_edges, temporal_attrs = generate_temporal_edges(model_df)\n",
    "        edges = np.concatenate([spatial_edges, temporal_edges], axis=0)\n",
    "        edge_attr = np.concatenate([spatial_attrs, temporal_attrs], axis=0)\n",
    "        bc_mask = build_bc_mask(model_df)\n",
    "        \n",
    "        assert bc_mask.shape == (len(model_df), 5), \\\n",
    "            f\"Invalid bc_mask shape: {bc_mask.shape} for model {model_name}\"\n",
    "        \n",
    "        graph = Data(\n",
    "            x=torch.from_numpy(head_feats),      # 水头模型特征（16维）\n",
    "            conc_x=torch.from_numpy(conc_feats), # 浓度模型特征（18维）\n",
    "            edge_index=torch.tensor(edges.T, dtype=torch.long),\n",
    "            edge_attr=torch.from_numpy(edge_attr),\n",
    "            y=torch.from_numpy(conc),\n",
    "            head_y=torch.from_numpy(head),\n",
    "            bc_mask=torch.from_numpy(bc_mask),\n",
    "            time_step=torch.from_numpy(model_df['time_step'].values).long(),\n",
    "            time_steps=model_df['time_step'].nunique(),\n",
    "            model_name=str(model_name),\n",
    "            row=torch.from_numpy(model_df['row'].values).long(),\n",
    "            col=torch.from_numpy(model_df['col'].values).long(),\n",
    "        )\n",
    "        graphs.append(graph)\n",
    "    \n",
    "    print(f\"\\n✅ All models processed! Total graphs created: {len(graphs):,}\")\n",
    "    return graphs\n",
    "\n",
    "\n",
    "def prepare_data(data, batch_size=4):\n",
    "    \"\"\"准备数据加载器\"\"\"\n",
    "    print('正在处理数据...')\n",
    "    all_graphs = build_spatiotemporal_graph(data)\n",
    "    print('数据处理完成！')\n",
    "    train_graphs, val_graphs = train_test_split(\n",
    "        all_graphs, test_size=0.3, random_state=42\n",
    "    )\n",
    "    train_dataset = HydroDataset(train_graphs)\n",
    "    val_dataset = HydroDataset(val_graphs)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "# Training configuration\n",
    "config = {\n",
    "    'head_input_dim': 16,\n",
    "    'conc_input_dim': 19,\n",
    "    'hidden_dim': 96,  # 增大隐藏维度\n",
    "    'num_epochs': 500,\n",
    "    'lr': 1e-3,  # 降低学习率以提高稳定性\n",
    "    'weight_decay': 1e-4,\n",
    "    'patience': 30,\n",
    "    'save_path': './saved_models/blitz_bayesian_gnn_dual_base',\n",
    "    'mc_samples': 10,\n",
    "    'head_prior_sigma_1': 0.01,  # Blitz先验参数\n",
    "    'head_prior_sigma_2': 0.002,\n",
    "    'conc_prior_sigma_1': 0.05,  # 浓度模型使用较小的先验\n",
    "    'conc_prior_sigma_2': 0.002,\n",
    "    'kl_weight': 1e-4  # Blitz中的KL散度权重\n",
    "}\n",
    "\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    \"\"\"计算评估指标\"\"\"\n",
    "    if isinstance(y_true, torch.Tensor):\n",
    "        y_true = y_true.detach().cpu().numpy()\n",
    "    if isinstance(y_pred, torch.Tensor):\n",
    "        y_pred = y_pred.detach().cpu().numpy()\n",
    "\n",
    "    y_true = y_true.flatten()\n",
    "    y_pred = y_pred.flatten()\n",
    "\n",
    "    mask = ~np.isnan(y_true) & ~np.isinf(y_true) & ~np.isnan(y_pred) & ~np.isinf(y_pred)\n",
    "    y_true = y_true[mask]\n",
    "    y_pred = y_pred[mask]\n",
    "\n",
    "    mse = np.mean((y_true - y_pred) ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "    r2 = sklearn_r2_score(y_true, y_pred)\n",
    "\n",
    "    return {\n",
    "        'mse': mse,\n",
    "        'rmse': rmse,\n",
    "        'mae': mae,\n",
    "        'r2': r2\n",
    "    }\n",
    "\n",
    "def compute_uncertainty(model, data, mc_samples=10):\n",
    "    \"\"\"\n",
    "    为Blitz模型计算预测和不确定性\n",
    "    \"\"\"\n",
    "    model.train()  # Blitz在训练模式下采样权重\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(mc_samples):\n",
    "            pred = model(data)\n",
    "            predictions.append(pred)\n",
    "    \n",
    "    predictions = torch.stack(predictions, dim=0)\n",
    "    mean_pred = predictions.mean(dim=0)\n",
    "    std_pred = predictions.std(dim=0)\n",
    "    \n",
    "    return mean_pred, std_pred\n",
    "\n",
    "def compute_feature_shap_values_improved(model, data, n_samples=20, num_samples=10):\n",
    "    \"\"\"\n",
    "    计算模型对输入特征的重要性，使用Blitz贝叶斯网络\n",
    "    \"\"\"\n",
    "    model.train()  # 使用训练模式以启用贝叶斯采样\n",
    "    data = data.to(next(model.parameters()).device)\n",
    "    \n",
    "    print(f\"[FeatureSHAP] 开始特征重要性分析，抽样{n_samples}个节点...\")\n",
    "    \n",
    "    # 确保数据有必要的属性\n",
    "    if not hasattr(data, 'x') or not torch.is_tensor(data.x):\n",
    "        print(\"[FeatureSHAP] 错误: 数据缺少节点特征 (data.x)\")\n",
    "        return None, 0.0\n",
    "    \n",
    "    try:\n",
    "        # 获取当前时间步的节点\n",
    "        current_time_step = data.time_step.unique()[0].item() if hasattr(data, 'time_step') else 0\n",
    "        time_mask = data.time_step == current_time_step if hasattr(data, 'time_step') else torch.ones(data.num_nodes, dtype=torch.bool, device=data.x.device)\n",
    "        candidate_nodes = torch.where(time_mask)[0]\n",
    "        \n",
    "        if len(candidate_nodes) == 0:\n",
    "            print(\"[FeatureSHAP] 错误: 找不到满足条件的节点\")\n",
    "            return None, 0.0\n",
    "        \n",
    "        # 调整样本数\n",
    "        actual_n_samples = min(n_samples, len(candidate_nodes))\n",
    "        if actual_n_samples < n_samples:\n",
    "            print(f\"[FeatureSHAP] 警告: 候选节点数({len(candidate_nodes)})少于请求的样本数({n_samples})，调整为{actual_n_samples}\")\n",
    "        \n",
    "        # 随机抽样节点\n",
    "        sampled_indices = torch.randperm(len(candidate_nodes))[:actual_n_samples]\n",
    "        sampled_nodes = candidate_nodes[sampled_indices]\n",
    "        \n",
    "        # 特征数量\n",
    "        num_features = data.x.size(1)\n",
    "        \n",
    "        # 初始化SHAP值存储\n",
    "        all_shap_values = torch.zeros(actual_n_samples, num_features, device=data.x.device)\n",
    "        all_expected_values = torch.zeros(actual_n_samples, device=data.x.device)\n",
    "        \n",
    "        # 生成基准预测\n",
    "        baseline_preds = []\n",
    "        for _ in range(num_samples):\n",
    "            with torch.no_grad():\n",
    "                pred = model(data)\n",
    "                baseline_preds.append(pred)\n",
    "        baseline_pred = torch.stack(baseline_preds, dim=0).mean(dim=0)\n",
    "        \n",
    "        # 对每个抽样节点计算特征重要性\n",
    "        for i, node_idx in enumerate(sampled_nodes):\n",
    "            node_idx = node_idx.item()\n",
    "            original_value = baseline_pred[node_idx].item()\n",
    "            all_expected_values[i] = original_value\n",
    "            \n",
    "            # 对每个特征计算重要性\n",
    "            for feat_idx in range(num_features):\n",
    "                # 保存原始特征值\n",
    "                original_feat = data.x[:, feat_idx].clone()\n",
    "                \n",
    "                # 计算特征的平均值\n",
    "                feat_mean = original_feat.mean()\n",
    "                \n",
    "                # 掩码该特征（使用平均值替换）\n",
    "                data.x[:, feat_idx] = feat_mean\n",
    "                \n",
    "                # 蒙特卡洛采样以获取更稳定的结果\n",
    "                masked_preds = []\n",
    "                for _ in range(num_samples):\n",
    "                    with torch.no_grad():\n",
    "                        masked_pred = model(data)\n",
    "                        masked_preds.append(masked_pred)\n",
    "                \n",
    "                # 计算掩码后的平均预测\n",
    "                masked_pred = torch.stack(masked_preds, dim=0).mean(dim=0)\n",
    "                \n",
    "                # 计算特征重要性（原始预测与掩码后预测的差异）\n",
    "                shap_value = abs(original_value - masked_pred[node_idx].item())\n",
    "                all_shap_values[i, feat_idx] = shap_value\n",
    "                \n",
    "                # 恢复原始特征值\n",
    "                data.x[:, feat_idx] = original_feat\n",
    "            \n",
    "            # 每5个节点输出一次进度\n",
    "            if (i + 1) % 5 == 0 or i == len(sampled_nodes) - 1:\n",
    "                print(f\"[FeatureSHAP] 已完成 {i+1}/{len(sampled_nodes)} 个节点的分析\")\n",
    "        \n",
    "        # 计算平均SHAP值\n",
    "        avg_shap_values = all_shap_values.mean(dim=0)\n",
    "        avg_expected_value = all_expected_values.mean().item()\n",
    "        \n",
    "        # 归一化SHAP值\n",
    "        if avg_shap_values.sum() > 0:\n",
    "            avg_shap_values = avg_shap_values / avg_shap_values.sum()\n",
    "        \n",
    "        print(\"[FeatureSHAP] 特征重要性分析完成\")\n",
    "        return avg_shap_values.cpu().numpy(), avg_expected_value\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"[FeatureSHAP] 特征重要性分析出错: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, 0.0\n",
    "# 为Blitz的sample_elbo函数创建适配器损失函数\n",
    "class BlitzHeadLossAdapter(nn.Module):\n",
    "    def __init__(self, base_criterion, data, kl_weight=1e-4):\n",
    "        super().__init__()\n",
    "        self.base_criterion = base_criterion\n",
    "        self.data = data  # 保存数据对象\n",
    "        self.kl_weight = kl_weight\n",
    "    \n",
    "    def forward(self, pred, labels):\n",
    "        # 调用原始损失函数，但传入完整的data对象\n",
    "        loss, _ = self.base_criterion(pred, self.data)\n",
    "        return loss\n",
    "\n",
    "class BlitzConcLossAdapter(nn.Module):\n",
    "    def __init__(self, base_criterion, data, kl_weight=5e-5):\n",
    "        super().__init__()\n",
    "        self.base_criterion = base_criterion\n",
    "        self.data = data  # 保存数据对象\n",
    "        self.kl_weight = kl_weight\n",
    "    \n",
    "    def forward(self, pred, labels):\n",
    "        # 调用原始损失函数，但传入完整的data对象\n",
    "        loss, _ = self.base_criterion(pred, self.data)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2514bcc-fa5f-43cc-829a-038d23ef4567",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dual_model_improved(train_loader, val_loader, evaluation_criterion='r2'):\n",
    "    \"\"\"\n",
    "    改进的双模型训练，同时保存基于损失和R2的最佳模型\n",
    "    \n",
    "    Args:\n",
    "        train_loader: 训练数据加载器\n",
    "        val_loader: 验证数据加载器\n",
    "        evaluation_criterion: 最终评估使用的标准 ('loss' 或 'r2')\n",
    "    \"\"\"\n",
    "    try:\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"CUDA缓存已成功清除\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"无法清除CUDA缓存: {e}\")\n",
    "        return None, None, None\n",
    "    \n",
    "    # ===============================\n",
    "    # 第一阶段：训练水头模型\n",
    "    # ===============================\n",
    "    print(\"=\" * 80)\n",
    "    print(\"第一阶段：开始训练水头模型\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 根据实际数据更新特征维度\n",
    "    head_input_dim = 16  # 14个基本特征 + 2个前一时间步的水头\n",
    "    \n",
    "    # 初始化水头模型\n",
    "    head_model = BlitzHeadGNN(\n",
    "        node_features=head_input_dim,\n",
    "        spatial_dim=config['hidden_dim'],\n",
    "        temporal_dim=config['hidden_dim'],\n",
    "        prior_sigma_1=config['head_prior_sigma_1'],\n",
    "        prior_sigma_2=config['head_prior_sigma_2'],\n",
    "        dropout=0.1\n",
    "    ).to(device)\n",
    "    \n",
    "    # 损失函数 - 只需要水头损失\n",
    "    criterion_head = ImprovedPhysicsInformedLoss(alpha=0.1, kl_weight=config['kl_weight'])\n",
    "    \n",
    "    # 优化器 - 只优化水头模型参数\n",
    "    head_params = list(head_model.parameters())\n",
    "    head_optimizer = torch.optim.AdamW(head_params, lr=config['lr'], weight_decay=config['weight_decay'])\n",
    "    \n",
    "    # 学习率调度器\n",
    "    head_scheduler = CosineAnnealingWarmRestarts(\n",
    "        head_optimizer, T_0=20, T_mult=2, eta_min=1e-5\n",
    "    )\n",
    "    \n",
    "    # 跟踪变量 - 分别跟踪损失和R2\n",
    "    best_head_val_loss = float('inf')\n",
    "    best_head_r2 = float('-inf')\n",
    "    head_early_stop_counter = 0\n",
    "    head_losses = {'train': [], 'val': []}\n",
    "    \n",
    "    # 创建保存目录\n",
    "    os.makedirs(config['save_path'], exist_ok=True)\n",
    "    \n",
    "    print(\"开始训练水头模型\")\n",
    "    print(f\"水头模型参数数量: {sum(p.numel() for p in head_model.parameters() if p.requires_grad)}\")\n",
    "    \n",
    "    # 水头模型训练循环\n",
    "    for epoch in range(config['num_epochs']):\n",
    "        head_model.train()\n",
    "        train_loss = 0.0\n",
    "        train_batches = 0\n",
    "        \n",
    "        # 训练阶段\n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            try:\n",
    "                # 准备数据\n",
    "                batch = batch.to(device)\n",
    "                if hasattr(batch, 'edge_attr') and batch.edge_attr is not None:\n",
    "                    batch.edge_attr = batch.edge_attr.float()\n",
    "                \n",
    "                # 重置梯度\n",
    "                head_optimizer.zero_grad()\n",
    "                \n",
    "                # 前向传播\n",
    "                pred_head = head_model(batch)\n",
    "                \n",
    "                # 计算损失\n",
    "                criterion_output = criterion_head(pred_head, batch)\n",
    "                \n",
    "                # 处理损失函数的返回值\n",
    "                if isinstance(criterion_output, tuple):\n",
    "                    head_criterion_loss = criterion_output[0]\n",
    "                    if len(criterion_output) > 1:\n",
    "                        physics_loss = criterion_output[1]\n",
    "                        if isinstance(physics_loss, tuple):\n",
    "                            physics_loss_value = sum([p.item() if hasattr(p, 'item') else p for p in physics_loss])\n",
    "                        else:\n",
    "                            physics_loss_value = physics_loss.item() if hasattr(physics_loss, 'item') else physics_loss\n",
    "                    else:\n",
    "                        physics_loss_value = 0.0\n",
    "                else:\n",
    "                    head_criterion_loss = criterion_output\n",
    "                    physics_loss_value = 0.0\n",
    "                \n",
    "                kl_loss = head_model.nn_kl_divergence() * config['kl_weight']\n",
    "                total_loss = head_criterion_loss + kl_loss\n",
    "                \n",
    "                # 反向传播\n",
    "                total_loss.backward()\n",
    "                \n",
    "                # 梯度裁剪\n",
    "                torch.nn.utils.clip_grad_norm_(head_params, max_norm=1.0)\n",
    "                \n",
    "                # 更新参数\n",
    "                head_optimizer.step()\n",
    "                \n",
    "                # 记录损失\n",
    "                train_loss += total_loss.item()\n",
    "                train_batches += 1\n",
    "                \n",
    "                # 每50个批次输出一次详细信息\n",
    "                if batch_idx % 50 == 0:\n",
    "                    print(f\"水头模型 Epoch {epoch+1}, Batch {batch_idx}: \"\n",
    "                          f\"Total Loss: {total_loss.item():.4f}, \"\n",
    "                          f\"Criterion Loss: {head_criterion_loss.item():.4f}, \"\n",
    "                          f\"Physics Loss: {physics_loss_value:.4f}, \"\n",
    "                          f\"KL Loss: {kl_loss.item():.4f}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"水头模型训练批次 {batch_idx} 出错: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # 检查训练批次\n",
    "        if train_batches == 0:\n",
    "            print(\"警告: 水头模型本轮训练没有成功处理任何批次，跳过本轮\")\n",
    "            continue\n",
    "            \n",
    "        # 计算平均训练损失\n",
    "        avg_train_loss = train_loss / train_batches\n",
    "        \n",
    "        # 验证阶段\n",
    "        head_model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_metrics = {'mse': 0.0, 'rmse': 0.0, 'mae': 0.0, 'r2': 0.0}\n",
    "        val_batches = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch in enumerate(val_loader):\n",
    "                try:\n",
    "                    # 准备数据\n",
    "                    batch = batch.to(device)\n",
    "                    if hasattr(batch, 'edge_attr') and batch.edge_attr is not None:\n",
    "                        batch.edge_attr = batch.edge_attr.float()\n",
    "                    \n",
    "                    # 使用不确定性估计进行预测\n",
    "                    head_model.train()  # 开启dropout进行MC采样\n",
    "                    pred_head, head_std = compute_uncertainty(head_model, batch, mc_samples=config['mc_samples'])\n",
    "                    \n",
    "                    # 计算验证损失\n",
    "                    criterion_output = criterion_head(pred_head, batch)\n",
    "                    \n",
    "                    # 处理损失函数的返回值\n",
    "                    if isinstance(criterion_output, tuple):\n",
    "                        head_criterion_loss = criterion_output[0]\n",
    "                    else:\n",
    "                        head_criterion_loss = criterion_output\n",
    "                    \n",
    "                    # 计算指标\n",
    "                    metrics = compute_metrics(batch.head_y, pred_head)\n",
    "                    \n",
    "                    for k in metrics:\n",
    "                        val_metrics[k] += metrics[k]\n",
    "                    \n",
    "                    val_loss += head_criterion_loss.item()\n",
    "                    val_batches += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"水头模型验证批次 {batch_idx} 出错: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        # 计算平均验证损失和指标\n",
    "        if val_batches > 0:\n",
    "            avg_val_loss = val_loss / val_batches\n",
    "            for k in val_metrics:\n",
    "                val_metrics[k] /= val_batches\n",
    "        else:\n",
    "            print(\"警告: 水头模型本轮验证没有成功处理任何批次\")\n",
    "            avg_val_loss = float('inf')\n",
    "        \n",
    "        # 记录损失\n",
    "        head_losses['train'].append(avg_train_loss)\n",
    "        head_losses['val'].append({\n",
    "            'loss': avg_val_loss,\n",
    "            'metrics': val_metrics\n",
    "        })\n",
    "        \n",
    "        # 更新学习率\n",
    "        head_scheduler.step()\n",
    "        current_lr = head_scheduler.get_last_lr()[0]\n",
    "        \n",
    "        # 输出训练状态\n",
    "        print(f\"水头模型 Epoch {epoch+1:03d}/{config['num_epochs']} | \"\n",
    "              f\"训练损失: {avg_train_loss:.4f} | 验证损失: {avg_val_loss:.4f} | \"\n",
    "              f\"LR: {current_lr:.6f}\")\n",
    "        print(f\"水头验证指标 - MSE: {val_metrics['mse']:.4f}, \"\n",
    "              f\"RMSE: {val_metrics['rmse']:.4f}, \"\n",
    "              f\"MAE: {val_metrics['mae']:.4f}, \"\n",
    "              f\"R2: {val_metrics['r2']:.4f}\")\n",
    "        \n",
    "        # 保存基于损失的最佳模型\n",
    "        if avg_val_loss < best_head_val_loss:\n",
    "            best_head_val_loss = avg_val_loss\n",
    "            try:\n",
    "                torch.save({\n",
    "                    'model_state_dict': head_model.state_dict(),\n",
    "                    'epoch': epoch,\n",
    "                    'train_loss': avg_train_loss,\n",
    "                    'val_loss': avg_val_loss,\n",
    "                    'val_metrics': val_metrics,\n",
    "                    'config': config,\n",
    "                    'criterion': 'loss'\n",
    "                }, os.path.join(config['save_path'], 'best_head_model_loss.pth'))\n",
    "                print(f\"保存基于损失的最佳水头模型，验证损失: {best_head_val_loss:.4f}\")\n",
    "            except Exception as e:\n",
    "                print(f\"保存水头模型失败: {e}\")\n",
    "        \n",
    "        # 保存基于R2的最佳模型\n",
    "        if val_metrics['r2'] > best_head_r2:\n",
    "            best_head_r2 = val_metrics['r2']\n",
    "            head_early_stop_counter = 0  # 基于R2重置早停计数器\n",
    "            try:\n",
    "                torch.save({\n",
    "                    'model_state_dict': head_model.state_dict(),\n",
    "                    'epoch': epoch,\n",
    "                    'train_loss': avg_train_loss,\n",
    "                    'val_loss': avg_val_loss,\n",
    "                    'val_metrics': val_metrics,\n",
    "                    'config': config,\n",
    "                    'criterion': 'r2'\n",
    "                }, os.path.join(config['save_path'], 'best_head_model_r2.pth'))\n",
    "                print(f\"保存基于R2的最佳水头模型，R2: {best_head_r2:.4f}\")\n",
    "            except Exception as e:\n",
    "                print(f\"保存水头模型失败: {e}\")\n",
    "        else:\n",
    "            head_early_stop_counter += 1\n",
    "        \n",
    "        # 早停检查（基于R2）\n",
    "        if head_early_stop_counter >= config['patience']:\n",
    "            print(f\"水头模型早停触发! 在第{epoch+1}个epoch停止训练\")\n",
    "            break\n",
    "        \n",
    "        # 清理GPU内存\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"\\n水头模型训练完成!\")\n",
    "    print(f\"基于损失的最佳验证损失: {best_head_val_loss:.4f}\")\n",
    "    print(f\"基于R2的最佳R2分数: {best_head_r2:.4f}\")\n",
    "    \n",
    "    # ===============================\n",
    "    # 第二阶段：训练浓度模型\n",
    "    # ===============================\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"第二阶段：开始训练浓度模型\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 根据评估标准选择水头模型\n",
    "    head_model_file = f'best_head_model_{evaluation_criterion}.pth'\n",
    "    try:\n",
    "        checkpoint = torch.load(os.path.join(config['save_path'], head_model_file),weights_only=False)\n",
    "        head_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        print(f\"成功加载基于{evaluation_criterion}的最佳水头模型\")\n",
    "    except Exception as e:\n",
    "        print(f\"加载水头模型失败，使用当前模型: {e}\")\n",
    "    \n",
    "    # 固定水头模型参数\n",
    "    for param in head_model.parameters():\n",
    "        param.requires_grad = False\n",
    "    head_model.eval()\n",
    "    \n",
    "    # 初始化浓度模型\n",
    "    conc_input_dim = 19  # 基础特征14 + 前一/前二时间步水头2 + 前一/前二时间步浓度2\n",
    "    conc_model = BlitzConcGNN(\n",
    "        node_features=conc_input_dim,  # 18维\n",
    "        spatial_dim=config['hidden_dim'],\n",
    "        temporal_dim=config['hidden_dim'],\n",
    "        prior_sigma_1=0.1,\n",
    "        prior_sigma_2=0.01,\n",
    "        dropout=0.1,\n",
    "        posterior_mu_init=0.0,\n",
    "        posterior_rho_init=-3.0\n",
    "    ).to(device)\n",
    "    \n",
    "    # 浓度模型损失函数\n",
    "    criterion_conc = ImprovedConcLoss(kl_weight=config['kl_weight'], l1_weight=1e-5)\n",
    "    \n",
    "    # 浓度模型优化器\n",
    "    conc_params = list(conc_model.parameters())\n",
    "    conc_optimizer = torch.optim.AdamW(conc_params, lr=config['lr'] * 0.8, weight_decay=config['weight_decay'])\n",
    "    \n",
    "    # 浓度模型学习率调度器\n",
    "    conc_scheduler = CosineAnnealingWarmRestarts(\n",
    "        conc_optimizer, T_0=15, T_mult=2, eta_min=1e-6\n",
    "    )\n",
    "    \n",
    "    # 浓度模型跟踪变量 - 分别跟踪损失和R2\n",
    "    best_conc_val_loss = float('inf')\n",
    "    best_conc_r2 = float('-inf')\n",
    "    conc_early_stop_counter = 0\n",
    "    conc_losses = {'train': [], 'val': []}\n",
    "    \n",
    "    print(f\"浓度模型参数数量: {sum(p.numel() for p in conc_model.parameters() if p.requires_grad)}\")\n",
    "    \n",
    "    # 浓度模型训练循环\n",
    "    for epoch in range(config['num_epochs']):\n",
    "        conc_model.train()\n",
    "        train_loss = 0.0\n",
    "        train_batches = 0\n",
    "        \n",
    "        # 训练阶段\n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            try:\n",
    "                # 准备数据\n",
    "                batch = batch.to(device)\n",
    "                if hasattr(batch, 'edge_attr') and batch.edge_attr is not None:\n",
    "                    batch.edge_attr = batch.edge_attr.float()\n",
    "                \n",
    "                # 使用固定的水头模型预测水头\n",
    "                with torch.no_grad():\n",
    "                    pred_head = head_model(batch)\n",
    "                \n",
    "                # 重置梯度\n",
    "                conc_optimizer.zero_grad()\n",
    "                \n",
    "                # 浓度模型前向传播，使用预测的水头\n",
    "                pred_conc = conc_model(batch, pred_head)\n",
    "                \n",
    "                # 计算损失\n",
    "                criterion_output = criterion_conc(pred_conc, batch, conc_model)\n",
    "                \n",
    "                # 处理损失函数的返回值\n",
    "                if isinstance(criterion_output, tuple):\n",
    "                    conc_criterion_loss = criterion_output[0]\n",
    "                    if len(criterion_output) > 1:\n",
    "                        loss_components = criterion_output[1]\n",
    "                        if isinstance(loss_components, tuple) and len(loss_components) >= 3:\n",
    "                            mse_loss, kl_loss_val, l1_reg = loss_components[:3]\n",
    "                        else:\n",
    "                            mse_loss, kl_loss_val, l1_reg = 0.0, 0.0, 0.0\n",
    "                    else:\n",
    "                        mse_loss, kl_loss_val, l1_reg = 0.0, 0.0, 0.0\n",
    "                else:\n",
    "                    conc_criterion_loss = criterion_output\n",
    "                    mse_loss, kl_loss_val, l1_reg = 0.0, 0.0, 0.0\n",
    "                \n",
    "                kl_loss = conc_model.nn_kl_divergence() * config['kl_weight']\n",
    "                total_loss = conc_criterion_loss + kl_loss\n",
    "                \n",
    "                # 反向传播\n",
    "                total_loss.backward()\n",
    "                \n",
    "                # 梯度裁剪\n",
    "                torch.nn.utils.clip_grad_norm_(conc_params, max_norm=1.0)\n",
    "                \n",
    "                # 更新参数\n",
    "                conc_optimizer.step()\n",
    "                \n",
    "                # 记录损失\n",
    "                train_loss += total_loss.item()\n",
    "                train_batches += 1\n",
    "                \n",
    "                # 每50个批次输出一次详细信息\n",
    "                if batch_idx % 50 == 0:\n",
    "                    print(f\"浓度模型 Epoch {epoch+1}, Batch {batch_idx}: \"\n",
    "                          f\"Total Loss: {total_loss.item():.4f}, \"\n",
    "                          f\"Criterion Loss: {conc_criterion_loss.item():.4f}, \"\n",
    "                          f\"MSE: {mse_loss:.4f}, \"\n",
    "                          f\"KL Loss: {kl_loss.item():.4f}, \"\n",
    "                          f\"L1 Reg: {l1_reg:.4f}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"浓度模型训练批次 {batch_idx} 出错: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # 检查训练批次\n",
    "        if train_batches == 0:\n",
    "            print(\"警告: 浓度模型本轮训练没有成功处理任何批次，跳过本轮\")\n",
    "            continue\n",
    "            \n",
    "        # 计算平均训练损失\n",
    "        avg_train_loss = train_loss / train_batches\n",
    "        \n",
    "        # 验证阶段\n",
    "        conc_model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_metrics = {'mse': 0.0, 'rmse': 0.0, 'mae': 0.0, 'r2': 0.0}\n",
    "        val_batches = 0\n",
    "        \n",
    "        # 用于存储预测和真实值\n",
    "        all_conc_predictions = []\n",
    "        all_conc_targets = []\n",
    "        all_conc_uncertainties = []\n",
    "        all_head_predictions = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch in enumerate(val_loader):\n",
    "                try:\n",
    "                    # 准备数据\n",
    "                    batch = batch.to(device)\n",
    "                    if hasattr(batch, 'edge_attr') and batch.edge_attr is not None:\n",
    "                        batch.edge_attr = batch.edge_attr.float()\n",
    "                    \n",
    "                    # 使用水头模型预测水头\n",
    "                    pred_head = head_model(batch)\n",
    "                    \n",
    "                    # 使用不确定性估计进行浓度预测\n",
    "                    conc_model.train()  # 开启dropout进行MC采样\n",
    "                    pred_conc, conc_std = compute_uncertainty(conc_model, batch, mc_samples=config['mc_samples'])\n",
    "                    \n",
    "                    # 计算验证损失\n",
    "                    criterion_output = criterion_conc(pred_conc, batch, conc_model)\n",
    "                    \n",
    "                    # 处理损失函数的返回值\n",
    "                    if isinstance(criterion_output, tuple):\n",
    "                        conc_criterion_loss = criterion_output[0]\n",
    "                    else:\n",
    "                        conc_criterion_loss = criterion_output\n",
    "                    \n",
    "                    # 计算指标\n",
    "                    metrics = compute_metrics(batch.y, pred_conc)\n",
    "                    \n",
    "                    for k in metrics:\n",
    "                        val_metrics[k] += metrics[k]\n",
    "                    \n",
    "                    val_loss += conc_criterion_loss.item()\n",
    "                    val_batches += 1\n",
    "                    \n",
    "                    # 收集预测结果用于后续分析\n",
    "                    all_conc_predictions.append(pred_conc.cpu().numpy())\n",
    "                    all_conc_targets.append(batch.y.cpu().numpy())\n",
    "                    all_conc_uncertainties.append(conc_std.cpu().numpy())\n",
    "                    all_head_predictions.append(pred_head.cpu().numpy())\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"浓度模型验证批次 {batch_idx} 出错: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        # 计算平均验证损失和指标\n",
    "        if val_batches > 0:\n",
    "            avg_val_loss = val_loss / val_batches\n",
    "            for k in val_metrics:\n",
    "                val_metrics[k] /= val_batches\n",
    "        else:\n",
    "            print(\"警告: 浓度模型本轮验证没有成功处理任何批次\")\n",
    "            avg_val_loss = float('inf')\n",
    "        \n",
    "        # 记录损失\n",
    "        conc_losses['train'].append(avg_train_loss)\n",
    "        conc_losses['val'].append({\n",
    "            'loss': avg_val_loss,\n",
    "            'metrics': val_metrics\n",
    "        })\n",
    "        \n",
    "        # 更新学习率\n",
    "        conc_scheduler.step()\n",
    "        current_lr = conc_scheduler.get_last_lr()[0]\n",
    "        \n",
    "        # 输出训练状态\n",
    "        print(f\"浓度模型 Epoch {epoch+1:03d}/{config['num_epochs']} | \"\n",
    "              f\"训练损失: {avg_train_loss:.4f} | 验证损失: {avg_val_loss:.4f} | \"\n",
    "              f\"LR: {current_lr:.6f}\")\n",
    "        print(f\"浓度验证指标 - MSE: {val_metrics['mse']:.4f}, \"\n",
    "              f\"RMSE: {val_metrics['rmse']:.4f}, \"\n",
    "              f\"MAE: {val_metrics['mae']:.4f}, \"\n",
    "              f\"R2: {val_metrics['r2']:.4f}\")\n",
    "        \n",
    "        # 保存基于损失的最佳浓度模型\n",
    "        if avg_val_loss < best_conc_val_loss:\n",
    "            best_conc_val_loss = avg_val_loss\n",
    "            try:\n",
    "                torch.save({\n",
    "                    'model_state_dict': conc_model.state_dict(),\n",
    "                    'epoch': epoch,\n",
    "                    'train_loss': avg_train_loss,\n",
    "                    'val_loss': avg_val_loss,\n",
    "                    'val_metrics': val_metrics,\n",
    "                    'config': config,\n",
    "                    'criterion': 'loss'\n",
    "                }, os.path.join(config['save_path'], 'best_conc_model_loss.pth'))\n",
    "                \n",
    "                # 保存预测结果\n",
    "                if all_conc_predictions:\n",
    "                    np.save(os.path.join(config['save_path'], 'best_conc_predictions_loss.npy'), \n",
    "                           np.concatenate(all_conc_predictions, axis=0))\n",
    "                    np.save(os.path.join(config['save_path'], 'best_conc_targets_loss.npy'), \n",
    "                           np.concatenate(all_conc_targets, axis=0))\n",
    "                    np.save(os.path.join(config['save_path'], 'best_conc_uncertainties_loss.npy'), \n",
    "                           np.concatenate(all_conc_uncertainties, axis=0))\n",
    "                \n",
    "                print(f\"保存基于损失的最佳浓度模型，验证损失: {best_conc_val_loss:.4f}\")\n",
    "            except Exception as e:\n",
    "                print(f\"保存浓度模型失败: {e}\")\n",
    "        \n",
    "        # 保存基于R2的最佳浓度模型\n",
    "        if val_metrics['r2'] > best_conc_r2:\n",
    "            best_conc_r2 = val_metrics['r2']\n",
    "            conc_early_stop_counter = 0  # 基于R2重置早停计数器\n",
    "            try:\n",
    "                torch.save({\n",
    "                    'model_state_dict': conc_model.state_dict(),\n",
    "                    'epoch': epoch,\n",
    "                    'train_loss': avg_train_loss,\n",
    "                    'val_loss': avg_val_loss,\n",
    "                    'val_metrics': val_metrics,\n",
    "                    'config': config,\n",
    "                    'criterion': 'r2'\n",
    "                }, os.path.join(config['save_path'], 'best_conc_model_r2.pth'))\n",
    "                \n",
    "                # 保存预测结果\n",
    "                if all_conc_predictions:\n",
    "                    np.save(os.path.join(config['save_path'], 'best_conc_predictions_r2.npy'), \n",
    "                           np.concatenate(all_conc_predictions, axis=0))\n",
    "                    np.save(os.path.join(config['save_path'], 'best_conc_targets_r2.npy'), \n",
    "                           np.concatenate(all_conc_targets, axis=0))\n",
    "                    np.save(os.path.join(config['save_path'], 'best_conc_uncertainties_r2.npy'), \n",
    "                           np.concatenate(all_conc_uncertainties, axis=0))\n",
    "                \n",
    "                print(f\"保存基于R2的最佳浓度模型，R2: {best_conc_r2:.4f}\")\n",
    "            except Exception as e:\n",
    "                print(f\"保存浓度模型失败: {e}\")\n",
    "        else:\n",
    "            conc_early_stop_counter += 1\n",
    "        \n",
    "        # 早停检查（基于R2）\n",
    "        if conc_early_stop_counter >= config['patience']:\n",
    "            print(f\"浓度模型早停触发! 在第{epoch+1}个epoch停止训练\")\n",
    "            break\n",
    "        \n",
    "        # 清理GPU内存\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"\\n浓度模型训练完成!\")\n",
    "    print(f\"基于损失的最佳验证损失: {best_conc_val_loss:.4f}\")\n",
    "    print(f\"基于R2的最佳R2分数: {best_conc_r2:.4f}\")\n",
    "    \n",
    "    # ===============================\n",
    "    # 保存训练历史和可视化\n",
    "    # ===============================\n",
    "    try:\n",
    "        # 保存水头模型训练历史\n",
    "        head_history_data = []\n",
    "        for i, (train_loss, val_data) in enumerate(zip(head_losses['train'], head_losses['val'])):\n",
    "            head_history_data.append({\n",
    "                'epoch': i + 1,\n",
    "                'train_loss': train_loss,\n",
    "                'val_loss': val_data['loss'],\n",
    "                'val_mse': val_data['metrics']['mse'],\n",
    "                'val_rmse': val_data['metrics']['rmse'],\n",
    "                'val_mae': val_data['metrics']['mae'],\n",
    "                'val_r2': val_data['metrics']['r2']\n",
    "            })\n",
    "        \n",
    "        if head_history_data:\n",
    "            head_history_df = pd.DataFrame(head_history_data)\n",
    "            head_history_df.to_csv(os.path.join(config['save_path'], 'head_training_history.csv'), index=False)\n",
    "        \n",
    "        # 保存浓度模型训练历史\n",
    "        conc_history_data = []\n",
    "        for i, (train_loss, val_data) in enumerate(zip(conc_losses['train'], conc_losses['val'])):\n",
    "            conc_history_data.append({\n",
    "                'epoch': i + 1,\n",
    "                'train_loss': train_loss,\n",
    "                'val_loss': val_data['loss'],\n",
    "                'val_mse': val_data['metrics']['mse'],\n",
    "                'val_rmse': val_data['metrics']['rmse'],\n",
    "                'val_mae': val_data['metrics']['mae'],\n",
    "                'val_r2': val_data['metrics']['r2']\n",
    "            })\n",
    "        \n",
    "        if conc_history_data:\n",
    "            conc_history_df = pd.DataFrame(conc_history_data)\n",
    "            conc_history_df.to_csv(os.path.join(config['save_path'], 'conc_training_history.csv'), index=False)\n",
    "        \n",
    "        # 绘制双模型训练曲线，包含最佳点标记\n",
    "        if head_history_data and conc_history_data:\n",
    "            plt.figure(figsize=(20, 12))\n",
    "            \n",
    "            # 水头模型曲线\n",
    "            plt.subplot(2, 4, 1)\n",
    "            plt.plot(head_history_df['epoch'], head_history_df['train_loss'], 'b-', label='Head Train Loss')\n",
    "            plt.plot(head_history_df['epoch'], head_history_df['val_loss'], 'r-', label='Head Val Loss')\n",
    "            # 标记最佳损失点\n",
    "            best_loss_epoch = head_history_df.loc[head_history_df['val_loss'].idxmin(), 'epoch']\n",
    "            best_loss_value = head_history_df['val_loss'].min()\n",
    "            plt.scatter(best_loss_epoch, best_loss_value, color='red', s=100, marker='*', \n",
    "                       label=f'Best Loss (E{best_loss_epoch})')\n",
    "            plt.title('Head Model: Training and Validation Loss')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            \n",
    "            plt.subplot(2, 4, 2)\n",
    "            plt.plot(head_history_df['epoch'], head_history_df['val_r2'], 'g-', label='Head R2')\n",
    "            # 标记最佳R2点\n",
    "            best_r2_epoch = head_history_df.loc[head_history_df['val_r2'].idxmax(), 'epoch']\n",
    "            best_r2_value = head_history_df['val_r2'].max()\n",
    "            plt.scatter(best_r2_epoch, best_r2_value, color='green', s=100, marker='*', \n",
    "                       label=f'Best R2 (E{best_r2_epoch})')\n",
    "            plt.title('Head Model: Validation R2 Score')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('R2')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            \n",
    "            plt.subplot(2, 4, 3)\n",
    "            plt.plot(head_history_df['epoch'], head_history_df['val_mse'], 'orange', label='Head MSE')\n",
    "            plt.title('Head Model: Validation MSE')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('MSE')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            \n",
    "            plt.subplot(2, 4, 4)\n",
    "            plt.plot(head_history_df['epoch'], head_history_df['val_rmse'], 'purple', label='Head RMSE')\n",
    "            plt.title('Head Model: Validation RMSE')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('RMSE')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            \n",
    "            # 浓度模型曲线\n",
    "            plt.subplot(2, 4, 5)\n",
    "            plt.plot(conc_history_df['epoch'], conc_history_df['train_loss'], 'b--', label='Conc Train Loss')\n",
    "            plt.plot(conc_history_df['epoch'], conc_history_df['val_loss'], 'r--', label='Conc Val Loss')\n",
    "            # 标记最佳损失点\n",
    "            best_loss_epoch = conc_history_df.loc[conc_history_df['val_loss'].idxmin(), 'epoch']\n",
    "            best_loss_value = conc_history_df['val_loss'].min()\n",
    "            plt.scatter(best_loss_epoch, best_loss_value, color='red', s=100, marker='*', \n",
    "                       label=f'Best Loss (E{best_loss_epoch})')\n",
    "            plt.title('Conc Model: Training and Validation Loss')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            \n",
    "            plt.subplot(2, 4, 6)\n",
    "            plt.plot(conc_history_df['epoch'], conc_history_df['val_r2'], 'g--', label='Conc R2')\n",
    "            # 标记最佳R2点\n",
    "            best_r2_epoch = conc_history_df.loc[conc_history_df['val_r2'].idxmax(), 'epoch']\n",
    "            best_r2_value = conc_history_df['val_r2'].max()\n",
    "            plt.scatter(best_r2_epoch, best_r2_value, color='green', s=100, marker='*', \n",
    "                       label=f'Best R2 (E{best_r2_epoch})')\n",
    "            plt.title('Conc Model: Validation R2 Score')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('R2')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            \n",
    "            plt.subplot(2, 4, 7)\n",
    "            plt.plot(conc_history_df['epoch'], conc_history_df['val_mse'], 'orange', linestyle='--', label='Conc MSE')\n",
    "            plt.title('Conc Model: Validation MSE')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('MSE')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            \n",
    "            plt.subplot(2, 4, 8)\n",
    "            plt.plot(conc_history_df['epoch'], conc_history_df['val_rmse'], 'purple', linestyle='--', label='Conc RMSE')\n",
    "            plt.title('Conc Model: Validation RMSE')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('RMSE')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(config['save_path'], 'dual_model_training_curves_improved.png'), \n",
    "                       dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            \n",
    "            print(f\"改进的双模型训练曲线已保存\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"保存训练历史或绘图失败: {e}\")\n",
    "    \n",
    "    # 重新启用水头模型的梯度计算（如果需要）\n",
    "    for param in head_model.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"双模型训练完成总结:\")\n",
    "    print(f\"水头模型 - 基于损失的最佳验证损失: {best_head_val_loss:.4f}\")\n",
    "    print(f\"水头模型 - 基于R2的最佳R2分数: {best_head_r2:.4f}\")\n",
    "    print(f\"浓度模型 - 基于损失的最佳验证损失: {best_conc_val_loss:.4f}\")\n",
    "    print(f\"浓度模型 - 基于R2的最佳R2分数: {best_conc_r2:.4f}\")\n",
    "    print(f\"评估将使用基于{evaluation_criterion}的模型\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    return head_model, conc_model, {'head': head_losses, 'conc': conc_losses}\n",
    "\n",
    "def evaluate_dual_model_improved(head_model, conc_model, val_loader, evaluation_criterion='loss'):\n",
    "    \"\"\"\n",
    "    改进的双模型评估，可选择基于损失或R2的最佳模型\n",
    "    \n",
    "    Args:\n",
    "        head_model: 水头预测模型\n",
    "        conc_model: 浓度预测模型\n",
    "        val_loader: 验证数据加载器\n",
    "        evaluation_criterion: 评估标准 ('loss' 或 'r2')\n",
    "    \"\"\"\n",
    "    print(f\"开始评估双模型性能（基于{evaluation_criterion}标准）...\")\n",
    "    \n",
    "    # 加载指定标准的最佳模型权重\n",
    "    try:\n",
    "        head_model_file = f'best_head_model_{evaluation_criterion}.pth'\n",
    "        print()\n",
    "        head_checkpoint = torch.load(os.path.join(config['save_path'], head_model_file),weights_only=False)\n",
    "        head_model.load_state_dict(head_checkpoint['model_state_dict'])\n",
    "        \n",
    "        conc_model_file = f'best_conc_model_{evaluation_criterion}.pth'\n",
    "        conc_checkpoint = torch.load(os.path.join(config['save_path'], conc_model_file),weights_only=False)\n",
    "        conc_model.load_state_dict(conc_checkpoint['model_state_dict'])\n",
    "        \n",
    "        print(f\"成功加载基于{evaluation_criterion}的最佳模型权重\")\n",
    "        print(f\"水头模型来自epoch {head_checkpoint['epoch']}, 验证损失: {head_checkpoint['val_loss']:.4f}, R2: {head_checkpoint['val_metrics']['r2']:.4f}\")\n",
    "        print(f\"浓度模型来自epoch {conc_checkpoint['epoch']}, 验证损失: {conc_checkpoint['val_loss']:.4f}, R2: {conc_checkpoint['val_metrics']['r2']:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"加载模型权重失败，使用当前权重: {e}\")\n",
    "    \n",
    "    head_model.eval()\n",
    "    conc_model.eval()\n",
    "    \n",
    "    # 存储所有预测结果\n",
    "    all_head_preds = []\n",
    "    all_head_targets = []\n",
    "    all_head_uncertainties = []\n",
    "    all_conc_preds = []\n",
    "    all_conc_targets = []\n",
    "    all_conc_uncertainties = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            try:\n",
    "                batch = batch.to(device)\n",
    "                if hasattr(batch, 'edge_attr') and batch.edge_attr is not None:\n",
    "                    batch.edge_attr = batch.edge_attr.float()\n",
    "                \n",
    "                # 水头预测\n",
    "                head_pred, head_std = compute_uncertainty(head_model, batch, mc_samples=config['mc_samples'])\n",
    "                \n",
    "                # 浓度预测（使用预测的水头）\n",
    "                conc_pred, conc_std = compute_uncertainty(conc_model, batch, mc_samples=config['mc_samples'])\n",
    "                \n",
    "                # 收集结果\n",
    "                all_head_preds.append(head_pred.cpu().numpy())\n",
    "                all_head_targets.append(batch.head_y.cpu().numpy())\n",
    "                all_head_uncertainties.append(head_std.cpu().numpy())\n",
    "                all_conc_preds.append(conc_pred.cpu().numpy())\n",
    "                all_conc_targets.append(batch.y.cpu().numpy())\n",
    "                all_conc_uncertainties.append(conc_std.cpu().numpy())\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"评估批次出错: {e}\")\n",
    "                continue\n",
    "    \n",
    "    # 合并所有预测结果\n",
    "    all_head_preds = np.concatenate(all_head_preds, axis=0)\n",
    "    all_head_targets = np.concatenate(all_head_targets, axis=0)\n",
    "    all_head_uncertainties = np.concatenate(all_head_uncertainties, axis=0)\n",
    "    all_conc_preds = np.concatenate(all_conc_preds, axis=0)\n",
    "    all_conc_targets = np.concatenate(all_conc_targets, axis=0)\n",
    "    all_conc_uncertainties = np.concatenate(all_conc_uncertainties, axis=0)\n",
    "    \n",
    "    # 计算指标\n",
    "    head_metrics = compute_metrics(all_head_targets, all_head_preds)\n",
    "    conc_metrics = compute_metrics(all_conc_targets, all_conc_preds)\n",
    "    \n",
    "    print(f\"\\n水头模型评估结果（基于{evaluation_criterion}）:\")\n",
    "    for metric, value in head_metrics.items():\n",
    "        print(f\"  {metric.upper()}: {value:.4f}\")\n",
    "    \n",
    "    print(f\"\\n浓度模型评估结果（基于{evaluation_criterion}）:\")\n",
    "    for metric, value in conc_metrics.items():\n",
    "        print(f\"  {metric.upper()}: {value:.4f}\")\n",
    "    \n",
    "    # 保存评估结果\n",
    "    evaluation_results = {\n",
    "        'criterion': evaluation_criterion,\n",
    "        'head_metrics': head_metrics,\n",
    "        'conc_metrics': conc_metrics,\n",
    "        'head_predictions': all_head_preds,\n",
    "        'head_targets': all_head_targets,\n",
    "        'head_uncertainties': all_head_uncertainties,\n",
    "        'conc_predictions': all_conc_preds,\n",
    "        'conc_targets': all_conc_targets,\n",
    "        'conc_uncertainties': all_conc_uncertainties\n",
    "    }\n",
    "    \n",
    "    # 保存为文件\n",
    "    filename = f'dual_model_evaluation_{evaluation_criterion}.npy'\n",
    "    np.save(os.path.join(config['save_path'], filename), evaluation_results)\n",
    "    print(f\"\\n评估结果已保存到: {config['save_path']}/{filename}\")\n",
    "    \n",
    "    return evaluation_results\n",
    "\n",
    "def compare_model_criteria(head_model, conc_model, val_loader):\n",
    "    \"\"\"\n",
    "    比较基于损失和基于R2的模型性能\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"比较不同选择标准的模型性能\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 分别评估两种标准的模型\n",
    "    loss_results = evaluate_dual_model_improved(head_model, conc_model, val_loader, 'loss')\n",
    "    r2_results = evaluate_dual_model_improved(head_model, conc_model, val_loader, 'r2')\n",
    "    \n",
    "    # 创建比较表格\n",
    "    comparison_data = []\n",
    "    \n",
    "    # 水头模型比较\n",
    "    comparison_data.append({\n",
    "        'Model': 'Head',\n",
    "        'Criterion': 'Loss',\n",
    "        'MSE': loss_results['head_metrics']['mse'],\n",
    "        'RMSE': loss_results['head_metrics']['rmse'],\n",
    "        'MAE': loss_results['head_metrics']['mae'],\n",
    "        'R2': loss_results['head_metrics']['r2']\n",
    "    })\n",
    "    \n",
    "    comparison_data.append({\n",
    "        'Model': 'Head',\n",
    "        'Criterion': 'R2',\n",
    "        'MSE': r2_results['head_metrics']['mse'],\n",
    "        'RMSE': r2_results['head_metrics']['rmse'],\n",
    "        'MAE': r2_results['head_metrics']['mae'],\n",
    "        'R2': r2_results['head_metrics']['r2']\n",
    "    })\n",
    "    \n",
    "    # 浓度模型比较\n",
    "    comparison_data.append({\n",
    "        'Model': 'Concentration',\n",
    "        'Criterion': 'Loss',\n",
    "        'MSE': loss_results['conc_metrics']['mse'],\n",
    "        'RMSE': loss_results['conc_metrics']['rmse'],\n",
    "        'MAE': loss_results['conc_metrics']['mae'],\n",
    "        'R2': loss_results['conc_metrics']['r2']\n",
    "    })\n",
    "    \n",
    "    comparison_data.append({\n",
    "        'Model': 'Concentration',\n",
    "        'Criterion': 'R2',\n",
    "        'MSE': r2_results['conc_metrics']['mse'],\n",
    "        'RMSE': r2_results['conc_metrics']['rmse'],\n",
    "        'MAE': r2_results['conc_metrics']['mae'],\n",
    "        'R2': r2_results['conc_metrics']['r2']\n",
    "    })\n",
    "    \n",
    "    # 创建比较DataFrame\n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    \n",
    "    # 保存比较结果\n",
    "    comparison_df.to_csv(os.path.join(config['save_path'], 'model_criteria_comparison.csv'), index=False)\n",
    "    \n",
    "    # 打印比较结果\n",
    "    print(\"\\n模型选择标准比较结果:\")\n",
    "    print(comparison_df.to_string(index=False, float_format='%.4f'))\n",
    "    \n",
    "    # 绘制比较图\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # R2比较\n",
    "    plt.subplot(2, 3, 1)\n",
    "    head_r2 = [loss_results['head_metrics']['r2'], r2_results['head_metrics']['r2']]\n",
    "    conc_r2 = [loss_results['conc_metrics']['r2'], r2_results['conc_metrics']['r2']]\n",
    "    x = ['Loss-based', 'R2-based']\n",
    "    plt.bar([0, 1], head_r2, alpha=0.7, label='Head Model', width=0.35)\n",
    "    plt.bar([0.35, 1.35], conc_r2, alpha=0.7, label='Concentration Model', width=0.35)\n",
    "    plt.xlabel('Model Selection Criterion')\n",
    "    plt.ylabel('R2 Score')\n",
    "    plt.title('R2 Score Comparison')\n",
    "    plt.xticks([0.175, 1.175], x)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # MSE比较\n",
    "    plt.subplot(2, 3, 2)\n",
    "    head_mse = [loss_results['head_metrics']['mse'], r2_results['head_metrics']['mse']]\n",
    "    conc_mse = [loss_results['conc_metrics']['mse'], r2_results['conc_metrics']['mse']]\n",
    "    plt.bar([0, 1], head_mse, alpha=0.7, label='Head Model', width=0.35)\n",
    "    plt.bar([0.35, 1.35], conc_mse, alpha=0.7, label='Concentration Model', width=0.35)\n",
    "    plt.xlabel('Model Selection Criterion')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.title('MSE Comparison')\n",
    "    plt.xticks([0.175, 1.175], x)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # RMSE比较\n",
    "    plt.subplot(2, 3, 3)\n",
    "    head_rmse = [loss_results['head_metrics']['rmse'], r2_results['head_metrics']['rmse']]\n",
    "    conc_rmse = [loss_results['conc_metrics']['rmse'], r2_results['conc_metrics']['rmse']]\n",
    "    plt.bar([0, 1], head_rmse, alpha=0.7, label='Head Model', width=0.35)\n",
    "    plt.bar([0.35, 1.35], conc_rmse, alpha=0.7, label='Concentration Model', width=0.35)\n",
    "    plt.xlabel('Model Selection Criterion')\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.title('RMSE Comparison')\n",
    "    plt.xticks([0.175, 1.175], x)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # MAE比较\n",
    "    plt.subplot(2, 3, 4)\n",
    "    head_mae = [loss_results['head_metrics']['mae'], r2_results['head_metrics']['mae']]\n",
    "    conc_mae = [loss_results['conc_metrics']['mae'], r2_results['conc_metrics']['mae']]\n",
    "    plt.bar([0, 1], head_mae, alpha=0.7, label='Head Model', width=0.35)\n",
    "    plt.bar([0.35, 1.35], conc_mae, alpha=0.7, label='Concentration Model', width=0.35)\n",
    "    plt.xlabel('Model Selection Criterion')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.title('MAE Comparison')\n",
    "    plt.xticks([0.175, 1.175], x)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 水头模型散点图比较\n",
    "    plt.subplot(2, 3, 5)\n",
    "    plt.scatter(loss_results['head_targets'], loss_results['head_predictions'], alpha=0.5, label='Loss-based')\n",
    "    plt.scatter(r2_results['head_targets'], r2_results['head_predictions'], alpha=0.5, label='R2-based')\n",
    "    plt.plot([min(loss_results['head_targets']), max(loss_results['head_targets'])], \n",
    "             [min(loss_results['head_targets']), max(loss_results['head_targets'])], 'r--', alpha=0.8)\n",
    "    plt.xlabel('True Head Values')\n",
    "    plt.ylabel('Predicted Head Values')\n",
    "    plt.title('Head Model: True vs Predicted')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 浓度模型散点图比较\n",
    "    plt.subplot(2, 3, 6)\n",
    "    plt.scatter(loss_results['conc_targets'], loss_results['conc_predictions'], alpha=0.5, label='Loss-based')\n",
    "    plt.scatter(r2_results['conc_targets'], r2_results['conc_predictions'], alpha=0.5, label='R2-based')\n",
    "    plt.plot([min(loss_results['conc_targets']), max(loss_results['conc_targets'])], \n",
    "             [min(loss_results['conc_targets']), max(loss_results['conc_targets'])], 'r--', alpha=0.8)\n",
    "    plt.xlabel('True Concentration Values')\n",
    "    plt.ylabel('Predicted Concentration Values')\n",
    "    plt.title('Concentration Model: True vs Predicted')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(config['save_path'], 'model_criteria_comparison.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"\\n比较图表已保存到: {config['save_path']}/model_criteria_comparison.png\")\n",
    "    print(f\"比较数据已保存到: {config['save_path']}/model_criteria_comparison.csv\")\n",
    "    \n",
    "    return comparison_df, loss_results, r2_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b05bfd3-f3a8-4b60-a100-7e20e0aae720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在处理数据...\n",
      "\n",
      "▶ Started building spatiotemporal graphs\n",
      "▷ Total models to process: 100\n",
      "\n",
      "▣ Processing model 1/100: dual_42\n",
      "\n",
      "▣ Processing model 2/100: dual_93\n",
      "\n",
      "▣ Processing model 3/100: dual_71\n",
      "\n",
      "▣ Processing model 4/100: dual_31\n",
      "\n",
      "▣ Processing model 5/100: dual_60\n",
      "\n",
      "▣ Processing model 6/100: dual_15\n",
      "\n",
      "▣ Processing model 7/100: dual_88\n",
      "\n",
      "▣ Processing model 8/100: dual_40\n",
      "\n",
      "▣ Processing model 9/100: dual_20\n",
      "\n",
      "▣ Processing model 10/100: dual_94\n",
      "\n",
      "▣ Processing model 11/100: dual_76\n",
      "\n",
      "▣ Processing model 12/100: dual_84\n",
      "\n",
      "▣ Processing model 13/100: dual_62\n",
      "\n",
      "▣ Processing model 14/100: dual_10\n",
      "\n",
      "▣ Processing model 15/100: dual_21\n",
      "\n",
      "▣ Processing model 16/100: dual_0\n",
      "\n",
      "▣ Processing model 17/100: dual_29\n",
      "\n",
      "▣ Processing model 18/100: dual_49\n",
      "\n",
      "▣ Processing model 19/100: dual_37\n",
      "\n",
      "▣ Processing model 20/100: dual_23\n",
      "\n",
      "▣ Processing model 21/100: dual_61\n",
      "\n",
      "▣ Processing model 22/100: dual_68\n",
      "\n",
      "▣ Processing model 23/100: dual_18\n",
      "\n",
      "▣ Processing model 24/100: dual_66\n",
      "\n",
      "▣ Processing model 25/100: dual_17\n",
      "\n",
      "▣ Processing model 26/100: dual_51\n",
      "\n",
      "▣ Processing model 27/100: dual_36\n",
      "\n",
      "▣ Processing model 28/100: dual_48\n",
      "\n",
      "▣ Processing model 29/100: dual_34\n",
      "\n",
      "▣ Processing model 30/100: dual_47\n",
      "\n",
      "▣ Processing model 31/100: dual_24\n",
      "\n",
      "▣ Processing model 32/100: dual_85\n",
      "\n",
      "▣ Processing model 33/100: dual_67\n",
      "\n",
      "▣ Processing model 34/100: dual_54\n",
      "\n",
      "▣ Processing model 35/100: dual_55\n",
      "\n",
      "▣ Processing model 36/100: dual_87\n",
      "\n",
      "▣ Processing model 37/100: dual_90\n",
      "\n",
      "▣ Processing model 38/100: dual_8\n",
      "\n",
      "▣ Processing model 39/100: dual_6\n",
      "\n",
      "▣ Processing model 40/100: dual_7\n",
      "\n",
      "▣ Processing model 41/100: dual_99\n",
      "\n",
      "▣ Processing model 42/100: dual_16\n",
      "\n",
      "▣ Processing model 43/100: dual_32\n",
      "\n",
      "▣ Processing model 44/100: dual_33\n",
      "\n",
      "▣ Processing model 45/100: dual_43\n",
      "\n",
      "▣ Processing model 46/100: dual_63\n",
      "\n",
      "▣ Processing model 47/100: dual_72\n",
      "\n",
      "▣ Processing model 48/100: dual_35\n",
      "\n",
      "▣ Processing model 49/100: dual_91\n",
      "\n",
      "▣ Processing model 50/100: dual_26\n",
      "\n",
      "▣ Processing model 51/100: dual_39\n",
      "\n",
      "▣ Processing model 52/100: dual_81\n",
      "\n",
      "▣ Processing model 53/100: dual_74\n",
      "\n",
      "▣ Processing model 54/100: dual_96\n",
      "\n",
      "▣ Processing model 55/100: dual_52\n",
      "\n",
      "▣ Processing model 56/100: dual_19\n",
      "\n",
      "▣ Processing model 57/100: dual_38\n",
      "\n",
      "▣ Processing model 58/100: dual_3\n",
      "\n",
      "▣ Processing model 59/100: dual_44\n",
      "\n",
      "▣ Processing model 60/100: dual_83\n",
      "\n",
      "▣ Processing model 61/100: dual_82\n",
      "\n",
      "▣ Processing model 62/100: dual_97\n",
      "\n",
      "▣ Processing model 63/100: dual_5\n",
      "\n",
      "▣ Processing model 64/100: dual_57\n",
      "\n",
      "▣ Processing model 65/100: dual_45\n",
      "\n",
      "▣ Processing model 66/100: dual_73\n",
      "\n",
      "▣ Processing model 67/100: dual_12\n",
      "\n",
      "▣ Processing model 68/100: dual_27\n",
      "\n",
      "▣ Processing model 69/100: dual_11\n",
      "\n",
      "▣ Processing model 70/100: dual_50\n",
      "\n",
      "▣ Processing model 71/100: dual_41\n",
      "\n",
      "▣ Processing model 72/100: dual_79\n",
      "\n",
      "▣ Processing model 73/100: dual_13\n",
      "\n",
      "▣ Processing model 74/100: dual_77\n",
      "\n",
      "▣ Processing model 75/100: dual_92\n",
      "\n",
      "▣ Processing model 76/100: dual_98\n",
      "\n",
      "▣ Processing model 77/100: dual_89\n",
      "\n",
      "▣ Processing model 78/100: dual_28\n",
      "\n",
      "▣ Processing model 79/100: dual_1\n",
      "\n",
      "▣ Processing model 80/100: dual_59\n",
      "\n",
      "▣ Processing model 81/100: dual_56\n",
      "\n",
      "▣ Processing model 82/100: dual_69\n",
      "\n",
      "▣ Processing model 83/100: dual_70\n",
      "\n",
      "▣ Processing model 84/100: dual_65\n",
      "\n",
      "▣ Processing model 85/100: dual_64\n",
      "\n",
      "▣ Processing model 86/100: dual_58\n",
      "\n",
      "▣ Processing model 87/100: dual_4\n",
      "\n",
      "▣ Processing model 88/100: dual_86\n",
      "\n",
      "▣ Processing model 89/100: dual_22\n",
      "\n",
      "▣ Processing model 90/100: dual_25\n",
      "\n",
      "▣ Processing model 91/100: dual_46\n",
      "\n",
      "▣ Processing model 92/100: dual_95\n",
      "\n",
      "▣ Processing model 93/100: dual_9\n",
      "\n",
      "▣ Processing model 94/100: dual_78\n",
      "\n",
      "▣ Processing model 95/100: dual_2\n",
      "\n",
      "▣ Processing model 96/100: dual_75\n",
      "\n",
      "▣ Processing model 97/100: dual_14\n",
      "\n",
      "▣ Processing model 98/100: dual_53\n",
      "\n",
      "▣ Processing model 99/100: dual_30\n",
      "\n",
      "▣ Processing model 100/100: dual_80\n",
      "\n",
      "✅ All models processed! Total graphs created: 100\n",
      "数据处理完成！\n",
      "CUDA缓存已成功清除\n",
      "================================================================================\n",
      "第一阶段：开始训练水头模型\n",
      "================================================================================\n",
      "开始训练水头模型\n",
      "水头模型参数数量: 949853\n",
      "水头模型 Epoch 1, Batch 0: Total Loss: 9573.2021, Criterion Loss: 9376.2344, Physics Loss: 9566.2173, KL Loss: 196.9680\n",
      "水头模型 Epoch 001/500 | 训练损失: 9581.8674 | 验证损失: 9248.6765 | LR: 0.000994\n",
      "水头验证指标 - MSE: 9248.6764, RMSE: 96.1674, MAE: 95.9953, R2: -291.4923\n",
      "保存基于损失的最佳水头模型，验证损失: 9248.6765\n",
      "保存基于R2的最佳水头模型，R2: -291.4923\n",
      "水头模型 Epoch 2, Batch 0: Total Loss: 9552.0166, Criterion Loss: 9358.8828, Physics Loss: 9548.7436, KL Loss: 193.1335\n",
      "水头模型 Epoch 002/500 | 训练损失: 9344.1236 | 验证损失: 8871.5166 | LR: 0.000976\n",
      "水头验证指标 - MSE: 8871.5166, RMSE: 94.1860, MAE: 93.9936, R2: -279.5610\n",
      "保存基于损失的最佳水头模型，验证损失: 8871.5166\n",
      "保存基于R2的最佳水头模型，R2: -279.5610\n",
      "水头模型 Epoch 3, Batch 0: Total Loss: 9184.3994, Criterion Loss: 8994.2129, Physics Loss: 9185.1414, KL Loss: 190.1868\n",
      "水头模型 Epoch 003/500 | 训练损失: 8687.2024 | 验证损失: 7826.9693 | LR: 0.000946\n",
      "水头验证指标 - MSE: 7826.9689, RMSE: 88.4677, MAE: 88.2347, R2: -246.5359\n",
      "保存基于损失的最佳水头模型，验证损失: 7826.9693\n",
      "保存基于R2的最佳水头模型，R2: -246.5359\n",
      "水头模型 Epoch 4, Batch 0: Total Loss: 8176.3335, Criterion Loss: 7987.2637, Physics Loss: 8180.9342, KL Loss: 189.0700\n",
      "水头模型 Epoch 004/500 | 训练损失: 7137.4646 | 验证损失: 5379.2067 | LR: 0.000905\n",
      "水头验证指标 - MSE: 5379.2067, RMSE: 73.3372, MAE: 73.0177, R2: -168.9303\n",
      "保存基于损失的最佳水头模型，验证损失: 5379.2067\n",
      "保存基于R2的最佳水头模型，R2: -168.9303\n",
      "水头模型 Epoch 5, Batch 0: Total Loss: 5581.5430, Criterion Loss: 5393.0127, Physics Loss: 5581.2863, KL Loss: 188.5302\n",
      "水头模型 Epoch 005/500 | 训练损失: 3513.0340 | 验证损失: 646.1089 | LR: 0.000855\n",
      "水头验证指标 - MSE: 646.1089, RMSE: 25.3889, MAE: 24.4485, R2: -19.2757\n",
      "保存基于损失的最佳水头模型，验证损失: 646.1089\n",
      "保存基于R2的最佳水头模型，R2: -19.2757\n",
      "水头模型 Epoch 6, Batch 0: Total Loss: 1030.3948, Criterion Loss: 841.5029, Physics Loss: 1049.6555, KL Loss: 188.8920\n",
      "水头模型 Epoch 006/500 | 训练损失: 691.2452 | 验证损失: 107.9554 | LR: 0.000796\n",
      "水头验证指标 - MSE: 107.9554, RMSE: 10.3587, MAE: 8.5900, R2: -2.4672\n",
      "保存基于损失的最佳水头模型，验证损失: 107.9554\n",
      "保存基于R2的最佳水头模型，R2: -2.4672\n",
      "水头模型 Epoch 7, Batch 0: Total Loss: 484.4174, Criterion Loss: 295.8731, Physics Loss: 581.1348, KL Loss: 188.5443\n",
      "水头模型 Epoch 007/500 | 训练损失: 417.5406 | 验证损失: 52.1683 | LR: 0.000730\n",
      "水头验证指标 - MSE: 52.1683, RMSE: 7.1994, MAE: 5.6763, R2: -0.6663\n",
      "保存基于损失的最佳水头模型，验证损失: 52.1683\n",
      "保存基于R2的最佳水头模型，R2: -0.6663\n",
      "水头模型 Epoch 8, Batch 0: Total Loss: 316.4113, Criterion Loss: 128.3513, Physics Loss: 313.9068, KL Loss: 188.0600\n",
      "水头模型 Epoch 008/500 | 训练损失: 336.0671 | 验证损失: 34.6616 | LR: 0.000658\n",
      "水头验证指标 - MSE: 34.6616, RMSE: 5.8605, MAE: 4.6869, R2: -0.0787\n",
      "保存基于损失的最佳水头模型，验证损失: 34.6616\n",
      "保存基于R2的最佳水头模型，R2: -0.0787\n",
      "水头模型 Epoch 9, Batch 0: Total Loss: 298.0424, Criterion Loss: 111.8220, Physics Loss: 271.4335, KL Loss: 186.2204\n",
      "水头模型 Epoch 009/500 | 训练损失: 323.0051 | 验证损失: 31.3748 | LR: 0.000582\n",
      "水头验证指标 - MSE: 31.3748, RMSE: 5.5531, MAE: 4.4351, R2: 0.0402\n",
      "保存基于损失的最佳水头模型，验证损失: 31.3748\n",
      "保存基于R2的最佳水头模型，R2: 0.0402\n",
      "水头模型 Epoch 10, Batch 0: Total Loss: 265.1849, Criterion Loss: 80.7219, Physics Loss: 219.7423, KL Loss: 184.4629\n",
      "水头模型 Epoch 010/500 | 训练损失: 329.5058 | 验证损失: 29.7882 | LR: 0.000505\n",
      "水头验证指标 - MSE: 29.7882, RMSE: 5.4341, MAE: 4.3200, R2: 0.0703\n",
      "保存基于损失的最佳水头模型，验证损失: 29.7882\n",
      "保存基于R2的最佳水头模型，R2: 0.0703\n",
      "水头模型 Epoch 11, Batch 0: Total Loss: 273.7588, Criterion Loss: 90.9999, Physics Loss: 225.7888, KL Loss: 182.7589\n",
      "水头模型 Epoch 011/500 | 训练损失: 285.1752 | 验证损失: 28.0361 | LR: 0.000428\n",
      "水头验证指标 - MSE: 28.0361, RMSE: 5.2879, MAE: 4.2143, R2: 0.1127\n",
      "保存基于损失的最佳水头模型，验证损失: 28.0361\n",
      "保存基于R2的最佳水头模型，R2: 0.1127\n",
      "水头模型 Epoch 12, Batch 0: Total Loss: 278.9817, Criterion Loss: 97.4638, Physics Loss: 222.3477, KL Loss: 181.5178\n",
      "水头模型 Epoch 012/500 | 训练损失: 304.7682 | 验证损失: 27.3171 | LR: 0.000352\n",
      "水头验证指标 - MSE: 27.3171, RMSE: 5.1817, MAE: 4.1342, R2: 0.1617\n",
      "保存基于损失的最佳水头模型，验证损失: 27.3171\n",
      "保存基于R2的最佳水头模型，R2: 0.1617\n",
      "水头模型 Epoch 13, Batch 0: Total Loss: 259.0333, Criterion Loss: 79.0540, Physics Loss: 206.3017, KL Loss: 179.9793\n",
      "水头模型 Epoch 013/500 | 训练损失: 270.3487 | 验证损失: 51.2868 | LR: 0.000280\n",
      "水头验证指标 - MSE: 51.2868, RMSE: 7.0626, MAE: 6.0735, R2: -0.6772\n",
      "水头模型 Epoch 14, Batch 0: Total Loss: 263.1658, Criterion Loss: 84.3460, Physics Loss: 231.5368, KL Loss: 178.8198\n",
      "水头模型 Epoch 014/500 | 训练损失: 283.1307 | 验证损失: 36.5176 | LR: 0.000214\n",
      "水头验证指标 - MSE: 36.5176, RMSE: 5.8329, MAE: 4.7962, R2: -0.0805\n",
      "水头模型 Epoch 15, Batch 0: Total Loss: 251.1844, Criterion Loss: 73.2899, Physics Loss: 207.0534, KL Loss: 177.8945\n",
      "水头模型 Epoch 015/500 | 训练损失: 286.6071 | 验证损失: 24.8957 | LR: 0.000155\n",
      "水头验证指标 - MSE: 24.8957, RMSE: 4.9510, MAE: 4.0436, R2: 0.1970\n",
      "保存基于损失的最佳水头模型，验证损失: 24.8957\n",
      "保存基于R2的最佳水头模型，R2: 0.1970\n",
      "水头模型 Epoch 16, Batch 0: Total Loss: 252.7773, Criterion Loss: 74.7158, Physics Loss: 206.2158, KL Loss: 178.0615\n",
      "水头模型 Epoch 016/500 | 训练损失: 265.7205 | 验证损失: 18.2375 | LR: 0.000105\n",
      "水头验证指标 - MSE: 18.2375, RMSE: 4.2585, MAE: 3.3924, R2: 0.4330\n",
      "保存基于损失的最佳水头模型，验证损失: 18.2375\n",
      "保存基于R2的最佳水头模型，R2: 0.4330\n",
      "水头模型 Epoch 17, Batch 0: Total Loss: 242.9795, Criterion Loss: 65.9042, Physics Loss: 192.5041, KL Loss: 177.0753\n",
      "水头模型 Epoch 017/500 | 训练损失: 271.4298 | 验证损失: 18.6361 | LR: 0.000064\n",
      "水头验证指标 - MSE: 18.6361, RMSE: 4.3044, MAE: 3.4262, R2: 0.4200\n",
      "水头模型 Epoch 18, Batch 0: Total Loss: 413.8324, Criterion Loss: 237.3833, Physics Loss: 403.9995, KL Loss: 176.4491\n",
      "水头模型 Epoch 018/500 | 训练损失: 292.4477 | 验证损失: 18.7352 | LR: 0.000034\n",
      "水头验证指标 - MSE: 18.7352, RMSE: 4.3136, MAE: 3.4387, R2: 0.4103\n",
      "水头模型 Epoch 19, Batch 0: Total Loss: 249.6878, Criterion Loss: 73.3231, Physics Loss: 190.4669, KL Loss: 176.3646\n",
      "水头模型 Epoch 019/500 | 训练损失: 268.1319 | 验证损失: 18.8782 | LR: 0.000016\n",
      "水头验证指标 - MSE: 18.8782, RMSE: 4.3152, MAE: 3.4317, R2: 0.4194\n",
      "水头模型 Epoch 20, Batch 0: Total Loss: 249.8203, Criterion Loss: 73.2129, Physics Loss: 198.0324, KL Loss: 176.6074\n",
      "水头模型 Epoch 020/500 | 训练损失: 278.2864 | 验证损失: 20.1261 | LR: 0.001000\n",
      "水头验证指标 - MSE: 20.1261, RMSE: 4.4500, MAE: 3.5622, R2: 0.3796\n",
      "水头模型 Epoch 21, Batch 0: Total Loss: 264.4813, Criterion Loss: 87.9799, Physics Loss: 223.2392, KL Loss: 176.5014\n",
      "水头模型 Epoch 021/500 | 训练损失: 287.9356 | 验证损失: 28.0508 | LR: 0.000998\n",
      "水头验证指标 - MSE: 28.0508, RMSE: 5.2658, MAE: 4.3169, R2: 0.1147\n",
      "水头模型 Epoch 22, Batch 0: Total Loss: 245.9984, Criterion Loss: 72.4153, Physics Loss: 204.8722, KL Loss: 173.5831\n",
      "水头模型 Epoch 022/500 | 训练损失: 254.8608 | 验证损失: 41.4806 | LR: 0.000994\n",
      "水头验证指标 - MSE: 41.4806, RMSE: 6.3277, MAE: 5.4157, R2: -0.3357\n",
      "水头模型 Epoch 23, Batch 0: Total Loss: 246.4688, Criterion Loss: 74.9370, Physics Loss: 204.6988, KL Loss: 171.5318\n",
      "水头模型 Epoch 023/500 | 训练损失: 260.6558 | 验证损失: 58.4317 | LR: 0.000986\n",
      "水头验证指标 - MSE: 58.4317, RMSE: 7.5711, MAE: 6.6591, R2: -0.8616\n",
      "水头模型 Epoch 24, Batch 0: Total Loss: 237.0994, Criterion Loss: 67.7399, Physics Loss: 186.6087, KL Loss: 169.3594\n",
      "水头模型 Epoch 024/500 | 训练损失: 262.0167 | 验证损失: 39.5374 | LR: 0.000976\n",
      "水头验证指标 - MSE: 39.5374, RMSE: 6.2105, MAE: 5.0633, R2: -0.2590\n",
      "水头模型 Epoch 25, Batch 0: Total Loss: 241.9050, Criterion Loss: 74.1490, Physics Loss: 195.3100, KL Loss: 167.7560\n",
      "水头模型 Epoch 025/500 | 训练损失: 262.1501 | 验证损失: 20.1690 | LR: 0.000962\n",
      "水头验证指标 - MSE: 20.1690, RMSE: 4.4594, MAE: 3.6026, R2: 0.3593\n",
      "水头模型 Epoch 26, Batch 0: Total Loss: 240.3499, Criterion Loss: 74.0228, Physics Loss: 175.4229, KL Loss: 166.3271\n",
      "水头模型 Epoch 026/500 | 训练损失: 270.1716 | 验证损失: 40.4090 | LR: 0.000946\n",
      "水头验证指标 - MSE: 40.4090, RMSE: 6.3258, MAE: 5.2742, R2: -0.2534\n",
      "水头模型 Epoch 27, Batch 0: Total Loss: 231.9099, Criterion Loss: 67.7005, Physics Loss: 174.5226, KL Loss: 164.2094\n",
      "水头模型 Epoch 027/500 | 训练损失: 247.8952 | 验证损失: 25.8659 | LR: 0.000927\n",
      "水头验证指标 - MSE: 25.8659, RMSE: 5.0306, MAE: 4.1030, R2: 0.1900\n",
      "水头模型 Epoch 28, Batch 0: Total Loss: 271.5108, Criterion Loss: 108.6765, Physics Loss: 243.2877, KL Loss: 162.8343\n",
      "水头模型 Epoch 028/500 | 训练损失: 235.8518 | 验证损失: 18.7345 | LR: 0.000905\n",
      "水头验证指标 - MSE: 18.7345, RMSE: 4.2926, MAE: 3.4351, R2: 0.4168\n",
      "水头模型 Epoch 29, Batch 0: Total Loss: 230.2438, Criterion Loss: 69.4370, Physics Loss: 189.2415, KL Loss: 160.8069\n",
      "水头模型 Epoch 029/500 | 训练损失: 239.3236 | 验证损失: 16.6420 | LR: 0.000881\n",
      "水头验证指标 - MSE: 16.6420, RMSE: 4.0680, MAE: 3.2363, R2: 0.4760\n",
      "保存基于损失的最佳水头模型，验证损失: 16.6420\n",
      "保存基于R2的最佳水头模型，R2: 0.4760\n",
      "水头模型 Epoch 30, Batch 0: Total Loss: 219.1158, Criterion Loss: 59.7146, Physics Loss: 166.7241, KL Loss: 159.4012\n",
      "水头模型 Epoch 030/500 | 训练损失: 238.9659 | 验证损失: 16.9243 | LR: 0.000855\n",
      "水头验证指标 - MSE: 16.9243, RMSE: 4.1019, MAE: 3.3159, R2: 0.4675\n",
      "水头模型 Epoch 31, Batch 0: Total Loss: 214.4202, Criterion Loss: 56.6315, Physics Loss: 158.0564, KL Loss: 157.7887\n",
      "水头模型 Epoch 031/500 | 训练损失: 230.2906 | 验证损失: 15.5127 | LR: 0.000826\n",
      "水头验证指标 - MSE: 15.5127, RMSE: 3.9163, MAE: 3.1448, R2: 0.5168\n",
      "保存基于损失的最佳水头模型，验证损失: 15.5127\n",
      "保存基于R2的最佳水头模型，R2: 0.5168\n",
      "水头模型 Epoch 32, Batch 0: Total Loss: 209.6681, Criterion Loss: 53.0760, Physics Loss: 152.0545, KL Loss: 156.5921\n",
      "水头模型 Epoch 032/500 | 训练损失: 226.9719 | 验证损失: 73.0816 | LR: 0.000796\n",
      "水头验证指标 - MSE: 73.0816, RMSE: 8.4705, MAE: 7.6134, R2: -1.3615\n",
      "水头模型 Epoch 33, Batch 0: Total Loss: 246.6863, Criterion Loss: 91.7914, Physics Loss: 208.0827, KL Loss: 154.8949\n",
      "水头模型 Epoch 033/500 | 训练损失: 253.9911 | 验证损失: 21.2322 | LR: 0.000764\n",
      "水头验证指标 - MSE: 21.2322, RMSE: 4.5568, MAE: 3.6741, R2: 0.3407\n",
      "水头模型 Epoch 34, Batch 0: Total Loss: 202.0758, Criterion Loss: 48.0243, Physics Loss: 140.3721, KL Loss: 154.0515\n",
      "水头模型 Epoch 034/500 | 训练损失: 230.0864 | 验证损失: 18.0212 | LR: 0.000730\n",
      "水头验证指标 - MSE: 18.0212, RMSE: 4.2144, MAE: 3.3897, R2: 0.4446\n",
      "水头模型 Epoch 35, Batch 0: Total Loss: 237.3974, Criterion Loss: 84.8624, Physics Loss: 204.8121, KL Loss: 152.5350\n",
      "水头模型 Epoch 035/500 | 训练损失: 229.4120 | 验证损失: 13.9454 | LR: 0.000694\n",
      "水头验证指标 - MSE: 13.9454, RMSE: 3.7226, MAE: 2.9624, R2: 0.5670\n",
      "保存基于损失的最佳水头模型，验证损失: 13.9454\n",
      "保存基于R2的最佳水头模型，R2: 0.5670\n",
      "水头模型 Epoch 36, Batch 0: Total Loss: 224.9195, Criterion Loss: 73.1981, Physics Loss: 178.9521, KL Loss: 151.7214\n",
      "水头模型 Epoch 036/500 | 训练损失: 209.4259 | 验证损失: 13.4983 | LR: 0.000658\n",
      "水头验证指标 - MSE: 13.4983, RMSE: 3.6613, MAE: 2.9137, R2: 0.5809\n",
      "保存基于损失的最佳水头模型，验证损失: 13.4983\n",
      "保存基于R2的最佳水头模型，R2: 0.5809\n",
      "水头模型 Epoch 37, Batch 0: Total Loss: 245.7411, Criterion Loss: 95.1178, Physics Loss: 175.6583, KL Loss: 150.6232\n",
      "水头模型 Epoch 037/500 | 训练损失: 218.7712 | 验证损失: 51.2089 | LR: 0.000621\n",
      "水头验证指标 - MSE: 51.2089, RMSE: 7.0386, MAE: 6.2403, R2: -0.6769\n",
      "水头模型 Epoch 38, Batch 0: Total Loss: 246.8036, Criterion Loss: 96.9499, Physics Loss: 200.5424, KL Loss: 149.8537\n",
      "水头模型 Epoch 038/500 | 训练损失: 227.6512 | 验证损失: 13.8291 | LR: 0.000582\n",
      "水头验证指标 - MSE: 13.8291, RMSE: 3.6860, MAE: 2.9168, R2: 0.5764\n",
      "水头模型 Epoch 39, Batch 0: Total Loss: 207.5779, Criterion Loss: 58.6550, Physics Loss: 160.8400, KL Loss: 148.9229\n",
      "水头模型 Epoch 039/500 | 训练损失: 215.0431 | 验证损失: 26.1188 | LR: 0.000544\n",
      "水头验证指标 - MSE: 26.1188, RMSE: 4.9847, MAE: 4.1183, R2: 0.2109\n",
      "水头模型 Epoch 40, Batch 0: Total Loss: 231.1950, Criterion Loss: 82.7955, Physics Loss: 163.0585, KL Loss: 148.3996\n",
      "水头模型 Epoch 040/500 | 训练损失: 229.3212 | 验证损失: 14.9934 | LR: 0.000505\n",
      "水头验证指标 - MSE: 14.9934, RMSE: 3.8602, MAE: 3.0874, R2: 0.5317\n",
      "水头模型 Epoch 41, Batch 0: Total Loss: 201.5051, Criterion Loss: 53.5674, Physics Loss: 144.6926, KL Loss: 147.9377\n",
      "水头模型 Epoch 041/500 | 训练损失: 207.6562 | 验证损失: 13.3285 | LR: 0.000466\n",
      "水头验证指标 - MSE: 13.3285, RMSE: 3.6459, MAE: 2.9346, R2: 0.5812\n",
      "保存基于损失的最佳水头模型，验证损失: 13.3285\n",
      "保存基于R2的最佳水头模型，R2: 0.5812\n",
      "水头模型 Epoch 42, Batch 0: Total Loss: 203.4947, Criterion Loss: 56.4323, Physics Loss: 149.2358, KL Loss: 147.0624\n",
      "水头模型 Epoch 042/500 | 训练损失: 234.1973 | 验证损失: 13.8842 | LR: 0.000428\n",
      "水头验证指标 - MSE: 13.8842, RMSE: 3.7226, MAE: 2.9966, R2: 0.5632\n",
      "水头模型 Epoch 43, Batch 0: Total Loss: 190.4542, Criterion Loss: 44.1650, Physics Loss: 129.2505, KL Loss: 146.2892\n",
      "水头模型 Epoch 043/500 | 训练损失: 219.1175 | 验证损失: 41.4472 | LR: 0.000389\n",
      "水头验证指标 - MSE: 41.4472, RMSE: 6.3538, MAE: 5.5412, R2: -0.3496\n",
      "水头模型 Epoch 44, Batch 0: Total Loss: 203.1473, Criterion Loss: 56.8507, Physics Loss: 152.8724, KL Loss: 146.2966\n",
      "水头模型 Epoch 044/500 | 训练损失: 210.0157 | 验证损失: 23.6466 | LR: 0.000352\n",
      "水头验证指标 - MSE: 23.6466, RMSE: 4.7973, MAE: 3.9356, R2: 0.2722\n",
      "水头模型 Epoch 45, Batch 0: Total Loss: 210.9769, Criterion Loss: 65.7274, Physics Loss: 145.7023, KL Loss: 145.2495\n",
      "水头模型 Epoch 045/500 | 训练损失: 206.9828 | 验证损失: 13.9760 | LR: 0.000316\n",
      "水头验证指标 - MSE: 13.9760, RMSE: 3.7086, MAE: 2.9515, R2: 0.5658\n",
      "水头模型 Epoch 46, Batch 0: Total Loss: 228.7982, Criterion Loss: 83.8614, Physics Loss: 183.0382, KL Loss: 144.9368\n",
      "水头模型 Epoch 046/500 | 训练损失: 214.8240 | 验证损失: 20.2880 | LR: 0.000280\n",
      "水头验证指标 - MSE: 20.2880, RMSE: 4.4439, MAE: 3.6170, R2: 0.3814\n",
      "水头模型 Epoch 47, Batch 0: Total Loss: 193.7702, Criterion Loss: 49.5622, Physics Loss: 128.8258, KL Loss: 144.2080\n",
      "水头模型 Epoch 047/500 | 训练损失: 201.6462 | 验证损失: 17.3215 | LR: 0.000246\n",
      "水头验证指标 - MSE: 17.3215, RMSE: 4.1420, MAE: 3.3881, R2: 0.4528\n",
      "水头模型 Epoch 48, Batch 0: Total Loss: 213.3071, Criterion Loss: 69.1104, Physics Loss: 146.1732, KL Loss: 144.1967\n",
      "水头模型 Epoch 048/500 | 训练损失: 211.3378 | 验证损失: 14.1333 | LR: 0.000214\n",
      "水头验证指标 - MSE: 14.1333, RMSE: 3.7087, MAE: 2.9787, R2: 0.5689\n",
      "水头模型 Epoch 49, Batch 0: Total Loss: 207.8092, Criterion Loss: 64.2233, Physics Loss: 144.2158, KL Loss: 143.5858\n",
      "水头模型 Epoch 049/500 | 训练损失: 201.3681 | 验证损失: 17.5581 | LR: 0.000184\n",
      "水头验证指标 - MSE: 17.5581, RMSE: 4.1277, MAE: 3.3318, R2: 0.4622\n",
      "水头模型 Epoch 50, Batch 0: Total Loss: 204.8734, Criterion Loss: 61.2348, Physics Loss: 152.0387, KL Loss: 143.6386\n",
      "水头模型 Epoch 050/500 | 训练损失: 206.3613 | 验证损失: 18.7640 | LR: 0.000155\n",
      "水头验证指标 - MSE: 18.7640, RMSE: 4.2677, MAE: 3.4993, R2: 0.4044\n",
      "水头模型 Epoch 51, Batch 0: Total Loss: 203.2080, Criterion Loss: 60.3922, Physics Loss: 140.7572, KL Loss: 142.8158\n",
      "水头模型 Epoch 051/500 | 训练损失: 207.1553 | 验证损失: 12.6455 | LR: 0.000129\n",
      "水头验证指标 - MSE: 12.6455, RMSE: 3.5338, MAE: 2.8172, R2: 0.6108\n",
      "保存基于损失的最佳水头模型，验证损失: 12.6455\n",
      "保存基于R2的最佳水头模型，R2: 0.6108\n",
      "水头模型 Epoch 52, Batch 0: Total Loss: 195.4030, Criterion Loss: 52.1189, Physics Loss: 138.5337, KL Loss: 143.2841\n",
      "水头模型 Epoch 052/500 | 训练损失: 205.9763 | 验证损失: 21.3980 | LR: 0.000105\n",
      "水头验证指标 - MSE: 21.3980, RMSE: 4.5365, MAE: 3.7079, R2: 0.3461\n",
      "水头模型 Epoch 53, Batch 0: Total Loss: 231.6744, Criterion Loss: 88.2264, Physics Loss: 165.8415, KL Loss: 143.4481\n",
      "水头模型 Epoch 053/500 | 训练损失: 205.0640 | 验证损失: 13.7753 | LR: 0.000083\n",
      "水头验证指标 - MSE: 13.7753, RMSE: 3.6896, MAE: 2.9558, R2: 0.5756\n",
      "水头模型 Epoch 54, Batch 0: Total Loss: 183.6940, Criterion Loss: 40.9964, Physics Loss: 120.1907, KL Loss: 142.6976\n",
      "水头模型 Epoch 054/500 | 训练损失: 204.1619 | 验证损失: 16.6136 | LR: 0.000064\n",
      "水头验证指标 - MSE: 16.6136, RMSE: 3.9967, MAE: 3.2167, R2: 0.4953\n",
      "水头模型 Epoch 55, Batch 0: Total Loss: 213.7068, Criterion Loss: 70.7388, Physics Loss: 148.2454, KL Loss: 142.9681\n",
      "水头模型 Epoch 055/500 | 训练损失: 204.7467 | 验证损失: 13.4535 | LR: 0.000048\n",
      "水头验证指标 - MSE: 13.4535, RMSE: 3.6300, MAE: 2.9171, R2: 0.5864\n",
      "水头模型 Epoch 56, Batch 0: Total Loss: 222.3263, Criterion Loss: 79.1074, Physics Loss: 153.3170, KL Loss: 143.2189\n",
      "水头模型 Epoch 056/500 | 训练损失: 204.8466 | 验证损失: 12.9421 | LR: 0.000034\n",
      "水头验证指标 - MSE: 12.9421, RMSE: 3.5841, MAE: 2.8849, R2: 0.5967\n",
      "水头模型 Epoch 57, Batch 0: Total Loss: 190.0711, Criterion Loss: 47.4569, Physics Loss: 131.5153, KL Loss: 142.6142\n",
      "水头模型 Epoch 057/500 | 训练损失: 202.5568 | 验证损失: 12.8996 | LR: 0.000024\n",
      "水头验证指标 - MSE: 12.8996, RMSE: 3.5772, MAE: 2.8703, R2: 0.5948\n",
      "水头模型 Epoch 58, Batch 0: Total Loss: 186.6626, Criterion Loss: 44.2230, Physics Loss: 122.6119, KL Loss: 142.4396\n",
      "水头模型 Epoch 058/500 | 训练损失: 201.1013 | 验证损失: 14.4724 | LR: 0.000016\n",
      "水头验证指标 - MSE: 14.4724, RMSE: 3.7894, MAE: 3.0664, R2: 0.5398\n",
      "水头模型 Epoch 59, Batch 0: Total Loss: 187.0419, Criterion Loss: 43.8535, Physics Loss: 124.3064, KL Loss: 143.1883\n",
      "水头模型 Epoch 059/500 | 训练损失: 210.0857 | 验证损失: 14.6070 | LR: 0.000012\n",
      "水头验证指标 - MSE: 14.6070, RMSE: 3.7681, MAE: 3.0373, R2: 0.5553\n",
      "水头模型 Epoch 60, Batch 0: Total Loss: 200.0897, Criterion Loss: 58.0561, Physics Loss: 148.2760, KL Loss: 142.0336\n",
      "水头模型 Epoch 060/500 | 训练损失: 201.8238 | 验证损失: 12.0943 | LR: 0.001000\n",
      "水头验证指标 - MSE: 12.0943, RMSE: 3.4634, MAE: 2.7617, R2: 0.6228\n",
      "保存基于损失的最佳水头模型，验证损失: 12.0943\n",
      "保存基于R2的最佳水头模型，R2: 0.6228\n",
      "水头模型 Epoch 61, Batch 0: Total Loss: 188.5272, Criterion Loss: 45.8651, Physics Loss: 125.1584, KL Loss: 142.6621\n",
      "水头模型 Epoch 061/500 | 训练损失: 213.7369 | 验证损失: 48.3735 | LR: 0.001000\n",
      "水头验证指标 - MSE: 48.3735, RMSE: 6.7492, MAE: 5.9685, R2: -0.5738\n",
      "水头模型 Epoch 62, Batch 0: Total Loss: 215.1494, Criterion Loss: 73.4845, Physics Loss: 166.1677, KL Loss: 141.6649\n",
      "水头模型 Epoch 062/500 | 训练损失: 237.3868 | 验证损失: 20.8675 | LR: 0.000998\n",
      "水头验证指标 - MSE: 20.8675, RMSE: 4.5219, MAE: 3.6949, R2: 0.3335\n",
      "水头模型 Epoch 63, Batch 0: Total Loss: 192.6300, Criterion Loss: 51.4743, Physics Loss: 140.5424, KL Loss: 141.1558\n",
      "水头模型 Epoch 063/500 | 训练损失: 212.9605 | 验证损失: 18.0239 | LR: 0.000997\n",
      "水头验证指标 - MSE: 18.0239, RMSE: 4.2341, MAE: 3.3512, R2: 0.4389\n",
      "水头模型 Epoch 64, Batch 0: Total Loss: 194.2508, Criterion Loss: 53.2105, Physics Loss: 136.8669, KL Loss: 141.0403\n",
      "水头模型 Epoch 064/500 | 训练损失: 207.1840 | 验证损失: 18.6690 | LR: 0.000994\n",
      "水头验证指标 - MSE: 18.6690, RMSE: 4.3007, MAE: 3.4415, R2: 0.4194\n",
      "水头模型 Epoch 65, Batch 0: Total Loss: 246.5855, Criterion Loss: 106.2831, Physics Loss: 211.4689, KL Loss: 140.3023\n",
      "水头模型 Epoch 065/500 | 训练损失: 228.5236 | 验证损失: 32.2395 | LR: 0.000990\n",
      "水头验证指标 - MSE: 32.2395, RMSE: 5.6437, MAE: 4.7933, R2: -0.0298\n",
      "水头模型 Epoch 66, Batch 0: Total Loss: 183.6430, Criterion Loss: 44.0117, Physics Loss: 130.2286, KL Loss: 139.6313\n",
      "水头模型 Epoch 066/500 | 训练损失: 197.7608 | 验证损失: 33.4412 | LR: 0.000986\n",
      "水头验证指标 - MSE: 33.4412, RMSE: 5.7003, MAE: 4.8459, R2: -0.0889\n",
      "水头模型 Epoch 67, Batch 0: Total Loss: 211.3228, Criterion Loss: 72.4948, Physics Loss: 169.4939, KL Loss: 138.8280\n",
      "水头模型 Epoch 067/500 | 训练损失: 205.9638 | 验证损失: 18.5942 | LR: 0.000981\n",
      "水头验证指标 - MSE: 18.5942, RMSE: 4.2031, MAE: 3.4212, R2: 0.4451\n",
      "水头模型 Epoch 68, Batch 0: Total Loss: 202.1894, Criterion Loss: 64.0743, Physics Loss: 152.8306, KL Loss: 138.1151\n",
      "水头模型 Epoch 068/500 | 训练损失: 196.5061 | 验证损失: 17.6801 | LR: 0.000976\n",
      "水头验证指标 - MSE: 17.6801, RMSE: 4.1807, MAE: 3.4310, R2: 0.4381\n",
      "水头模型 Epoch 69, Batch 0: Total Loss: 189.3325, Criterion Loss: 52.0377, Physics Loss: 133.2443, KL Loss: 137.2948\n",
      "水头模型 Epoch 069/500 | 训练损失: 187.8661 | 验证损失: 30.5621 | LR: 0.000969\n",
      "水头验证指标 - MSE: 30.5621, RMSE: 5.4683, MAE: 4.6083, R2: 0.0667\n",
      "水头模型 Epoch 70, Batch 0: Total Loss: 226.1194, Criterion Loss: 90.0027, Physics Loss: 159.8472, KL Loss: 136.1167\n",
      "水头模型 Epoch 070/500 | 训练损失: 191.1210 | 验证损失: 22.1500 | LR: 0.000962\n",
      "水头验证指标 - MSE: 22.1500, RMSE: 4.6532, MAE: 3.8083, R2: 0.3207\n",
      "水头模型 Epoch 71, Batch 0: Total Loss: 175.7966, Criterion Loss: 39.7404, Physics Loss: 115.3225, KL Loss: 136.0562\n",
      "水头模型 Epoch 071/500 | 训练损失: 198.1383 | 验证损失: 19.2814 | LR: 0.000955\n",
      "水头验证指标 - MSE: 19.2814, RMSE: 4.2721, MAE: 3.4774, R2: 0.4172\n",
      "水头模型 Epoch 72, Batch 0: Total Loss: 198.6089, Criterion Loss: 63.7694, Physics Loss: 136.1091, KL Loss: 134.8396\n",
      "水头模型 Epoch 072/500 | 训练损失: 187.9369 | 验证损失: 24.1943 | LR: 0.000946\n",
      "水头验证指标 - MSE: 24.1943, RMSE: 4.8654, MAE: 4.0251, R2: 0.2527\n",
      "水头模型 Epoch 73, Batch 0: Total Loss: 185.7185, Criterion Loss: 51.7275, Physics Loss: 123.1288, KL Loss: 133.9910\n",
      "水头模型 Epoch 073/500 | 训练损失: 188.0735 | 验证损失: 15.6362 | LR: 0.000937\n",
      "水头验证指标 - MSE: 15.6362, RMSE: 3.8620, MAE: 3.0960, R2: 0.5305\n",
      "水头模型 Epoch 74, Batch 0: Total Loss: 182.6360, Criterion Loss: 49.5618, Physics Loss: 119.4121, KL Loss: 133.0742\n",
      "水头模型 Epoch 074/500 | 训练损失: 182.5309 | 验证损失: 18.4899 | LR: 0.000927\n",
      "水头验证指标 - MSE: 18.4899, RMSE: 4.2601, MAE: 3.4969, R2: 0.4158\n",
      "水头模型 Epoch 75, Batch 0: Total Loss: 189.8487, Criterion Loss: 57.5547, Physics Loss: 126.0539, KL Loss: 132.2941\n",
      "水头模型 Epoch 075/500 | 训练损失: 185.0889 | 验证损失: 15.0459 | LR: 0.000917\n",
      "水头验证指标 - MSE: 15.0459, RMSE: 3.8386, MAE: 3.1068, R2: 0.5206\n",
      "水头模型 Epoch 76, Batch 0: Total Loss: 192.9886, Criterion Loss: 61.2719, Physics Loss: 141.4021, KL Loss: 131.7168\n",
      "水头模型 Epoch 076/500 | 训练损失: 191.3719 | 验证损失: 17.6656 | LR: 0.000905\n",
      "水头验证指标 - MSE: 17.6656, RMSE: 4.1727, MAE: 3.4060, R2: 0.4414\n",
      "水头模型 Epoch 77, Batch 0: Total Loss: 194.2395, Criterion Loss: 63.1220, Physics Loss: 145.1394, KL Loss: 131.1176\n",
      "水头模型 Epoch 077/500 | 训练损失: 184.0439 | 验证损失: 12.7591 | LR: 0.000894\n",
      "水头验证指标 - MSE: 12.7591, RMSE: 3.5471, MAE: 2.8364, R2: 0.6085\n",
      "水头模型 Epoch 78, Batch 0: Total Loss: 170.9075, Criterion Loss: 40.1659, Physics Loss: 109.2743, KL Loss: 130.7416\n",
      "水头模型 Epoch 078/500 | 训练损失: 194.0956 | 验证损失: 16.9481 | LR: 0.000881\n",
      "水头验证指标 - MSE: 16.9481, RMSE: 4.0946, MAE: 3.3631, R2: 0.4533\n",
      "水头模型 Epoch 79, Batch 0: Total Loss: 184.7097, Criterion Loss: 54.8267, Physics Loss: 127.9958, KL Loss: 129.8830\n",
      "水头模型 Epoch 079/500 | 训练损失: 200.7882 | 验证损失: 13.0654 | LR: 0.000868\n",
      "水头验证指标 - MSE: 13.0654, RMSE: 3.6098, MAE: 2.9063, R2: 0.5876\n",
      "水头模型 Epoch 80, Batch 0: Total Loss: 183.4736, Criterion Loss: 54.0282, Physics Loss: 127.8102, KL Loss: 129.4455\n",
      "水头模型 Epoch 080/500 | 训练损失: 181.9944 | 验证损失: 12.3610 | LR: 0.000855\n",
      "水头验证指标 - MSE: 12.3610, RMSE: 3.4865, MAE: 2.7656, R2: 0.6215\n",
      "水头模型 Epoch 81, Batch 0: Total Loss: 174.5649, Criterion Loss: 45.5543, Physics Loss: 112.0624, KL Loss: 129.0106\n",
      "水头模型 Epoch 081/500 | 训练损失: 177.8944 | 验证损失: 19.7815 | LR: 0.000841\n",
      "水头验证指标 - MSE: 19.7815, RMSE: 4.3991, MAE: 3.6637, R2: 0.3680\n",
      "水头模型 Epoch 82, Batch 0: Total Loss: 170.8322, Criterion Loss: 42.7336, Physics Loss: 118.3386, KL Loss: 128.0986\n",
      "水头模型 Epoch 082/500 | 训练损失: 177.0504 | 验证损失: 21.2519 | LR: 0.000826\n",
      "水头验证指标 - MSE: 21.2519, RMSE: 4.4698, MAE: 3.6650, R2: 0.3635\n",
      "水头模型 Epoch 83, Batch 0: Total Loss: 162.8299, Criterion Loss: 35.3673, Physics Loss: 100.4962, KL Loss: 127.4626\n",
      "水头模型 Epoch 083/500 | 训练损失: 177.9093 | 验证损失: 16.4266 | LR: 0.000811\n",
      "水头验证指标 - MSE: 16.4266, RMSE: 4.0449, MAE: 3.2138, R2: 0.4851\n",
      "水头模型 Epoch 84, Batch 0: Total Loss: 170.6592, Criterion Loss: 44.0517, Physics Loss: 118.7163, KL Loss: 126.6075\n",
      "水头模型 Epoch 084/500 | 训练损失: 180.4037 | 验证损失: 14.3837 | LR: 0.000796\n",
      "水头验证指标 - MSE: 14.3837, RMSE: 3.7818, MAE: 3.0666, R2: 0.5405\n",
      "水头模型 Epoch 85, Batch 0: Total Loss: 181.6280, Criterion Loss: 55.2670, Physics Loss: 127.5078, KL Loss: 126.3610\n",
      "水头模型 Epoch 085/500 | 训练损失: 188.7097 | 验证损失: 12.4030 | LR: 0.000780\n",
      "水头验证指标 - MSE: 12.4030, RMSE: 3.5050, MAE: 2.7719, R2: 0.6170\n",
      "水头模型 Epoch 86, Batch 0: Total Loss: 170.4084, Criterion Loss: 44.3458, Physics Loss: 109.2908, KL Loss: 126.0626\n",
      "水头模型 Epoch 086/500 | 训练损失: 176.9977 | 验证损失: 16.8022 | LR: 0.000764\n",
      "水头验证指标 - MSE: 16.8022, RMSE: 4.0844, MAE: 3.2345, R2: 0.4742\n",
      "水头模型 Epoch 87, Batch 0: Total Loss: 178.0323, Criterion Loss: 52.8274, Physics Loss: 121.4254, KL Loss: 125.2050\n",
      "水头模型 Epoch 087/500 | 训练损失: 174.2498 | 验证损失: 15.9629 | LR: 0.000747\n",
      "水头验证指标 - MSE: 15.9629, RMSE: 3.9251, MAE: 3.1465, R2: 0.5191\n",
      "水头模型 Epoch 88, Batch 0: Total Loss: 159.9628, Criterion Loss: 35.5714, Physics Loss: 99.0840, KL Loss: 124.3914\n",
      "水头模型 Epoch 088/500 | 训练损失: 170.6592 | 验证损失: 13.4786 | LR: 0.000730\n",
      "水头验证指标 - MSE: 13.4786, RMSE: 3.6272, MAE: 2.8919, R2: 0.5872\n",
      "水头模型 Epoch 89, Batch 0: Total Loss: 191.3073, Criterion Loss: 67.4781, Physics Loss: 144.1854, KL Loss: 123.8292\n",
      "水头模型 Epoch 089/500 | 训练损失: 171.2242 | 验证损失: 18.2214 | LR: 0.000712\n",
      "水头验证指标 - MSE: 18.2214, RMSE: 4.2369, MAE: 3.5027, R2: 0.4117\n",
      "水头模型 Epoch 90, Batch 0: Total Loss: 163.2946, Criterion Loss: 39.9053, Physics Loss: 102.9758, KL Loss: 123.3893\n",
      "水头模型 Epoch 090/500 | 训练损失: 183.0337 | 验证损失: 31.9128 | LR: 0.000694\n",
      "水头验证指标 - MSE: 31.9128, RMSE: 5.5896, MAE: 4.5089, R2: 0.0275\n",
      "水头模型早停触发! 在第90个epoch停止训练\n",
      "\n",
      "水头模型训练完成!\n",
      "基于损失的最佳验证损失: 12.0943\n",
      "基于R2的最佳R2分数: 0.6228\n",
      "\n",
      "================================================================================\n",
      "第二阶段：开始训练浓度模型\n",
      "================================================================================\n",
      "成功加载基于r2的最佳水头模型\n",
      "浓度模型参数数量: 1057246\n",
      "浓度模型 Epoch 1, Batch 0: Total Loss: 42.3523, Criterion Loss: 16.0492, MSE: 9.2332, KL Loss: 26.3031, L1 Reg: 681599.7500\n",
      "浓度模型 Epoch 001/500 | 训练损失: 41.0899 | 验证损失: 15.3995 | LR: 0.000791\n",
      "浓度验证指标 - MSE: 8.6356, RMSE: 2.9370, MAE: 0.6753, R2: 0.0404\n",
      "保存基于损失的最佳浓度模型，验证损失: 15.3995\n",
      "保存基于R2的最佳浓度模型，R2: 0.0404\n",
      "浓度模型 Epoch 2, Batch 0: Total Loss: 37.0717, Criterion Loss: 14.8710, MSE: 8.1070, KL Loss: 22.2007, L1 Reg: 676392.3125\n",
      "浓度模型 Epoch 002/500 | 训练损失: 36.2956 | 验证损失: 12.7812 | LR: 0.000765\n",
      "浓度验证指标 - MSE: 6.0555, RMSE: 2.4586, MAE: 0.6089, R2: 0.3279\n",
      "保存基于损失的最佳浓度模型，验证损失: 12.7812\n",
      "保存基于R2的最佳浓度模型，R2: 0.3279\n",
      "浓度模型 Epoch 3, Batch 0: Total Loss: 32.5754, Criterion Loss: 13.0629, MSE: 6.3372, KL Loss: 19.5125, L1 Reg: 672570.5000\n",
      "浓度模型 Epoch 003/500 | 训练损失: 31.1620 | 验证损失: 10.2690 | LR: 0.000724\n",
      "浓度验证指标 - MSE: 3.5688, RMSE: 1.8873, MAE: 0.3620, R2: 0.6038\n",
      "保存基于损失的最佳浓度模型，验证损失: 10.2690\n",
      "保存基于R2的最佳浓度模型，R2: 0.6038\n",
      "浓度模型 Epoch 4, Batch 0: Total Loss: 39.6121, Criterion Loss: 21.5679, MSE: 14.8677, KL Loss: 18.0442, L1 Reg: 670021.4375\n",
      "浓度模型 Epoch 004/500 | 训练损失: 28.1618 | 验证损失: 9.6294 | LR: 0.000668\n",
      "浓度验证指标 - MSE: 2.9631, RMSE: 1.7186, MAE: 0.2739, R2: 0.6716\n",
      "保存基于损失的最佳浓度模型，验证损失: 9.6294\n",
      "保存基于R2的最佳浓度模型，R2: 0.6716\n",
      "浓度模型 Epoch 5, Batch 0: Total Loss: 25.1298, Criterion Loss: 9.1220, MSE: 2.4558, KL Loss: 16.0077, L1 Reg: 666625.2500\n",
      "浓度模型 Epoch 005/500 | 训练损失: 25.7697 | 验证损失: 9.1997 | LR: 0.000600\n",
      "浓度验证指标 - MSE: 2.5648, RMSE: 1.5987, MAE: 0.2771, R2: 0.7158\n",
      "保存基于损失的最佳浓度模型，验证损失: 9.1997\n",
      "保存基于R2的最佳浓度模型，R2: 0.7158\n",
      "浓度模型 Epoch 6, Batch 0: Total Loss: 35.1514, Criterion Loss: 20.9200, MSE: 14.2852, KL Loss: 14.2313, L1 Reg: 663484.5000\n",
      "浓度模型 Epoch 006/500 | 训练损失: 24.1206 | 验证损失: 8.9685 | LR: 0.000524\n",
      "浓度验证指标 - MSE: 2.3562, RMSE: 1.5323, MAE: 0.2654, R2: 0.7389\n",
      "保存基于损失的最佳浓度模型，验证损失: 8.9685\n",
      "保存基于R2的最佳浓度模型，R2: 0.7389\n",
      "浓度模型 Epoch 7, Batch 0: Total Loss: 33.3941, Criterion Loss: 20.2524, MSE: 13.6400, KL Loss: 13.1417, L1 Reg: 661232.1875\n",
      "浓度模型 Epoch 007/500 | 训练损失: 22.8679 | 验证损失: 8.7661 | LR: 0.000442\n",
      "浓度验证指标 - MSE: 2.1728, RMSE: 1.4710, MAE: 0.2332, R2: 0.7593\n",
      "保存基于损失的最佳浓度模型，验证损失: 8.7661\n",
      "保存基于R2的最佳浓度模型，R2: 0.7593\n",
      "浓度模型 Epoch 8, Batch 0: Total Loss: 21.0590, Criterion Loss: 8.7510, MSE: 2.1577, KL Loss: 12.3080, L1 Reg: 659325.6250\n",
      "浓度模型 Epoch 008/500 | 训练损失: 21.8281 | 验证损失: 8.5439 | LR: 0.000359\n",
      "浓度验证指标 - MSE: 1.9672, RMSE: 1.3996, MAE: 0.2129, R2: 0.7821\n",
      "保存基于损失的最佳浓度模型，验证损失: 8.5439\n",
      "保存基于R2的最佳浓度模型，R2: 0.7821\n",
      "浓度模型 Epoch 9, Batch 0: Total Loss: 20.4276, Criterion Loss: 8.8890, MSE: 2.3122, KL Loss: 11.5386, L1 Reg: 657674.8750\n",
      "浓度模型 Epoch 009/500 | 训练损失: 21.1519 | 验证损失: 8.3993 | LR: 0.000277\n",
      "浓度验证指标 - MSE: 1.8326, RMSE: 1.3507, MAE: 0.2113, R2: 0.7970\n",
      "保存基于损失的最佳浓度模型，验证损失: 8.3993\n",
      "保存基于R2的最佳浓度模型，R2: 0.7970\n",
      "浓度模型 Epoch 10, Batch 0: Total Loss: 20.5181, Criterion Loss: 9.3768, MSE: 2.8101, KL Loss: 11.1413, L1 Reg: 656669.1875\n",
      "浓度模型 Epoch 010/500 | 训练损失: 20.5603 | 验证损失: 8.2864 | LR: 0.000201\n",
      "浓度验证指标 - MSE: 1.7278, RMSE: 1.3106, MAE: 0.2031, R2: 0.8089\n",
      "保存基于损失的最佳浓度模型，验证损失: 8.2864\n",
      "保存基于R2的最佳浓度模型，R2: 0.8089\n",
      "浓度模型 Epoch 11, Batch 0: Total Loss: 19.5342, Criterion Loss: 8.7787, MSE: 2.2202, KL Loss: 10.7555, L1 Reg: 655851.0000\n",
      "浓度模型 Epoch 011/500 | 训练损失: 20.2367 | 验证损失: 8.2146 | LR: 0.000133\n",
      "浓度验证指标 - MSE: 1.6618, RMSE: 1.2853, MAE: 0.1896, R2: 0.8162\n",
      "保存基于损失的最佳浓度模型，验证损失: 8.2146\n",
      "保存基于R2的最佳浓度模型，R2: 0.8162\n",
      "浓度模型 Epoch 12, Batch 0: Total Loss: 19.2267, Criterion Loss: 8.7410, MSE: 2.1882, KL Loss: 10.4858, L1 Reg: 655276.6250\n",
      "浓度模型 Epoch 012/500 | 训练损失: 19.9102 | 验证损失: 8.1684 | LR: 0.000077\n",
      "浓度验证指标 - MSE: 1.6198, RMSE: 1.2688, MAE: 0.1898, R2: 0.8208\n",
      "保存基于损失的最佳浓度模型，验证损失: 8.1684\n",
      "保存基于R2的最佳浓度模型，R2: 0.8208\n",
      "浓度模型 Epoch 13, Batch 0: Total Loss: 19.5821, Criterion Loss: 9.2053, MSE: 2.6568, KL Loss: 10.3768, L1 Reg: 654853.5000\n",
      "浓度模型 Epoch 013/500 | 训练损失: 19.8279 | 验证损失: 8.1341 | LR: 0.000036\n",
      "浓度验证指标 - MSE: 1.5880, RMSE: 1.2561, MAE: 0.1794, R2: 0.8243\n",
      "保存基于损失的最佳浓度模型，验证损失: 8.1341\n",
      "保存基于R2的最佳浓度模型，R2: 0.8243\n",
      "浓度模型 Epoch 14, Batch 0: Total Loss: 18.7569, Criterion Loss: 8.4478, MSE: 1.9016, KL Loss: 10.3091, L1 Reg: 654612.0625\n",
      "浓度模型 Epoch 014/500 | 训练损失: 19.6835 | 验证损失: 8.1188 | LR: 0.000010\n",
      "浓度验证指标 - MSE: 1.5737, RMSE: 1.2501, MAE: 0.1810, R2: 0.8260\n",
      "保存基于损失的最佳浓度模型，验证损失: 8.1188\n",
      "保存基于R2的最佳浓度模型，R2: 0.8260\n",
      "浓度模型 Epoch 15, Batch 0: Total Loss: 18.9180, Criterion Loss: 8.6465, MSE: 2.1015, KL Loss: 10.2714, L1 Reg: 654502.6250\n",
      "浓度模型 Epoch 015/500 | 训练损失: 19.5759 | 验证损失: 8.0836 | LR: 0.000800\n",
      "浓度验证指标 - MSE: 1.5390, RMSE: 1.2365, MAE: 0.1824, R2: 0.8298\n",
      "保存基于损失的最佳浓度模型，验证损失: 8.0836\n",
      "保存基于R2的最佳浓度模型，R2: 0.8298\n",
      "浓度模型 Epoch 16, Batch 0: Total Loss: 19.4800, Criterion Loss: 9.2374, MSE: 2.6928, KL Loss: 10.2426, L1 Reg: 654466.5000\n",
      "浓度模型 Epoch 016/500 | 训练损失: 18.9925 | 验证损失: 7.9807 | LR: 0.000798\n",
      "浓度验证指标 - MSE: 1.4645, RMSE: 1.2056, MAE: 0.1971, R2: 0.8378\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.9807\n",
      "保存基于R2的最佳浓度模型，R2: 0.8378\n",
      "浓度模型 Epoch 17, Batch 0: Total Loss: 17.2472, Criterion Loss: 8.0992, MSE: 1.5830, KL Loss: 9.1480, L1 Reg: 651619.1875\n",
      "浓度模型 Epoch 017/500 | 训练损失: 18.3651 | 验证损失: 7.9049 | LR: 0.000791\n",
      "浓度验证指标 - MSE: 1.4085, RMSE: 1.1829, MAE: 0.1952, R2: 0.8442\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.9049\n",
      "保存基于R2的最佳浓度模型，R2: 0.8442\n",
      "浓度模型 Epoch 18, Batch 0: Total Loss: 17.2365, Criterion Loss: 8.7510, MSE: 2.2546, KL Loss: 8.4855, L1 Reg: 649640.3125\n",
      "浓度模型 Epoch 018/500 | 训练损失: 17.3681 | 验证损失: 7.9204 | LR: 0.000780\n",
      "浓度验证指标 - MSE: 1.4461, RMSE: 1.1994, MAE: 0.2047, R2: 0.8400\n",
      "浓度模型 Epoch 19, Batch 0: Total Loss: 16.7257, Criterion Loss: 8.9753, MSE: 2.5010, KL Loss: 7.7505, L1 Reg: 647426.0000\n",
      "浓度模型 Epoch 019/500 | 训练损失: 16.7431 | 验证损失: 7.9635 | LR: 0.000765\n",
      "浓度验证指标 - MSE: 1.5138, RMSE: 1.2275, MAE: 0.2383, R2: 0.8318\n",
      "浓度模型 Epoch 20, Batch 0: Total Loss: 16.2226, Criterion Loss: 9.1708, MSE: 2.7212, KL Loss: 7.0518, L1 Reg: 644961.6875\n",
      "浓度模型 Epoch 020/500 | 训练损失: 15.9310 | 验证损失: 7.8253 | LR: 0.000746\n",
      "浓度验证指标 - MSE: 1.4016, RMSE: 1.1797, MAE: 0.2058, R2: 0.8450\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.8253\n",
      "保存基于R2的最佳浓度模型，R2: 0.8450\n",
      "浓度模型 Epoch 21, Batch 0: Total Loss: 15.3786, Criterion Loss: 8.9705, MSE: 2.5468, KL Loss: 6.4081, L1 Reg: 642367.7500\n",
      "浓度模型 Epoch 021/500 | 训练损失: 15.1224 | 验证损失: 7.7117 | LR: 0.000724\n",
      "浓度验证指标 - MSE: 1.3170, RMSE: 1.1433, MAE: 0.2194, R2: 0.8544\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.7117\n",
      "保存基于R2的最佳浓度模型，R2: 0.8544\n",
      "浓度模型 Epoch 22, Batch 0: Total Loss: 14.1414, Criterion Loss: 8.4196, MSE: 2.0249, KL Loss: 5.7219, L1 Reg: 639464.6875\n",
      "浓度模型 Epoch 022/500 | 训练损失: 14.4167 | 验证损失: 7.7387 | LR: 0.000697\n",
      "浓度验证指标 - MSE: 1.3700, RMSE: 1.1659, MAE: 0.2146, R2: 0.8487\n",
      "浓度模型 Epoch 23, Batch 0: Total Loss: 14.1180, Criterion Loss: 8.9179, MSE: 2.5492, KL Loss: 5.2001, L1 Reg: 636873.4375\n",
      "浓度模型 Epoch 023/500 | 训练损失: 14.0432 | 验证损失: 7.7232 | LR: 0.000668\n",
      "浓度验证指标 - MSE: 1.3751, RMSE: 1.1675, MAE: 0.2146, R2: 0.8481\n",
      "浓度模型 Epoch 24, Batch 0: Total Loss: 18.9104, Criterion Loss: 13.9857, MSE: 7.6376, KL Loss: 4.9247, L1 Reg: 634808.4375\n",
      "浓度模型 Epoch 024/500 | 训练损失: 13.8319 | 验证损失: 7.6402 | LR: 0.000635\n",
      "浓度验证指标 - MSE: 1.3111, RMSE: 1.1402, MAE: 0.2152, R2: 0.8551\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.6402\n",
      "保存基于R2的最佳浓度模型，R2: 0.8551\n",
      "浓度模型 Epoch 25, Batch 0: Total Loss: 12.3136, Criterion Loss: 7.7534, MSE: 1.4243, KL Loss: 4.5602, L1 Reg: 632910.0000\n",
      "浓度模型 Epoch 025/500 | 训练损失: 13.5599 | 验证损失: 7.5976 | LR: 0.000600\n",
      "浓度验证指标 - MSE: 1.2906, RMSE: 1.1316, MAE: 0.2280, R2: 0.8573\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.5976\n",
      "保存基于R2的最佳浓度模型，R2: 0.8573\n",
      "浓度模型 Epoch 26, Batch 0: Total Loss: 12.1794, Criterion Loss: 7.9042, MSE: 1.5972, KL Loss: 4.2752, L1 Reg: 630699.4375\n",
      "浓度模型 Epoch 026/500 | 训练损失: 12.9915 | 验证损失: 7.5700 | LR: 0.000563\n",
      "浓度验证指标 - MSE: 1.2813, RMSE: 1.1276, MAE: 0.2069, R2: 0.8584\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.5700\n",
      "保存基于R2的最佳浓度模型，R2: 0.8584\n",
      "浓度模型 Epoch 27, Batch 0: Total Loss: 11.4822, Criterion Loss: 7.4663, MSE: 1.1776, KL Loss: 4.0158, L1 Reg: 628873.1875\n",
      "浓度模型 Epoch 027/500 | 训练损失: 12.7420 | 验证损失: 7.5583 | LR: 0.000524\n",
      "浓度验证指标 - MSE: 1.2873, RMSE: 1.1306, MAE: 0.2248, R2: 0.8576\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.5583\n",
      "浓度模型 Epoch 28, Batch 0: Total Loss: 11.6298, Criterion Loss: 7.8432, MSE: 1.5722, KL Loss: 3.7866, L1 Reg: 627100.6875\n",
      "浓度模型 Epoch 028/500 | 训练损失: 12.6642 | 验证损失: 7.5301 | LR: 0.000484\n",
      "浓度验证指标 - MSE: 1.2744, RMSE: 1.1245, MAE: 0.2186, R2: 0.8591\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.5301\n",
      "保存基于R2的最佳浓度模型，R2: 0.8591\n",
      "浓度模型 Epoch 29, Batch 0: Total Loss: 21.4792, Criterion Loss: 17.8178, MSE: 11.5621, KL Loss: 3.6614, L1 Reg: 625568.8750\n",
      "浓度模型 Epoch 029/500 | 训练损失: 12.4625 | 验证损失: 7.5008 | LR: 0.000442\n",
      "浓度验证指标 - MSE: 1.2615, RMSE: 1.1183, MAE: 0.2076, R2: 0.8607\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.5008\n",
      "保存基于R2的最佳浓度模型，R2: 0.8607\n",
      "浓度模型 Epoch 30, Batch 0: Total Loss: 11.3257, Criterion Loss: 7.8465, MSE: 1.6072, KL Loss: 3.4792, L1 Reg: 623922.8125\n",
      "浓度模型 Epoch 030/500 | 训练损失: 12.0706 | 验证损失: 7.5313 | LR: 0.000401\n",
      "浓度验证指标 - MSE: 1.3066, RMSE: 1.1384, MAE: 0.1976, R2: 0.8556\n",
      "浓度模型 Epoch 31, Batch 0: Total Loss: 11.4134, Criterion Loss: 8.0850, MSE: 1.8603, KL Loss: 3.3285, L1 Reg: 622467.8750\n",
      "浓度模型 Epoch 031/500 | 训练损失: 11.9554 | 验证损失: 7.4475 | LR: 0.000359\n",
      "浓度验证指标 - MSE: 1.2353, RMSE: 1.1068, MAE: 0.2006, R2: 0.8635\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.4475\n",
      "保存基于R2的最佳浓度模型，R2: 0.8635\n",
      "浓度模型 Epoch 32, Batch 0: Total Loss: 11.3034, Criterion Loss: 8.0757, MSE: 1.8635, KL Loss: 3.2277, L1 Reg: 621224.0000\n",
      "浓度模型 Epoch 032/500 | 训练损失: 11.8452 | 验证损失: 7.4967 | LR: 0.000317\n",
      "浓度验证指标 - MSE: 1.2961, RMSE: 1.1338, MAE: 0.1979, R2: 0.8568\n",
      "浓度模型 Epoch 33, Batch 0: Total Loss: 10.6919, Criterion Loss: 7.5440, MSE: 1.3434, KL Loss: 3.1479, L1 Reg: 620053.9375\n",
      "浓度模型 Epoch 033/500 | 训练损失: 11.7635 | 验证损失: 7.4435 | LR: 0.000277\n",
      "浓度验证指标 - MSE: 1.2541, RMSE: 1.1151, MAE: 0.2070, R2: 0.8615\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.4435\n",
      "浓度模型 Epoch 34, Batch 0: Total Loss: 10.9272, Criterion Loss: 7.9195, MSE: 1.7300, KL Loss: 3.0077, L1 Reg: 618947.0000\n",
      "浓度模型 Epoch 034/500 | 训练损失: 11.6239 | 验证损失: 7.4710 | LR: 0.000238\n",
      "浓度验证指标 - MSE: 1.2918, RMSE: 1.1319, MAE: 0.1911, R2: 0.8572\n",
      "浓度模型 Epoch 35, Batch 0: Total Loss: 10.8592, Criterion Loss: 7.8827, MSE: 1.7036, KL Loss: 2.9764, L1 Reg: 617916.5000\n",
      "浓度模型 Epoch 035/500 | 训练损失: 11.9090 | 验证损失: 7.4359 | LR: 0.000201\n",
      "浓度验证指标 - MSE: 1.2648, RMSE: 1.1201, MAE: 0.1893, R2: 0.8602\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.4359\n",
      "浓度模型 Epoch 36, Batch 0: Total Loss: 10.3446, Criterion Loss: 7.4481, MSE: 1.2770, KL Loss: 2.8966, L1 Reg: 617109.6250\n",
      "浓度模型 Epoch 036/500 | 训练损失: 11.4778 | 验证损失: 7.4129 | LR: 0.000166\n",
      "浓度验证指标 - MSE: 1.2487, RMSE: 1.1127, MAE: 0.1996, R2: 0.8620\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.4129\n",
      "浓度模型 Epoch 37, Batch 0: Total Loss: 10.4570, Criterion Loss: 7.5710, MSE: 1.4068, KL Loss: 2.8860, L1 Reg: 616419.8125\n",
      "浓度模型 Epoch 037/500 | 训练损失: 11.5227 | 验证损失: 7.4345 | LR: 0.000133\n",
      "浓度验证指标 - MSE: 1.2757, RMSE: 1.1246, MAE: 0.1932, R2: 0.8591\n",
      "浓度模型 Epoch 38, Batch 0: Total Loss: 10.4192, Criterion Loss: 7.5773, MSE: 1.4185, KL Loss: 2.8418, L1 Reg: 615884.7500\n",
      "浓度模型 Epoch 038/500 | 训练损失: 11.4647 | 验证损失: 7.4017 | LR: 0.000104\n",
      "浓度验证指标 - MSE: 1.2471, RMSE: 1.1118, MAE: 0.2009, R2: 0.8623\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.4017\n",
      "浓度模型 Epoch 39, Batch 0: Total Loss: 11.6321, Criterion Loss: 8.8170, MSE: 2.6625, KL Loss: 2.8151, L1 Reg: 615454.8750\n",
      "浓度模型 Epoch 039/500 | 训练损失: 11.3938 | 验证损失: 7.3995 | LR: 0.000077\n",
      "浓度验证指标 - MSE: 1.2488, RMSE: 1.1129, MAE: 0.1913, R2: 0.8620\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.3995\n",
      "浓度模型 Epoch 40, Batch 0: Total Loss: 10.1299, Criterion Loss: 7.3575, MSE: 1.2068, KL Loss: 2.7724, L1 Reg: 615070.7500\n",
      "浓度模型 Epoch 040/500 | 训练损失: 11.3351 | 验证损失: 7.4205 | LR: 0.000055\n",
      "浓度验证指标 - MSE: 1.2725, RMSE: 1.1233, MAE: 0.1928, R2: 0.8594\n",
      "浓度模型 Epoch 41, Batch 0: Total Loss: 10.4308, Criterion Loss: 7.7189, MSE: 1.5709, KL Loss: 2.7119, L1 Reg: 614806.6250\n",
      "浓度模型 Epoch 041/500 | 训练损失: 11.2587 | 验证损失: 7.3835 | LR: 0.000036\n",
      "浓度验证指标 - MSE: 1.2374, RMSE: 1.1078, MAE: 0.1902, R2: 0.8633\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.3835\n",
      "浓度模型 Epoch 42, Batch 0: Total Loss: 11.0475, Criterion Loss: 8.3049, MSE: 2.1588, KL Loss: 2.7426, L1 Reg: 614607.4375\n",
      "浓度模型 Epoch 042/500 | 训练损失: 11.3050 | 验证损失: 7.3908 | LR: 0.000021\n",
      "浓度验证指标 - MSE: 1.2461, RMSE: 1.1110, MAE: 0.1892, R2: 0.8625\n",
      "浓度模型 Epoch 43, Batch 0: Total Loss: 10.6111, Criterion Loss: 7.8638, MSE: 1.7191, KL Loss: 2.7473, L1 Reg: 614476.0000\n",
      "浓度模型 Epoch 043/500 | 训练损失: 11.4115 | 验证损失: 7.3887 | LR: 0.000010\n",
      "浓度验证指标 - MSE: 1.2446, RMSE: 1.1110, MAE: 0.1909, R2: 0.8625\n",
      "浓度模型 Epoch 44, Batch 0: Total Loss: 10.1389, Criterion Loss: 7.4336, MSE: 1.2894, KL Loss: 2.7053, L1 Reg: 614414.7500\n",
      "浓度模型 Epoch 044/500 | 训练损失: 11.3126 | 验证损失: 7.3783 | LR: 0.000003\n",
      "浓度验证指标 - MSE: 1.2345, RMSE: 1.1062, MAE: 0.1959, R2: 0.8636\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.3783\n",
      "保存基于R2的最佳浓度模型，R2: 0.8636\n",
      "浓度模型 Epoch 45, Batch 0: Total Loss: 10.7914, Criterion Loss: 8.0598, MSE: 1.9160, KL Loss: 2.7316, L1 Reg: 614381.8125\n",
      "浓度模型 Epoch 045/500 | 训练损失: 11.3118 | 验证损失: 7.3854 | LR: 0.000800\n",
      "浓度验证指标 - MSE: 1.2417, RMSE: 1.1092, MAE: 0.1941, R2: 0.8629\n",
      "浓度模型 Epoch 46, Batch 0: Total Loss: 10.2980, Criterion Loss: 7.5870, MSE: 1.4433, KL Loss: 2.7110, L1 Reg: 614371.5625\n",
      "浓度模型 Epoch 046/500 | 训练损失: 11.2796 | 验证损失: 7.4050 | LR: 0.000799\n",
      "浓度验证指标 - MSE: 1.2838, RMSE: 1.1281, MAE: 0.1998, R2: 0.8582\n",
      "浓度模型 Epoch 47, Batch 0: Total Loss: 16.3313, Criterion Loss: 13.7915, MSE: 7.6703, KL Loss: 2.5398, L1 Reg: 612117.5625\n",
      "浓度模型 Epoch 047/500 | 训练损失: 11.1788 | 验证损失: 7.4332 | LR: 0.000798\n",
      "浓度验证指标 - MSE: 1.3324, RMSE: 1.1495, MAE: 0.2052, R2: 0.8528\n",
      "浓度模型 Epoch 48, Batch 0: Total Loss: 10.1285, Criterion Loss: 7.6627, MSE: 1.5619, KL Loss: 2.4658, L1 Reg: 610076.9375\n",
      "浓度模型 Epoch 048/500 | 训练损失: 11.0330 | 验证损失: 7.3514 | LR: 0.000795\n",
      "浓度验证指标 - MSE: 1.2698, RMSE: 1.1221, MAE: 0.2013, R2: 0.8597\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.3514\n",
      "浓度模型 Epoch 49, Batch 0: Total Loss: 9.8043, Criterion Loss: 7.4379, MSE: 1.3564, KL Loss: 2.3664, L1 Reg: 608152.7500\n",
      "浓度模型 Epoch 049/500 | 训练损失: 11.5944 | 验证损失: 7.4081 | LR: 0.000791\n",
      "浓度验证指标 - MSE: 1.3465, RMSE: 1.1564, MAE: 0.1925, R2: 0.8511\n",
      "浓度模型 Epoch 50, Batch 0: Total Loss: 9.7519, Criterion Loss: 7.4761, MSE: 1.4144, KL Loss: 2.2759, L1 Reg: 606166.8750\n",
      "浓度模型 Epoch 050/500 | 训练损失: 10.7793 | 验证损失: 7.3748 | LR: 0.000786\n",
      "浓度验证指标 - MSE: 1.3327, RMSE: 1.1491, MAE: 0.1804, R2: 0.8529\n",
      "浓度模型 Epoch 51, Batch 0: Total Loss: 9.9287, Criterion Loss: 7.7264, MSE: 1.6843, KL Loss: 2.2023, L1 Reg: 604204.3750\n",
      "浓度模型 Epoch 051/500 | 训练损失: 10.7793 | 验证损失: 7.2730 | LR: 0.000780\n",
      "浓度验证指标 - MSE: 1.2474, RMSE: 1.1124, MAE: 0.1990, R2: 0.8621\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.2730\n",
      "浓度模型 Epoch 52, Batch 0: Total Loss: 9.4610, Criterion Loss: 7.3154, MSE: 1.2899, KL Loss: 2.1455, L1 Reg: 602557.5000\n",
      "浓度模型 Epoch 052/500 | 训练损失: 10.9170 | 验证损失: 7.2786 | LR: 0.000773\n",
      "浓度验证指标 - MSE: 1.2741, RMSE: 1.1235, MAE: 0.1876, R2: 0.8593\n",
      "浓度模型 Epoch 53, Batch 0: Total Loss: 9.6204, Criterion Loss: 7.5593, MSE: 1.5547, KL Loss: 2.0611, L1 Reg: 600453.5000\n",
      "浓度模型 Epoch 053/500 | 训练损失: 10.6262 | 验证损失: 7.2448 | LR: 0.000765\n",
      "浓度验证指标 - MSE: 1.2572, RMSE: 1.1169, MAE: 0.2000, R2: 0.8610\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.2448\n",
      "浓度模型 Epoch 54, Batch 0: Total Loss: 9.6946, Criterion Loss: 7.7269, MSE: 1.7393, KL Loss: 1.9677, L1 Reg: 598762.7500\n",
      "浓度模型 Epoch 054/500 | 训练损失: 10.5376 | 验证损失: 7.2346 | LR: 0.000756\n",
      "浓度验证指标 - MSE: 1.2624, RMSE: 1.1185, MAE: 0.1885, R2: 0.8606\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.2346\n",
      "浓度模型 Epoch 55, Batch 0: Total Loss: 9.2290, Criterion Loss: 7.3146, MSE: 1.3424, KL Loss: 1.9144, L1 Reg: 597224.5000\n",
      "浓度模型 Epoch 055/500 | 训练损失: 10.3614 | 验证损失: 7.2306 | LR: 0.000746\n",
      "浓度验证指标 - MSE: 1.2744, RMSE: 1.1233, MAE: 0.1916, R2: 0.8593\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.2306\n",
      "浓度模型 Epoch 56, Batch 0: Total Loss: 8.9173, Criterion Loss: 7.0546, MSE: 1.0984, KL Loss: 1.8627, L1 Reg: 595621.3125\n",
      "浓度模型 Epoch 056/500 | 训练损失: 10.9024 | 验证损失: 7.1964 | LR: 0.000736\n",
      "浓度验证指标 - MSE: 1.2534, RMSE: 1.1148, MAE: 0.1981, R2: 0.8614\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.1964\n",
      "浓度模型 Epoch 57, Batch 0: Total Loss: 9.6354, Criterion Loss: 7.8031, MSE: 1.8602, KL Loss: 1.8324, L1 Reg: 594292.3750\n",
      "浓度模型 Epoch 057/500 | 训练损失: 10.4926 | 验证损失: 7.3369 | LR: 0.000724\n",
      "浓度验证指标 - MSE: 1.4073, RMSE: 1.1809, MAE: 0.1786, R2: 0.8447\n",
      "浓度模型 Epoch 58, Batch 0: Total Loss: 9.4827, Criterion Loss: 7.6877, MSE: 1.7581, KL Loss: 1.7950, L1 Reg: 592964.4375\n",
      "浓度模型 Epoch 058/500 | 训练损失: 10.4338 | 验证损失: 7.2839 | LR: 0.000711\n",
      "浓度验证指标 - MSE: 1.3678, RMSE: 1.1638, MAE: 0.1799, R2: 0.8490\n",
      "浓度模型 Epoch 59, Batch 0: Total Loss: 9.5691, Criterion Loss: 7.8417, MSE: 1.9256, KL Loss: 1.7275, L1 Reg: 591611.6250\n",
      "浓度模型 Epoch 059/500 | 训练损失: 10.4831 | 验证损失: 7.2686 | LR: 0.000697\n",
      "浓度验证指标 - MSE: 1.3669, RMSE: 1.1642, MAE: 0.2082, R2: 0.8491\n",
      "浓度模型 Epoch 60, Batch 0: Total Loss: 9.3558, Criterion Loss: 7.6275, MSE: 1.7258, KL Loss: 1.7283, L1 Reg: 590168.9375\n",
      "浓度模型 Epoch 060/500 | 训练损失: 10.2578 | 验证损失: 7.2825 | LR: 0.000683\n",
      "浓度验证指标 - MSE: 1.3948, RMSE: 1.1758, MAE: 0.1850, R2: 0.8461\n",
      "浓度模型 Epoch 61, Batch 0: Total Loss: 8.9193, Criterion Loss: 7.2618, MSE: 1.3740, KL Loss: 1.6575, L1 Reg: 588776.0000\n",
      "浓度模型 Epoch 061/500 | 训练损失: 10.1063 | 验证损失: 7.1551 | LR: 0.000668\n",
      "浓度验证指标 - MSE: 1.2833, RMSE: 1.1284, MAE: 0.2092, R2: 0.8579\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.1551\n",
      "浓度模型 Epoch 62, Batch 0: Total Loss: 9.2641, Criterion Loss: 7.6301, MSE: 1.7583, KL Loss: 1.6340, L1 Reg: 587178.3750\n",
      "浓度模型 Epoch 062/500 | 训练损失: 10.0775 | 验证损失: 7.1404 | LR: 0.000652\n",
      "浓度验证指标 - MSE: 1.2821, RMSE: 1.1271, MAE: 0.1936, R2: 0.8585\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.1404\n",
      "浓度模型 Epoch 63, Batch 0: Total Loss: 9.4150, Criterion Loss: 7.8454, MSE: 1.9871, KL Loss: 1.5696, L1 Reg: 585828.5625\n",
      "浓度模型 Epoch 063/500 | 训练损失: 10.1969 | 验证损失: 7.3561 | LR: 0.000635\n",
      "浓度验证指标 - MSE: 1.5119, RMSE: 1.2231, MAE: 0.1882, R2: 0.8334\n",
      "浓度模型 Epoch 64, Batch 0: Total Loss: 9.0006, Criterion Loss: 7.4797, MSE: 1.6355, KL Loss: 1.5209, L1 Reg: 584419.3750\n",
      "浓度模型 Epoch 064/500 | 训练损失: 10.0181 | 验证损失: 7.0944 | LR: 0.000618\n",
      "浓度验证指标 - MSE: 1.2620, RMSE: 1.1185, MAE: 0.1989, R2: 0.8606\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.0944\n",
      "浓度模型 Epoch 65, Batch 0: Total Loss: 8.8815, Criterion Loss: 7.3638, MSE: 1.5315, KL Loss: 1.5177, L1 Reg: 583230.3125\n",
      "浓度模型 Epoch 065/500 | 训练损失: 9.9244 | 验证损失: 7.0491 | LR: 0.000600\n",
      "浓度验证指标 - MSE: 1.2272, RMSE: 1.1029, MAE: 0.1808, R2: 0.8644\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.0491\n",
      "保存基于R2的最佳浓度模型，R2: 0.8644\n",
      "浓度模型 Epoch 66, Batch 0: Total Loss: 8.6446, Criterion Loss: 7.1506, MSE: 1.3287, KL Loss: 1.4940, L1 Reg: 582185.6875\n",
      "浓度模型 Epoch 066/500 | 训练损失: 9.9269 | 验证损失: 7.0798 | LR: 0.000582\n",
      "浓度验证指标 - MSE: 1.2673, RMSE: 1.1205, MAE: 0.1938, R2: 0.8599\n",
      "浓度模型 Epoch 67, Batch 0: Total Loss: 8.8032, Criterion Loss: 7.3197, MSE: 1.5073, KL Loss: 1.4834, L1 Reg: 581242.5625\n",
      "浓度模型 Epoch 067/500 | 训练损失: 9.8999 | 验证损失: 7.0930 | LR: 0.000563\n",
      "浓度验证指标 - MSE: 1.2893, RMSE: 1.1312, MAE: 0.1847, R2: 0.8575\n",
      "浓度模型 Epoch 68, Batch 0: Total Loss: 8.3897, Criterion Loss: 6.9465, MSE: 1.1428, KL Loss: 1.4431, L1 Reg: 580370.6250\n",
      "浓度模型 Epoch 068/500 | 训练损失: 9.6964 | 验证损失: 7.0580 | LR: 0.000544\n",
      "浓度验证指标 - MSE: 1.2688, RMSE: 1.1211, MAE: 0.1865, R2: 0.8599\n",
      "浓度模型 Epoch 69, Batch 0: Total Loss: 8.7851, Criterion Loss: 7.3834, MSE: 1.5942, KL Loss: 1.4016, L1 Reg: 578921.5000\n",
      "浓度模型 Epoch 069/500 | 训练损失: 9.6955 | 验证损失: 7.0926 | LR: 0.000524\n",
      "浓度验证指标 - MSE: 1.3168, RMSE: 1.1428, MAE: 0.1820, R2: 0.8545\n",
      "浓度模型 Epoch 70, Batch 0: Total Loss: 8.5025, Criterion Loss: 7.1354, MSE: 1.3596, KL Loss: 1.3671, L1 Reg: 577580.2500\n",
      "浓度模型 Epoch 070/500 | 训练损失: 9.7490 | 验证损失: 7.0507 | LR: 0.000504\n",
      "浓度验证指标 - MSE: 1.2878, RMSE: 1.1299, MAE: 0.1890, R2: 0.8578\n",
      "浓度模型 Epoch 71, Batch 0: Total Loss: 9.0805, Criterion Loss: 7.7299, MSE: 1.9671, KL Loss: 1.3506, L1 Reg: 576286.6875\n",
      "浓度模型 Epoch 071/500 | 训练损失: 9.6078 | 验证损失: 7.0592 | LR: 0.000484\n",
      "浓度验证指标 - MSE: 1.3066, RMSE: 1.1392, MAE: 0.2057, R2: 0.8554\n",
      "浓度模型 Epoch 72, Batch 0: Total Loss: 8.6357, Criterion Loss: 7.3191, MSE: 1.5665, KL Loss: 1.3166, L1 Reg: 575254.3750\n",
      "浓度模型 Epoch 072/500 | 训练损失: 9.6842 | 验证损失: 7.0049 | LR: 0.000463\n",
      "浓度验证指标 - MSE: 1.2624, RMSE: 1.1180, MAE: 0.1916, R2: 0.8606\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.0049\n",
      "浓度模型 Epoch 73, Batch 0: Total Loss: 8.7489, Criterion Loss: 7.4728, MSE: 1.7304, KL Loss: 1.2761, L1 Reg: 574243.6875\n",
      "浓度模型 Epoch 073/500 | 训练损失: 9.7412 | 验证损失: 7.1296 | LR: 0.000442\n",
      "浓度验证指标 - MSE: 1.3974, RMSE: 1.1774, MAE: 0.1782, R2: 0.8457\n",
      "浓度模型 Epoch 74, Batch 0: Total Loss: 8.5993, Criterion Loss: 7.3211, MSE: 1.5888, KL Loss: 1.2782, L1 Reg: 573223.3750\n",
      "浓度模型 Epoch 074/500 | 训练损失: 9.6695 | 验证损失: 7.0205 | LR: 0.000421\n",
      "浓度验证指标 - MSE: 1.2984, RMSE: 1.1342, MAE: 0.1958, R2: 0.8567\n",
      "浓度模型 Epoch 75, Batch 0: Total Loss: 8.4555, Criterion Loss: 7.1934, MSE: 1.4713, KL Loss: 1.2621, L1 Reg: 572210.0625\n",
      "浓度模型 Epoch 075/500 | 训练损失: 9.7771 | 验证损失: 6.9579 | LR: 0.000401\n",
      "浓度验证指标 - MSE: 1.2437, RMSE: 1.1106, MAE: 0.1847, R2: 0.8626\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.9579\n",
      "浓度模型 Epoch 76, Batch 0: Total Loss: 8.7528, Criterion Loss: 7.5246, MSE: 1.8103, KL Loss: 1.2282, L1 Reg: 571428.5625\n",
      "浓度模型 Epoch 076/500 | 训练损失: 9.5054 | 验证损失: 6.9670 | LR: 0.000380\n",
      "浓度验证指标 - MSE: 1.2607, RMSE: 1.1181, MAE: 0.1932, R2: 0.8606\n",
      "浓度模型 Epoch 77, Batch 0: Total Loss: 8.2645, Criterion Loss: 7.0450, MSE: 1.3388, KL Loss: 1.2195, L1 Reg: 570626.1250\n",
      "浓度模型 Epoch 077/500 | 训练损失: 9.9462 | 验证损失: 6.9455 | LR: 0.000359\n",
      "浓度验证指标 - MSE: 1.2474, RMSE: 1.1120, MAE: 0.1797, R2: 0.8622\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.9455\n",
      "浓度模型 Epoch 78, Batch 0: Total Loss: 8.1188, Criterion Loss: 6.9543, MSE: 1.2563, KL Loss: 1.1645, L1 Reg: 569804.3750\n",
      "浓度模型 Epoch 078/500 | 训练损失: 9.4144 | 验证损失: 6.9800 | LR: 0.000338\n",
      "浓度验证指标 - MSE: 1.2901, RMSE: 1.1306, MAE: 0.1882, R2: 0.8576\n",
      "浓度模型 Epoch 79, Batch 0: Total Loss: 9.0054, Criterion Loss: 7.8251, MSE: 2.1353, KL Loss: 1.1802, L1 Reg: 568987.6250\n",
      "浓度模型 Epoch 079/500 | 训练损失: 10.1414 | 验证损失: 6.9874 | LR: 0.000317\n",
      "浓度验证指标 - MSE: 1.3046, RMSE: 1.1376, MAE: 0.1796, R2: 0.8559\n",
      "浓度模型 Epoch 80, Batch 0: Total Loss: 8.3477, Criterion Loss: 7.1785, MSE: 1.4957, KL Loss: 1.1692, L1 Reg: 568275.5000\n",
      "浓度模型 Epoch 080/500 | 训练损失: 9.4160 | 验证损失: 6.9003 | LR: 0.000297\n",
      "浓度验证指标 - MSE: 1.2240, RMSE: 1.1013, MAE: 0.1824, R2: 0.8648\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.9003\n",
      "保存基于R2的最佳浓度模型，R2: 0.8648\n",
      "浓度模型 Epoch 81, Batch 0: Total Loss: 8.3065, Criterion Loss: 7.1636, MSE: 1.4872, KL Loss: 1.1428, L1 Reg: 567637.0625\n",
      "浓度模型 Epoch 081/500 | 训练损失: 9.4065 | 验证损失: 6.9381 | LR: 0.000277\n",
      "浓度验证指标 - MSE: 1.2692, RMSE: 1.1207, MAE: 0.1788, R2: 0.8599\n",
      "浓度模型 Epoch 82, Batch 0: Total Loss: 18.4307, Criterion Loss: 17.2974, MSE: 11.6284, KL Loss: 1.1333, L1 Reg: 566892.1250\n",
      "浓度模型 Epoch 082/500 | 训练损失: 9.2613 | 验证损失: 6.9148 | LR: 0.000257\n",
      "浓度验证指标 - MSE: 1.2518, RMSE: 1.1138, MAE: 0.1765, R2: 0.8617\n",
      "浓度模型 Epoch 83, Batch 0: Total Loss: 8.1525, Criterion Loss: 7.0461, MSE: 1.3831, KL Loss: 1.1065, L1 Reg: 566299.8125\n",
      "浓度模型 Epoch 083/500 | 训练损失: 9.2855 | 验证损失: 7.0061 | LR: 0.000238\n",
      "浓度验证指标 - MSE: 1.3501, RMSE: 1.1569, MAE: 0.2147, R2: 0.8506\n",
      "浓度模型 Epoch 84, Batch 0: Total Loss: 8.4153, Criterion Loss: 7.2976, MSE: 1.6417, KL Loss: 1.1177, L1 Reg: 565595.1875\n",
      "浓度模型 Epoch 084/500 | 训练损失: 9.4761 | 验证损失: 6.8947 | LR: 0.000219\n",
      "浓度验证指标 - MSE: 1.2444, RMSE: 1.1112, MAE: 0.1770, R2: 0.8624\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.8947\n",
      "浓度模型 Epoch 85, Batch 0: Total Loss: 8.5980, Criterion Loss: 7.5038, MSE: 1.8535, KL Loss: 1.0943, L1 Reg: 565031.8125\n",
      "浓度模型 Epoch 085/500 | 训练损失: 9.3919 | 验证损失: 6.8850 | LR: 0.000201\n",
      "浓度验证指标 - MSE: 1.2406, RMSE: 1.1080, MAE: 0.1836, R2: 0.8630\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.8850\n",
      "浓度模型 Epoch 86, Batch 0: Total Loss: 8.0276, Criterion Loss: 6.9574, MSE: 1.3130, KL Loss: 1.0702, L1 Reg: 564437.0000\n",
      "浓度模型 Epoch 086/500 | 训练损失: 9.9504 | 验证损失: 6.9251 | LR: 0.000183\n",
      "浓度验证指标 - MSE: 1.2851, RMSE: 1.1282, MAE: 0.1808, R2: 0.8582\n",
      "浓度模型 Epoch 87, Batch 0: Total Loss: 8.1554, Criterion Loss: 7.0710, MSE: 1.4311, KL Loss: 1.0844, L1 Reg: 563992.0625\n",
      "浓度模型 Epoch 087/500 | 训练损失: 9.2569 | 验证损失: 6.9716 | LR: 0.000166\n",
      "浓度验证指标 - MSE: 1.3361, RMSE: 1.1511, MAE: 0.1776, R2: 0.8525\n",
      "浓度模型 Epoch 88, Batch 0: Total Loss: 7.9464, Criterion Loss: 6.9049, MSE: 1.2694, KL Loss: 1.0415, L1 Reg: 563549.0625\n",
      "浓度模型 Epoch 088/500 | 训练损失: 9.3690 | 验证损失: 6.8793 | LR: 0.000149\n",
      "浓度验证指标 - MSE: 1.2471, RMSE: 1.1120, MAE: 0.1805, R2: 0.8622\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.8793\n",
      "浓度模型 Epoch 89, Batch 0: Total Loss: 8.2993, Criterion Loss: 7.2360, MSE: 1.6038, KL Loss: 1.0633, L1 Reg: 563221.5625\n",
      "浓度模型 Epoch 089/500 | 训练损失: 9.2068 | 验证损失: 6.8571 | LR: 0.000133\n",
      "浓度验证指标 - MSE: 1.2284, RMSE: 1.1037, MAE: 0.1792, R2: 0.8642\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.8571\n",
      "浓度模型 Epoch 90, Batch 0: Total Loss: 8.6553, Criterion Loss: 7.6150, MSE: 1.9863, KL Loss: 1.0403, L1 Reg: 562875.2500\n",
      "浓度模型 Epoch 090/500 | 训练损失: 9.2510 | 验证损失: 6.8482 | LR: 0.000118\n",
      "浓度验证指标 - MSE: 1.2226, RMSE: 1.1008, MAE: 0.1792, R2: 0.8649\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.8482\n",
      "保存基于R2的最佳浓度模型，R2: 0.8649\n",
      "浓度模型 Epoch 91, Batch 0: Total Loss: 8.5613, Criterion Loss: 7.5313, MSE: 1.9056, KL Loss: 1.0301, L1 Reg: 562568.8750\n",
      "浓度模型 Epoch 091/500 | 训练损失: 9.2408 | 验证损失: 6.8496 | LR: 0.000104\n",
      "浓度验证指标 - MSE: 1.2265, RMSE: 1.1023, MAE: 0.1797, R2: 0.8645\n",
      "浓度模型 Epoch 92, Batch 0: Total Loss: 8.7711, Criterion Loss: 7.7420, MSE: 2.1190, KL Loss: 1.0291, L1 Reg: 562305.0625\n",
      "浓度模型 Epoch 092/500 | 训练损失: 9.4352 | 验证损失: 6.8308 | LR: 0.000090\n",
      "浓度验证指标 - MSE: 1.2102, RMSE: 1.0951, MAE: 0.1783, R2: 0.8663\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.8308\n",
      "保存基于R2的最佳浓度模型，R2: 0.8663\n",
      "浓度模型 Epoch 93, Batch 0: Total Loss: 8.0976, Criterion Loss: 7.0502, MSE: 1.4296, KL Loss: 1.0474, L1 Reg: 562056.4375\n",
      "浓度模型 Epoch 093/500 | 训练损失: 9.0733 | 验证损失: 6.8547 | LR: 0.000077\n",
      "浓度验证指标 - MSE: 1.2366, RMSE: 1.1077, MAE: 0.1775, R2: 0.8633\n",
      "浓度模型 Epoch 94, Batch 0: Total Loss: 13.9890, Criterion Loss: 12.9439, MSE: 7.3259, KL Loss: 1.0451, L1 Reg: 561804.3750\n",
      "浓度模型 Epoch 094/500 | 训练损失: 9.2335 | 验证损失: 6.8360 | LR: 0.000065\n",
      "浓度验证指标 - MSE: 1.2197, RMSE: 1.0997, MAE: 0.1801, R2: 0.8652\n",
      "浓度模型 Epoch 95, Batch 0: Total Loss: 8.4174, Criterion Loss: 7.3848, MSE: 1.7685, KL Loss: 1.0326, L1 Reg: 561628.8750\n",
      "浓度模型 Epoch 095/500 | 训练损失: 9.1741 | 验证损失: 6.8313 | LR: 0.000055\n",
      "浓度验证指标 - MSE: 1.2163, RMSE: 1.0985, MAE: 0.1745, R2: 0.8655\n",
      "浓度模型 Epoch 96, Batch 0: Total Loss: 8.3193, Criterion Loss: 7.2898, MSE: 1.6748, KL Loss: 1.0295, L1 Reg: 561505.5000\n",
      "浓度模型 Epoch 096/500 | 训练损失: 9.1357 | 验证损失: 6.8298 | LR: 0.000045\n",
      "浓度验证指标 - MSE: 1.2161, RMSE: 1.0979, MAE: 0.1794, R2: 0.8657\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.8298\n",
      "浓度模型 Epoch 97, Batch 0: Total Loss: 18.1300, Criterion Loss: 17.1032, MSE: 11.4894, KL Loss: 1.0268, L1 Reg: 561378.3125\n",
      "浓度模型 Epoch 097/500 | 训练损失: 9.2876 | 验证损失: 6.8448 | LR: 0.000036\n",
      "浓度验证指标 - MSE: 1.2320, RMSE: 1.1045, MAE: 0.1759, R2: 0.8640\n",
      "浓度模型 Epoch 98, Batch 0: Total Loss: 7.9829, Criterion Loss: 6.9886, MSE: 1.3757, KL Loss: 0.9943, L1 Reg: 561284.6250\n",
      "浓度模型 Epoch 098/500 | 训练损失: 9.1329 | 验证损失: 6.8462 | LR: 0.000028\n",
      "浓度验证指标 - MSE: 1.2342, RMSE: 1.1056, MAE: 0.1813, R2: 0.8638\n",
      "浓度模型 Epoch 99, Batch 0: Total Loss: 8.0644, Criterion Loss: 7.0499, MSE: 1.4379, KL Loss: 1.0145, L1 Reg: 561207.1875\n",
      "浓度模型 Epoch 099/500 | 训练损失: 9.1238 | 验证损失: 6.8476 | LR: 0.000021\n",
      "浓度验证指标 - MSE: 1.2361, RMSE: 1.1063, MAE: 0.1810, R2: 0.8635\n",
      "浓度模型 Epoch 100, Batch 0: Total Loss: 8.0151, Criterion Loss: 6.9862, MSE: 1.3747, KL Loss: 1.0289, L1 Reg: 561149.4375\n",
      "浓度模型 Epoch 100/500 | 训练损失: 9.2552 | 验证损失: 6.8466 | LR: 0.000015\n",
      "浓度验证指标 - MSE: 1.2356, RMSE: 1.1064, MAE: 0.1831, R2: 0.8635\n",
      "浓度模型 Epoch 101, Batch 0: Total Loss: 8.0935, Criterion Loss: 7.0770, MSE: 1.4659, KL Loss: 1.0165, L1 Reg: 561105.8125\n",
      "浓度模型 Epoch 101/500 | 训练损失: 9.0981 | 验证损失: 6.8572 | LR: 0.000010\n",
      "浓度验证指标 - MSE: 1.2465, RMSE: 1.1118, MAE: 0.1850, R2: 0.8622\n",
      "浓度模型 Epoch 102, Batch 0: Total Loss: 7.9892, Criterion Loss: 6.9605, MSE: 1.3498, KL Loss: 1.0287, L1 Reg: 561069.5000\n",
      "浓度模型 Epoch 102/500 | 训练损失: 9.4277 | 验证损失: 6.8361 | LR: 0.000006\n",
      "浓度验证指标 - MSE: 1.2256, RMSE: 1.1023, MAE: 0.1834, R2: 0.8646\n",
      "浓度模型 Epoch 103, Batch 0: Total Loss: 7.8412, Criterion Loss: 6.8352, MSE: 1.2247, KL Loss: 1.0060, L1 Reg: 561045.0625\n",
      "浓度模型 Epoch 103/500 | 训练损失: 9.0670 | 验证损失: 6.8590 | LR: 0.000003\n",
      "浓度验证指标 - MSE: 1.2487, RMSE: 1.1124, MAE: 0.1836, R2: 0.8621\n",
      "浓度模型 Epoch 104, Batch 0: Total Loss: 8.1664, Criterion Loss: 7.1519, MSE: 1.5416, KL Loss: 1.0145, L1 Reg: 561028.3125\n",
      "浓度模型 Epoch 104/500 | 训练损失: 9.2817 | 验证损失: 6.8438 | LR: 0.000002\n",
      "浓度验证指标 - MSE: 1.2335, RMSE: 1.1053, MAE: 0.1821, R2: 0.8639\n",
      "浓度模型 Epoch 105, Batch 0: Total Loss: 8.1747, Criterion Loss: 7.1683, MSE: 1.5581, KL Loss: 1.0065, L1 Reg: 561021.5000\n",
      "浓度模型 Epoch 105/500 | 训练损失: 9.1812 | 验证损失: 6.8294 | LR: 0.000800\n",
      "浓度验证指标 - MSE: 1.2192, RMSE: 1.0990, MAE: 0.1823, R2: 0.8654\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.8294\n",
      "浓度模型 Epoch 106, Batch 0: Total Loss: 8.2894, Criterion Loss: 7.2609, MSE: 1.6507, KL Loss: 1.0285, L1 Reg: 561018.0000\n",
      "浓度模型 Epoch 106/500 | 训练损失: 9.2169 | 验证损失: 6.8676 | LR: 0.000800\n",
      "浓度验证指标 - MSE: 1.2740, RMSE: 1.1243, MAE: 0.1861, R2: 0.8592\n",
      "浓度模型 Epoch 107, Batch 0: Total Loss: 8.0494, Criterion Loss: 7.0762, MSE: 1.4826, KL Loss: 0.9732, L1 Reg: 559354.5625\n",
      "浓度模型 Epoch 107/500 | 训练损失: 9.0593 | 验证损失: 6.9056 | LR: 0.000799\n",
      "浓度验证指标 - MSE: 1.3272, RMSE: 1.1468, MAE: 0.1805, R2: 0.8535\n",
      "浓度模型 Epoch 108, Batch 0: Total Loss: 8.1796, Criterion Loss: 7.2303, MSE: 1.6519, KL Loss: 0.9494, L1 Reg: 557838.6250\n",
      "浓度模型 Epoch 108/500 | 训练损失: 9.1765 | 验证损失: 6.8796 | LR: 0.000799\n",
      "浓度验证指标 - MSE: 1.3170, RMSE: 1.1442, MAE: 0.2163, R2: 0.8539\n",
      "浓度模型 Epoch 109, Batch 0: Total Loss: 7.9717, Criterion Loss: 7.0441, MSE: 1.4814, KL Loss: 0.9276, L1 Reg: 556266.3750\n",
      "浓度模型 Epoch 109/500 | 训练损失: 9.1903 | 验证损失: 6.8520 | LR: 0.000798\n",
      "浓度验证指标 - MSE: 1.3026, RMSE: 1.1369, MAE: 0.2007, R2: 0.8559\n",
      "浓度模型 Epoch 110, Batch 0: Total Loss: 8.6796, Criterion Loss: 7.7475, MSE: 2.1981, KL Loss: 0.9321, L1 Reg: 554943.9375\n",
      "浓度模型 Epoch 110/500 | 训练损失: 9.0918 | 验证损失: 6.8247 | LR: 0.000797\n",
      "浓度验证指标 - MSE: 1.2888, RMSE: 1.1304, MAE: 0.1711, R2: 0.8575\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.8247\n",
      "浓度模型 Epoch 111, Batch 0: Total Loss: 9.3207, Criterion Loss: 8.4095, MSE: 2.8736, KL Loss: 0.9112, L1 Reg: 553590.1875\n",
      "浓度模型 Epoch 111/500 | 训练损失: 9.1837 | 验证损失: 6.8709 | LR: 0.000795\n",
      "浓度验证指标 - MSE: 1.3483, RMSE: 1.1561, MAE: 0.1897, R2: 0.8510\n",
      "浓度模型 Epoch 112, Batch 0: Total Loss: 8.2831, Criterion Loss: 7.4144, MSE: 1.8917, KL Loss: 0.8687, L1 Reg: 552264.5000\n",
      "浓度模型 Epoch 112/500 | 训练损失: 9.1366 | 验证损失: 7.0216 | LR: 0.000793\n",
      "浓度验证指标 - MSE: 1.5128, RMSE: 1.2234, MAE: 0.1809, R2: 0.8332\n",
      "浓度模型 Epoch 113, Batch 0: Total Loss: 14.1945, Criterion Loss: 13.3276, MSE: 7.8188, KL Loss: 0.8669, L1 Reg: 550879.8750\n",
      "浓度模型 Epoch 113/500 | 训练损失: 9.1239 | 验证损失: 6.8211 | LR: 0.000791\n",
      "浓度验证指标 - MSE: 1.3236, RMSE: 1.1454, MAE: 0.1853, R2: 0.8538\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.8211\n",
      "浓度模型 Epoch 114, Batch 0: Total Loss: 8.3253, Criterion Loss: 7.4853, MSE: 1.9878, KL Loss: 0.8400, L1 Reg: 549751.0625\n",
      "浓度模型 Epoch 114/500 | 训练损失: 9.1564 | 验证损失: 6.7372 | LR: 0.000789\n",
      "浓度验证指标 - MSE: 1.2505, RMSE: 1.1131, MAE: 0.1895, R2: 0.8618\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.7372\n",
      "浓度模型 Epoch 115, Batch 0: Total Loss: 8.9078, Criterion Loss: 8.0876, MSE: 2.6010, KL Loss: 0.8202, L1 Reg: 548663.9375\n",
      "浓度模型 Epoch 115/500 | 训练损失: 8.9210 | 验证损失: 7.3777 | LR: 0.000786\n",
      "浓度验证指标 - MSE: 1.9049, RMSE: 1.3720, MAE: 0.2828, R2: 0.7869\n",
      "浓度模型 Epoch 116, Batch 0: Total Loss: 7.9753, Criterion Loss: 7.1668, MSE: 1.6940, KL Loss: 0.8085, L1 Reg: 547278.6875\n",
      "浓度模型 Epoch 116/500 | 训练损失: 9.2936 | 验证损失: 6.8384 | LR: 0.000784\n",
      "浓度验证指标 - MSE: 1.3786, RMSE: 1.1691, MAE: 0.1807, R2: 0.8476\n",
      "浓度模型 Epoch 117, Batch 0: Total Loss: 13.5705, Criterion Loss: 12.7870, MSE: 7.3272, KL Loss: 0.7835, L1 Reg: 545982.0625\n",
      "浓度模型 Epoch 117/500 | 训练损失: 8.8456 | 验证损失: 6.9493 | LR: 0.000780\n",
      "浓度验证指标 - MSE: 1.5041, RMSE: 1.2213, MAE: 0.1920, R2: 0.8338\n",
      "浓度模型 Epoch 118, Batch 0: Total Loss: 7.9102, Criterion Loss: 7.1361, MSE: 1.6909, KL Loss: 0.7741, L1 Reg: 544519.2500\n",
      "浓度模型 Epoch 118/500 | 训练损失: 9.1167 | 验证损失: 6.7339 | LR: 0.000777\n",
      "浓度验证指标 - MSE: 1.3032, RMSE: 1.1370, MAE: 0.1970, R2: 0.8559\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.7339\n",
      "浓度模型 Epoch 119, Batch 0: Total Loss: 13.3318, Criterion Loss: 12.5654, MSE: 7.1347, KL Loss: 0.7664, L1 Reg: 543066.8125\n",
      "浓度模型 Epoch 119/500 | 训练损失: 9.0404 | 验证损失: 6.7183 | LR: 0.000773\n",
      "浓度验证指标 - MSE: 1.3025, RMSE: 1.1373, MAE: 0.1866, R2: 0.8560\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.7183\n",
      "浓度模型 Epoch 120, Batch 0: Total Loss: 8.2218, Criterion Loss: 7.4711, MSE: 2.0553, KL Loss: 0.7507, L1 Reg: 541579.2500\n",
      "浓度模型 Epoch 120/500 | 训练损失: 9.0149 | 验证损失: 7.3946 | LR: 0.000770\n",
      "浓度验证指标 - MSE: 1.9927, RMSE: 1.4017, MAE: 0.2701, R2: 0.7794\n",
      "浓度模型 Epoch 121, Batch 0: Total Loss: 18.3050, Criterion Loss: 17.5766, MSE: 12.1747, KL Loss: 0.7284, L1 Reg: 540183.5000\n",
      "浓度模型 Epoch 121/500 | 训练损失: 8.9234 | 验证损失: 6.7387 | LR: 0.000765\n",
      "浓度验证指标 - MSE: 1.3483, RMSE: 1.1564, MAE: 0.1788, R2: 0.8510\n",
      "浓度模型 Epoch 122, Batch 0: Total Loss: 8.0442, Criterion Loss: 7.3476, MSE: 1.9573, KL Loss: 0.6966, L1 Reg: 539037.2500\n",
      "浓度模型 Epoch 122/500 | 训练损失: 8.8479 | 验证损失: 6.6211 | LR: 0.000761\n",
      "浓度验证指标 - MSE: 1.2429, RMSE: 1.1102, MAE: 0.1783, R2: 0.8626\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.6211\n",
      "浓度模型早停触发! 在第122个epoch停止训练\n",
      "\n",
      "浓度模型训练完成!\n",
      "基于损失的最佳验证损失: 6.6211\n",
      "基于R2的最佳R2分数: 0.8663\n",
      "改进的双模型训练曲线已保存\n",
      "\n",
      "================================================================================\n",
      "双模型训练完成总结:\n",
      "水头模型 - 基于损失的最佳验证损失: 12.0943\n",
      "水头模型 - 基于R2的最佳R2分数: 0.6228\n",
      "浓度模型 - 基于损失的最佳验证损失: 6.6211\n",
      "浓度模型 - 基于R2的最佳R2分数: 0.8663\n",
      "评估将使用基于r2的模型\n",
      "================================================================================\n",
      "开始评估双模型性能（基于loss标准）...\n",
      "\n",
      "成功加载基于loss的最佳模型权重\n",
      "水头模型来自epoch 59, 验证损失: 12.0943, R2: 0.6228\n",
      "浓度模型来自epoch 121, 验证损失: 6.6211, R2: 0.8626\n",
      "\n",
      "水头模型评估结果（基于loss）:\n",
      "  MSE: 12.3136\n",
      "  RMSE: 3.5091\n",
      "  MAE: 2.7764\n",
      "  R2: 0.6244\n",
      "\n",
      "浓度模型评估结果（基于loss）:\n",
      "  MSE: 1.2907\n",
      "  RMSE: 1.1361\n",
      "  MAE: 0.1778\n",
      "  R2: 0.8575\n",
      "\n",
      "评估结果已保存到: ./saved_models/blitz_bayesian_gnn_dual_base/dual_model_evaluation_loss.npy\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('conc_dual_guass.csv')  # 替换为您的数据文件\n",
    "train_loader, val_loader = prepare_data(data, batch_size=4)\n",
    "head_model, conc_model, training_losses = train_dual_model_improved(train_loader, val_loader)\n",
    "evaluation_results = evaluate_dual_model_improved(head_model, conc_model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbbd911-78d3-4c5d-8826-c1dfb68dd702",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
