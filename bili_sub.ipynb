{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0191dc01-8b2c-4fb8-84b2-76b65ae94b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import add_self_loops\n",
    "from sklearn.model_selection import train_test_split                                                                                                   \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.amp import autocast\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts\n",
    "from sklearn.metrics import r2_score as sklearn_r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import sys\n",
    "sys.path.append('/home/jovyan/work/GNO/GNN/GNNShap')\n",
    "from gnnshap.explainer import GNNShapExplainer\n",
    "import uuid\n",
    "\n",
    "# 导入Blitz库\n",
    "from blitz.modules import BayesianLinear                 \n",
    "from blitz.utils import variational_estimator\n",
    "\n",
    "# 设备配置\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 自定义数据集类\n",
    "class HydroDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, graphs):\n",
    "        self.graphs = graphs\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.graphs[idx]\n",
    "\n",
    "class BlitzSTConv(MessagePassing):\n",
    "    \"\"\"\n",
    "    使用Blitz实现的贝叶斯时空卷积层，增强鲁棒性\n",
    "    \"\"\"\n",
    "    def __init__(self, spatial_dim, prior_sigma_1=0.1, prior_sigma_2=0.002, posterior_mu_init=0.0, posterior_rho_init=-3.0, dropout=0.1):\n",
    "        super().__init__(aggr='mean')\n",
    "        # 使用标准的PyTorch层进行初始化处理\n",
    "        self.pre_msg = nn.Linear(2 * spatial_dim + 3, spatial_dim)\n",
    "        \n",
    "        # 然后使用Blitz层进行贝叶斯推断\n",
    "        self.bayes_msg = nn.Sequential(\n",
    "            BayesianLinear(spatial_dim, spatial_dim,\n",
    "                        prior_sigma_1=prior_sigma_1, \n",
    "                        prior_sigma_2=prior_sigma_2,\n",
    "                        posterior_mu_init=posterior_mu_init,\n",
    "                        posterior_rho_init=posterior_rho_init),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.LayerNorm(spatial_dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        # 同样的模式用于gate网络\n",
    "        self.pre_gate = nn.Linear(3 * spatial_dim, spatial_dim)\n",
    "        self.bayes_gate = nn.Sequential(\n",
    "            BayesianLinear(spatial_dim, spatial_dim,\n",
    "                        prior_sigma_1=prior_sigma_1, \n",
    "                        prior_sigma_2=prior_sigma_2,\n",
    "                        posterior_mu_init=posterior_mu_init,\n",
    "                        posterior_rho_init=posterior_rho_init),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # 残差处理\n",
    "        self.pre_res = nn.Linear(spatial_dim, spatial_dim)\n",
    "        self.bayes_res = BayesianLinear(spatial_dim, spatial_dim,\n",
    "                                     prior_sigma_1=prior_sigma_1/2, \n",
    "                                     prior_sigma_2=prior_sigma_2/2,\n",
    "                                     posterior_mu_init=posterior_mu_init,\n",
    "                                     posterior_rho_init=posterior_rho_init)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        try:\n",
    "            # 添加调试信息\n",
    "            # 确保edge_attr是浮点类型\n",
    "            edge_attr = edge_attr.float()\n",
    "            \n",
    "            # 尝试传播消息\n",
    "            out = self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "            \n",
    "            # Gate机制\n",
    "            combined = torch.cat([x, out, x - out], dim=-1)\n",
    "            gate_pre = self.pre_gate(combined)\n",
    "            gate = self.bayes_gate(gate_pre)\n",
    "            \n",
    "            # 残差连接\n",
    "            res_pre = self.pre_res(x)\n",
    "            res = self.bayes_res(res_pre)\n",
    "            \n",
    "            return x + gate * out + 0.1 * res\n",
    "        except Exception as e:\n",
    "            print(f\"Error in BlitzSTConv.forward: {e}\")\n",
    "            # 提供更详细的错误信息\n",
    "            print(f\"x shape: {x.shape}, dtype: {x.dtype}\")\n",
    "            print(f\"edge_index shape: {edge_index.shape}, dtype: {edge_index.dtype}\")\n",
    "            print(f\"edge_attr shape: {edge_attr.shape}, dtype: {edge_attr.dtype}\")\n",
    "            raise\n",
    "\n",
    "    def message(self, x_i, x_j, edge_attr):\n",
    "        try:\n",
    "            # 添加调试信息\n",
    "            edge_attr = edge_attr.to(x_i.dtype).to(x_i.device)\n",
    "            \n",
    "            # 先使用标准层，然后使用贝叶斯层\n",
    "            combined = torch.cat([x_i, x_j, edge_attr], dim=-1)\n",
    "            pre_msg = self.pre_msg(combined)\n",
    "            return self.bayes_msg(pre_msg)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in BlitzSTConv.message: {e}\")\n",
    "            # 提供更详细的错误信息\n",
    "            print(f\"x_i shape: {x_i.shape}, dtype: {x_i.dtype}\")\n",
    "            print(f\"x_j shape: {x_j.shape}, dtype: {x_j.dtype}\")\n",
    "            print(f\"edge_attr shape: {edge_attr.shape}, dtype: {edge_attr.dtype}\")\n",
    "            raise\n",
    "\n",
    "class BlitzBoundaryProcessor(nn.Module):\n",
    "    \"\"\"\n",
    "    使用Blitz实现的贝叶斯边界处理器\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, prior_sigma_1=0.1, prior_sigma_2=0.002, posterior_mu_init=0.0, posterior_rho_init=-3.0):\n",
    "        super().__init__()\n",
    "        self.boundary_net = nn.Sequential(\n",
    "            BayesianLinear(dim + 1, dim,\n",
    "                        prior_sigma_1=prior_sigma_1, \n",
    "                        prior_sigma_2=prior_sigma_2,\n",
    "                        posterior_mu_init=posterior_mu_init,\n",
    "                        posterior_rho_init=posterior_rho_init),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.river_net = nn.Sequential(\n",
    "            BayesianLinear(dim + 2, dim,\n",
    "                        prior_sigma_1=prior_sigma_1, \n",
    "                        prior_sigma_2=prior_sigma_2,\n",
    "                        posterior_mu_init=posterior_mu_init,\n",
    "                        posterior_rho_init=posterior_rho_init),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.well_net = BayesianLinear(dim + 1, dim,\n",
    "                                    prior_sigma_1=prior_sigma_1, \n",
    "                                    prior_sigma_2=prior_sigma_2,\n",
    "                                    posterior_mu_init=posterior_mu_init,\n",
    "                                    posterior_rho_init=posterior_rho_init)\n",
    "        \n",
    "        self.gate = nn.Sequential(\n",
    "            BayesianLinear(2 * dim, dim,\n",
    "                        prior_sigma_1=prior_sigma_1/2, \n",
    "                        prior_sigma_2=prior_sigma_2/2,\n",
    "                        posterior_mu_init=posterior_mu_init,\n",
    "                        posterior_rho_init=posterior_rho_init),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.chd_enforcer = BayesianLinear(dim, dim,\n",
    "                                        prior_sigma_1=prior_sigma_1/2, \n",
    "                                        prior_sigma_2=prior_sigma_2/2,\n",
    "                                        posterior_mu_init=posterior_mu_init,\n",
    "                                        posterior_rho_init=posterior_rho_init)\n",
    "    \n",
    "    def forward(self, x, bc_mask):\n",
    "        boundary_feat = self.boundary_net(\n",
    "            torch.cat([x, bc_mask[:, 0:1]], dim=-1)\n",
    "        ) * bc_mask[:, 0:1]\n",
    "        \n",
    "        river_feat = self.river_net(\n",
    "            torch.cat([x, bc_mask[:, 1:3]], dim=-1)\n",
    "        ) * bc_mask[:, 1:2]\n",
    "        \n",
    "        well_feat = self.well_net(\n",
    "            torch.cat([x, bc_mask[:, 3:4]], dim=-1)\n",
    "        ) * bc_mask[:, 4:5]\n",
    "        \n",
    "        combined = boundary_feat + river_feat + well_feat\n",
    "        gate = self.gate(torch.cat([x, combined], dim=-1))\n",
    "        out = x * (1 - gate) + combined * gate\n",
    "        \n",
    "        chd_mask = bc_mask[:, 0] > 0\n",
    "        if chd_mask.sum() > 0:\n",
    "            chd_out = self.chd_enforcer(out[chd_mask]).to(out.dtype)\n",
    "            out[chd_mask] = chd_out\n",
    "            \n",
    "        return out\n",
    "\n",
    "@variational_estimator\n",
    "class BlitzHeadGNN(nn.Module):\n",
    "    \"\"\"\n",
    "    使用Blitz实现的贝叶斯水头预测GNN，加入前一时间步的水头和浓度特征\n",
    "    \"\"\"\n",
    "    def __init__(self, node_features=16, max_time_steps=40, spatial_dim=64, \n",
    "                temporal_dim=64, output_dim=1, prior_sigma_1=0.05, prior_sigma_2=0.001,\n",
    "                posterior_mu_init=0.0, posterior_rho_init=-3.0, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.spatial_dim = spatial_dim\n",
    "        self.time_embed = nn.Embedding(max_time_steps + 1, temporal_dim)\n",
    "        \n",
    "        # 节点编码器 - 注意这里的输入维度变为node_features + temporal_dim\n",
    "        # 节点编码器 - 更保守的设计\n",
    "        self.node_enc = nn.Sequential(\n",
    "            nn.Linear(node_features + temporal_dim, spatial_dim),\n",
    "            nn.BatchNorm1d(spatial_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(spatial_dim, spatial_dim),\n",
    "            nn.BatchNorm1d(spatial_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        # 卷积层\n",
    "        self.conv_layers = nn.ModuleList([\n",
    "            BlitzSTConv(spatial_dim, prior_sigma_1, prior_sigma_2, \n",
    "                     posterior_mu_init, posterior_rho_init, dropout) \n",
    "            for _ in range(4)\n",
    "        ])\n",
    "        \n",
    "        # 边界处理器\n",
    "        self.bc_processor = BlitzBoundaryProcessor(\n",
    "            spatial_dim, prior_sigma_1, prior_sigma_2, \n",
    "            posterior_mu_init, posterior_rho_init\n",
    "        )\n",
    "        \n",
    "        # 确定性路径 - 增强权重\n",
    "        self.deterministic_path = nn.Sequential(\n",
    "            nn.Linear(spatial_dim, spatial_dim // 2),\n",
    "            nn.BatchNorm1d(spatial_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(spatial_dim // 2, spatial_dim // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(spatial_dim // 4, output_dim),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "        \n",
    "        # 贝叶斯路径 - 降低复杂度\n",
    "        self.bayesian_path = nn.Sequential(\n",
    "            BayesianLinear(spatial_dim, spatial_dim // 2,\n",
    "                          prior_sigma_1=prior_sigma_1, \n",
    "                          prior_sigma_2=prior_sigma_2,\n",
    "                          posterior_mu_init=posterior_mu_init,\n",
    "                          posterior_rho_init=posterior_rho_init),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            BayesianLinear(spatial_dim // 2, output_dim,\n",
    "                          prior_sigma_1=prior_sigma_1/2, \n",
    "                          prior_sigma_2=prior_sigma_2/2,\n",
    "                          posterior_mu_init=posterior_mu_init,\n",
    "                          posterior_rho_init=posterior_rho_init),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "        \n",
    "        # 注意力机制用于特征选择\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(spatial_dim, spatial_dim // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(spatial_dim // 4, spatial_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr.to(torch.float32)\n",
    "        \n",
    "        # 特征工程\n",
    "        if hasattr(self, 'feature_engineering'):\n",
    "            x = self.feature_engineering(x)\n",
    "        \n",
    "        # 时间嵌入\n",
    "        time_emb = self.time_embed(data.time_step)\n",
    "        node_feat = torch.cat([x, time_emb], dim=-1)\n",
    "        \n",
    "        # 节点编码\n",
    "        h = self.node_enc(node_feat)\n",
    "        \n",
    "        # 简化的图卷积\n",
    "        for conv in self.conv_layers:\n",
    "            h_new = conv(h, edge_index, edge_attr)\n",
    "            h = h + 0.1 * h_new  # 残差连接\n",
    "        \n",
    "        # 注意力加权\n",
    "        attention_weights = self.attention(h)\n",
    "        h = h * attention_weights\n",
    "        \n",
    "        # 边界处理\n",
    "        h = self.bc_processor(h, data.bc_mask)\n",
    "        \n",
    "        # 双路径预测，增加确定性路径权重\n",
    "        det_pred = self.deterministic_path(h.detach())\n",
    "        bayes_pred = self.bayesian_path(h)\n",
    "        \n",
    "        # 自适应权重组合\n",
    "        return det_pred * 0.7 + bayes_pred * 0.3\n",
    "\n",
    "class ImprovedPhysicsInformedLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    改进的物理信息损失函数，无需显式计算KL散度（Blitz内部处理）\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha=0.5, kl_weight=1e-4):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.kl_weight = kl_weight  # 在Blitz中，KL权重在sample_elbo中传入\n",
    "        \n",
    "    def forward(self, pred, data, model=None):  # 添加model参数使接口一致，但不使用\n",
    "        # 基础MSE损失\n",
    "        mse_loss = F.mse_loss(pred, data.head_y.unsqueeze(1))\n",
    "        \n",
    "        # 物理约束损失\n",
    "        time_steps = data.time_step.unique(sorted=True)\n",
    "        flux_loss = 0\n",
    "        for t in time_steps[:-1]:\n",
    "            mask_t = (data.time_step == t)\n",
    "            mask_next = (data.time_step == t + 1)\n",
    "            if mask_t.sum() > 0 and mask_next.sum() > 0:\n",
    "                flux_diff = torch.mean((pred[mask_next] - pred[mask_t]) ** 2)\n",
    "                flux_loss += flux_diff\n",
    "        flux_loss /= len(time_steps) - 1 if len(time_steps) > 1 else 1\n",
    "        \n",
    "        # 边界条件损失\n",
    "        bc_mask = data.bc_mask[:, 0] > 0\n",
    "        bc_loss = F.l1_loss(pred[bc_mask], data.head_y[bc_mask].unsqueeze(1)) if bc_mask.sum() > 0 else torch.tensor(0.0, device=pred.device)\n",
    "        \n",
    "        # 井条件损失\n",
    "        well_mask = data.bc_mask[:, 4] > 0\n",
    "        well_loss = F.l1_loss(pred[well_mask], data.head_y[well_mask].unsqueeze(1)) if well_mask.sum() > 0 else torch.tensor(0.0, device=pred.device)\n",
    "        \n",
    "        # 总损失 - 不包含KL散度，KL散度由Blitz内部处理\n",
    "        total_loss = (1 - self.alpha) * mse_loss + self.alpha * (flux_loss + bc_loss + well_loss)\n",
    "        \n",
    "        return total_loss, (mse_loss.item(), flux_loss.item(), bc_loss.item(), well_loss.item(), 0.0)  # 返回0.0表示KL损失，但实际上由Blitz处理\n",
    "\n",
    "\n",
    "@variational_estimator\n",
    "class BlitzConcGNN(nn.Module):\n",
    "    \"\"\"\n",
    "    简化的贝叶斯浓度预测GNN，直接使用18维输入特征\n",
    "    \"\"\"\n",
    "    def __init__(self, node_features=19, max_time_steps=40, spatial_dim=128,\n",
    "                temporal_dim=64, output_dim=1, prior_sigma_1=0.1, prior_sigma_2=0.01,\n",
    "                posterior_mu_init=0.0, posterior_rho_init=-3.0, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.spatial_dim = spatial_dim\n",
    "        self.time_embed = nn.Embedding(max_time_steps + 1, temporal_dim)\n",
    "        \n",
    "        # 简化的节点编码器 - 直接处理18维特征\n",
    "        self.node_enc_scale1 = nn.Sequential(\n",
    "            nn.Linear(node_features + temporal_dim, spatial_dim),  # 18 + 64 = 82 -> 128\n",
    "            nn.BatchNorm1d(spatial_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout * 0.5)\n",
    "        )\n",
    "        \n",
    "        self.node_enc = nn.Sequential(\n",
    "            BayesianLinear(spatial_dim, spatial_dim,\n",
    "                        prior_sigma_1=prior_sigma_1, \n",
    "                        prior_sigma_2=prior_sigma_2,\n",
    "                        posterior_mu_init=posterior_mu_init,\n",
    "                        posterior_rho_init=posterior_rho_init),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.LayerNorm(spatial_dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        # 卷积层\n",
    "        self.conv_layers = nn.ModuleList([\n",
    "            BlitzSTConv(spatial_dim, prior_sigma_1, prior_sigma_2, \n",
    "                     posterior_mu_init, posterior_rho_init, dropout) \n",
    "            for _ in range(4)\n",
    "        ])\n",
    "        \n",
    "        # 边界处理器\n",
    "        self.bc_processor = BlitzBoundaryProcessor(\n",
    "            spatial_dim, prior_sigma_1, prior_sigma_2, \n",
    "            posterior_mu_init, posterior_rho_init\n",
    "        )\n",
    "        \n",
    "        # 注意力机制\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(spatial_dim, spatial_dim // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(spatial_dim // 4, spatial_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # 贝叶斯分支解码器\n",
    "        self.decoder = nn.Sequential(\n",
    "            BayesianLinear(spatial_dim, 128,\n",
    "                        prior_sigma_1=prior_sigma_1/2, \n",
    "                        prior_sigma_2=prior_sigma_2/2,\n",
    "                        posterior_mu_init=posterior_mu_init,\n",
    "                        posterior_rho_init=posterior_rho_init),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            BayesianLinear(128, 64,\n",
    "                        prior_sigma_1=prior_sigma_1/2, \n",
    "                        prior_sigma_2=prior_sigma_2/2,\n",
    "                        posterior_mu_init=posterior_mu_init,\n",
    "                        posterior_rho_init=posterior_rho_init),\n",
    "            nn.ReLU(),\n",
    "            BayesianLinear(64, output_dim,\n",
    "                        prior_sigma_1=prior_sigma_1/4, \n",
    "                        prior_sigma_2=prior_sigma_2/4,\n",
    "                        posterior_mu_init=posterior_mu_init,\n",
    "                        posterior_rho_init=posterior_rho_init),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "        \n",
    "        # 确定性分支解码器\n",
    "        self.decoder_det = nn.Sequential(\n",
    "            nn.Linear(spatial_dim, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, output_dim),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "        \n",
    "        # 自适应分支权重\n",
    "        self.branch_weight = nn.Parameter(torch.tensor(0.3))\n",
    "\n",
    "    def forward(self, data, pred_head=None):\n",
    "        # 直接使用conc_x作为输入（18维特征）\n",
    "        x = data.conc_x\n",
    "        edge_index, edge_attr = data.edge_index, data.edge_attr\n",
    "        \n",
    "        # 确保所有张量在同一设备\n",
    "        if edge_attr is not None:\n",
    "            edge_attr = edge_attr.to(torch.float32).to(x.device)\n",
    "        \n",
    "        # 时间嵌入\n",
    "        time_step = data.time_step.to(x.device)\n",
    "        time_emb = self.time_embed(time_step)\n",
    "        \n",
    "        # 节点特征与时间嵌入结合\n",
    "        node_feat = torch.cat([x, time_emb], dim=-1)  # (18 + 64) = 82维\n",
    "        \n",
    "        # 节点编码\n",
    "        h_scale1 = self.node_enc_scale1(node_feat)\n",
    "        h = self.node_enc(h_scale1)\n",
    "        \n",
    "        # 图卷积层\n",
    "        for conv in self.conv_layers:\n",
    "            h_new = conv(h, edge_index, edge_attr)\n",
    "            h = h + 0.1 * h_new  # 残差连接\n",
    "        \n",
    "        # 注意力加权\n",
    "        attention_weights = self.attention(h)\n",
    "        h = h * attention_weights\n",
    "        \n",
    "        # 边界处理\n",
    "        bc_mask = data.bc_mask.to(x.device) if hasattr(data, 'bc_mask') else None\n",
    "        h = self.bc_processor(h, bc_mask)\n",
    "        \n",
    "        # 双分支输出\n",
    "        bayes_output = self.decoder(h)\n",
    "        det_output = self.decoder_det(h.detach())\n",
    "        \n",
    "        # 自适应权重组合\n",
    "        combined_output = (\n",
    "            torch.sigmoid(self.branch_weight) * bayes_output + \n",
    "            (1 - torch.sigmoid(self.branch_weight)) * det_output\n",
    "        )\n",
    "        \n",
    "        return combined_output\n",
    "\n",
    "class ImprovedConcLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    改进的浓度预测损失函数，优化L1正则化\n",
    "    \"\"\"\n",
    "    def __init__(self, kl_weight=5e-5, l1_weight=1e-8):  # 大幅降低L1权重\n",
    "        super().__init__()\n",
    "        self.kl_weight = kl_weight\n",
    "        self.l1_weight = l1_weight  # L1正则化权重降低1000倍\n",
    "        \n",
    "    def forward(self, pred, data, model=None):\n",
    "        # 使用MSE损失\n",
    "        mse_loss = F.mse_loss(pred, data.y.unsqueeze(1))\n",
    "        \n",
    "        # 只对贝叶斯层应用L1正则化\n",
    "        l1_reg = torch.tensor(0., device=pred.device)\n",
    "        if model is not None and self.l1_weight > 0:\n",
    "            for name, param in model.named_parameters():\n",
    "                # 只对贝叶斯层的权重应用L1正则化\n",
    "                if 'weight' in name and ('bayesian' in name.lower() or 'bayes' in name.lower()):\n",
    "                    l1_reg += torch.norm(param, 1)\n",
    "        \n",
    "        # 总损失\n",
    "        total_loss = mse_loss + self.l1_weight * l1_reg\n",
    "        \n",
    "        return total_loss, (mse_loss.item(), 0.0, l1_reg.item())\n",
    "\n",
    "def generate_spatial_edges(model_df):\n",
    "    \"\"\"生成空间边和边属性\"\"\"\n",
    "    spatial_edges = []\n",
    "    time_steps = model_df['time_step'].unique()\n",
    "    for t in time_steps:\n",
    "        time_df = model_df[model_df['time_step'] == t]\n",
    "        coord_to_idx = {(r, c): idx for idx, r, c in zip(time_df['local_index'], time_df['row'], time_df['col'])}\n",
    "        for idx, row, col in zip(time_df['local_index'], time_df['row'], time_df['col']):\n",
    "            right_coord = (row, col + 1)\n",
    "            if right_coord in coord_to_idx:\n",
    "                spatial_edges.append([idx, coord_to_idx[right_coord]])\n",
    "            upper_coord = (row + 1, col)\n",
    "            if upper_coord in coord_to_idx:\n",
    "                spatial_edges.append([idx, coord_to_idx[upper_coord]])\n",
    "    return np.array(spatial_edges), np.full((len(spatial_edges), 3), [1.0, 0, 0], dtype=np.float32)\n",
    "\n",
    "def generate_temporal_edges(model_df):\n",
    "    \"\"\"生成时间边和边属性\"\"\"\n",
    "    temporal_edges = []\n",
    "    groups = model_df.groupby(['row', 'col'], sort=False)\n",
    "    for (row, col), group in groups:\n",
    "        time_series = group.sort_values('time_step')\n",
    "        for i in range(len(time_series) - 1):\n",
    "            global_src = time_series['local_index'].iloc[i]\n",
    "            global_dst = time_series['local_index'].iloc[i + 1]\n",
    "            temporal_edges.append([global_src, global_dst])\n",
    "    return np.array(temporal_edges), np.full((len(temporal_edges), 3), [0.0, 1.0, 0], dtype=np.float32)\n",
    "\n",
    "def build_bc_mask(model_df):\n",
    "    \"\"\"构建边界条件掩码\"\"\"\n",
    "    bc_mask = np.zeros((len(model_df), 5), dtype=np.float32)\n",
    "    bc_mask[:, 0] = model_df['chd_mask'].values.astype(np.float32)\n",
    "    bc_mask[:, 1] = (model_df['river_cond'] > 0).astype(np.float32)\n",
    "    bc_mask[:, 2] = model_df['river_stage'].values.astype(np.float32)\n",
    "    bc_mask[:, 3] = model_df['well_rate'].values.astype(np.float32)\n",
    "    bc_mask[:, 4] = model_df['well_mask'].values.astype(np.float32)\n",
    "    return bc_mask\n",
    "def build_spatiotemporal_graph(df):\n",
    "    \"\"\"构建时空图，将所有特征整合到一个输入中\"\"\"\n",
    "    print(f\"\\n▶ Started building spatiotemporal graphs\")\n",
    "    print(f\"▷ Total models to process: {len(df['model_name'].unique())}\")\n",
    "    graphs = []\n",
    "    \n",
    "    # 修正：添加 lytyp 字段的类型定义\n",
    "    df = df.astype({\n",
    "        'x': np.float32, 'y': np.float32, 'top': np.float32, \n",
    "        'bottom': np.float32, 'K': np.float32, 'recharge': np.float32,\n",
    "        'ET': np.float32, 'river_stage': np.float32, 'river_cond': np.float32,\n",
    "        'river_rbot': np.float32, 'well_rate': np.float32, 'well_mask': np.uint8,\n",
    "        'chd_mask': np.uint8, 'lytyp': np.uint8, 'head': np.float32, \n",
    "        'concentration': np.float32,'conc_mask': np.uint8\n",
    "    })\n",
    "    \n",
    "    time_min = df['time_step'].min()\n",
    "    df['time_step'] = df['time_step'] - time_min\n",
    "    \n",
    "    model_groups = list(df.groupby('model_name', sort=False))\n",
    "    total_models = len(model_groups)\n",
    "    \n",
    "    for model_idx, (model_name, model_df) in enumerate(model_groups, 1):\n",
    "        model_df = model_df.reset_index(drop=True).copy()\n",
    "        model_df['local_index'] = model_df.index\n",
    "        print(f\"\\n▣ Processing model {model_idx}/{total_models}: {model_name}\")\n",
    "        \n",
    "        model_df = model_df.sort_values(['row', 'col', 'time_step'])\n",
    "        \n",
    "        # 基础特征列（14维）\n",
    "        feature_cols = [\n",
    "            'x', 'y', 'top', 'bottom', 'K', 'recharge', 'ET',\n",
    "            'river_stage', 'river_cond', 'river_rbot', 'well_rate', 'well_mask',\n",
    "            'chd_mask', 'lytyp'\n",
    "        ]\n",
    "        node_feats = model_df[feature_cols].values.astype(np.float32)\n",
    "        col_types = df[feature_cols].dtypes.to_dict()\n",
    "        float_indices = [i for i, col in enumerate(feature_cols) if col_types[col] != np.uint8]\n",
    "        float_feats = node_feats[:, float_indices]\n",
    "        scaler = StandardScaler()\n",
    "        float_feats_scaled = scaler.fit_transform(float_feats)\n",
    "        node_feats[:, float_indices] = float_feats_scaled\n",
    "        conc_feature_cols = [\n",
    "            'x', 'y', 'top', 'bottom', 'K', 'recharge', 'ET',\n",
    "            'river_stage', 'river_cond', 'river_rbot', 'well_rate', 'well_mask',\n",
    "            'chd_mask', 'lytyp','conc_mask'\n",
    "        ]\n",
    "        conc_node_feats = model_df[conc_feature_cols].values.astype(np.float32)\n",
    "        col_types = df[conc_feature_cols].dtypes.to_dict()\n",
    "        float_indices = [i for i, col in enumerate(conc_feature_cols) if col_types[col] != np.uint8]\n",
    "        conc_float_feats = conc_node_feats[:, float_indices]\n",
    "        scaler = StandardScaler()\n",
    "        conc_float_feats_scaled = scaler.fit_transform(conc_float_feats)\n",
    "        conc_node_feats[:, float_indices] = conc_float_feats_scaled\n",
    "        # 计算前一时间步和前两个时间步的水头和浓度\n",
    "        prev_head = np.zeros(len(model_df), dtype=np.float32)\n",
    "        prev2_head = np.zeros(len(model_df), dtype=np.float32)\n",
    "        prev_conc = np.zeros(len(model_df), dtype=np.float32)\n",
    "        prev2_conc = np.zeros(len(model_df), dtype=np.float32)\n",
    "        \n",
    "        groups = model_df.groupby(['row', 'col'], sort=False)\n",
    "        for (row, col), group in groups:\n",
    "            time_series = group.sort_values('time_step')\n",
    "            prev_head[time_series.index] = np.roll(time_series['head'].values, 1)\n",
    "            prev2_head[time_series.index] = np.roll(time_series['head'].values, 2)\n",
    "            prev_conc[time_series.index] = np.roll(time_series['concentration'].values, 1)\n",
    "            prev2_conc[time_series.index] = np.roll(time_series['concentration'].values, 2)\n",
    "            \n",
    "            first_idx = time_series.index[0]\n",
    "            if len(time_series) > 1:\n",
    "                second_idx = time_series.index[1]\n",
    "                # 水头特征处理\n",
    "                prev_head[first_idx] = time_series['head'].values[0]\n",
    "                prev2_head[first_idx] = time_series['head'].values[0]\n",
    "                prev2_head[second_idx] = time_series['head'].values[0]\n",
    "                \n",
    "                # 浓度特征处理\n",
    "                prev_conc[first_idx] = time_series['concentration'].values[0]\n",
    "                prev2_conc[first_idx] = time_series['concentration'].values[0]\n",
    "                prev2_conc[second_idx] = time_series['concentration'].values[0]\n",
    "            else:\n",
    "                prev_head[first_idx] = 0.0\n",
    "                prev2_head[first_idx] = 0.0\n",
    "                prev_conc[first_idx] = 0.0\n",
    "                prev2_conc[first_idx] = 0.0\n",
    "\n",
    "        # 为水头模型：基础特征 + 前一/前二时间步水头（16维）\n",
    "        head_feats = np.concatenate([\n",
    "            node_feats,           # 14维基础特征\n",
    "            prev_head[:, None],   # 1维前一时间步水头\n",
    "            prev2_head[:, None]   # 1维前二时间步水头\n",
    "        ], axis=1)\n",
    "        \n",
    "        # 为浓度模型：基础特征 + 前一/前二时间步水头 + 前一/前二时间步浓度（18维）\n",
    "        conc_feats = np.concatenate([\n",
    "            conc_node_feats,           # 14维基础特征\n",
    "            prev_head[:, None],   # 1维前一时间步水头\n",
    "            prev2_head[:, None],  # 1维前二时间步水头\n",
    "            prev_conc[:, None],   # 1维前一时间步浓度\n",
    "            prev2_conc[:, None]   # 1维前二时间步浓度\n",
    "        ], axis=1)\n",
    "        \n",
    "        if np.any(np.isnan(head_feats)) or np.any(np.isinf(head_feats)):\n",
    "            print(f\"Warning: head_feats contains NaN or Inf for model {model_name}\")\n",
    "            head_feats = np.nan_to_num(head_feats, nan=0.0, posinf=1e6, neginf=-1e6)\n",
    "        \n",
    "        if np.any(np.isnan(conc_feats)) or np.any(np.isinf(conc_feats)):\n",
    "            print(f\"Warning: conc_feats contains NaN or Inf for model {model_name}\")\n",
    "            conc_feats = np.nan_to_num(conc_feats, nan=0.0, posinf=1e6, neginf=-1e6)\n",
    "        \n",
    "        conc = model_df['concentration'].values.astype(np.float32)\n",
    "        head = model_df['head'].values.astype(np.float32)\n",
    "        spatial_edges, spatial_attrs = generate_spatial_edges(model_df)\n",
    "        temporal_edges, temporal_attrs = generate_temporal_edges(model_df)\n",
    "        edges = np.concatenate([spatial_edges, temporal_edges], axis=0)\n",
    "        edge_attr = np.concatenate([spatial_attrs, temporal_attrs], axis=0)\n",
    "        bc_mask = build_bc_mask(model_df)\n",
    "        \n",
    "        assert bc_mask.shape == (len(model_df), 5), \\\n",
    "            f\"Invalid bc_mask shape: {bc_mask.shape} for model {model_name}\"\n",
    "        \n",
    "        graph = Data(\n",
    "            x=torch.from_numpy(head_feats),      # 水头模型特征（16维）\n",
    "            conc_x=torch.from_numpy(conc_feats), # 浓度模型特征（18维）\n",
    "            edge_index=torch.tensor(edges.T, dtype=torch.long),\n",
    "            edge_attr=torch.from_numpy(edge_attr),\n",
    "            y=torch.from_numpy(conc),\n",
    "            head_y=torch.from_numpy(head),\n",
    "            bc_mask=torch.from_numpy(bc_mask),\n",
    "            time_step=torch.from_numpy(model_df['time_step'].values).long(),\n",
    "            time_steps=model_df['time_step'].nunique(),\n",
    "            model_name=str(model_name),\n",
    "            row=torch.from_numpy(model_df['row'].values).long(),\n",
    "            col=torch.from_numpy(model_df['col'].values).long(),\n",
    "        )\n",
    "        graphs.append(graph)\n",
    "    \n",
    "    print(f\"\\n✅ All models processed! Total graphs created: {len(graphs):,}\")\n",
    "    return graphs\n",
    "\n",
    "\n",
    "def prepare_data(data, batch_size=4):\n",
    "    \"\"\"准备数据加载器\"\"\"\n",
    "    print('正在处理数据...')\n",
    "    all_graphs = build_spatiotemporal_graph(data)\n",
    "    print('数据处理完成！')\n",
    "    train_graphs, val_graphs = train_test_split(\n",
    "        all_graphs, test_size=0.3, random_state=42\n",
    "    )\n",
    "    train_dataset = HydroDataset(train_graphs)\n",
    "    val_dataset = HydroDataset(val_graphs)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "# Training configuration\n",
    "config = {\n",
    "    'head_input_dim': 16,\n",
    "    'conc_input_dim': 19,\n",
    "    'hidden_dim': 96,  # 增大隐藏维度\n",
    "    'num_epochs': 500,\n",
    "    'lr': 1e-3,  # 降低学习率以提高稳定性\n",
    "    'weight_decay': 1e-4,\n",
    "    'patience': 30,\n",
    "    'save_path': './saved_models/blitz_bayesian_gnn_Sub',\n",
    "    'mc_samples': 10,\n",
    "    'head_prior_sigma_1': 0.01,  # Blitz先验参数\n",
    "    'head_prior_sigma_2': 0.002,\n",
    "    'conc_prior_sigma_1': 0.05,  # 浓度模型使用较小的先验\n",
    "    'conc_prior_sigma_2': 0.002,\n",
    "    'kl_weight': 1e-4  # Blitz中的KL散度权重\n",
    "}\n",
    "\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    \"\"\"计算评估指标\"\"\"\n",
    "    if isinstance(y_true, torch.Tensor):\n",
    "        y_true = y_true.detach().cpu().numpy()\n",
    "    if isinstance(y_pred, torch.Tensor):\n",
    "        y_pred = y_pred.detach().cpu().numpy()\n",
    "\n",
    "    y_true = y_true.flatten()\n",
    "    y_pred = y_pred.flatten()\n",
    "\n",
    "    mask = ~np.isnan(y_true) & ~np.isinf(y_true) & ~np.isnan(y_pred) & ~np.isinf(y_pred)\n",
    "    y_true = y_true[mask]\n",
    "    y_pred = y_pred[mask]\n",
    "\n",
    "    mse = np.mean((y_true - y_pred) ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "    r2 = sklearn_r2_score(y_true, y_pred)\n",
    "\n",
    "    return {\n",
    "        'mse': mse,\n",
    "        'rmse': rmse,\n",
    "        'mae': mae,\n",
    "        'r2': r2\n",
    "    }\n",
    "\n",
    "def compute_uncertainty(model, data, mc_samples=10):\n",
    "    \"\"\"\n",
    "    为Blitz模型计算预测和不确定性\n",
    "    \"\"\"\n",
    "    model.train()  # Blitz在训练模式下采样权重\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(mc_samples):\n",
    "            pred = model(data)\n",
    "            predictions.append(pred)\n",
    "    \n",
    "    predictions = torch.stack(predictions, dim=0)\n",
    "    mean_pred = predictions.mean(dim=0)\n",
    "    std_pred = predictions.std(dim=0)\n",
    "    \n",
    "    return mean_pred, std_pred\n",
    "\n",
    "def compute_feature_shap_values_improved(model, data, n_samples=20, num_samples=10):\n",
    "    \"\"\"\n",
    "    计算模型对输入特征的重要性，使用Blitz贝叶斯网络\n",
    "    \"\"\"\n",
    "    model.train()  # 使用训练模式以启用贝叶斯采样\n",
    "    data = data.to(next(model.parameters()).device)\n",
    "    \n",
    "    print(f\"[FeatureSHAP] 开始特征重要性分析，抽样{n_samples}个节点...\")\n",
    "    \n",
    "    # 确保数据有必要的属性\n",
    "    if not hasattr(data, 'x') or not torch.is_tensor(data.x):\n",
    "        print(\"[FeatureSHAP] 错误: 数据缺少节点特征 (data.x)\")\n",
    "        return None, 0.0\n",
    "    \n",
    "    try:\n",
    "        # 获取当前时间步的节点\n",
    "        current_time_step = data.time_step.unique()[0].item() if hasattr(data, 'time_step') else 0\n",
    "        time_mask = data.time_step == current_time_step if hasattr(data, 'time_step') else torch.ones(data.num_nodes, dtype=torch.bool, device=data.x.device)\n",
    "        candidate_nodes = torch.where(time_mask)[0]\n",
    "        \n",
    "        if len(candidate_nodes) == 0:\n",
    "            print(\"[FeatureSHAP] 错误: 找不到满足条件的节点\")\n",
    "            return None, 0.0\n",
    "        \n",
    "        # 调整样本数\n",
    "        actual_n_samples = min(n_samples, len(candidate_nodes))\n",
    "        if actual_n_samples < n_samples:\n",
    "            print(f\"[FeatureSHAP] 警告: 候选节点数({len(candidate_nodes)})少于请求的样本数({n_samples})，调整为{actual_n_samples}\")\n",
    "        \n",
    "        # 随机抽样节点\n",
    "        sampled_indices = torch.randperm(len(candidate_nodes))[:actual_n_samples]\n",
    "        sampled_nodes = candidate_nodes[sampled_indices]\n",
    "        \n",
    "        # 特征数量\n",
    "        num_features = data.x.size(1)\n",
    "        \n",
    "        # 初始化SHAP值存储\n",
    "        all_shap_values = torch.zeros(actual_n_samples, num_features, device=data.x.device)\n",
    "        all_expected_values = torch.zeros(actual_n_samples, device=data.x.device)\n",
    "        \n",
    "        # 生成基准预测\n",
    "        baseline_preds = []\n",
    "        for _ in range(num_samples):\n",
    "            with torch.no_grad():\n",
    "                pred = model(data)\n",
    "                baseline_preds.append(pred)\n",
    "        baseline_pred = torch.stack(baseline_preds, dim=0).mean(dim=0)\n",
    "        \n",
    "        # 对每个抽样节点计算特征重要性\n",
    "        for i, node_idx in enumerate(sampled_nodes):\n",
    "            node_idx = node_idx.item()\n",
    "            original_value = baseline_pred[node_idx].item()\n",
    "            all_expected_values[i] = original_value\n",
    "            \n",
    "            # 对每个特征计算重要性\n",
    "            for feat_idx in range(num_features):\n",
    "                # 保存原始特征值\n",
    "                original_feat = data.x[:, feat_idx].clone()\n",
    "                \n",
    "                # 计算特征的平均值\n",
    "                feat_mean = original_feat.mean()\n",
    "                \n",
    "                # 掩码该特征（使用平均值替换）\n",
    "                data.x[:, feat_idx] = feat_mean\n",
    "                \n",
    "                # 蒙特卡洛采样以获取更稳定的结果\n",
    "                masked_preds = []\n",
    "                for _ in range(num_samples):\n",
    "                    with torch.no_grad():\n",
    "                        masked_pred = model(data)\n",
    "                        masked_preds.append(masked_pred)\n",
    "                \n",
    "                # 计算掩码后的平均预测\n",
    "                masked_pred = torch.stack(masked_preds, dim=0).mean(dim=0)\n",
    "                \n",
    "                # 计算特征重要性（原始预测与掩码后预测的差异）\n",
    "                shap_value = abs(original_value - masked_pred[node_idx].item())\n",
    "                all_shap_values[i, feat_idx] = shap_value\n",
    "                \n",
    "                # 恢复原始特征值\n",
    "                data.x[:, feat_idx] = original_feat\n",
    "            \n",
    "            # 每5个节点输出一次进度\n",
    "            if (i + 1) % 5 == 0 or i == len(sampled_nodes) - 1:\n",
    "                print(f\"[FeatureSHAP] 已完成 {i+1}/{len(sampled_nodes)} 个节点的分析\")\n",
    "        \n",
    "        # 计算平均SHAP值\n",
    "        avg_shap_values = all_shap_values.mean(dim=0)\n",
    "        avg_expected_value = all_expected_values.mean().item()\n",
    "        \n",
    "        # 归一化SHAP值\n",
    "        if avg_shap_values.sum() > 0:\n",
    "            avg_shap_values = avg_shap_values / avg_shap_values.sum()\n",
    "        \n",
    "        print(\"[FeatureSHAP] 特征重要性分析完成\")\n",
    "        return avg_shap_values.cpu().numpy(), avg_expected_value\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"[FeatureSHAP] 特征重要性分析出错: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, 0.0\n",
    "# 为Blitz的sample_elbo函数创建适配器损失函数\n",
    "class BlitzHeadLossAdapter(nn.Module):\n",
    "    def __init__(self, base_criterion, data, kl_weight=1e-4):\n",
    "        super().__init__()\n",
    "        self.base_criterion = base_criterion\n",
    "        self.data = data  # 保存数据对象\n",
    "        self.kl_weight = kl_weight\n",
    "    \n",
    "    def forward(self, pred, labels):\n",
    "        # 调用原始损失函数，但传入完整的data对象\n",
    "        loss, _ = self.base_criterion(pred, self.data)\n",
    "        return loss\n",
    "\n",
    "class BlitzConcLossAdapter(nn.Module):\n",
    "    def __init__(self, base_criterion, data, kl_weight=5e-5):\n",
    "        super().__init__()\n",
    "        self.base_criterion = base_criterion\n",
    "        self.data = data  # 保存数据对象\n",
    "        self.kl_weight = kl_weight\n",
    "    \n",
    "    def forward(self, pred, labels):\n",
    "        # 调用原始损失函数，但传入完整的data对象\n",
    "        loss, _ = self.base_criterion(pred, self.data)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1deb275e-907b-4b87-8ac9-5ae138360ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dual_model_improved(train_loader, val_loader, evaluation_criterion='r2'):\n",
    "    \"\"\"\n",
    "    改进的双模型训练，同时保存基于损失和R2的最佳模型\n",
    "    \n",
    "    Args:\n",
    "        train_loader: 训练数据加载器\n",
    "        val_loader: 验证数据加载器\n",
    "        evaluation_criterion: 最终评估使用的标准 ('loss' 或 'r2')\n",
    "    \"\"\"\n",
    "    try:\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"CUDA缓存已成功清除\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"无法清除CUDA缓存: {e}\")\n",
    "        return None, None, None\n",
    "    \n",
    "    # ===============================\n",
    "    # 第一阶段：训练水头模型\n",
    "    # ===============================\n",
    "    print(\"=\" * 80)\n",
    "    print(\"第一阶段：开始训练水头模型\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 根据实际数据更新特征维度\n",
    "    head_input_dim = 16  # 14个基本特征 + 2个前一时间步的水头\n",
    "    \n",
    "    # 初始化水头模型\n",
    "    head_model = BlitzHeadGNN(\n",
    "        node_features=head_input_dim,\n",
    "        spatial_dim=config['hidden_dim'],\n",
    "        temporal_dim=config['hidden_dim'],\n",
    "        prior_sigma_1=config['head_prior_sigma_1'],\n",
    "        prior_sigma_2=config['head_prior_sigma_2'],\n",
    "        dropout=0.1\n",
    "    ).to(device)\n",
    "    \n",
    "    # 损失函数 - 只需要水头损失\n",
    "    criterion_head = ImprovedPhysicsInformedLoss(alpha=0.1, kl_weight=config['kl_weight'])\n",
    "    \n",
    "    # 优化器 - 只优化水头模型参数\n",
    "    head_params = list(head_model.parameters())\n",
    "    head_optimizer = torch.optim.AdamW(head_params, lr=config['lr'], weight_decay=config['weight_decay'])\n",
    "    \n",
    "    # 学习率调度器\n",
    "    head_scheduler = CosineAnnealingWarmRestarts(\n",
    "        head_optimizer, T_0=20, T_mult=2, eta_min=1e-5\n",
    "    )\n",
    "    \n",
    "    # 跟踪变量 - 分别跟踪损失和R2\n",
    "    best_head_val_loss = float('inf')\n",
    "    best_head_r2 = float('-inf')\n",
    "    head_early_stop_counter = 0\n",
    "    head_losses = {'train': [], 'val': []}\n",
    "    \n",
    "    # 创建保存目录\n",
    "    os.makedirs(config['save_path'], exist_ok=True)\n",
    "    \n",
    "    print(\"开始训练水头模型\")\n",
    "    print(f\"水头模型参数数量: {sum(p.numel() for p in head_model.parameters() if p.requires_grad)}\")\n",
    "    \n",
    "    # 水头模型训练循环\n",
    "    for epoch in range(config['num_epochs']):\n",
    "        head_model.train()\n",
    "        train_loss = 0.0\n",
    "        train_batches = 0\n",
    "        \n",
    "        # 训练阶段\n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            try:\n",
    "                # 准备数据\n",
    "                batch = batch.to(device)\n",
    "                if hasattr(batch, 'edge_attr') and batch.edge_attr is not None:\n",
    "                    batch.edge_attr = batch.edge_attr.float()\n",
    "                \n",
    "                # 重置梯度\n",
    "                head_optimizer.zero_grad()\n",
    "                \n",
    "                # 前向传播\n",
    "                pred_head = head_model(batch)\n",
    "                \n",
    "                # 计算损失\n",
    "                criterion_output = criterion_head(pred_head, batch)\n",
    "                \n",
    "                # 处理损失函数的返回值\n",
    "                if isinstance(criterion_output, tuple):\n",
    "                    head_criterion_loss = criterion_output[0]\n",
    "                    if len(criterion_output) > 1:\n",
    "                        physics_loss = criterion_output[1]\n",
    "                        if isinstance(physics_loss, tuple):\n",
    "                            physics_loss_value = sum([p.item() if hasattr(p, 'item') else p for p in physics_loss])\n",
    "                        else:\n",
    "                            physics_loss_value = physics_loss.item() if hasattr(physics_loss, 'item') else physics_loss\n",
    "                    else:\n",
    "                        physics_loss_value = 0.0\n",
    "                else:\n",
    "                    head_criterion_loss = criterion_output\n",
    "                    physics_loss_value = 0.0\n",
    "                \n",
    "                kl_loss = head_model.nn_kl_divergence() * config['kl_weight']\n",
    "                total_loss = head_criterion_loss + kl_loss\n",
    "                \n",
    "                # 反向传播\n",
    "                total_loss.backward()\n",
    "                \n",
    "                # 梯度裁剪\n",
    "                torch.nn.utils.clip_grad_norm_(head_params, max_norm=1.0)\n",
    "                \n",
    "                # 更新参数\n",
    "                head_optimizer.step()\n",
    "                \n",
    "                # 记录损失\n",
    "                train_loss += total_loss.item()\n",
    "                train_batches += 1\n",
    "                \n",
    "                # 每50个批次输出一次详细信息\n",
    "                if batch_idx % 50 == 0:\n",
    "                    print(f\"水头模型 Epoch {epoch+1}, Batch {batch_idx}: \"\n",
    "                          f\"Total Loss: {total_loss.item():.4f}, \"\n",
    "                          f\"Criterion Loss: {head_criterion_loss.item():.4f}, \"\n",
    "                          f\"Physics Loss: {physics_loss_value:.4f}, \"\n",
    "                          f\"KL Loss: {kl_loss.item():.4f}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"水头模型训练批次 {batch_idx} 出错: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # 检查训练批次\n",
    "        if train_batches == 0:\n",
    "            print(\"警告: 水头模型本轮训练没有成功处理任何批次，跳过本轮\")\n",
    "            continue\n",
    "            \n",
    "        # 计算平均训练损失\n",
    "        avg_train_loss = train_loss / train_batches\n",
    "        \n",
    "        # 验证阶段\n",
    "        head_model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_metrics = {'mse': 0.0, 'rmse': 0.0, 'mae': 0.0, 'r2': 0.0}\n",
    "        val_batches = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch in enumerate(val_loader):\n",
    "                try:\n",
    "                    # 准备数据\n",
    "                    batch = batch.to(device)\n",
    "                    if hasattr(batch, 'edge_attr') and batch.edge_attr is not None:\n",
    "                        batch.edge_attr = batch.edge_attr.float()\n",
    "                    \n",
    "                    # 使用不确定性估计进行预测\n",
    "                    head_model.train()  # 开启dropout进行MC采样\n",
    "                    pred_head, head_std = compute_uncertainty(head_model, batch, mc_samples=config['mc_samples'])\n",
    "                    \n",
    "                    # 计算验证损失\n",
    "                    criterion_output = criterion_head(pred_head, batch)\n",
    "                    \n",
    "                    # 处理损失函数的返回值\n",
    "                    if isinstance(criterion_output, tuple):\n",
    "                        head_criterion_loss = criterion_output[0]\n",
    "                    else:\n",
    "                        head_criterion_loss = criterion_output\n",
    "                    \n",
    "                    # 计算指标\n",
    "                    metrics = compute_metrics(batch.head_y, pred_head)\n",
    "                    \n",
    "                    for k in metrics:\n",
    "                        val_metrics[k] += metrics[k]\n",
    "                    \n",
    "                    val_loss += head_criterion_loss.item()\n",
    "                    val_batches += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"水头模型验证批次 {batch_idx} 出错: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        # 计算平均验证损失和指标\n",
    "        if val_batches > 0:\n",
    "            avg_val_loss = val_loss / val_batches\n",
    "            for k in val_metrics:\n",
    "                val_metrics[k] /= val_batches\n",
    "        else:\n",
    "            print(\"警告: 水头模型本轮验证没有成功处理任何批次\")\n",
    "            avg_val_loss = float('inf')\n",
    "        \n",
    "        # 记录损失\n",
    "        head_losses['train'].append(avg_train_loss)\n",
    "        head_losses['val'].append({\n",
    "            'loss': avg_val_loss,\n",
    "            'metrics': val_metrics\n",
    "        })\n",
    "        \n",
    "        # 更新学习率\n",
    "        head_scheduler.step()\n",
    "        current_lr = head_scheduler.get_last_lr()[0]\n",
    "        \n",
    "        # 输出训练状态\n",
    "        print(f\"水头模型 Epoch {epoch+1:03d}/{config['num_epochs']} | \"\n",
    "              f\"训练损失: {avg_train_loss:.4f} | 验证损失: {avg_val_loss:.4f} | \"\n",
    "              f\"LR: {current_lr:.6f}\")\n",
    "        print(f\"水头验证指标 - MSE: {val_metrics['mse']:.4f}, \"\n",
    "              f\"RMSE: {val_metrics['rmse']:.4f}, \"\n",
    "              f\"MAE: {val_metrics['mae']:.4f}, \"\n",
    "              f\"R2: {val_metrics['r2']:.4f}\")\n",
    "        \n",
    "        # 保存基于损失的最佳模型\n",
    "        if avg_val_loss < best_head_val_loss:\n",
    "            best_head_val_loss = avg_val_loss\n",
    "            try:\n",
    "                torch.save({\n",
    "                    'model_state_dict': head_model.state_dict(),\n",
    "                    'epoch': epoch,\n",
    "                    'train_loss': avg_train_loss,\n",
    "                    'val_loss': avg_val_loss,\n",
    "                    'val_metrics': val_metrics,\n",
    "                    'config': config,\n",
    "                    'criterion': 'loss'\n",
    "                }, os.path.join(config['save_path'], 'best_head_model_loss.pth'))\n",
    "                print(f\"保存基于损失的最佳水头模型，验证损失: {best_head_val_loss:.4f}\")\n",
    "            except Exception as e:\n",
    "                print(f\"保存水头模型失败: {e}\")\n",
    "        \n",
    "        # 保存基于R2的最佳模型\n",
    "        if val_metrics['r2'] > best_head_r2:\n",
    "            best_head_r2 = val_metrics['r2']\n",
    "            head_early_stop_counter = 0  # 基于R2重置早停计数器\n",
    "            try:\n",
    "                torch.save({\n",
    "                    'model_state_dict': head_model.state_dict(),\n",
    "                    'epoch': epoch,\n",
    "                    'train_loss': avg_train_loss,\n",
    "                    'val_loss': avg_val_loss,\n",
    "                    'val_metrics': val_metrics,\n",
    "                    'config': config,\n",
    "                    'criterion': 'r2'\n",
    "                }, os.path.join(config['save_path'], 'best_head_model_r2.pth'))\n",
    "                print(f\"保存基于R2的最佳水头模型，R2: {best_head_r2:.4f}\")\n",
    "            except Exception as e:\n",
    "                print(f\"保存水头模型失败: {e}\")\n",
    "        else:\n",
    "            head_early_stop_counter += 1\n",
    "        \n",
    "        # 早停检查（基于R2）\n",
    "        if head_early_stop_counter >= config['patience']:\n",
    "            print(f\"水头模型早停触发! 在第{epoch+1}个epoch停止训练\")\n",
    "            break\n",
    "        \n",
    "        # 清理GPU内存\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"\\n水头模型训练完成!\")\n",
    "    print(f\"基于损失的最佳验证损失: {best_head_val_loss:.4f}\")\n",
    "    print(f\"基于R2的最佳R2分数: {best_head_r2:.4f}\")\n",
    "    \n",
    "    # ===============================\n",
    "    # 第二阶段：训练浓度模型\n",
    "    # ===============================\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"第二阶段：开始训练浓度模型\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 根据评估标准选择水头模型\n",
    "    head_model_file = f'best_head_model_{evaluation_criterion}.pth'\n",
    "    try:\n",
    "        checkpoint = torch.load(os.path.join(config['save_path'], head_model_file),weights_only=False)\n",
    "        head_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        print(f\"成功加载基于{evaluation_criterion}的最佳水头模型\")\n",
    "    except Exception as e:\n",
    "        print(f\"加载水头模型失败，使用当前模型: {e}\")\n",
    "    \n",
    "    # 固定水头模型参数\n",
    "    for param in head_model.parameters():\n",
    "        param.requires_grad = False\n",
    "    head_model.eval()\n",
    "    \n",
    "    # 初始化浓度模型\n",
    "    conc_input_dim = 19  # 基础特征14 + 前一/前二时间步水头2 + 前一/前二时间步浓度2\n",
    "    conc_model = BlitzConcGNN(\n",
    "        node_features=conc_input_dim,  # 18维\n",
    "        spatial_dim=config['hidden_dim'],\n",
    "        temporal_dim=config['hidden_dim'],\n",
    "        prior_sigma_1=0.1,\n",
    "        prior_sigma_2=0.01,\n",
    "        dropout=0.1,\n",
    "        posterior_mu_init=0.0,\n",
    "        posterior_rho_init=-3.0\n",
    "    ).to(device)\n",
    "    \n",
    "    # 浓度模型损失函数\n",
    "    criterion_conc = ImprovedConcLoss(kl_weight=config['kl_weight'], l1_weight=1e-5)\n",
    "    \n",
    "    # 浓度模型优化器\n",
    "    conc_params = list(conc_model.parameters())\n",
    "    conc_optimizer = torch.optim.AdamW(conc_params, lr=config['lr'] * 0.8, weight_decay=config['weight_decay'])\n",
    "    \n",
    "    # 浓度模型学习率调度器\n",
    "    conc_scheduler = CosineAnnealingWarmRestarts(\n",
    "        conc_optimizer, T_0=15, T_mult=2, eta_min=1e-6\n",
    "    )\n",
    "    \n",
    "    # 浓度模型跟踪变量 - 分别跟踪损失和R2\n",
    "    best_conc_val_loss = float('inf')\n",
    "    best_conc_r2 = float('-inf')\n",
    "    conc_early_stop_counter = 0\n",
    "    conc_losses = {'train': [], 'val': []}\n",
    "    \n",
    "    print(f\"浓度模型参数数量: {sum(p.numel() for p in conc_model.parameters() if p.requires_grad)}\")\n",
    "    \n",
    "    # 浓度模型训练循环\n",
    "    for epoch in range(config['num_epochs']):\n",
    "        conc_model.train()\n",
    "        train_loss = 0.0\n",
    "        train_batches = 0\n",
    "        \n",
    "        # 训练阶段\n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            try:\n",
    "                # 准备数据\n",
    "                batch = batch.to(device)\n",
    "                if hasattr(batch, 'edge_attr') and batch.edge_attr is not None:\n",
    "                    batch.edge_attr = batch.edge_attr.float()\n",
    "                \n",
    "                # 使用固定的水头模型预测水头\n",
    "                with torch.no_grad():\n",
    "                    pred_head = head_model(batch)\n",
    "                \n",
    "                # 重置梯度\n",
    "                conc_optimizer.zero_grad()\n",
    "                \n",
    "                # 浓度模型前向传播，使用预测的水头\n",
    "                pred_conc = conc_model(batch, pred_head)\n",
    "                \n",
    "                # 计算损失\n",
    "                criterion_output = criterion_conc(pred_conc, batch, conc_model)\n",
    "                \n",
    "                # 处理损失函数的返回值\n",
    "                if isinstance(criterion_output, tuple):\n",
    "                    conc_criterion_loss = criterion_output[0]\n",
    "                    if len(criterion_output) > 1:\n",
    "                        loss_components = criterion_output[1]\n",
    "                        if isinstance(loss_components, tuple) and len(loss_components) >= 3:\n",
    "                            mse_loss, kl_loss_val, l1_reg = loss_components[:3]\n",
    "                        else:\n",
    "                            mse_loss, kl_loss_val, l1_reg = 0.0, 0.0, 0.0\n",
    "                    else:\n",
    "                        mse_loss, kl_loss_val, l1_reg = 0.0, 0.0, 0.0\n",
    "                else:\n",
    "                    conc_criterion_loss = criterion_output\n",
    "                    mse_loss, kl_loss_val, l1_reg = 0.0, 0.0, 0.0\n",
    "                \n",
    "                kl_loss = conc_model.nn_kl_divergence() * config['kl_weight']\n",
    "                total_loss = conc_criterion_loss + kl_loss\n",
    "                \n",
    "                # 反向传播\n",
    "                total_loss.backward()\n",
    "                \n",
    "                # 梯度裁剪\n",
    "                torch.nn.utils.clip_grad_norm_(conc_params, max_norm=1.0)\n",
    "                \n",
    "                # 更新参数\n",
    "                conc_optimizer.step()\n",
    "                \n",
    "                # 记录损失\n",
    "                train_loss += total_loss.item()\n",
    "                train_batches += 1\n",
    "                \n",
    "                # 每50个批次输出一次详细信息\n",
    "                if batch_idx % 50 == 0:\n",
    "                    print(f\"浓度模型 Epoch {epoch+1}, Batch {batch_idx}: \"\n",
    "                          f\"Total Loss: {total_loss.item():.4f}, \"\n",
    "                          f\"Criterion Loss: {conc_criterion_loss.item():.4f}, \"\n",
    "                          f\"MSE: {mse_loss:.4f}, \"\n",
    "                          f\"KL Loss: {kl_loss.item():.4f}, \"\n",
    "                          f\"L1 Reg: {l1_reg:.4f}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"浓度模型训练批次 {batch_idx} 出错: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # 检查训练批次\n",
    "        if train_batches == 0:\n",
    "            print(\"警告: 浓度模型本轮训练没有成功处理任何批次，跳过本轮\")\n",
    "            continue\n",
    "            \n",
    "        # 计算平均训练损失\n",
    "        avg_train_loss = train_loss / train_batches\n",
    "        \n",
    "        # 验证阶段\n",
    "        conc_model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_metrics = {'mse': 0.0, 'rmse': 0.0, 'mae': 0.0, 'r2': 0.0}\n",
    "        val_batches = 0\n",
    "        \n",
    "        # 用于存储预测和真实值\n",
    "        all_conc_predictions = []\n",
    "        all_conc_targets = []\n",
    "        all_conc_uncertainties = []\n",
    "        all_head_predictions = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch in enumerate(val_loader):\n",
    "                try:\n",
    "                    # 准备数据\n",
    "                    batch = batch.to(device)\n",
    "                    if hasattr(batch, 'edge_attr') and batch.edge_attr is not None:\n",
    "                        batch.edge_attr = batch.edge_attr.float()\n",
    "                    \n",
    "                    # 使用水头模型预测水头\n",
    "                    pred_head = head_model(batch)\n",
    "                    \n",
    "                    # 使用不确定性估计进行浓度预测\n",
    "                    conc_model.train()  # 开启dropout进行MC采样\n",
    "                    pred_conc, conc_std = compute_uncertainty(conc_model, batch, mc_samples=config['mc_samples'])\n",
    "                    \n",
    "                    # 计算验证损失\n",
    "                    criterion_output = criterion_conc(pred_conc, batch, conc_model)\n",
    "                    \n",
    "                    # 处理损失函数的返回值\n",
    "                    if isinstance(criterion_output, tuple):\n",
    "                        conc_criterion_loss = criterion_output[0]\n",
    "                    else:\n",
    "                        conc_criterion_loss = criterion_output\n",
    "                    \n",
    "                    # 计算指标\n",
    "                    metrics = compute_metrics(batch.y, pred_conc)\n",
    "                    \n",
    "                    for k in metrics:\n",
    "                        val_metrics[k] += metrics[k]\n",
    "                    \n",
    "                    val_loss += conc_criterion_loss.item()\n",
    "                    val_batches += 1\n",
    "                    \n",
    "                    # 收集预测结果用于后续分析\n",
    "                    all_conc_predictions.append(pred_conc.cpu().numpy())\n",
    "                    all_conc_targets.append(batch.y.cpu().numpy())\n",
    "                    all_conc_uncertainties.append(conc_std.cpu().numpy())\n",
    "                    all_head_predictions.append(pred_head.cpu().numpy())\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"浓度模型验证批次 {batch_idx} 出错: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        # 计算平均验证损失和指标\n",
    "        if val_batches > 0:\n",
    "            avg_val_loss = val_loss / val_batches\n",
    "            for k in val_metrics:\n",
    "                val_metrics[k] /= val_batches\n",
    "        else:\n",
    "            print(\"警告: 浓度模型本轮验证没有成功处理任何批次\")\n",
    "            avg_val_loss = float('inf')\n",
    "        \n",
    "        # 记录损失\n",
    "        conc_losses['train'].append(avg_train_loss)\n",
    "        conc_losses['val'].append({\n",
    "            'loss': avg_val_loss,\n",
    "            'metrics': val_metrics\n",
    "        })\n",
    "        \n",
    "        # 更新学习率\n",
    "        conc_scheduler.step()\n",
    "        current_lr = conc_scheduler.get_last_lr()[0]\n",
    "        \n",
    "        # 输出训练状态\n",
    "        print(f\"浓度模型 Epoch {epoch+1:03d}/{config['num_epochs']} | \"\n",
    "              f\"训练损失: {avg_train_loss:.4f} | 验证损失: {avg_val_loss:.4f} | \"\n",
    "              f\"LR: {current_lr:.6f}\")\n",
    "        print(f\"浓度验证指标 - MSE: {val_metrics['mse']:.4f}, \"\n",
    "              f\"RMSE: {val_metrics['rmse']:.4f}, \"\n",
    "              f\"MAE: {val_metrics['mae']:.4f}, \"\n",
    "              f\"R2: {val_metrics['r2']:.4f}\")\n",
    "        \n",
    "        # 保存基于损失的最佳浓度模型\n",
    "        if avg_val_loss < best_conc_val_loss:\n",
    "            best_conc_val_loss = avg_val_loss\n",
    "            try:\n",
    "                torch.save({\n",
    "                    'model_state_dict': conc_model.state_dict(),\n",
    "                    'epoch': epoch,\n",
    "                    'train_loss': avg_train_loss,\n",
    "                    'val_loss': avg_val_loss,\n",
    "                    'val_metrics': val_metrics,\n",
    "                    'config': config,\n",
    "                    'criterion': 'loss'\n",
    "                }, os.path.join(config['save_path'], 'best_conc_model_loss.pth'))\n",
    "                \n",
    "                # 保存预测结果\n",
    "                if all_conc_predictions:\n",
    "                    np.save(os.path.join(config['save_path'], 'best_conc_predictions_loss.npy'), \n",
    "                           np.concatenate(all_conc_predictions, axis=0))\n",
    "                    np.save(os.path.join(config['save_path'], 'best_conc_targets_loss.npy'), \n",
    "                           np.concatenate(all_conc_targets, axis=0))\n",
    "                    np.save(os.path.join(config['save_path'], 'best_conc_uncertainties_loss.npy'), \n",
    "                           np.concatenate(all_conc_uncertainties, axis=0))\n",
    "                \n",
    "                print(f\"保存基于损失的最佳浓度模型，验证损失: {best_conc_val_loss:.4f}\")\n",
    "            except Exception as e:\n",
    "                print(f\"保存浓度模型失败: {e}\")\n",
    "        \n",
    "        # 保存基于R2的最佳浓度模型\n",
    "        if val_metrics['r2'] > best_conc_r2:\n",
    "            best_conc_r2 = val_metrics['r2']\n",
    "            conc_early_stop_counter = 0  # 基于R2重置早停计数器\n",
    "            try:\n",
    "                torch.save({\n",
    "                    'model_state_dict': conc_model.state_dict(),\n",
    "                    'epoch': epoch,\n",
    "                    'train_loss': avg_train_loss,\n",
    "                    'val_loss': avg_val_loss,\n",
    "                    'val_metrics': val_metrics,\n",
    "                    'config': config,\n",
    "                    'criterion': 'r2'\n",
    "                }, os.path.join(config['save_path'], 'best_conc_model_r2.pth'))\n",
    "                \n",
    "                # 保存预测结果\n",
    "                if all_conc_predictions:\n",
    "                    np.save(os.path.join(config['save_path'], 'best_conc_predictions_r2.npy'), \n",
    "                           np.concatenate(all_conc_predictions, axis=0))\n",
    "                    np.save(os.path.join(config['save_path'], 'best_conc_targets_r2.npy'), \n",
    "                           np.concatenate(all_conc_targets, axis=0))\n",
    "                    np.save(os.path.join(config['save_path'], 'best_conc_uncertainties_r2.npy'), \n",
    "                           np.concatenate(all_conc_uncertainties, axis=0))\n",
    "                \n",
    "                print(f\"保存基于R2的最佳浓度模型，R2: {best_conc_r2:.4f}\")\n",
    "            except Exception as e:\n",
    "                print(f\"保存浓度模型失败: {e}\")\n",
    "        else:\n",
    "            conc_early_stop_counter += 1\n",
    "        \n",
    "        # 早停检查（基于R2）\n",
    "        if conc_early_stop_counter >= config['patience']:\n",
    "            print(f\"浓度模型早停触发! 在第{epoch+1}个epoch停止训练\")\n",
    "            break\n",
    "        \n",
    "        # 清理GPU内存\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"\\n浓度模型训练完成!\")\n",
    "    print(f\"基于损失的最佳验证损失: {best_conc_val_loss:.4f}\")\n",
    "    print(f\"基于R2的最佳R2分数: {best_conc_r2:.4f}\")\n",
    "    \n",
    "    # ===============================\n",
    "    # 保存训练历史和可视化\n",
    "    # ===============================\n",
    "    try:\n",
    "        # 保存水头模型训练历史\n",
    "        head_history_data = []\n",
    "        for i, (train_loss, val_data) in enumerate(zip(head_losses['train'], head_losses['val'])):\n",
    "            head_history_data.append({\n",
    "                'epoch': i + 1,\n",
    "                'train_loss': train_loss,\n",
    "                'val_loss': val_data['loss'],\n",
    "                'val_mse': val_data['metrics']['mse'],\n",
    "                'val_rmse': val_data['metrics']['rmse'],\n",
    "                'val_mae': val_data['metrics']['mae'],\n",
    "                'val_r2': val_data['metrics']['r2']\n",
    "            })\n",
    "        \n",
    "        if head_history_data:\n",
    "            head_history_df = pd.DataFrame(head_history_data)\n",
    "            head_history_df.to_csv(os.path.join(config['save_path'], 'head_training_history.csv'), index=False)\n",
    "        \n",
    "        # 保存浓度模型训练历史\n",
    "        conc_history_data = []\n",
    "        for i, (train_loss, val_data) in enumerate(zip(conc_losses['train'], conc_losses['val'])):\n",
    "            conc_history_data.append({\n",
    "                'epoch': i + 1,\n",
    "                'train_loss': train_loss,\n",
    "                'val_loss': val_data['loss'],\n",
    "                'val_mse': val_data['metrics']['mse'],\n",
    "                'val_rmse': val_data['metrics']['rmse'],\n",
    "                'val_mae': val_data['metrics']['mae'],\n",
    "                'val_r2': val_data['metrics']['r2']\n",
    "            })\n",
    "        \n",
    "        if conc_history_data:\n",
    "            conc_history_df = pd.DataFrame(conc_history_data)\n",
    "            conc_history_df.to_csv(os.path.join(config['save_path'], 'conc_training_history.csv'), index=False)\n",
    "        \n",
    "        # 绘制双模型训练曲线，包含最佳点标记\n",
    "        if head_history_data and conc_history_data:\n",
    "            plt.figure(figsize=(20, 12))\n",
    "            \n",
    "            # 水头模型曲线\n",
    "            plt.subplot(2, 4, 1)\n",
    "            plt.plot(head_history_df['epoch'], head_history_df['train_loss'], 'b-', label='Head Train Loss')\n",
    "            plt.plot(head_history_df['epoch'], head_history_df['val_loss'], 'r-', label='Head Val Loss')\n",
    "            # 标记最佳损失点\n",
    "            best_loss_epoch = head_history_df.loc[head_history_df['val_loss'].idxmin(), 'epoch']\n",
    "            best_loss_value = head_history_df['val_loss'].min()\n",
    "            plt.scatter(best_loss_epoch, best_loss_value, color='red', s=100, marker='*', \n",
    "                       label=f'Best Loss (E{best_loss_epoch})')\n",
    "            plt.title('Head Model: Training and Validation Loss')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            \n",
    "            plt.subplot(2, 4, 2)\n",
    "            plt.plot(head_history_df['epoch'], head_history_df['val_r2'], 'g-', label='Head R2')\n",
    "            # 标记最佳R2点\n",
    "            best_r2_epoch = head_history_df.loc[head_history_df['val_r2'].idxmax(), 'epoch']\n",
    "            best_r2_value = head_history_df['val_r2'].max()\n",
    "            plt.scatter(best_r2_epoch, best_r2_value, color='green', s=100, marker='*', \n",
    "                       label=f'Best R2 (E{best_r2_epoch})')\n",
    "            plt.title('Head Model: Validation R2 Score')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('R2')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            \n",
    "            plt.subplot(2, 4, 3)\n",
    "            plt.plot(head_history_df['epoch'], head_history_df['val_mse'], 'orange', label='Head MSE')\n",
    "            plt.title('Head Model: Validation MSE')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('MSE')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            \n",
    "            plt.subplot(2, 4, 4)\n",
    "            plt.plot(head_history_df['epoch'], head_history_df['val_rmse'], 'purple', label='Head RMSE')\n",
    "            plt.title('Head Model: Validation RMSE')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('RMSE')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            \n",
    "            # 浓度模型曲线\n",
    "            plt.subplot(2, 4, 5)\n",
    "            plt.plot(conc_history_df['epoch'], conc_history_df['train_loss'], 'b--', label='Conc Train Loss')\n",
    "            plt.plot(conc_history_df['epoch'], conc_history_df['val_loss'], 'r--', label='Conc Val Loss')\n",
    "            # 标记最佳损失点\n",
    "            best_loss_epoch = conc_history_df.loc[conc_history_df['val_loss'].idxmin(), 'epoch']\n",
    "            best_loss_value = conc_history_df['val_loss'].min()\n",
    "            plt.scatter(best_loss_epoch, best_loss_value, color='red', s=100, marker='*', \n",
    "                       label=f'Best Loss (E{best_loss_epoch})')\n",
    "            plt.title('Conc Model: Training and Validation Loss')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            \n",
    "            plt.subplot(2, 4, 6)\n",
    "            plt.plot(conc_history_df['epoch'], conc_history_df['val_r2'], 'g--', label='Conc R2')\n",
    "            # 标记最佳R2点\n",
    "            best_r2_epoch = conc_history_df.loc[conc_history_df['val_r2'].idxmax(), 'epoch']\n",
    "            best_r2_value = conc_history_df['val_r2'].max()\n",
    "            plt.scatter(best_r2_epoch, best_r2_value, color='green', s=100, marker='*', \n",
    "                       label=f'Best R2 (E{best_r2_epoch})')\n",
    "            plt.title('Conc Model: Validation R2 Score')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('R2')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            \n",
    "            plt.subplot(2, 4, 7)\n",
    "            plt.plot(conc_history_df['epoch'], conc_history_df['val_mse'], 'orange', linestyle='--', label='Conc MSE')\n",
    "            plt.title('Conc Model: Validation MSE')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('MSE')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            \n",
    "            plt.subplot(2, 4, 8)\n",
    "            plt.plot(conc_history_df['epoch'], conc_history_df['val_rmse'], 'purple', linestyle='--', label='Conc RMSE')\n",
    "            plt.title('Conc Model: Validation RMSE')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('RMSE')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(config['save_path'], 'dual_model_training_curves_improved.png'), \n",
    "                       dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            \n",
    "            print(f\"改进的双模型训练曲线已保存\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"保存训练历史或绘图失败: {e}\")\n",
    "    \n",
    "    # 重新启用水头模型的梯度计算（如果需要）\n",
    "    for param in head_model.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"双模型训练完成总结:\")\n",
    "    print(f\"水头模型 - 基于损失的最佳验证损失: {best_head_val_loss:.4f}\")\n",
    "    print(f\"水头模型 - 基于R2的最佳R2分数: {best_head_r2:.4f}\")\n",
    "    print(f\"浓度模型 - 基于损失的最佳验证损失: {best_conc_val_loss:.4f}\")\n",
    "    print(f\"浓度模型 - 基于R2的最佳R2分数: {best_conc_r2:.4f}\")\n",
    "    print(f\"评估将使用基于{evaluation_criterion}的模型\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    return head_model, conc_model, {'head': head_losses, 'conc': conc_losses}\n",
    "\n",
    "def compute_uncertainty_with_func(forward_func, data, mc_samples=30):\n",
    "    \"\"\"\n",
    "    计算模型预测的不确定性，支持自定义前向传播函数\n",
    "    \n",
    "    参数:\n",
    "        forward_func: 前向传播函数，接受data参数\n",
    "        data: 输入数据\n",
    "        mc_samples: Monte Carlo采样次数\n",
    "    \n",
    "    返回:\n",
    "        pred_mean: 预测的均值\n",
    "        pred_std: 预测的标准差（不确定性）\n",
    "    \"\"\"\n",
    "    all_preds = []\n",
    "    for _ in range(mc_samples):\n",
    "        with torch.no_grad():\n",
    "            # 使用传入的函数进行前向传播\n",
    "            pred = forward_func(data)\n",
    "            all_preds.append(pred)\n",
    "    \n",
    "    # 计算预测的均值和标准差\n",
    "    all_preds = torch.stack(all_preds, dim=0)\n",
    "    pred_mean = all_preds.mean(dim=0)\n",
    "    pred_std = all_preds.std(dim=0)\n",
    "    \n",
    "    return pred_mean, pred_std\n",
    "\n",
    "def evaluate_dual_model_improved(head_model, conc_model, val_loader, evaluation_criterion='loss'):\n",
    "    \"\"\"\n",
    "    改进的双模型评估，使用compute_uncertainty_with_func进行不确定性估计\n",
    "    \n",
    "    Args:\n",
    "        head_model: 水头预测模型\n",
    "        conc_model: 浓度预测模型\n",
    "        val_loader: 验证数据加载器\n",
    "        evaluation_criterion: 评估标准 ('loss' 或 'r2')\n",
    "    \"\"\"\n",
    "    print(f\"开始评估双模型性能（基于{evaluation_criterion}标准）...\")\n",
    "    \n",
    "    # 加载指定标准的最佳模型权重\n",
    "    try:\n",
    "        head_model_file = f'best_head_model_{evaluation_criterion}.pth'\n",
    "        head_checkpoint = torch.load(os.path.join(config['save_path'], head_model_file), weights_only=False)\n",
    "        head_model.load_state_dict(head_checkpoint['model_state_dict'])\n",
    "        \n",
    "        conc_model_file = f'best_conc_model_{evaluation_criterion}.pth'\n",
    "        conc_checkpoint = torch.load(os.path.join(config['save_path'], conc_model_file), weights_only=False)\n",
    "        conc_model.load_state_dict(conc_checkpoint['model_state_dict'])\n",
    "        \n",
    "        print(f\"成功加载基于{evaluation_criterion}的最佳模型权重\")\n",
    "        print(f\"水头模型来自epoch {head_checkpoint['epoch']}, 验证损失: {head_checkpoint['val_loss']:.4f}, R2: {head_checkpoint['val_metrics']['r2']:.4f}\")\n",
    "        print(f\"浓度模型来自epoch {conc_checkpoint['epoch']}, 验证损失: {conc_checkpoint['val_loss']:.4f}, R2: {conc_checkpoint['val_metrics']['r2']:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"加载模型权重失败，使用当前权重: {e}\")\n",
    "    \n",
    "    # 设置模型为训练模式以进行MC dropout\n",
    "    head_model.train()  \n",
    "    conc_model.train()\n",
    "    \n",
    "    # 确保结果目录存在\n",
    "    results_dir = os.path.join(config['save_path'], 'evaluation_results')\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    # 存储所有预测结果\n",
    "    all_head_preds = []\n",
    "    all_head_targets = []\n",
    "    all_head_uncertainties = []\n",
    "    all_conc_preds = []\n",
    "    all_conc_targets = []\n",
    "    all_conc_uncertainties = []\n",
    "    \n",
    "    # 存储详细预测结果\n",
    "    predictions = []\n",
    "    uncertainties = []\n",
    "    \n",
    "    # 定义前向传播函数\n",
    "    def head_forward_func(batch):\n",
    "        \"\"\"水头模型前向传播函数\"\"\"\n",
    "        return head_model(batch)\n",
    "    \n",
    "    def conc_forward_func(batch_with_head):\n",
    "        \"\"\"浓度模型前向传播函数\"\"\"\n",
    "        return conc_model(batch_with_head)\n",
    "    \n",
    "    print(\"开始处理验证数据...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(val_loader):\n",
    "            try:\n",
    "                batch = batch.to(device)\n",
    "                if hasattr(batch, 'edge_attr') and batch.edge_attr is not None:\n",
    "                    batch.edge_attr = batch.edge_attr.float()\n",
    "                \n",
    "                # 使用新的不确定性计算函数进行水头预测\n",
    "                head_pred, head_std = compute_uncertainty_with_func(\n",
    "                    head_forward_func, batch, mc_samples=config.get('mc_samples', 30)\n",
    "                )\n",
    "                \n",
    "                # 为浓度预测准备输入（包含预测的水头）\n",
    "                batch_conc = batch.clone()\n",
    "                # 假设需要将预测的水头添加到特征中\n",
    "                if hasattr(batch_conc, 'x'):\n",
    "                    # 将预测的水头添加到节点特征中\n",
    "                    batch_conc.x = torch.cat([batch.x, head_pred.detach()], dim=1)\n",
    "                else:\n",
    "                    # 如果没有x属性，创建一个包含预测水头的特征\n",
    "                    batch_conc.x = head_pred.detach()\n",
    "                \n",
    "                # 使用新的不确定性计算函数进行浓度预测\n",
    "                conc_pred, conc_std = compute_uncertainty_with_func(\n",
    "                    conc_forward_func, batch_conc, mc_samples=config.get('mc_samples', 30)\n",
    "                )\n",
    "                \n",
    "                # 收集结果\n",
    "                all_head_preds.append(head_pred.cpu().numpy())\n",
    "                all_head_targets.append(batch.head_y.cpu().numpy())\n",
    "                all_head_uncertainties.append(head_std.cpu().numpy())\n",
    "                all_conc_preds.append(conc_pred.cpu().numpy())\n",
    "                all_conc_targets.append(batch.y.cpu().numpy())\n",
    "                all_conc_uncertainties.append(conc_std.cpu().numpy())\n",
    "                \n",
    "                # 保存详细预测结果\n",
    "                batch_predictions = {\n",
    "                    'batch_idx': batch_idx,\n",
    "                    'pred_head': head_pred.cpu().numpy().flatten(),\n",
    "                    'true_head': batch.head_y.cpu().numpy().flatten(),\n",
    "                    'pred_conc': conc_pred.cpu().numpy().flatten(),\n",
    "                    'true_conc': batch.y.cpu().numpy().flatten()\n",
    "                }\n",
    "                \n",
    "                # 如果有空间信息，也保存\n",
    "                if hasattr(batch, 'row') and hasattr(batch, 'col'):\n",
    "                    batch_predictions['row'] = batch.row.cpu().numpy()\n",
    "                    batch_predictions['col'] = batch.col.cpu().numpy()\n",
    "                if hasattr(batch, 'time_step'):\n",
    "                    batch_predictions['time_step'] = batch.time_step.cpu().numpy()\n",
    "                \n",
    "                predictions.append(batch_predictions)\n",
    "                \n",
    "                # 保存不确定性估计\n",
    "                batch_uncertainties = {\n",
    "                    'batch_idx': batch_idx,\n",
    "                    'head_std': head_std.cpu().numpy().flatten(),\n",
    "                    'conc_std': conc_std.cpu().numpy().flatten()\n",
    "                }\n",
    "                \n",
    "                # 如果有空间信息，也保存\n",
    "                if hasattr(batch, 'row') and hasattr(batch, 'col'):\n",
    "                    batch_uncertainties['row'] = batch.row.cpu().numpy()\n",
    "                    batch_uncertainties['col'] = batch.col.cpu().numpy()\n",
    "                if hasattr(batch, 'time_step'):\n",
    "                    batch_uncertainties['time_step'] = batch.time_step.cpu().numpy()\n",
    "                \n",
    "                uncertainties.append(batch_uncertainties)\n",
    "                \n",
    "                # 每10个批次输出进度\n",
    "                if batch_idx % 10 == 0:\n",
    "                    print(f\"处理批次 {batch_idx}/{len(val_loader)}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"评估批次 {batch_idx} 出错: {e}\")\n",
    "                continue\n",
    "    \n",
    "    # 合并所有预测结果\n",
    "    all_head_preds = np.concatenate(all_head_preds, axis=0)\n",
    "    all_head_targets = np.concatenate(all_head_targets, axis=0)\n",
    "    all_head_uncertainties = np.concatenate(all_head_uncertainties, axis=0)\n",
    "    all_conc_preds = np.concatenate(all_conc_preds, axis=0)\n",
    "    all_conc_targets = np.concatenate(all_conc_targets, axis=0)\n",
    "    all_conc_uncertainties = np.concatenate(all_conc_uncertainties, axis=0)\n",
    "    \n",
    "    # 计算指标\n",
    "    head_metrics = compute_metrics(all_head_targets, all_head_preds)\n",
    "    conc_metrics = compute_metrics(all_conc_targets, all_conc_preds)\n",
    "    \n",
    "    print(f\"\\n水头模型评估结果（基于{evaluation_criterion}）:\")\n",
    "    for metric, value in head_metrics.items():\n",
    "        print(f\"  {metric.upper()}: {value:.4f}\")\n",
    "    \n",
    "    print(f\"\\n浓度模型评估结果（基于{evaluation_criterion}）:\")\n",
    "    for metric, value in conc_metrics.items():\n",
    "        print(f\"  {metric.upper()}: {value:.4f}\")\n",
    "    \n",
    "    # 生成可视化图表\n",
    "    print(\"生成可视化图表...\")\n",
    "    \n",
    "    # 1. 水头预测散点图（带不确定性）\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.errorbar(all_head_targets.flatten(), all_head_preds.flatten(), \n",
    "                yerr=all_head_uncertainties.flatten(), fmt='o', alpha=0.3, \n",
    "                ecolor='lightgray', elinewidth=0.5, capsize=0, markersize=2)\n",
    "    \n",
    "    min_val = min(np.min(all_head_targets), np.min(all_head_preds))\n",
    "    max_val = max(np.max(all_head_targets), np.max(all_head_preds))\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2)\n",
    "    \n",
    "    plt.xlabel('True Head Values', fontsize=14)\n",
    "    plt.ylabel('Predicted Head Values', fontsize=14)\n",
    "    plt.title(f'Head Predictions (R² = {head_metrics[\"r2\"]:.4f}, RMSE = {head_metrics[\"rmse\"]:.4f})', fontsize=16)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(results_dir, f'head_predictions_{evaluation_criterion}.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. 浓度预测散点图（带不确定性）\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.errorbar(all_conc_targets.flatten(), all_conc_preds.flatten(), \n",
    "                yerr=all_conc_uncertainties.flatten(), fmt='o', alpha=0.3,\n",
    "                ecolor='lightgray', elinewidth=0.5, capsize=0, markersize=2)\n",
    "    \n",
    "    min_val = min(np.min(all_conc_targets), np.min(all_conc_preds))\n",
    "    max_val = max(np.max(all_conc_targets), np.max(all_conc_preds))\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2)\n",
    "    \n",
    "    plt.xlabel('True Concentration Values', fontsize=14)\n",
    "    plt.ylabel('Predicted Concentration Values', fontsize=14)\n",
    "    plt.title(f'Concentration Predictions (R² = {conc_metrics[\"r2\"]:.4f}, RMSE = {conc_metrics[\"rmse\"]:.4f})', fontsize=16)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(results_dir, f'conc_predictions_{evaluation_criterion}.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 3. 不确定性分布图\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    ax1.hist(all_head_uncertainties.flatten(), bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
    "    ax1.set_xlabel('Head Uncertainty (Std)', fontsize=12)\n",
    "    ax1.set_ylabel('Frequency', fontsize=12)\n",
    "    ax1.set_title('Head Uncertainty Distribution', fontsize=14)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax2.hist(all_conc_uncertainties.flatten(), bins=50, alpha=0.7, color='green', edgecolor='black')\n",
    "    ax2.set_xlabel('Concentration Uncertainty (Std)', fontsize=12)\n",
    "    ax2.set_ylabel('Frequency', fontsize=12)\n",
    "    ax2.set_title('Concentration Uncertainty Distribution', fontsize=14)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(results_dir, f'uncertainty_distributions_{evaluation_criterion}.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 4. 不确定性 vs 误差关系图\n",
    "    head_errors = np.abs(all_head_preds.flatten() - all_head_targets.flatten())\n",
    "    conc_errors = np.abs(all_conc_preds.flatten() - all_conc_targets.flatten())\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    ax1.scatter(all_head_uncertainties.flatten(), head_errors, alpha=0.5, s=10)\n",
    "    head_corr = np.corrcoef(all_head_uncertainties.flatten(), head_errors)[0, 1]\n",
    "    ax1.set_xlabel('Head Uncertainty (Std)', fontsize=12)\n",
    "    ax1.set_ylabel('Head Absolute Error', fontsize=12)\n",
    "    ax1.set_title(f'Head: Uncertainty vs Error (r={head_corr:.3f})', fontsize=14)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax2.scatter(all_conc_uncertainties.flatten(), conc_errors, alpha=0.5, s=10)\n",
    "    conc_corr = np.corrcoef(all_conc_uncertainties.flatten(), conc_errors)[0, 1]\n",
    "    ax2.set_xlabel('Concentration Uncertainty (Std)', fontsize=12)\n",
    "    ax2.set_ylabel('Concentration Absolute Error', fontsize=12)\n",
    "    ax2.set_title(f'Concentration: Uncertainty vs Error (r={conc_corr:.3f})', fontsize=14)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(results_dir, f'uncertainty_vs_error_{evaluation_criterion}.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 保存评估结果\n",
    "    evaluation_results = {\n",
    "        'criterion': evaluation_criterion,\n",
    "        'head_metrics': head_metrics,\n",
    "        'conc_metrics': conc_metrics,\n",
    "        'head_predictions': all_head_preds,\n",
    "        'head_targets': all_head_targets,\n",
    "        'head_uncertainties': all_head_uncertainties,\n",
    "        'conc_predictions': all_conc_preds,\n",
    "        'conc_targets': all_conc_targets,\n",
    "        'conc_uncertainties': all_conc_uncertainties,\n",
    "        'detailed_predictions': predictions,\n",
    "        'detailed_uncertainties': uncertainties\n",
    "    }\n",
    "    \n",
    "    # 保存为文件\n",
    "    filename = f'dual_model_evaluation_{evaluation_criterion}.npy'\n",
    "    np.save(os.path.join(config['save_path'], filename), evaluation_results)\n",
    "    print(f\"\\n评估结果已保存到: {config['save_path']}/{filename}\")\n",
    "    \n",
    "    # 保存CSV格式的预测结果\n",
    "    if predictions:\n",
    "        pred_dfs = []\n",
    "        for pred_dict in predictions:\n",
    "            pred_df = pd.DataFrame({k: v for k, v in pred_dict.items() if not k.startswith('batch')})\n",
    "            pred_dfs.append(pred_df)\n",
    "        \n",
    "        if pred_dfs:\n",
    "            predictions_df = pd.concat(pred_dfs, ignore_index=True)\n",
    "            predictions_df.to_csv(os.path.join(results_dir, f'predictions_{evaluation_criterion}.csv'), index=False)\n",
    "            print(f\"预测结果CSV已保存到: {results_dir}/predictions_{evaluation_criterion}.csv\")\n",
    "    \n",
    "    # 保存CSV格式的不确定性结果\n",
    "    if uncertainties:\n",
    "        unc_dfs = []\n",
    "        for unc_dict in uncertainties:\n",
    "            unc_df = pd.DataFrame({k: v for k, v in unc_dict.items() if not k.startswith('batch')})\n",
    "            unc_dfs.append(unc_df)\n",
    "        \n",
    "        if unc_dfs:\n",
    "            uncertainties_df = pd.concat(unc_dfs, ignore_index=True)\n",
    "            uncertainties_df.to_csv(os.path.join(results_dir, f'uncertainties_{evaluation_criterion}.csv'), index=False)\n",
    "            print(f\"不确定性结果CSV已保存到: {results_dir}/uncertainties_{evaluation_criterion}.csv\")\n",
    "    \n",
    "    # 保存整体评估指标\n",
    "    metrics_summary = {\n",
    "        'evaluation_criterion': evaluation_criterion,\n",
    "        'head_mse': head_metrics['mse'],\n",
    "        'head_rmse': head_metrics['rmse'],\n",
    "        'head_mae': head_metrics['mae'],\n",
    "        'head_r2': head_metrics['r2'],\n",
    "        'conc_mse': conc_metrics['mse'],\n",
    "        'conc_rmse': conc_metrics['rmse'],\n",
    "        'conc_mae': conc_metrics['mae'],\n",
    "        'conc_r2': conc_metrics['r2'],\n",
    "        'head_uncertainty_mean': np.mean(all_head_uncertainties),\n",
    "        'head_uncertainty_std': np.std(all_head_uncertainties),\n",
    "        'conc_uncertainty_mean': np.mean(all_conc_uncertainties),\n",
    "        'conc_uncertainty_std': np.std(all_conc_uncertainties),\n",
    "        'head_error_uncertainty_correlation': head_corr,\n",
    "        'conc_error_uncertainty_correlation': conc_corr\n",
    "    }\n",
    "    \n",
    "    metrics_df = pd.DataFrame([metrics_summary])\n",
    "    metrics_df.to_csv(os.path.join(results_dir, f'evaluation_summary_{evaluation_criterion}.csv'), index=False)\n",
    "    \n",
    "    print(f\"\\n📊 评估完成!\")\n",
    "    print(f\"📈 水头模型 - R2: {head_metrics['r2']:.4f}, RMSE: {head_metrics['rmse']:.4f}\")\n",
    "    print(f\"📈 浓度模型 - R2: {conc_metrics['r2']:.4f}, RMSE: {conc_metrics['rmse']:.4f}\")\n",
    "    print(f\"📁 所有结果已保存到: {results_dir}\")\n",
    "    \n",
    "    return evaluation_results\n",
    "\n",
    "def compare_model_criteria(head_model, conc_model, val_loader):\n",
    "    \"\"\"\n",
    "    比较基于损失和基于R2的模型性能，使用改进的评估函数\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"比较不同选择标准的模型性能\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 分别评估两种标准的模型\n",
    "    loss_results = evaluate_dual_model_improved(head_model, conc_model, val_loader, 'loss')\n",
    "    r2_results = evaluate_dual_model_improved(head_model, conc_model, val_loader, 'r2')\n",
    "    \n",
    "    # 创建比较表格\n",
    "    comparison_data = []\n",
    "    \n",
    "    # 水头模型比较\n",
    "    comparison_data.append({\n",
    "        'Model': 'Head',\n",
    "        'Criterion': 'Loss',\n",
    "        'MSE': loss_results['head_metrics']['mse'],\n",
    "        'RMSE': loss_results['head_metrics']['rmse'],\n",
    "        'MAE': loss_results['head_metrics']['mae'],\n",
    "        'R2': loss_results['head_metrics']['r2'],\n",
    "        'Uncertainty_Mean': np.mean(loss_results['head_uncertainties']),\n",
    "        'Error_Uncertainty_Corr': np.corrcoef(\n",
    "            loss_results['head_uncertainties'].flatten(),\n",
    "            np.abs(loss_results['head_predictions'].flatten() - loss_results['head_targets'].flatten())\n",
    "        )[0, 1]\n",
    "    })\n",
    "    \n",
    "    comparison_data.append({\n",
    "        'Model': 'Head',\n",
    "        'Criterion': 'R2',\n",
    "        'MSE': r2_results['head_metrics']['mse'],\n",
    "        'RMSE': r2_results['head_metrics']['rmse'],\n",
    "        'MAE': r2_results['head_metrics']['mae'],\n",
    "        'R2': r2_results['head_metrics']['r2'],\n",
    "        'Uncertainty_Mean': np.mean(r2_results['head_uncertainties']),\n",
    "        'Error_Uncertainty_Corr': np.corrcoef(\n",
    "            r2_results['head_uncertainties'].flatten(),\n",
    "            np.abs(r2_results['head_predictions'].flatten() - r2_results['head_targets'].flatten())\n",
    "        )[0, 1]\n",
    "    })\n",
    "    \n",
    "    # 浓度模型比较\n",
    "    comparison_data.append({\n",
    "        'Model': 'Concentration',\n",
    "        'Criterion': 'Loss',\n",
    "        'MSE': loss_results['conc_metrics']['mse'],\n",
    "        'RMSE': loss_results['conc_metrics']['rmse'],\n",
    "        'MAE': loss_results['conc_metrics']['mae'],\n",
    "        'R2': loss_results['conc_metrics']['r2'],\n",
    "        'Uncertainty_Mean': np.mean(loss_results['conc_uncertainties']),\n",
    "        'Error_Uncertainty_Corr': np.corrcoef(\n",
    "            loss_results['conc_uncertainties'].flatten(),\n",
    "            np.abs(loss_results['conc_predictions'].flatten() - loss_results['conc_targets'].flatten())\n",
    "        )[0, 1]\n",
    "    })\n",
    "    \n",
    "    comparison_data.append({\n",
    "        'Model': 'Concentration',\n",
    "        'Criterion': 'R2',\n",
    "        'MSE': r2_results['conc_metrics']['mse'],\n",
    "        'RMSE': r2_results['conc_metrics']['rmse'],\n",
    "        'MAE': r2_results['conc_metrics']['mae'],\n",
    "        'R2': r2_results['conc_metrics']['r2'],\n",
    "        'Uncertainty_Mean': np.mean(r2_results['conc_uncertainties']),\n",
    "        'Error_Uncertainty_Corr': np.corrcoef(\n",
    "            r2_results['conc_uncertainties'].flatten(),\n",
    "            np.abs(r2_results['conc_predictions'].flatten() - r2_results['conc_targets'].flatten())\n",
    "        )[0, 1]\n",
    "    })\n",
    "    \n",
    "    # 创建比较DataFrame\n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    \n",
    "    # 保存比较结果\n",
    "    results_dir = os.path.join(config['save_path'], 'evaluation_results')\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    comparison_df.to_csv(os.path.join(results_dir, 'model_criteria_comparison.csv'), index=False)\n",
    "    \n",
    "    # 打印比较结果\n",
    "    print(\"\\n模型选择标准比较结果:\")\n",
    "    print(comparison_df.to_string(index=False, float_format='%.4f'))\n",
    "    \n",
    "    # 绘制扩展的比较图\n",
    "    plt.figure(figsize=(20, 12))\n",
    "    \n",
    "    # R2比较\n",
    "    plt.subplot(2, 4, 1)\n",
    "    head_r2 = [loss_results['head_metrics']['r2'], r2_results['head_metrics']['r2']]\n",
    "    conc_r2 = [loss_results['conc_metrics']['r2'], r2_results['conc_metrics']['r2']]\n",
    "    x = ['Loss-based', 'R2-based']\n",
    "    plt.bar([0, 1], head_r2, alpha=0.7, label='Head Model', width=0.35)\n",
    "    plt.bar([0.35, 1.35], conc_r2, alpha=0.7, label='Concentration Model', width=0.35)\n",
    "    plt.xlabel('Model Selection Criterion')\n",
    "    plt.ylabel('R2 Score')\n",
    "    plt.title('R2 Score Comparison')\n",
    "    plt.xticks([0.175, 1.175], x)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # MSE比较\n",
    "    plt.subplot(2, 4, 2)\n",
    "    head_mse = [loss_results['head_metrics']['mse'], r2_results['head_metrics']['mse']]\n",
    "    conc_mse = [loss_results['conc_metrics']['mse'], r2_results['conc_metrics']['mse']]\n",
    "    plt.bar([0, 1], head_mse, alpha=0.7, label='Head Model', width=0.35)\n",
    "    plt.bar([0.35, 1.35], conc_mse, alpha=0.7, label='Concentration Model', width=0.35)\n",
    "    plt.xlabel('Model Selection Criterion')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.title('MSE Comparison')\n",
    "    plt.xticks([0.175, 1.175], x)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 不确定性比较\n",
    "    plt.subplot(2, 4, 3)\n",
    "    head_unc = [np.mean(loss_results['head_uncertainties']), np.mean(r2_results['head_uncertainties'])]\n",
    "    conc_unc = [np.mean(loss_results['conc_uncertainties']), np.mean(r2_results['conc_uncertainties'])]\n",
    "    plt.bar([0, 1], head_unc, alpha=0.7, label='Head Model', width=0.35)\n",
    "    plt.bar([0.35, 1.35], conc_unc, alpha=0.7, label='Concentration Model', width=0.35)\n",
    "    plt.xlabel('Model Selection Criterion')\n",
    "    plt.ylabel('Mean Uncertainty')\n",
    "    plt.title('Uncertainty Comparison')\n",
    "    plt.xticks([0.175, 1.175], x)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 误差-不确定性相关性比较\n",
    "    plt.subplot(2, 4, 4)\n",
    "    head_corr = [comparison_data[0]['Error_Uncertainty_Corr'], comparison_data[1]['Error_Uncertainty_Corr']]\n",
    "    conc_corr = [comparison_data[2]['Error_Uncertainty_Corr'], comparison_data[3]['Error_Uncertainty_Corr']]\n",
    "    plt.bar([0, 1], head_corr, alpha=0.7, label='Head Model', width=0.35)\n",
    "    plt.bar([0.35, 1.35], conc_corr, alpha=0.7, label='Concentration Model', width=0.35)\n",
    "    plt.xlabel('Model Selection Criterion')\n",
    "    plt.ylabel('Error-Uncertainty Correlation')\n",
    "    plt.title('Calibration Quality Comparison')\n",
    "    plt.xticks([0.175, 1.175], x)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 预测散点图比较\n",
    "    plt.subplot(2, 4, 5)\n",
    "    plt.scatter(loss_results['head_targets'].flatten(), loss_results['head_predictions'].flatten(), \n",
    "               alpha=0.5, label='Loss-based', s=5)\n",
    "    plt.scatter(r2_results['head_targets'].flatten(), r2_results['head_predictions'].flatten(), \n",
    "               alpha=0.5, label='R2-based', s=5)\n",
    "    plt.plot([loss_results['head_targets'].min(), loss_results['head_targets'].max()], \n",
    "             [loss_results['head_targets'].min(), loss_results['head_targets'].max()], 'r--', alpha=0.8)\n",
    "    plt.xlabel('True Head Values')\n",
    "    plt.ylabel('Predicted Head Values')\n",
    "    plt.title('Head Model: True vs Predicted')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(2, 4, 6)\n",
    "    plt.scatter(loss_results['conc_targets'].flatten(), loss_results['conc_predictions'].flatten(), \n",
    "               alpha=0.5, label='Loss-based', s=5)\n",
    "    plt.scatter(r2_results['conc_targets'].flatten(), r2_results['conc_predictions'].flatten(), \n",
    "               alpha=0.5, label='R2-based', s=5)\n",
    "    plt.plot([loss_results['conc_targets'].min(), loss_results['conc_targets'].max()], \n",
    "             [loss_results['conc_targets'].min(), loss_results['conc_targets'].max()], 'r--', alpha=0.8)\n",
    "    plt.xlabel('True Concentration Values')\n",
    "    plt.ylabel('Predicted Concentration Values')\n",
    "    plt.title('Concentration Model: True vs Predicted')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 不确定性分布比较\n",
    "    plt.subplot(2, 4, 7)\n",
    "    plt.hist(loss_results['head_uncertainties'].flatten(), bins=30, alpha=0.5, label='Loss-based', density=True)\n",
    "    plt.hist(r2_results['head_uncertainties'].flatten(), bins=30, alpha=0.5, label='R2-based', density=True)\n",
    "    plt.xlabel('Head Uncertainty')\n",
    "    plt.ylabel('Density')\n",
    "    plt.title('Head Uncertainty Distribution')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(2, 4, 8)\n",
    "    plt.hist(loss_results['conc_uncertainties'].flatten(), bins=30, alpha=0.5, label='Loss-based', density=True)\n",
    "    plt.hist(r2_results['conc_uncertainties'].flatten(), bins=30, alpha=0.5, label='R2-based', density=True)\n",
    "    plt.xlabel('Concentration Uncertainty')\n",
    "    plt.ylabel('Density')\n",
    "    plt.title('Concentration Uncertainty Distribution')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(results_dir, 'model_criteria_comparison_comprehensive.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"\\n比较图表已保存到: {results_dir}/model_criteria_comparison_comprehensive.png\")\n",
    "    print(f\"比较数据已保存到: {results_dir}/model_criteria_comparison.csv\")\n",
    "    \n",
    "    return comparison_df, loss_results, r2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "507904ba-5515-4009-8db6-31fcd7f524ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在处理数据...\n",
      "\n",
      "▶ Started building spatiotemporal graphs\n",
      "▷ Total models to process: 100\n",
      "\n",
      "▣ Processing model 1/100: Sub_80\n",
      "\n",
      "▣ Processing model 2/100: Sub_37\n",
      "\n",
      "▣ Processing model 3/100: Sub_61\n",
      "\n",
      "▣ Processing model 4/100: Sub_83\n",
      "\n",
      "▣ Processing model 5/100: Sub_85\n",
      "\n",
      "▣ Processing model 6/100: Sub_42\n",
      "\n",
      "▣ Processing model 7/100: Sub_12\n",
      "\n",
      "▣ Processing model 8/100: Sub_66\n",
      "\n",
      "▣ Processing model 9/100: Sub_72\n",
      "\n",
      "▣ Processing model 10/100: Sub_82\n",
      "\n",
      "▣ Processing model 11/100: Sub_79\n",
      "\n",
      "▣ Processing model 12/100: Sub_5\n",
      "\n",
      "▣ Processing model 13/100: Sub_30\n",
      "\n",
      "▣ Processing model 14/100: Sub_33\n",
      "\n",
      "▣ Processing model 15/100: Sub_58\n",
      "\n",
      "▣ Processing model 16/100: Sub_44\n",
      "\n",
      "▣ Processing model 17/100: Sub_27\n",
      "\n",
      "▣ Processing model 18/100: Sub_73\n",
      "\n",
      "▣ Processing model 19/100: Sub_10\n",
      "\n",
      "▣ Processing model 20/100: Sub_1\n",
      "\n",
      "▣ Processing model 21/100: Sub_35\n",
      "\n",
      "▣ Processing model 22/100: Sub_62\n",
      "\n",
      "▣ Processing model 23/100: Sub_23\n",
      "\n",
      "▣ Processing model 24/100: Sub_68\n",
      "\n",
      "▣ Processing model 25/100: Sub_78\n",
      "\n",
      "▣ Processing model 26/100: Sub_6\n",
      "\n",
      "▣ Processing model 27/100: Sub_98\n",
      "\n",
      "▣ Processing model 28/100: Sub_87\n",
      "\n",
      "▣ Processing model 29/100: Sub_95\n",
      "\n",
      "▣ Processing model 30/100: Sub_0\n",
      "\n",
      "▣ Processing model 31/100: Sub_19\n",
      "\n",
      "▣ Processing model 32/100: Sub_45\n",
      "\n",
      "▣ Processing model 33/100: Sub_26\n",
      "\n",
      "▣ Processing model 34/100: Sub_50\n",
      "\n",
      "▣ Processing model 35/100: Sub_56\n",
      "\n",
      "▣ Processing model 36/100: Sub_53\n",
      "\n",
      "▣ Processing model 37/100: Sub_4\n",
      "\n",
      "▣ Processing model 38/100: Sub_24\n",
      "\n",
      "▣ Processing model 39/100: Sub_41\n",
      "\n",
      "▣ Processing model 40/100: Sub_28\n",
      "\n",
      "▣ Processing model 41/100: Sub_15\n",
      "\n",
      "▣ Processing model 42/100: Sub_99\n",
      "\n",
      "▣ Processing model 43/100: Sub_76\n",
      "\n",
      "▣ Processing model 44/100: Sub_11\n",
      "\n",
      "▣ Processing model 45/100: Sub_51\n",
      "\n",
      "▣ Processing model 46/100: Sub_86\n",
      "\n",
      "▣ Processing model 47/100: Sub_71\n",
      "\n",
      "▣ Processing model 48/100: Sub_96\n",
      "\n",
      "▣ Processing model 49/100: Sub_46\n",
      "\n",
      "▣ Processing model 50/100: Sub_29\n",
      "\n",
      "▣ Processing model 51/100: Sub_63\n",
      "\n",
      "▣ Processing model 52/100: Sub_32\n",
      "\n",
      "▣ Processing model 53/100: Sub_21\n",
      "\n",
      "▣ Processing model 54/100: Sub_67\n",
      "\n",
      "▣ Processing model 55/100: Sub_91\n",
      "\n",
      "▣ Processing model 56/100: Sub_47\n",
      "\n",
      "▣ Processing model 57/100: Sub_8\n",
      "\n",
      "▣ Processing model 58/100: Sub_40\n",
      "\n",
      "▣ Processing model 59/100: Sub_70\n",
      "\n",
      "▣ Processing model 60/100: Sub_16\n",
      "\n",
      "▣ Processing model 61/100: Sub_93\n",
      "\n",
      "▣ Processing model 62/100: Sub_90\n",
      "\n",
      "▣ Processing model 63/100: Sub_97\n",
      "\n",
      "▣ Processing model 64/100: Sub_2\n",
      "\n",
      "▣ Processing model 65/100: Sub_59\n",
      "\n",
      "▣ Processing model 66/100: Sub_54\n",
      "\n",
      "▣ Processing model 67/100: Sub_7\n",
      "\n",
      "▣ Processing model 68/100: Sub_57\n",
      "\n",
      "▣ Processing model 69/100: Sub_60\n",
      "\n",
      "▣ Processing model 70/100: Sub_88\n",
      "\n",
      "▣ Processing model 71/100: Sub_89\n",
      "\n",
      "▣ Processing model 72/100: Sub_13\n",
      "\n",
      "▣ Processing model 73/100: Sub_18\n",
      "\n",
      "▣ Processing model 74/100: Sub_77\n",
      "\n",
      "▣ Processing model 75/100: Sub_55\n",
      "\n",
      "▣ Processing model 76/100: Sub_49\n",
      "\n",
      "▣ Processing model 77/100: Sub_43\n",
      "\n",
      "▣ Processing model 78/100: Sub_48\n",
      "\n",
      "▣ Processing model 79/100: Sub_69\n",
      "\n",
      "▣ Processing model 80/100: Sub_9\n",
      "\n",
      "▣ Processing model 81/100: Sub_38\n",
      "\n",
      "▣ Processing model 82/100: Sub_22\n",
      "\n",
      "▣ Processing model 83/100: Sub_65\n",
      "\n",
      "▣ Processing model 84/100: Sub_34\n",
      "\n",
      "▣ Processing model 85/100: Sub_36\n",
      "\n",
      "▣ Processing model 86/100: Sub_94\n",
      "\n",
      "▣ Processing model 87/100: Sub_25\n",
      "\n",
      "▣ Processing model 88/100: Sub_52\n",
      "\n",
      "▣ Processing model 89/100: Sub_39\n",
      "\n",
      "▣ Processing model 90/100: Sub_81\n",
      "\n",
      "▣ Processing model 91/100: Sub_20\n",
      "\n",
      "▣ Processing model 92/100: Sub_74\n",
      "\n",
      "▣ Processing model 93/100: Sub_64\n",
      "\n",
      "▣ Processing model 94/100: Sub_3\n",
      "\n",
      "▣ Processing model 95/100: Sub_31\n",
      "\n",
      "▣ Processing model 96/100: Sub_14\n",
      "\n",
      "▣ Processing model 97/100: Sub_92\n",
      "\n",
      "▣ Processing model 98/100: Sub_84\n",
      "\n",
      "▣ Processing model 99/100: Sub_75\n",
      "\n",
      "▣ Processing model 100/100: Sub_17\n",
      "\n",
      "✅ All models processed! Total graphs created: 100\n",
      "数据处理完成！\n",
      "CUDA缓存已成功清除\n",
      "================================================================================\n",
      "第一阶段：开始训练水头模型\n",
      "================================================================================\n",
      "开始训练水头模型\n",
      "水头模型参数数量: 949853\n",
      "水头模型 Epoch 1, Batch 0: Total Loss: 10494.2705, Criterion Loss: 10297.4746, Physics Loss: 11623.4859, KL Loss: 196.7961\n",
      "水头模型 Epoch 001/500 | 训练损失: 10208.4091 | 验证损失: 9892.9171 | LR: 0.000994\n",
      "水头验证指标 - MSE: 10970.2516, RMSE: 104.7373, MAE: 104.2328, R2: -104.9239\n",
      "保存基于损失的最佳水头模型，验证损失: 9892.9171\n",
      "保存基于R2的最佳水头模型，R2: -104.9239\n",
      "水头模型 Epoch 2, Batch 0: Total Loss: 9781.0586, Criterion Loss: 9588.5645, Physics Loss: 10825.2405, KL Loss: 192.4946\n",
      "水头模型 Epoch 002/500 | 训练损失: 10010.2400 | 验证损失: 9563.2512 | LR: 0.000976\n",
      "水头验证指标 - MSE: 10604.1404, RMSE: 102.9748, MAE: 102.4604, R2: -101.3881\n",
      "保存基于损失的最佳水头模型，验证损失: 9563.2512\n",
      "保存基于R2的最佳水头模型，R2: -101.3881\n",
      "水头模型 Epoch 3, Batch 0: Total Loss: 10156.6816, Criterion Loss: 9966.9736, Physics Loss: 11253.6777, KL Loss: 189.7075\n",
      "水头模型 Epoch 003/500 | 训练损失: 9489.4742 | 验证损失: 8771.3822 | LR: 0.000946\n",
      "水头验证指标 - MSE: 9724.8245, RMSE: 98.6125, MAE: 98.0416, R2: -92.8925\n",
      "保存基于损失的最佳水头模型，验证损失: 8771.3822\n",
      "保存基于R2的最佳水头模型，R2: -92.8925\n",
      "水头模型 Epoch 4, Batch 0: Total Loss: 9040.3701, Criterion Loss: 8852.3916, Physics Loss: 10008.8072, KL Loss: 187.9789\n",
      "水头模型 Epoch 004/500 | 训练损失: 8281.8821 | 验证损失: 6894.4486 | LR: 0.000905\n",
      "水头验证指标 - MSE: 7641.6069, RMSE: 87.4132, MAE: 86.6011, R2: -72.7706\n",
      "保存基于损失的最佳水头模型，验证损失: 6894.4486\n",
      "保存基于R2的最佳水头模型，R2: -72.7706\n",
      "水头模型 Epoch 5, Batch 0: Total Loss: 7040.6831, Criterion Loss: 6853.2881, Physics Loss: 7771.7537, KL Loss: 187.3952\n",
      "水头模型 Epoch 005/500 | 训练损失: 5309.0630 | 验证损失: 2483.8444 | LR: 0.000855\n",
      "水头验证指标 - MSE: 2746.8058, RMSE: 52.3918, MAE: 49.9264, R2: -25.4819\n",
      "保存基于损失的最佳水头模型，验证损失: 2483.8444\n",
      "保存基于R2的最佳水头模型，R2: -25.4819\n",
      "水头模型 Epoch 6, Batch 0: Total Loss: 3004.3674, Criterion Loss: 2816.7405, Physics Loss: 3296.9632, KL Loss: 187.6269\n",
      "水头模型 Epoch 006/500 | 训练损失: 1186.5352 | 验证损失: 250.3691 | LR: 0.000796\n",
      "水头验证指标 - MSE: 263.6313, RMSE: 16.1971, MAE: 13.1900, R2: -1.5608\n",
      "保存基于损失的最佳水头模型，验证损失: 250.3691\n",
      "保存基于R2的最佳水头模型，R2: -1.5608\n",
      "水头模型 Epoch 7, Batch 0: Total Loss: 467.3306, Criterion Loss: 279.4336, Physics Loss: 611.7603, KL Loss: 187.8970\n",
      "水头模型 Epoch 007/500 | 训练损失: 502.6102 | 验证损失: 133.5554 | LR: 0.000730\n",
      "水头验证指标 - MSE: 142.2398, RMSE: 11.8618, MAE: 9.7386, R2: -0.3756\n",
      "保存基于损失的最佳水头模型，验证损失: 133.5554\n",
      "保存基于R2的最佳水头模型，R2: -0.3756\n",
      "水头模型 Epoch 8, Batch 0: Total Loss: 413.3734, Criterion Loss: 226.2249, Physics Loss: 434.9076, KL Loss: 187.1485\n",
      "水头模型 Epoch 008/500 | 训练损失: 384.6032 | 验证损失: 66.5637 | LR: 0.000658\n",
      "水头验证指标 - MSE: 68.7036, RMSE: 8.2742, MAE: 6.5791, R2: 0.3415\n",
      "保存基于损失的最佳水头模型，验证损失: 66.5637\n",
      "保存基于R2的最佳水头模型，R2: 0.3415\n",
      "水头模型 Epoch 9, Batch 0: Total Loss: 362.9550, Criterion Loss: 176.8354, Physics Loss: 380.4931, KL Loss: 186.1196\n",
      "水头模型 Epoch 009/500 | 训练损失: 364.4679 | 验证损失: 57.5941 | LR: 0.000582\n",
      "水头验证指标 - MSE: 58.9595, RMSE: 7.6690, MAE: 6.0424, R2: 0.4343\n",
      "保存基于损失的最佳水头模型，验证损失: 57.5941\n",
      "保存基于R2的最佳水头模型，R2: 0.4343\n",
      "水头模型 Epoch 10, Batch 0: Total Loss: 379.9559, Criterion Loss: 195.2247, Physics Loss: 390.2983, KL Loss: 184.7313\n",
      "水头模型 Epoch 010/500 | 训练损失: 344.2901 | 验证损失: 54.1950 | LR: 0.000505\n",
      "水头验证指标 - MSE: 55.4886, RMSE: 7.4411, MAE: 5.8737, R2: 0.4640\n",
      "保存基于损失的最佳水头模型，验证损失: 54.1950\n",
      "保存基于R2的最佳水头模型，R2: 0.4640\n",
      "水头模型 Epoch 11, Batch 0: Total Loss: 343.1812, Criterion Loss: 160.3421, Physics Loss: 371.9949, KL Loss: 182.8390\n",
      "水头模型 Epoch 011/500 | 训练损失: 339.8168 | 验证损失: 49.8698 | LR: 0.000428\n",
      "水头验证指标 - MSE: 50.9865, RMSE: 7.1218, MAE: 5.6138, R2: 0.5080\n",
      "保存基于损失的最佳水头模型，验证损失: 49.8698\n",
      "保存基于R2的最佳水头模型，R2: 0.5080\n",
      "水头模型 Epoch 12, Batch 0: Total Loss: 306.3420, Criterion Loss: 125.0051, Physics Loss: 309.2607, KL Loss: 181.3370\n",
      "水头模型 Epoch 012/500 | 训练损失: 351.7222 | 验证损失: 81.3478 | LR: 0.000352\n",
      "水头验证指标 - MSE: 86.3025, RMSE: 9.2197, MAE: 7.6282, R2: 0.1767\n",
      "水头模型 Epoch 13, Batch 0: Total Loss: 414.3054, Criterion Loss: 234.1922, Physics Loss: 397.9248, KL Loss: 180.1133\n",
      "水头模型 Epoch 013/500 | 训练损失: 361.2852 | 验证损失: 49.5519 | LR: 0.000280\n",
      "水头验证指标 - MSE: 50.5420, RMSE: 7.0886, MAE: 5.5631, R2: 0.5124\n",
      "保存基于损失的最佳水头模型，验证损失: 49.5519\n",
      "保存基于R2的最佳水头模型，R2: 0.5124\n",
      "水头模型 Epoch 14, Batch 0: Total Loss: 491.6530, Criterion Loss: 312.2653, Physics Loss: 576.9679, KL Loss: 179.3878\n",
      "水头模型 Epoch 014/500 | 训练损失: 356.5641 | 验证损失: 46.7651 | LR: 0.000214\n",
      "水头验证指标 - MSE: 47.8970, RMSE: 6.8775, MAE: 5.5039, R2: 0.5431\n",
      "保存基于损失的最佳水头模型，验证损失: 46.7651\n",
      "保存基于R2的最佳水头模型，R2: 0.5431\n",
      "水头模型 Epoch 15, Batch 0: Total Loss: 298.7119, Criterion Loss: 119.9660, Physics Loss: 291.5124, KL Loss: 178.7459\n",
      "水头模型 Epoch 015/500 | 训练损失: 335.4861 | 验证损失: 39.4601 | LR: 0.000155\n",
      "水头验证指标 - MSE: 39.6285, RMSE: 6.2865, MAE: 4.9617, R2: 0.6179\n",
      "保存基于损失的最佳水头模型，验证损失: 39.4601\n",
      "保存基于R2的最佳水头模型，R2: 0.6179\n",
      "水头模型 Epoch 16, Batch 0: Total Loss: 385.4165, Criterion Loss: 207.0392, Physics Loss: 369.4383, KL Loss: 178.3773\n",
      "水头模型 Epoch 016/500 | 训练损失: 318.0027 | 验证损失: 37.9099 | LR: 0.000105\n",
      "水头验证指标 - MSE: 38.1451, RMSE: 6.1659, MAE: 4.8373, R2: 0.6338\n",
      "保存基于损失的最佳水头模型，验证损失: 37.9099\n",
      "保存基于R2的最佳水头模型，R2: 0.6338\n",
      "水头模型 Epoch 17, Batch 0: Total Loss: 289.4747, Criterion Loss: 111.2644, Physics Loss: 285.5132, KL Loss: 178.2103\n",
      "水头模型 Epoch 017/500 | 训练损失: 322.8171 | 验证损失: 37.1615 | LR: 0.000064\n",
      "水头验证指标 - MSE: 37.3325, RMSE: 6.0996, MAE: 4.7797, R2: 0.6408\n",
      "保存基于损失的最佳水头模型，验证损失: 37.1615\n",
      "保存基于R2的最佳水头模型，R2: 0.6408\n",
      "水头模型 Epoch 18, Batch 0: Total Loss: 389.4833, Criterion Loss: 211.6484, Physics Loss: 443.1829, KL Loss: 177.8348\n",
      "水头模型 Epoch 018/500 | 训练损失: 334.7819 | 验证损失: 37.4215 | LR: 0.000034\n",
      "水头验证指标 - MSE: 37.6105, RMSE: 6.1134, MAE: 4.8071, R2: 0.6399\n",
      "水头模型 Epoch 19, Batch 0: Total Loss: 433.5943, Criterion Loss: 256.5022, Physics Loss: 428.1658, KL Loss: 177.0921\n",
      "水头模型 Epoch 019/500 | 训练损失: 317.0469 | 验证损失: 37.0198 | LR: 0.000016\n",
      "水头验证指标 - MSE: 37.1554, RMSE: 6.0746, MAE: 4.7691, R2: 0.6432\n",
      "保存基于损失的最佳水头模型，验证损失: 37.0198\n",
      "保存基于R2的最佳水头模型，R2: 0.6432\n",
      "水头模型 Epoch 20, Batch 0: Total Loss: 360.9716, Criterion Loss: 183.5679, Physics Loss: 358.4836, KL Loss: 177.4036\n",
      "水头模型 Epoch 020/500 | 训练损失: 314.0839 | 验证损失: 35.2660 | LR: 0.001000\n",
      "水头验证指标 - MSE: 35.2047, RMSE: 5.9242, MAE: 4.6420, R2: 0.6622\n",
      "保存基于损失的最佳水头模型，验证损失: 35.2660\n",
      "保存基于R2的最佳水头模型，R2: 0.6622\n",
      "水头模型 Epoch 21, Batch 0: Total Loss: 341.0405, Criterion Loss: 163.9086, Physics Loss: 377.5039, KL Loss: 177.1319\n",
      "水头模型 Epoch 021/500 | 训练损失: 319.6241 | 验证损失: 87.7418 | LR: 0.000998\n",
      "水头验证指标 - MSE: 93.1575, RMSE: 9.4787, MAE: 8.1978, R2: 0.1069\n",
      "水头模型 Epoch 22, Batch 0: Total Loss: 355.0250, Criterion Loss: 180.9142, Physics Loss: 346.3441, KL Loss: 174.1108\n",
      "水头模型 Epoch 022/500 | 训练损失: 346.2486 | 验证损失: 50.3270 | LR: 0.000994\n",
      "水头验证指标 - MSE: 50.7851, RMSE: 7.0701, MAE: 5.6663, R2: 0.5157\n",
      "水头模型 Epoch 23, Batch 0: Total Loss: 288.1740, Criterion Loss: 115.7567, Physics Loss: 287.1152, KL Loss: 172.4173\n",
      "水头模型 Epoch 023/500 | 训练损失: 298.8996 | 验证损失: 33.3672 | LR: 0.000986\n",
      "水头验证指标 - MSE: 33.2756, RMSE: 5.7041, MAE: 4.5225, R2: 0.6835\n",
      "保存基于损失的最佳水头模型，验证损失: 33.3672\n",
      "保存基于R2的最佳水头模型，R2: 0.6835\n",
      "水头模型 Epoch 24, Batch 0: Total Loss: 321.3271, Criterion Loss: 150.5599, Physics Loss: 306.9281, KL Loss: 170.7673\n",
      "水头模型 Epoch 024/500 | 训练损失: 311.1578 | 验证损失: 64.3249 | LR: 0.000976\n",
      "水头验证指标 - MSE: 67.2089, RMSE: 8.1201, MAE: 6.8285, R2: 0.3525\n",
      "水头模型 Epoch 25, Batch 0: Total Loss: 279.1902, Criterion Loss: 110.5061, Physics Loss: 268.7047, KL Loss: 168.6841\n",
      "水头模型 Epoch 025/500 | 训练损失: 341.0081 | 验证损失: 33.8402 | LR: 0.000962\n",
      "水头验证指标 - MSE: 33.8695, RMSE: 5.7542, MAE: 4.5864, R2: 0.6751\n",
      "水头模型 Epoch 26, Batch 0: Total Loss: 296.8075, Criterion Loss: 129.2289, Physics Loss: 275.4482, KL Loss: 167.5787\n",
      "水头模型 Epoch 026/500 | 训练损失: 300.6129 | 验证损失: 30.4127 | LR: 0.000946\n",
      "水头验证指标 - MSE: 30.0713, RMSE: 5.4687, MAE: 4.2701, R2: 0.7082\n",
      "保存基于损失的最佳水头模型，验证损失: 30.4127\n",
      "保存基于R2的最佳水头模型，R2: 0.7082\n",
      "水头模型 Epoch 27, Batch 0: Total Loss: 269.6092, Criterion Loss: 103.3969, Physics Loss: 256.2165, KL Loss: 166.2123\n",
      "水头模型 Epoch 027/500 | 训练损失: 288.2703 | 验证损失: 26.0925 | LR: 0.000927\n",
      "水头验证指标 - MSE: 25.6903, RMSE: 5.0597, MAE: 3.9523, R2: 0.7537\n",
      "保存基于损失的最佳水头模型，验证损失: 26.0925\n",
      "保存基于R2的最佳水头模型，R2: 0.7537\n",
      "水头模型 Epoch 28, Batch 0: Total Loss: 271.3190, Criterion Loss: 106.6501, Physics Loss: 262.1497, KL Loss: 164.6689\n",
      "水头模型 Epoch 028/500 | 训练损失: 282.8436 | 验证损失: 83.4157 | LR: 0.000905\n",
      "水头验证指标 - MSE: 89.2474, RMSE: 9.2573, MAE: 8.1138, R2: 0.1601\n",
      "水头模型 Epoch 29, Batch 0: Total Loss: 277.4306, Criterion Loss: 114.9836, Physics Loss: 258.0226, KL Loss: 162.4470\n",
      "水头模型 Epoch 029/500 | 训练损失: 284.5124 | 验证损失: 30.2225 | LR: 0.000881\n",
      "水头验证指标 - MSE: 29.4185, RMSE: 5.4073, MAE: 4.2353, R2: 0.7155\n",
      "水头模型 Epoch 30, Batch 0: Total Loss: 313.5408, Criterion Loss: 152.1482, Physics Loss: 338.3554, KL Loss: 161.3927\n",
      "水头模型 Epoch 030/500 | 训练损失: 294.3685 | 验证损失: 41.9386 | LR: 0.000855\n",
      "水头验证指标 - MSE: 42.6785, RMSE: 6.5066, MAE: 5.2316, R2: 0.5844\n",
      "水头模型 Epoch 31, Batch 0: Total Loss: 268.8101, Criterion Loss: 108.4298, Physics Loss: 274.2882, KL Loss: 160.3803\n",
      "水头模型 Epoch 031/500 | 训练损失: 296.0172 | 验证损失: 46.4587 | LR: 0.000826\n",
      "水头验证指标 - MSE: 48.4240, RMSE: 6.7594, MAE: 5.5998, R2: 0.5396\n",
      "水头模型 Epoch 32, Batch 0: Total Loss: 261.3460, Criterion Loss: 102.3162, Physics Loss: 236.0607, KL Loss: 159.0298\n",
      "水头模型 Epoch 032/500 | 训练损失: 262.9730 | 验证损失: 24.9393 | LR: 0.000796\n",
      "水头验证指标 - MSE: 24.1876, RMSE: 4.9131, MAE: 3.8507, R2: 0.7669\n",
      "保存基于损失的最佳水头模型，验证损失: 24.9393\n",
      "保存基于R2的最佳水头模型，R2: 0.7669\n",
      "水头模型 Epoch 33, Batch 0: Total Loss: 400.6096, Criterion Loss: 242.5366, Physics Loss: 449.8076, KL Loss: 158.0730\n",
      "水头模型 Epoch 033/500 | 训练损失: 291.2731 | 验证损失: 33.9885 | LR: 0.000764\n",
      "水头验证指标 - MSE: 34.3220, RMSE: 5.8066, MAE: 4.7037, R2: 0.6706\n",
      "水头模型 Epoch 34, Batch 0: Total Loss: 244.8105, Criterion Loss: 87.9123, Physics Loss: 227.2752, KL Loss: 156.8983\n",
      "水头模型 Epoch 034/500 | 训练损失: 286.6715 | 验证损失: 37.3708 | LR: 0.000730\n",
      "水头验证指标 - MSE: 37.9535, RMSE: 6.1257, MAE: 4.9770, R2: 0.6324\n",
      "水头模型 Epoch 35, Batch 0: Total Loss: 248.8976, Criterion Loss: 93.0761, Physics Loss: 243.0611, KL Loss: 155.8215\n",
      "水头模型 Epoch 035/500 | 训练损失: 271.7546 | 验证损失: 24.9341 | LR: 0.000694\n",
      "水头验证指标 - MSE: 24.3486, RMSE: 4.9229, MAE: 3.8419, R2: 0.7656\n",
      "保存基于损失的最佳水头模型，验证损失: 24.9341\n",
      "水头模型 Epoch 36, Batch 0: Total Loss: 275.4846, Criterion Loss: 119.7911, Physics Loss: 246.5209, KL Loss: 155.6935\n",
      "水头模型 Epoch 036/500 | 训练损失: 267.8399 | 验证损失: 32.8314 | LR: 0.000658\n",
      "水头验证指标 - MSE: 33.0105, RMSE: 5.6884, MAE: 4.5545, R2: 0.6764\n",
      "水头模型 Epoch 37, Batch 0: Total Loss: 291.3340, Criterion Loss: 136.8715, Physics Loss: 300.4778, KL Loss: 154.4625\n",
      "水头模型 Epoch 037/500 | 训练损失: 262.8880 | 验证损失: 30.9192 | LR: 0.000621\n",
      "水头验证指标 - MSE: 31.0833, RMSE: 5.5400, MAE: 4.4176, R2: 0.7031\n",
      "水头模型 Epoch 38, Batch 0: Total Loss: 259.9362, Criterion Loss: 106.3181, Physics Loss: 232.1319, KL Loss: 153.6181\n",
      "水头模型 Epoch 038/500 | 训练损失: 257.2509 | 验证损失: 22.1568 | LR: 0.000582\n",
      "水头验证指标 - MSE: 21.3355, RMSE: 4.6132, MAE: 3.5866, R2: 0.7946\n",
      "保存基于损失的最佳水头模型，验证损失: 22.1568\n",
      "保存基于R2的最佳水头模型，R2: 0.7946\n",
      "水头模型 Epoch 39, Batch 0: Total Loss: 245.0330, Criterion Loss: 92.1389, Physics Loss: 225.0349, KL Loss: 152.8941\n",
      "水头模型 Epoch 039/500 | 训练损失: 257.5660 | 验证损失: 45.6999 | LR: 0.000544\n",
      "水头验证指标 - MSE: 46.7089, RMSE: 6.7008, MAE: 5.5349, R2: 0.5456\n",
      "水头模型 Epoch 40, Batch 0: Total Loss: 311.7823, Criterion Loss: 160.3329, Physics Loss: 334.8806, KL Loss: 151.4494\n",
      "水头模型 Epoch 040/500 | 训练损失: 263.8550 | 验证损失: 31.4132 | LR: 0.000505\n",
      "水头验证指标 - MSE: 31.7301, RMSE: 5.5829, MAE: 4.5399, R2: 0.6955\n",
      "水头模型 Epoch 41, Batch 0: Total Loss: 236.1554, Criterion Loss: 85.2318, Physics Loss: 221.4752, KL Loss: 150.9236\n",
      "水头模型 Epoch 041/500 | 训练损失: 245.0003 | 验证损失: 41.1127 | LR: 0.000466\n",
      "水头验证指标 - MSE: 42.3057, RMSE: 6.4445, MAE: 5.4030, R2: 0.5921\n",
      "水头模型 Epoch 42, Batch 0: Total Loss: 295.9195, Criterion Loss: 145.5203, Physics Loss: 269.9655, KL Loss: 150.3992\n",
      "水头模型 Epoch 042/500 | 训练损失: 267.7740 | 验证损失: 24.7386 | LR: 0.000428\n",
      "水头验证指标 - MSE: 24.5058, RMSE: 4.9309, MAE: 3.8753, R2: 0.7637\n",
      "水头模型 Epoch 43, Batch 0: Total Loss: 226.2856, Criterion Loss: 76.2744, Physics Loss: 203.8698, KL Loss: 150.0113\n",
      "水头模型 Epoch 043/500 | 训练损失: 253.8270 | 验证损失: 24.8440 | LR: 0.000389\n",
      "水头验证指标 - MSE: 24.5300, RMSE: 4.8984, MAE: 3.8729, R2: 0.7656\n",
      "水头模型 Epoch 44, Batch 0: Total Loss: 242.7779, Criterion Loss: 93.1695, Physics Loss: 215.1189, KL Loss: 149.6084\n",
      "水头模型 Epoch 044/500 | 训练损失: 248.5739 | 验证损失: 24.2879 | LR: 0.000352\n",
      "水头验证指标 - MSE: 23.6334, RMSE: 4.8345, MAE: 3.8174, R2: 0.7738\n",
      "水头模型 Epoch 45, Batch 0: Total Loss: 253.1972, Criterion Loss: 103.8591, Physics Loss: 254.5206, KL Loss: 149.3381\n",
      "水头模型 Epoch 045/500 | 训练损失: 249.2831 | 验证损失: 20.4928 | LR: 0.000316\n",
      "水头验证指标 - MSE: 19.7553, RMSE: 4.4370, MAE: 3.4565, R2: 0.8104\n",
      "保存基于损失的最佳水头模型，验证损失: 20.4928\n",
      "保存基于R2的最佳水头模型，R2: 0.8104\n",
      "水头模型 Epoch 46, Batch 0: Total Loss: 232.6600, Criterion Loss: 83.9050, Physics Loss: 217.7009, KL Loss: 148.7550\n",
      "水头模型 Epoch 046/500 | 训练损失: 246.6070 | 验证损失: 21.9313 | LR: 0.000280\n",
      "水头验证指标 - MSE: 21.4382, RMSE: 4.6195, MAE: 3.6412, R2: 0.7945\n",
      "水头模型 Epoch 47, Batch 0: Total Loss: 239.4401, Criterion Loss: 91.2158, Physics Loss: 230.2809, KL Loss: 148.2243\n",
      "水头模型 Epoch 047/500 | 训练损失: 242.9358 | 验证损失: 22.1101 | LR: 0.000246\n",
      "水头验证指标 - MSE: 21.5995, RMSE: 4.6223, MAE: 3.6315, R2: 0.7940\n",
      "水头模型 Epoch 48, Batch 0: Total Loss: 245.7012, Criterion Loss: 97.6364, Physics Loss: 217.6714, KL Loss: 148.0648\n",
      "水头模型 Epoch 048/500 | 训练损失: 244.6002 | 验证损失: 27.1960 | LR: 0.000214\n",
      "水头验证指标 - MSE: 27.2217, RMSE: 5.1615, MAE: 4.1377, R2: 0.7387\n",
      "水头模型 Epoch 49, Batch 0: Total Loss: 233.4606, Criterion Loss: 85.5952, Physics Loss: 204.6697, KL Loss: 147.8654\n",
      "水头模型 Epoch 049/500 | 训练损失: 262.7649 | 验证损失: 20.9471 | LR: 0.000184\n",
      "水头验证指标 - MSE: 20.2081, RMSE: 4.4806, MAE: 3.5165, R2: 0.8044\n",
      "水头模型 Epoch 50, Batch 0: Total Loss: 235.4056, Criterion Loss: 87.5673, Physics Loss: 227.2278, KL Loss: 147.8383\n",
      "水头模型 Epoch 050/500 | 训练损失: 253.3659 | 验证损失: 22.7907 | LR: 0.000155\n",
      "水头验证指标 - MSE: 22.2408, RMSE: 4.7005, MAE: 3.7060, R2: 0.7845\n",
      "水头模型 Epoch 51, Batch 0: Total Loss: 234.7882, Criterion Loss: 87.1045, Physics Loss: 212.0003, KL Loss: 147.6837\n",
      "水头模型 Epoch 051/500 | 训练损失: 244.9058 | 验证损失: 25.1811 | LR: 0.000129\n",
      "水头验证指标 - MSE: 25.0313, RMSE: 4.9469, MAE: 3.9487, R2: 0.7601\n",
      "水头模型 Epoch 52, Batch 0: Total Loss: 286.3202, Criterion Loss: 139.0080, Physics Loss: 296.8451, KL Loss: 147.3122\n",
      "水头模型 Epoch 052/500 | 训练损失: 237.9460 | 验证损失: 21.3387 | LR: 0.000105\n",
      "水头验证指标 - MSE: 20.6210, RMSE: 4.5354, MAE: 3.5450, R2: 0.8010\n",
      "水头模型 Epoch 53, Batch 0: Total Loss: 237.4795, Criterion Loss: 90.4892, Physics Loss: 224.9389, KL Loss: 146.9903\n",
      "水头模型 Epoch 053/500 | 训练损失: 237.6440 | 验证损失: 25.6069 | LR: 0.000083\n",
      "水头验证指标 - MSE: 25.3662, RMSE: 4.9844, MAE: 4.0096, R2: 0.7570\n",
      "水头模型 Epoch 54, Batch 0: Total Loss: 297.6617, Criterion Loss: 151.0082, Physics Loss: 271.6853, KL Loss: 146.6535\n",
      "水头模型 Epoch 054/500 | 训练损失: 237.3504 | 验证损失: 20.9384 | LR: 0.000064\n",
      "水头验证指标 - MSE: 20.2982, RMSE: 4.4912, MAE: 3.5157, R2: 0.8052\n",
      "水头模型 Epoch 55, Batch 0: Total Loss: 252.1276, Criterion Loss: 105.5831, Physics Loss: 246.1185, KL Loss: 146.5445\n",
      "水头模型 Epoch 055/500 | 训练损失: 248.5852 | 验证损失: 20.8105 | LR: 0.000048\n",
      "水头验证指标 - MSE: 20.1888, RMSE: 4.4763, MAE: 3.5010, R2: 0.8059\n",
      "水头模型 Epoch 56, Batch 0: Total Loss: 239.0395, Criterion Loss: 92.2208, Physics Loss: 227.7028, KL Loss: 146.8188\n",
      "水头模型 Epoch 056/500 | 训练损失: 239.0066 | 验证损失: 20.5862 | LR: 0.000034\n",
      "水头验证指标 - MSE: 19.8733, RMSE: 4.4425, MAE: 3.4878, R2: 0.8085\n",
      "水头模型 Epoch 57, Batch 0: Total Loss: 226.5813, Criterion Loss: 79.3081, Physics Loss: 198.3490, KL Loss: 147.2732\n",
      "水头模型 Epoch 057/500 | 训练损失: 233.4974 | 验证损失: 22.1181 | LR: 0.000024\n",
      "水头验证指标 - MSE: 21.5324, RMSE: 4.6143, MAE: 3.6421, R2: 0.7922\n",
      "水头模型 Epoch 58, Batch 0: Total Loss: 228.4859, Criterion Loss: 81.9891, Physics Loss: 213.1807, KL Loss: 146.4968\n",
      "水头模型 Epoch 058/500 | 训练损失: 238.3779 | 验证损失: 19.6916 | LR: 0.000016\n",
      "水头验证指标 - MSE: 18.9550, RMSE: 4.3487, MAE: 3.3953, R2: 0.8171\n",
      "保存基于损失的最佳水头模型，验证损失: 19.6916\n",
      "保存基于R2的最佳水头模型，R2: 0.8171\n",
      "水头模型 Epoch 59, Batch 0: Total Loss: 235.1724, Criterion Loss: 88.7461, Physics Loss: 224.9391, KL Loss: 146.4263\n",
      "水头模型 Epoch 059/500 | 训练损失: 238.3880 | 验证损失: 20.8452 | LR: 0.000012\n",
      "水头验证指标 - MSE: 20.2403, RMSE: 4.4866, MAE: 3.5247, R2: 0.8048\n",
      "水头模型 Epoch 60, Batch 0: Total Loss: 242.9280, Criterion Loss: 96.0145, Physics Loss: 219.5892, KL Loss: 146.9135\n",
      "水头模型 Epoch 060/500 | 训练损失: 241.7115 | 验证损失: 19.6476 | LR: 0.001000\n",
      "水头验证指标 - MSE: 18.9084, RMSE: 4.3420, MAE: 3.4021, R2: 0.8176\n",
      "保存基于损失的最佳水头模型，验证损失: 19.6476\n",
      "保存基于R2的最佳水头模型，R2: 0.8176\n",
      "水头模型 Epoch 61, Batch 0: Total Loss: 271.0406, Criterion Loss: 124.2513, Physics Loss: 240.9343, KL Loss: 146.7893\n",
      "水头模型 Epoch 061/500 | 训练损失: 270.2523 | 验证损失: 40.6843 | LR: 0.001000\n",
      "水头验证指标 - MSE: 42.1479, RMSE: 6.4461, MAE: 5.3648, R2: 0.5969\n",
      "水头模型 Epoch 62, Batch 0: Total Loss: 220.5939, Criterion Loss: 75.0832, Physics Loss: 194.4949, KL Loss: 145.5107\n",
      "水头模型 Epoch 062/500 | 训练损失: 244.1898 | 验证损失: 29.5856 | LR: 0.000998\n",
      "水头验证指标 - MSE: 29.7198, RMSE: 5.4332, MAE: 4.3085, R2: 0.7113\n",
      "水头模型 Epoch 63, Batch 0: Total Loss: 227.2098, Criterion Loss: 81.7383, Physics Loss: 204.3396, KL Loss: 145.4715\n",
      "水头模型 Epoch 063/500 | 训练损失: 243.8235 | 验证损失: 22.8260 | LR: 0.000997\n",
      "水头验证指标 - MSE: 22.0567, RMSE: 4.6842, MAE: 3.6929, R2: 0.7884\n",
      "水头模型 Epoch 64, Batch 0: Total Loss: 222.5887, Criterion Loss: 78.3288, Physics Loss: 205.4131, KL Loss: 144.2600\n",
      "水头模型 Epoch 064/500 | 训练损失: 240.6925 | 验证损失: 27.0724 | LR: 0.000994\n",
      "水头验证指标 - MSE: 26.7133, RMSE: 5.1318, MAE: 4.1513, R2: 0.7453\n",
      "水头模型 Epoch 65, Batch 0: Total Loss: 218.3289, Criterion Loss: 74.3966, Physics Loss: 195.4634, KL Loss: 143.9323\n",
      "水头模型 Epoch 065/500 | 训练损失: 229.3061 | 验证损失: 24.8832 | LR: 0.000990\n",
      "水头验证指标 - MSE: 24.6694, RMSE: 4.9574, MAE: 3.8544, R2: 0.7628\n",
      "水头模型 Epoch 66, Batch 0: Total Loss: 221.2016, Criterion Loss: 78.0015, Physics Loss: 195.1879, KL Loss: 143.2001\n",
      "水头模型 Epoch 066/500 | 训练损失: 233.7148 | 验证损失: 20.6732 | LR: 0.000986\n",
      "水头验证指标 - MSE: 19.3521, RMSE: 4.3943, MAE: 3.4352, R2: 0.8136\n",
      "水头模型 Epoch 67, Batch 0: Total Loss: 213.2714, Criterion Loss: 70.6131, Physics Loss: 188.6513, KL Loss: 142.6583\n",
      "水头模型 Epoch 067/500 | 训练损失: 246.7702 | 验证损失: 25.5565 | LR: 0.000981\n",
      "水头验证指标 - MSE: 25.5132, RMSE: 5.0411, MAE: 3.9457, R2: 0.7540\n",
      "水头模型 Epoch 68, Batch 0: Total Loss: 252.9903, Criterion Loss: 111.4490, Physics Loss: 247.3965, KL Loss: 141.5413\n",
      "水头模型 Epoch 068/500 | 训练损失: 242.2425 | 验证损失: 24.4996 | LR: 0.000976\n",
      "水头验证指标 - MSE: 23.2806, RMSE: 4.8163, MAE: 3.8473, R2: 0.7751\n",
      "水头模型 Epoch 69, Batch 0: Total Loss: 216.7888, Criterion Loss: 76.0776, Physics Loss: 205.6948, KL Loss: 140.7113\n",
      "水头模型 Epoch 069/500 | 训练损失: 235.0232 | 验证损失: 19.0569 | LR: 0.000969\n",
      "水头验证指标 - MSE: 18.0646, RMSE: 4.2463, MAE: 3.3334, R2: 0.8254\n",
      "保存基于损失的最佳水头模型，验证损失: 19.0569\n",
      "保存基于R2的最佳水头模型，R2: 0.8254\n",
      "水头模型 Epoch 70, Batch 0: Total Loss: 208.4839, Criterion Loss: 68.3963, Physics Loss: 185.5097, KL Loss: 140.0877\n",
      "水头模型 Epoch 070/500 | 训练损失: 221.1374 | 验证损失: 30.4489 | LR: 0.000962\n",
      "水头验证指标 - MSE: 30.6164, RMSE: 5.5169, MAE: 4.2638, R2: 0.7063\n",
      "水头模型 Epoch 71, Batch 0: Total Loss: 226.0647, Criterion Loss: 85.7773, Physics Loss: 213.0137, KL Loss: 140.2874\n",
      "水头模型 Epoch 071/500 | 训练损失: 219.0352 | 验证损失: 20.3482 | LR: 0.000955\n",
      "水头验证指标 - MSE: 19.5806, RMSE: 4.4072, MAE: 3.4729, R2: 0.8099\n",
      "水头模型 Epoch 72, Batch 0: Total Loss: 209.0651, Criterion Loss: 69.9616, Physics Loss: 186.0397, KL Loss: 139.1035\n",
      "水头模型 Epoch 072/500 | 训练损失: 216.2386 | 验证损失: 24.3813 | LR: 0.000946\n",
      "水头验证指标 - MSE: 24.1140, RMSE: 4.8895, MAE: 3.8553, R2: 0.7695\n",
      "水头模型 Epoch 73, Batch 0: Total Loss: 219.9407, Criterion Loss: 81.7610, Physics Loss: 188.4839, KL Loss: 138.1798\n",
      "水头模型 Epoch 073/500 | 训练损失: 235.1437 | 验证损失: 24.4250 | LR: 0.000937\n",
      "水头验证指标 - MSE: 24.3004, RMSE: 4.8944, MAE: 3.9153, R2: 0.7646\n",
      "水头模型 Epoch 74, Batch 0: Total Loss: 279.1443, Criterion Loss: 142.0365, Physics Loss: 250.9201, KL Loss: 137.1078\n",
      "水头模型 Epoch 074/500 | 训练损失: 227.5211 | 验证损失: 23.7515 | LR: 0.000927\n",
      "水头验证指标 - MSE: 23.0912, RMSE: 4.7399, MAE: 3.8487, R2: 0.7817\n",
      "水头模型 Epoch 75, Batch 0: Total Loss: 204.8707, Criterion Loss: 68.0803, Physics Loss: 184.8068, KL Loss: 136.7904\n",
      "水头模型 Epoch 075/500 | 训练损失: 235.4694 | 验证损失: 56.4944 | LR: 0.000917\n",
      "水头验证指标 - MSE: 59.3717, RMSE: 7.6733, MAE: 6.7393, R2: 0.4312\n",
      "水头模型 Epoch 76, Batch 0: Total Loss: 224.5277, Criterion Loss: 88.4906, Physics Loss: 188.9088, KL Loss: 136.0370\n",
      "水头模型 Epoch 076/500 | 训练损失: 244.4057 | 验证损失: 20.2880 | LR: 0.000905\n",
      "水头验证指标 - MSE: 19.7570, RMSE: 4.4367, MAE: 3.4521, R2: 0.8094\n",
      "水头模型 Epoch 77, Batch 0: Total Loss: 205.5170, Criterion Loss: 69.6257, Physics Loss: 179.9050, KL Loss: 135.8913\n",
      "水头模型 Epoch 077/500 | 训练损失: 221.2218 | 验证损失: 29.7430 | LR: 0.000894\n",
      "水头验证指标 - MSE: 29.5888, RMSE: 5.3717, MAE: 4.4209, R2: 0.7180\n",
      "水头模型 Epoch 78, Batch 0: Total Loss: 260.0629, Criterion Loss: 124.9241, Physics Loss: 258.7643, KL Loss: 135.1388\n",
      "水头模型 Epoch 078/500 | 训练损失: 222.7158 | 验证损失: 27.9172 | LR: 0.000881\n",
      "水头验证指标 - MSE: 27.0705, RMSE: 5.1701, MAE: 4.1198, R2: 0.7374\n",
      "水头模型 Epoch 79, Batch 0: Total Loss: 213.1242, Criterion Loss: 78.9310, Physics Loss: 206.7386, KL Loss: 134.1932\n",
      "水头模型 Epoch 079/500 | 训练损失: 220.0965 | 验证损失: 41.6403 | LR: 0.000868\n",
      "水头验证指标 - MSE: 42.5344, RMSE: 6.4660, MAE: 5.4458, R2: 0.5868\n",
      "水头模型 Epoch 80, Batch 0: Total Loss: 277.6161, Criterion Loss: 144.0523, Physics Loss: 288.9662, KL Loss: 133.5638\n",
      "水头模型 Epoch 080/500 | 训练损失: 212.0784 | 验证损失: 55.7746 | LR: 0.000855\n",
      "水头验证指标 - MSE: 58.5001, RMSE: 7.6111, MAE: 6.6985, R2: 0.4308\n",
      "水头模型 Epoch 81, Batch 0: Total Loss: 281.4645, Criterion Loss: 148.4713, Physics Loss: 288.7609, KL Loss: 132.9931\n",
      "水头模型 Epoch 081/500 | 训练损失: 225.6824 | 验证损失: 22.3969 | LR: 0.000841\n",
      "水头验证指标 - MSE: 21.5278, RMSE: 4.6300, MAE: 3.7110, R2: 0.7918\n",
      "水头模型 Epoch 82, Batch 0: Total Loss: 209.2416, Criterion Loss: 77.0682, Physics Loss: 182.8279, KL Loss: 132.1734\n",
      "水头模型 Epoch 082/500 | 训练损失: 207.9912 | 验证损失: 22.9658 | LR: 0.000826\n",
      "水头验证指标 - MSE: 22.9296, RMSE: 4.7621, MAE: 3.7404, R2: 0.7810\n",
      "水头模型 Epoch 83, Batch 0: Total Loss: 190.1599, Criterion Loss: 58.3782, Physics Loss: 156.2033, KL Loss: 131.7817\n",
      "水头模型 Epoch 083/500 | 训练损失: 210.6260 | 验证损失: 23.9594 | LR: 0.000811\n",
      "水头验证指标 - MSE: 23.9226, RMSE: 4.8688, MAE: 3.8710, R2: 0.7699\n",
      "水头模型 Epoch 84, Batch 0: Total Loss: 202.3990, Criterion Loss: 70.9913, Physics Loss: 182.7955, KL Loss: 131.4077\n",
      "水头模型 Epoch 084/500 | 训练损失: 216.3762 | 验证损失: 18.2241 | LR: 0.000796\n",
      "水头验证指标 - MSE: 17.4195, RMSE: 4.1488, MAE: 3.2941, R2: 0.8317\n",
      "保存基于损失的最佳水头模型，验证损失: 18.2241\n",
      "保存基于R2的最佳水头模型，R2: 0.8317\n",
      "水头模型 Epoch 85, Batch 0: Total Loss: 203.8783, Criterion Loss: 73.3774, Physics Loss: 177.1740, KL Loss: 130.5009\n",
      "水头模型 Epoch 085/500 | 训练损失: 204.7266 | 验证损失: 17.6674 | LR: 0.000780\n",
      "水头验证指标 - MSE: 16.8520, RMSE: 4.0967, MAE: 3.2495, R2: 0.8379\n",
      "保存基于损失的最佳水头模型，验证损失: 17.6674\n",
      "保存基于R2的最佳水头模型，R2: 0.8379\n",
      "水头模型 Epoch 86, Batch 0: Total Loss: 199.4201, Criterion Loss: 69.7135, Physics Loss: 178.1393, KL Loss: 129.7066\n",
      "水头模型 Epoch 086/500 | 训练损失: 205.3946 | 验证损失: 20.1498 | LR: 0.000764\n",
      "水头验证指标 - MSE: 19.5048, RMSE: 4.4078, MAE: 3.4617, R2: 0.8118\n",
      "水头模型 Epoch 87, Batch 0: Total Loss: 199.8975, Criterion Loss: 70.8037, Physics Loss: 179.4087, KL Loss: 129.0938\n",
      "水头模型 Epoch 087/500 | 训练损失: 199.4799 | 验证损失: 15.6765 | LR: 0.000747\n",
      "水头验证指标 - MSE: 14.3327, RMSE: 3.7797, MAE: 2.9731, R2: 0.8618\n",
      "保存基于损失的最佳水头模型，验证损失: 15.6765\n",
      "保存基于R2的最佳水头模型，R2: 0.8618\n",
      "水头模型 Epoch 88, Batch 0: Total Loss: 207.5938, Criterion Loss: 78.8872, Physics Loss: 194.7488, KL Loss: 128.7067\n",
      "水头模型 Epoch 088/500 | 训练损失: 204.4952 | 验证损失: 16.9804 | LR: 0.000730\n",
      "水头验证指标 - MSE: 16.1404, RMSE: 4.0106, MAE: 3.1618, R2: 0.8442\n",
      "水头模型 Epoch 89, Batch 0: Total Loss: 189.6373, Criterion Loss: 61.4305, Physics Loss: 167.0510, KL Loss: 128.2068\n",
      "水头模型 Epoch 089/500 | 训练损失: 199.6583 | 验证损失: 17.4962 | LR: 0.000712\n",
      "水头验证指标 - MSE: 16.9355, RMSE: 4.1109, MAE: 3.2288, R2: 0.8360\n",
      "水头模型 Epoch 90, Batch 0: Total Loss: 197.3248, Criterion Loss: 69.5443, Physics Loss: 176.2444, KL Loss: 127.7805\n",
      "水头模型 Epoch 090/500 | 训练损失: 204.1327 | 验证损失: 17.2509 | LR: 0.000694\n",
      "水头验证指标 - MSE: 16.4582, RMSE: 4.0478, MAE: 3.1347, R2: 0.8422\n",
      "水头模型 Epoch 91, Batch 0: Total Loss: 187.3134, Criterion Loss: 60.1207, Physics Loss: 163.9650, KL Loss: 127.1927\n",
      "水头模型 Epoch 091/500 | 训练损失: 202.0640 | 验证损失: 32.6544 | LR: 0.000676\n",
      "水头验证指标 - MSE: 33.0629, RMSE: 5.7007, MAE: 4.6701, R2: 0.6795\n",
      "水头模型 Epoch 92, Batch 0: Total Loss: 222.3602, Criterion Loss: 95.3285, Physics Loss: 214.2197, KL Loss: 127.0317\n",
      "水头模型 Epoch 092/500 | 训练损失: 208.8205 | 验证损失: 18.3302 | LR: 0.000658\n",
      "水头验证指标 - MSE: 17.7876, RMSE: 4.2023, MAE: 3.2633, R2: 0.8290\n",
      "水头模型 Epoch 93, Batch 0: Total Loss: 228.1610, Criterion Loss: 101.5848, Physics Loss: 196.3741, KL Loss: 126.5762\n",
      "水头模型 Epoch 093/500 | 训练损失: 191.9700 | 验证损失: 19.3742 | LR: 0.000639\n",
      "水头验证指标 - MSE: 18.9201, RMSE: 4.3206, MAE: 3.4021, R2: 0.8190\n",
      "水头模型 Epoch 94, Batch 0: Total Loss: 190.1466, Criterion Loss: 64.1159, Physics Loss: 151.9029, KL Loss: 126.0307\n",
      "水头模型 Epoch 094/500 | 训练损失: 201.5843 | 验证损失: 18.1019 | LR: 0.000621\n",
      "水头验证指标 - MSE: 17.4520, RMSE: 4.1516, MAE: 3.2305, R2: 0.8326\n",
      "水头模型 Epoch 95, Batch 0: Total Loss: 182.5566, Criterion Loss: 57.0676, Physics Loss: 155.6904, KL Loss: 125.4890\n",
      "水头模型 Epoch 095/500 | 训练损失: 213.8580 | 验证损失: 25.5762 | LR: 0.000602\n",
      "水头验证指标 - MSE: 25.3726, RMSE: 5.0168, MAE: 4.1121, R2: 0.7556\n",
      "水头模型 Epoch 96, Batch 0: Total Loss: 185.9867, Criterion Loss: 61.1357, Physics Loss: 163.8565, KL Loss: 124.8510\n",
      "水头模型 Epoch 096/500 | 训练损失: 190.3342 | 验证损失: 26.0772 | LR: 0.000582\n",
      "水头验证指标 - MSE: 26.3895, RMSE: 5.1038, MAE: 4.0689, R2: 0.7473\n",
      "水头模型 Epoch 97, Batch 0: Total Loss: 180.3575, Criterion Loss: 56.1228, Physics Loss: 154.0618, KL Loss: 124.2347\n",
      "水头模型 Epoch 097/500 | 训练损失: 194.6719 | 验证损失: 21.1973 | LR: 0.000563\n",
      "水头验证指标 - MSE: 19.2256, RMSE: 4.3675, MAE: 3.2799, R2: 0.8134\n",
      "水头模型 Epoch 98, Batch 0: Total Loss: 193.5395, Criterion Loss: 69.1701, Physics Loss: 175.6779, KL Loss: 124.3694\n",
      "水头模型 Epoch 098/500 | 训练损失: 202.2365 | 验证损失: 26.6761 | LR: 0.000544\n",
      "水头验证指标 - MSE: 26.5968, RMSE: 5.1011, MAE: 4.1303, R2: 0.7469\n",
      "水头模型 Epoch 99, Batch 0: Total Loss: 185.6323, Criterion Loss: 61.9823, Physics Loss: 157.1030, KL Loss: 123.6501\n",
      "水头模型 Epoch 099/500 | 训练损失: 202.4705 | 验证损失: 23.9635 | LR: 0.000524\n",
      "水头验证指标 - MSE: 22.7966, RMSE: 4.6845, MAE: 3.7194, R2: 0.7848\n",
      "水头模型 Epoch 100, Batch 0: Total Loss: 185.1169, Criterion Loss: 62.1310, Physics Loss: 172.1826, KL Loss: 122.9859\n",
      "水头模型 Epoch 100/500 | 训练损失: 197.5708 | 验证损失: 17.5388 | LR: 0.000505\n",
      "水头验证指标 - MSE: 16.6484, RMSE: 4.0738, MAE: 3.1571, R2: 0.8393\n",
      "水头模型 Epoch 101, Batch 0: Total Loss: 185.6163, Criterion Loss: 62.2478, Physics Loss: 168.4606, KL Loss: 123.3685\n",
      "水头模型 Epoch 101/500 | 训练损失: 184.4656 | 验证损失: 15.8303 | LR: 0.000486\n",
      "水头验证指标 - MSE: 14.6074, RMSE: 3.8131, MAE: 2.9901, R2: 0.8587\n",
      "水头模型 Epoch 102, Batch 0: Total Loss: 181.4704, Criterion Loss: 58.8282, Physics Loss: 159.2113, KL Loss: 122.6422\n",
      "水头模型 Epoch 102/500 | 训练损失: 191.1939 | 验证损失: 26.9706 | LR: 0.000466\n",
      "水头验证指标 - MSE: 26.5657, RMSE: 5.0994, MAE: 4.2059, R2: 0.7447\n",
      "水头模型 Epoch 103, Batch 0: Total Loss: 238.5931, Criterion Loss: 116.5351, Physics Loss: 222.0270, KL Loss: 122.0580\n",
      "水头模型 Epoch 103/500 | 训练损失: 190.7180 | 验证损失: 18.3895 | LR: 0.000447\n",
      "水头验证指标 - MSE: 17.1121, RMSE: 4.1309, MAE: 3.2695, R2: 0.8338\n",
      "水头模型 Epoch 104, Batch 0: Total Loss: 176.7393, Criterion Loss: 55.4616, Physics Loss: 156.4334, KL Loss: 121.2777\n",
      "水头模型 Epoch 104/500 | 训练损失: 184.7438 | 验证损失: 19.4185 | LR: 0.000428\n",
      "水头验证指标 - MSE: 18.6405, RMSE: 4.2954, MAE: 3.3317, R2: 0.8208\n",
      "水头模型 Epoch 105, Batch 0: Total Loss: 175.5153, Criterion Loss: 54.8227, Physics Loss: 151.4917, KL Loss: 120.6926\n",
      "水头模型 Epoch 105/500 | 训练损失: 187.4281 | 验证损失: 17.0774 | LR: 0.000408\n",
      "水头验证指标 - MSE: 16.2578, RMSE: 4.0100, MAE: 3.1328, R2: 0.8441\n",
      "水头模型 Epoch 106, Batch 0: Total Loss: 185.9518, Criterion Loss: 65.2562, Physics Loss: 165.4354, KL Loss: 120.6956\n",
      "水头模型 Epoch 106/500 | 训练损失: 183.5227 | 验证损失: 37.0745 | LR: 0.000389\n",
      "水头验证指标 - MSE: 37.0270, RMSE: 6.0092, MAE: 4.9486, R2: 0.6424\n",
      "水头模型 Epoch 107, Batch 0: Total Loss: 290.9765, Criterion Loss: 170.8691, Physics Loss: 315.9309, KL Loss: 120.1074\n",
      "水头模型 Epoch 107/500 | 训练损失: 205.3793 | 验证损失: 21.7084 | LR: 0.000371\n",
      "水头验证指标 - MSE: 20.4684, RMSE: 4.5013, MAE: 3.6463, R2: 0.8039\n",
      "水头模型 Epoch 108, Batch 0: Total Loss: 176.0771, Criterion Loss: 56.2717, Physics Loss: 159.4848, KL Loss: 119.8055\n",
      "水头模型 Epoch 108/500 | 训练损失: 182.5016 | 验证损失: 16.8561 | LR: 0.000352\n",
      "水头验证指标 - MSE: 16.0355, RMSE: 3.9841, MAE: 3.0958, R2: 0.8459\n",
      "水头模型 Epoch 109, Batch 0: Total Loss: 199.1329, Criterion Loss: 78.9420, Physics Loss: 166.0621, KL Loss: 120.1909\n",
      "水头模型 Epoch 109/500 | 训练损失: 192.7925 | 验证损失: 15.2690 | LR: 0.000334\n",
      "水头验证指标 - MSE: 14.0255, RMSE: 3.7347, MAE: 2.9160, R2: 0.8645\n",
      "保存基于损失的最佳水头模型，验证损失: 15.2690\n",
      "保存基于R2的最佳水头模型，R2: 0.8645\n",
      "水头模型 Epoch 110, Batch 0: Total Loss: 180.2198, Criterion Loss: 60.9350, Physics Loss: 163.5251, KL Loss: 119.2847\n",
      "水头模型 Epoch 110/500 | 训练损失: 179.3325 | 验证损失: 15.6025 | LR: 0.000316\n",
      "水头验证指标 - MSE: 14.5394, RMSE: 3.8067, MAE: 2.9932, R2: 0.8591\n",
      "水头模型 Epoch 111, Batch 0: Total Loss: 175.0613, Criterion Loss: 55.8384, Physics Loss: 146.2262, KL Loss: 119.2228\n",
      "水头模型 Epoch 111/500 | 训练损失: 178.1511 | 验证损失: 15.9978 | LR: 0.000298\n",
      "水头验证指标 - MSE: 15.1433, RMSE: 3.8727, MAE: 3.0020, R2: 0.8539\n",
      "水头模型 Epoch 112, Batch 0: Total Loss: 187.1516, Criterion Loss: 68.5737, Physics Loss: 153.0418, KL Loss: 118.5779\n",
      "水头模型 Epoch 112/500 | 训练损失: 179.6485 | 验证损失: 15.0382 | LR: 0.000280\n",
      "水头验证指标 - MSE: 13.8727, RMSE: 3.7180, MAE: 2.9227, R2: 0.8668\n",
      "保存基于损失的最佳水头模型，验证损失: 15.0382\n",
      "保存基于R2的最佳水头模型，R2: 0.8668\n",
      "水头模型 Epoch 113, Batch 0: Total Loss: 174.9915, Criterion Loss: 56.6628, Physics Loss: 154.0492, KL Loss: 118.3288\n",
      "水头模型 Epoch 113/500 | 训练损失: 180.5762 | 验证损失: 14.8443 | LR: 0.000263\n",
      "水头验证指标 - MSE: 13.6487, RMSE: 3.6883, MAE: 2.8898, R2: 0.8685\n",
      "保存基于损失的最佳水头模型，验证损失: 14.8443\n",
      "保存基于R2的最佳水头模型，R2: 0.8685\n",
      "水头模型 Epoch 114, Batch 0: Total Loss: 173.8231, Criterion Loss: 55.9276, Physics Loss: 153.1906, KL Loss: 117.8955\n",
      "水头模型 Epoch 114/500 | 训练损失: 182.2681 | 验证损失: 14.7272 | LR: 0.000246\n",
      "水头验证指标 - MSE: 13.5592, RMSE: 3.6760, MAE: 2.8786, R2: 0.8689\n",
      "保存基于损失的最佳水头模型，验证损失: 14.7272\n",
      "保存基于R2的最佳水头模型，R2: 0.8689\n",
      "水头模型 Epoch 115, Batch 0: Total Loss: 177.1899, Criterion Loss: 59.3056, Physics Loss: 156.2332, KL Loss: 117.8843\n",
      "水头模型 Epoch 115/500 | 训练损失: 178.6404 | 验证损失: 14.9275 | LR: 0.000230\n",
      "水头验证指标 - MSE: 13.7675, RMSE: 3.6961, MAE: 2.9117, R2: 0.8668\n",
      "水头模型 Epoch 116, Batch 0: Total Loss: 181.8957, Criterion Loss: 64.3535, Physics Loss: 164.6598, KL Loss: 117.5422\n",
      "水头模型 Epoch 116/500 | 训练损失: 176.9482 | 验证损失: 15.8803 | LR: 0.000214\n",
      "水头验证指标 - MSE: 14.7300, RMSE: 3.8117, MAE: 3.0091, R2: 0.8565\n",
      "水头模型 Epoch 117, Batch 0: Total Loss: 175.7871, Criterion Loss: 58.3818, Physics Loss: 154.7165, KL Loss: 117.4052\n",
      "水头模型 Epoch 117/500 | 训练损失: 177.4053 | 验证损失: 16.0818 | LR: 0.000199\n",
      "水头验证指标 - MSE: 15.2281, RMSE: 3.8744, MAE: 3.0718, R2: 0.8529\n",
      "水头模型 Epoch 118, Batch 0: Total Loss: 168.7393, Criterion Loss: 51.6107, Physics Loss: 141.5612, KL Loss: 117.1286\n",
      "水头模型 Epoch 118/500 | 训练损失: 179.9082 | 验证损失: 15.1736 | LR: 0.000184\n",
      "水头验证指标 - MSE: 14.2717, RMSE: 3.7416, MAE: 2.9159, R2: 0.8645\n",
      "水头模型 Epoch 119, Batch 0: Total Loss: 170.5347, Criterion Loss: 53.1348, Physics Loss: 140.9737, KL Loss: 117.3999\n",
      "水头模型 Epoch 119/500 | 训练损失: 180.4489 | 验证损失: 14.8454 | LR: 0.000169\n",
      "水头验证指标 - MSE: 13.8840, RMSE: 3.7171, MAE: 2.8939, R2: 0.8664\n",
      "水头模型 Epoch 120, Batch 0: Total Loss: 168.2952, Criterion Loss: 51.1021, Physics Loss: 140.6825, KL Loss: 117.1930\n",
      "水头模型 Epoch 120/500 | 训练损失: 176.1273 | 验证损失: 15.3891 | LR: 0.000155\n",
      "水头验证指标 - MSE: 14.3879, RMSE: 3.7672, MAE: 2.9450, R2: 0.8619\n",
      "水头模型 Epoch 121, Batch 0: Total Loss: 169.8137, Criterion Loss: 53.3380, Physics Loss: 147.2931, KL Loss: 116.4757\n",
      "水头模型 Epoch 121/500 | 训练损失: 176.9549 | 验证损失: 13.9385 | LR: 0.000142\n",
      "水头验证指标 - MSE: 12.6309, RMSE: 3.5469, MAE: 2.7705, R2: 0.8785\n",
      "保存基于损失的最佳水头模型，验证损失: 13.9385\n",
      "保存基于R2的最佳水头模型，R2: 0.8785\n",
      "水头模型 Epoch 122, Batch 0: Total Loss: 173.4849, Criterion Loss: 56.8772, Physics Loss: 155.7101, KL Loss: 116.6077\n",
      "水头模型 Epoch 122/500 | 训练损失: 175.5030 | 验证损失: 14.6144 | LR: 0.000129\n",
      "水头验证指标 - MSE: 13.4408, RMSE: 3.6544, MAE: 2.8600, R2: 0.8699\n",
      "水头模型 Epoch 123, Batch 0: Total Loss: 172.5644, Criterion Loss: 56.0418, Physics Loss: 142.5377, KL Loss: 116.5226\n",
      "水头模型 Epoch 123/500 | 训练损失: 180.9297 | 验证损失: 13.7539 | LR: 0.000116\n",
      "水头验证指标 - MSE: 12.5039, RMSE: 3.5288, MAE: 2.7568, R2: 0.8793\n",
      "保存基于损失的最佳水头模型，验证损失: 13.7539\n",
      "保存基于R2的最佳水头模型，R2: 0.8793\n",
      "水头模型 Epoch 124, Batch 0: Total Loss: 169.9497, Criterion Loss: 53.4808, Physics Loss: 145.5147, KL Loss: 116.4688\n",
      "水头模型 Epoch 124/500 | 训练损失: 176.5630 | 验证损失: 15.8776 | LR: 0.000105\n",
      "水头验证指标 - MSE: 14.8900, RMSE: 3.8237, MAE: 3.0123, R2: 0.8579\n",
      "水头模型 Epoch 125, Batch 0: Total Loss: 166.0386, Criterion Loss: 49.7883, Physics Loss: 137.9244, KL Loss: 116.2503\n",
      "水头模型 Epoch 125/500 | 训练损失: 175.8001 | 验证损失: 13.8445 | LR: 0.000093\n",
      "水头验证指标 - MSE: 12.7047, RMSE: 3.5571, MAE: 2.7806, R2: 0.8773\n",
      "水头模型 Epoch 126, Batch 0: Total Loss: 179.7246, Criterion Loss: 63.6520, Physics Loss: 161.5308, KL Loss: 116.0726\n",
      "水头模型 Epoch 126/500 | 训练损失: 174.0064 | 验证损失: 16.4448 | LR: 0.000083\n",
      "水头验证指标 - MSE: 15.6065, RMSE: 3.9059, MAE: 3.1192, R2: 0.8489\n",
      "水头模型 Epoch 127, Batch 0: Total Loss: 172.6136, Criterion Loss: 56.3796, Physics Loss: 149.7841, KL Loss: 116.2340\n",
      "水头模型 Epoch 127/500 | 训练损失: 175.1317 | 验证损失: 17.0387 | LR: 0.000073\n",
      "水头验证指标 - MSE: 16.2859, RMSE: 4.0170, MAE: 3.1575, R2: 0.8441\n",
      "水头模型 Epoch 128, Batch 0: Total Loss: 178.7033, Criterion Loss: 62.7411, Physics Loss: 157.7842, KL Loss: 115.9622\n",
      "水头模型 Epoch 128/500 | 训练损失: 175.1739 | 验证损失: 13.7218 | LR: 0.000064\n",
      "水头验证指标 - MSE: 12.5233, RMSE: 3.5294, MAE: 2.7588, R2: 0.8794\n",
      "保存基于损失的最佳水头模型，验证损失: 13.7218\n",
      "保存基于R2的最佳水头模型，R2: 0.8794\n",
      "水头模型 Epoch 129, Batch 0: Total Loss: 184.7887, Criterion Loss: 68.5729, Physics Loss: 152.6089, KL Loss: 116.2158\n",
      "水头模型 Epoch 129/500 | 训练损失: 182.8538 | 验证损失: 15.4552 | LR: 0.000055\n",
      "水头验证指标 - MSE: 14.4820, RMSE: 3.7979, MAE: 3.0096, R2: 0.8601\n",
      "水头模型 Epoch 130, Batch 0: Total Loss: 175.3229, Criterion Loss: 59.2052, Physics Loss: 152.4503, KL Loss: 116.1177\n",
      "水头模型 Epoch 130/500 | 训练损失: 174.7630 | 验证损失: 14.2057 | LR: 0.000048\n",
      "水头验证指标 - MSE: 13.1122, RMSE: 3.6120, MAE: 2.8154, R2: 0.8734\n",
      "水头模型 Epoch 131, Batch 0: Total Loss: 179.5969, Criterion Loss: 63.6497, Physics Loss: 152.4854, KL Loss: 115.9473\n",
      "水头模型 Epoch 131/500 | 训练损失: 176.1714 | 验证损失: 17.0617 | LR: 0.000041\n",
      "水头验证指标 - MSE: 16.3488, RMSE: 4.0278, MAE: 3.1466, R2: 0.8420\n",
      "水头模型 Epoch 132, Batch 0: Total Loss: 173.1674, Criterion Loss: 57.5581, Physics Loss: 142.3408, KL Loss: 115.6092\n",
      "水头模型 Epoch 132/500 | 训练损失: 175.1629 | 验证损失: 14.2365 | LR: 0.000034\n",
      "水头验证指标 - MSE: 13.0335, RMSE: 3.5999, MAE: 2.8151, R2: 0.8745\n",
      "水头模型 Epoch 133, Batch 0: Total Loss: 168.8799, Criterion Loss: 52.7627, Physics Loss: 146.0627, KL Loss: 116.1172\n",
      "水头模型 Epoch 133/500 | 训练损失: 176.7792 | 验证损失: 14.3223 | LR: 0.000029\n",
      "水头验证指标 - MSE: 13.3311, RMSE: 3.6445, MAE: 2.8445, R2: 0.8711\n",
      "水头模型 Epoch 134, Batch 0: Total Loss: 170.0500, Criterion Loss: 54.1367, Physics Loss: 145.4143, KL Loss: 115.9132\n",
      "水头模型 Epoch 134/500 | 训练损失: 175.1046 | 验证损失: 14.7478 | LR: 0.000024\n",
      "水头验证指标 - MSE: 13.6929, RMSE: 3.6823, MAE: 2.8786, R2: 0.8685\n",
      "水头模型 Epoch 135, Batch 0: Total Loss: 175.2138, Criterion Loss: 59.3782, Physics Loss: 159.5015, KL Loss: 115.8357\n",
      "水头模型 Epoch 135/500 | 训练损失: 175.9014 | 验证损失: 14.0664 | LR: 0.000020\n",
      "水头验证指标 - MSE: 12.9472, RMSE: 3.5902, MAE: 2.8104, R2: 0.8746\n",
      "水头模型 Epoch 136, Batch 0: Total Loss: 171.6480, Criterion Loss: 56.0120, Physics Loss: 153.3478, KL Loss: 115.6360\n",
      "水头模型 Epoch 136/500 | 训练损失: 177.9149 | 验证损失: 13.4671 | LR: 0.000016\n",
      "水头验证指标 - MSE: 12.2241, RMSE: 3.4909, MAE: 2.7269, R2: 0.8818\n",
      "保存基于损失的最佳水头模型，验证损失: 13.4671\n",
      "保存基于R2的最佳水头模型，R2: 0.8818\n",
      "水头模型 Epoch 137, Batch 0: Total Loss: 171.8308, Criterion Loss: 55.6718, Physics Loss: 149.7809, KL Loss: 116.1591\n",
      "水头模型 Epoch 137/500 | 训练损失: 176.0246 | 验证损失: 14.5191 | LR: 0.000013\n",
      "水头验证指标 - MSE: 13.4946, RMSE: 3.6596, MAE: 2.8592, R2: 0.8701\n",
      "水头模型 Epoch 138, Batch 0: Total Loss: 172.3927, Criterion Loss: 56.6968, Physics Loss: 151.4969, KL Loss: 115.6959\n",
      "水头模型 Epoch 138/500 | 训练损失: 172.2557 | 验证损失: 14.3174 | LR: 0.000012\n",
      "水头验证指标 - MSE: 13.2220, RMSE: 3.6169, MAE: 2.8311, R2: 0.8737\n",
      "水头模型 Epoch 139, Batch 0: Total Loss: 165.6251, Criterion Loss: 49.7527, Physics Loss: 138.2294, KL Loss: 115.8724\n",
      "水头模型 Epoch 139/500 | 训练损失: 170.7213 | 验证损失: 13.4348 | LR: 0.000010\n",
      "水头验证指标 - MSE: 12.3251, RMSE: 3.5023, MAE: 2.7371, R2: 0.8812\n",
      "保存基于损失的最佳水头模型，验证损失: 13.4348\n",
      "水头模型 Epoch 140, Batch 0: Total Loss: 170.8575, Criterion Loss: 54.8733, Physics Loss: 138.9706, KL Loss: 115.9842\n",
      "水头模型 Epoch 140/500 | 训练损失: 174.4615 | 验证损失: 13.4742 | LR: 0.001000\n",
      "水头验证指标 - MSE: 12.3874, RMSE: 3.5158, MAE: 2.7323, R2: 0.8807\n",
      "水头模型 Epoch 141, Batch 0: Total Loss: 171.2753, Criterion Loss: 55.6005, Physics Loss: 149.7993, KL Loss: 115.6748\n",
      "水头模型 Epoch 141/500 | 训练损失: 179.4623 | 验证损失: 18.4397 | LR: 0.001000\n",
      "水头验证指标 - MSE: 17.4245, RMSE: 4.1548, MAE: 3.2815, R2: 0.8320\n",
      "水头模型 Epoch 142, Batch 0: Total Loss: 174.7188, Criterion Loss: 59.3004, Physics Loss: 150.7894, KL Loss: 115.4183\n",
      "水头模型 Epoch 142/500 | 训练损失: 178.7263 | 验证损失: 23.5587 | LR: 0.001000\n",
      "水头验证指标 - MSE: 23.6244, RMSE: 4.8087, MAE: 3.8250, R2: 0.7727\n",
      "水头模型 Epoch 143, Batch 0: Total Loss: 165.3745, Criterion Loss: 50.7761, Physics Loss: 136.5872, KL Loss: 114.5984\n",
      "水头模型 Epoch 143/500 | 训练损失: 181.8572 | 验证损失: 31.3252 | LR: 0.000999\n",
      "水头验证指标 - MSE: 32.2119, RMSE: 5.6581, MAE: 4.5516, R2: 0.6921\n",
      "水头模型 Epoch 144, Batch 0: Total Loss: 201.5722, Criterion Loss: 86.7893, Physics Loss: 170.9916, KL Loss: 114.7829\n",
      "水头模型 Epoch 144/500 | 训练损失: 179.5519 | 验证损失: 14.6393 | LR: 0.000998\n",
      "水头验证指标 - MSE: 13.3712, RMSE: 3.6503, MAE: 2.8639, R2: 0.8705\n",
      "水头模型 Epoch 145, Batch 0: Total Loss: 164.3137, Criterion Loss: 50.3565, Physics Loss: 141.5149, KL Loss: 113.9572\n",
      "水头模型 Epoch 145/500 | 训练损失: 176.4200 | 验证损失: 20.8045 | LR: 0.000998\n",
      "水头验证指标 - MSE: 20.4171, RMSE: 4.5017, MAE: 3.4861, R2: 0.8040\n",
      "水头模型 Epoch 146, Batch 0: Total Loss: 165.5133, Criterion Loss: 52.1994, Physics Loss: 137.8572, KL Loss: 113.3138\n",
      "水头模型 Epoch 146/500 | 训练损失: 190.1460 | 验证损失: 19.1328 | LR: 0.000997\n",
      "水头验证指标 - MSE: 18.5941, RMSE: 4.3005, MAE: 3.3464, R2: 0.8218\n",
      "水头模型 Epoch 147, Batch 0: Total Loss: 179.0439, Criterion Loss: 66.0326, Physics Loss: 153.8564, KL Loss: 113.0113\n",
      "水头模型 Epoch 147/500 | 训练损失: 176.2176 | 验证损失: 19.8886 | LR: 0.000995\n",
      "水头验证指标 - MSE: 18.8143, RMSE: 4.3210, MAE: 3.4805, R2: 0.8187\n",
      "水头模型 Epoch 148, Batch 0: Total Loss: 205.7722, Criterion Loss: 93.3398, Physics Loss: 189.1669, KL Loss: 112.4324\n",
      "水头模型 Epoch 148/500 | 训练损失: 175.8701 | 验证损失: 20.8510 | LR: 0.000994\n",
      "水头验证指标 - MSE: 19.5074, RMSE: 4.3899, MAE: 3.4925, R2: 0.8103\n",
      "水头模型 Epoch 149, Batch 0: Total Loss: 172.4487, Criterion Loss: 59.7411, Physics Loss: 153.7547, KL Loss: 112.7076\n",
      "水头模型 Epoch 149/500 | 训练损失: 176.6656 | 验证损失: 16.3070 | LR: 0.000992\n",
      "水头验证指标 - MSE: 15.6194, RMSE: 3.9460, MAE: 3.0474, R2: 0.8500\n",
      "水头模型 Epoch 150, Batch 0: Total Loss: 194.3536, Criterion Loss: 82.7181, Physics Loss: 170.0036, KL Loss: 111.6355\n",
      "水头模型 Epoch 150/500 | 训练损失: 173.4267 | 验证损失: 17.8087 | LR: 0.000990\n",
      "水头验证指标 - MSE: 17.2115, RMSE: 4.0994, MAE: 3.2009, R2: 0.8363\n",
      "水头模型 Epoch 151, Batch 0: Total Loss: 164.8335, Criterion Loss: 53.8956, Physics Loss: 146.0131, KL Loss: 110.9380\n",
      "水头模型 Epoch 151/500 | 训练损失: 172.9571 | 验证损失: 17.8640 | LR: 0.000988\n",
      "水头验证指标 - MSE: 17.1396, RMSE: 4.1084, MAE: 3.2182, R2: 0.8357\n",
      "水头模型 Epoch 152, Batch 0: Total Loss: 176.6970, Criterion Loss: 66.2305, Physics Loss: 156.5520, KL Loss: 110.4665\n",
      "水头模型 Epoch 152/500 | 训练损失: 169.8591 | 验证损失: 20.6097 | LR: 0.000986\n",
      "水头验证指标 - MSE: 20.3704, RMSE: 4.4966, MAE: 3.5212, R2: 0.8052\n",
      "水头模型 Epoch 153, Batch 0: Total Loss: 192.0776, Criterion Loss: 81.8869, Physics Loss: 166.3992, KL Loss: 110.1907\n",
      "水头模型 Epoch 153/500 | 训练损失: 169.4172 | 验证损失: 20.7356 | LR: 0.000984\n",
      "水头验证指标 - MSE: 19.5321, RMSE: 4.4109, MAE: 3.5303, R2: 0.8109\n",
      "水头模型 Epoch 154, Batch 0: Total Loss: 171.2492, Criterion Loss: 62.0773, Physics Loss: 153.9774, KL Loss: 109.1719\n",
      "水头模型 Epoch 154/500 | 训练损失: 172.5273 | 验证损失: 15.7247 | LR: 0.000981\n",
      "水头验证指标 - MSE: 14.8349, RMSE: 3.8299, MAE: 3.0437, R2: 0.8562\n",
      "水头模型 Epoch 155, Batch 0: Total Loss: 163.2548, Criterion Loss: 53.7914, Physics Loss: 139.6934, KL Loss: 109.4634\n",
      "水头模型 Epoch 155/500 | 训练损失: 179.5377 | 验证损失: 18.1603 | LR: 0.000979\n",
      "水头验证指标 - MSE: 17.3783, RMSE: 4.1536, MAE: 3.3250, R2: 0.8316\n",
      "水头模型 Epoch 156, Batch 0: Total Loss: 162.2913, Criterion Loss: 53.4635, Physics Loss: 144.2903, KL Loss: 108.8278\n",
      "水头模型 Epoch 156/500 | 训练损失: 168.7042 | 验证损失: 17.5999 | LR: 0.000976\n",
      "水头验证指标 - MSE: 16.5135, RMSE: 4.0514, MAE: 3.2179, R2: 0.8394\n",
      "水头模型 Epoch 157, Batch 0: Total Loss: 239.8628, Criterion Loss: 131.6536, Physics Loss: 257.5544, KL Loss: 108.2092\n",
      "水头模型 Epoch 157/500 | 训练损失: 169.8769 | 验证损失: 20.4384 | LR: 0.000973\n",
      "水头验证指标 - MSE: 19.9382, RMSE: 4.4287, MAE: 3.6158, R2: 0.8062\n",
      "水头模型 Epoch 158, Batch 0: Total Loss: 158.7434, Criterion Loss: 50.8859, Physics Loss: 138.7248, KL Loss: 107.8574\n",
      "水头模型 Epoch 158/500 | 训练损失: 169.5348 | 验证损失: 17.4783 | LR: 0.000969\n",
      "水头验证指标 - MSE: 16.4055, RMSE: 4.0203, MAE: 3.2187, R2: 0.8437\n",
      "水头模型 Epoch 159, Batch 0: Total Loss: 162.1996, Criterion Loss: 55.1691, Physics Loss: 148.2585, KL Loss: 107.0305\n",
      "水头模型 Epoch 159/500 | 训练损失: 168.4940 | 验证损失: 19.2493 | LR: 0.000966\n",
      "水头验证指标 - MSE: 17.7053, RMSE: 4.1888, MAE: 3.3448, R2: 0.8303\n",
      "水头模型 Epoch 160, Batch 0: Total Loss: 170.9387, Criterion Loss: 64.2993, Physics Loss: 154.8171, KL Loss: 106.6394\n",
      "水头模型 Epoch 160/500 | 训练损失: 162.9535 | 验证损失: 22.6671 | LR: 0.000962\n",
      "水头验证指标 - MSE: 21.9552, RMSE: 4.6766, MAE: 3.8382, R2: 0.7873\n",
      "水头模型 Epoch 161, Batch 0: Total Loss: 155.5296, Criterion Loss: 49.2128, Physics Loss: 135.2369, KL Loss: 106.3168\n",
      "水头模型 Epoch 161/500 | 训练损失: 162.2710 | 验证损失: 15.9984 | LR: 0.000959\n",
      "水头验证指标 - MSE: 14.6286, RMSE: 3.8055, MAE: 3.0079, R2: 0.8584\n",
      "水头模型 Epoch 162, Batch 0: Total Loss: 167.4262, Criterion Loss: 61.7635, Physics Loss: 153.4074, KL Loss: 105.6627\n",
      "水头模型 Epoch 162/500 | 训练损失: 167.7178 | 验证损失: 14.7671 | LR: 0.000955\n",
      "水头验证指标 - MSE: 13.4383, RMSE: 3.6497, MAE: 2.8457, R2: 0.8705\n",
      "水头模型 Epoch 163, Batch 0: Total Loss: 162.0091, Criterion Loss: 56.5244, Physics Loss: 136.5602, KL Loss: 105.4847\n",
      "水头模型 Epoch 163/500 | 训练损失: 162.2145 | 验证损失: 16.7462 | LR: 0.000950\n",
      "水头验证指标 - MSE: 15.2880, RMSE: 3.9015, MAE: 3.1236, R2: 0.8533\n",
      "水头模型 Epoch 164, Batch 0: Total Loss: 156.1223, Criterion Loss: 51.4638, Physics Loss: 141.5738, KL Loss: 104.6585\n",
      "水头模型 Epoch 164/500 | 训练损失: 158.6170 | 验证损失: 15.2582 | LR: 0.000946\n",
      "水头验证指标 - MSE: 14.4946, RMSE: 3.7905, MAE: 2.9762, R2: 0.8608\n",
      "水头模型 Epoch 165, Batch 0: Total Loss: 151.9691, Criterion Loss: 47.5796, Physics Loss: 129.9580, KL Loss: 104.3896\n",
      "水头模型 Epoch 165/500 | 训练损失: 162.0216 | 验证损失: 18.7555 | LR: 0.000942\n",
      "水头验证指标 - MSE: 18.2192, RMSE: 4.2513, MAE: 3.4678, R2: 0.8221\n",
      "水头模型 Epoch 166, Batch 0: Total Loss: 162.3697, Criterion Loss: 58.5793, Physics Loss: 147.0290, KL Loss: 103.7904\n",
      "水头模型 Epoch 166/500 | 训练损失: 155.9600 | 验证损失: 14.3161 | LR: 0.000937\n",
      "水头验证指标 - MSE: 13.3292, RMSE: 3.6430, MAE: 2.8403, R2: 0.8711\n",
      "水头模型早停触发! 在第166个epoch停止训练\n",
      "\n",
      "水头模型训练完成!\n",
      "基于损失的最佳验证损失: 13.4348\n",
      "基于R2的最佳R2分数: 0.8818\n",
      "\n",
      "================================================================================\n",
      "第二阶段：开始训练浓度模型\n",
      "================================================================================\n",
      "成功加载基于r2的最佳水头模型\n",
      "浓度模型参数数量: 1057246\n",
      "浓度模型 Epoch 1, Batch 0: Total Loss: 40.2433, Criterion Loss: 14.0472, MSE: 7.2327, KL Loss: 26.1962, L1 Reg: 681446.4375\n",
      "浓度模型 Epoch 001/500 | 训练损失: 37.9741 | 验证损失: 13.6278 | LR: 0.000791\n",
      "浓度验证指标 - MSE: 6.8658, RMSE: 2.6181, MAE: 0.6878, R2: 0.0361\n",
      "保存基于损失的最佳浓度模型，验证损失: 13.6278\n",
      "保存基于R2的最佳浓度模型，R2: 0.0361\n",
      "浓度模型 Epoch 2, Batch 0: Total Loss: 35.7447, Criterion Loss: 13.7965, MSE: 7.0346, KL Loss: 21.9482, L1 Reg: 676194.3750\n",
      "浓度模型 Epoch 002/500 | 训练损失: 33.1353 | 验证损失: 10.6288 | LR: 0.000765\n",
      "浓度验证指标 - MSE: 3.9074, RMSE: 1.9743, MAE: 0.5217, R2: 0.4520\n",
      "保存基于损失的最佳浓度模型，验证损失: 10.6288\n",
      "保存基于R2的最佳浓度模型，R2: 0.4520\n",
      "浓度模型 Epoch 3, Batch 0: Total Loss: 29.9988, Criterion Loss: 10.6861, MSE: 3.9646, KL Loss: 19.3127, L1 Reg: 672144.3125\n",
      "浓度模型 Epoch 003/500 | 训练损失: 27.3629 | 验证损失: 7.9646 | LR: 0.000724\n",
      "浓度验证指标 - MSE: 1.2702, RMSE: 1.1248, MAE: 0.2531, R2: 0.8206\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.9646\n",
      "保存基于R2的最佳浓度模型，R2: 0.8206\n",
      "浓度模型 Epoch 4, Batch 0: Total Loss: 25.4242, Criterion Loss: 7.8897, MSE: 1.1954, KL Loss: 17.5345, L1 Reg: 669431.0625\n",
      "浓度模型 Epoch 004/500 | 训练损失: 24.3597 | 验证损失: 7.6066 | LR: 0.000668\n",
      "浓度验证指标 - MSE: 0.9493, RMSE: 0.9714, MAE: 0.2193, R2: 0.8661\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.6066\n",
      "保存基于R2的最佳浓度模型，R2: 0.8661\n",
      "浓度模型 Epoch 5, Batch 0: Total Loss: 23.1146, Criterion Loss: 7.6527, MSE: 0.9953, KL Loss: 15.4619, L1 Reg: 665738.1875\n",
      "浓度模型 Epoch 005/500 | 训练损失: 21.9681 | 验证损失: 7.4875 | LR: 0.000600\n",
      "浓度验证指标 - MSE: 0.8702, RMSE: 0.9296, MAE: 0.2114, R2: 0.8775\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.4875\n",
      "保存基于R2的最佳浓度模型，R2: 0.8775\n",
      "浓度模型 Epoch 6, Batch 0: Total Loss: 20.8360, Criterion Loss: 7.5725, MSE: 0.9552, KL Loss: 13.2635, L1 Reg: 661734.0625\n",
      "浓度模型 Epoch 006/500 | 训练损失: 19.9797 | 验证损失: 7.3931 | LR: 0.000524\n",
      "浓度验证指标 - MSE: 0.8099, RMSE: 0.8970, MAE: 0.2235, R2: 0.8858\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.3931\n",
      "保存基于R2的最佳浓度模型，R2: 0.8858\n",
      "浓度模型 Epoch 7, Batch 0: Total Loss: 19.0616, Criterion Loss: 7.5029, MSE: 0.9197, KL Loss: 11.5587, L1 Reg: 658321.9375\n",
      "浓度模型 Epoch 007/500 | 训练损失: 18.4435 | 验证损失: 7.3578 | LR: 0.000442\n",
      "浓度验证指标 - MSE: 0.8031, RMSE: 0.8926, MAE: 0.2000, R2: 0.8872\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.3578\n",
      "保存基于R2的最佳浓度模型，R2: 0.8872\n",
      "浓度模型 Epoch 8, Batch 0: Total Loss: 17.6330, Criterion Loss: 7.2905, MSE: 0.7358, KL Loss: 10.3425, L1 Reg: 655466.1875\n",
      "浓度模型 Epoch 008/500 | 训练损失: 17.2812 | 验证损失: 7.3007 | LR: 0.000359\n",
      "浓度验证指标 - MSE: 0.7703, RMSE: 0.8742, MAE: 0.2056, R2: 0.8916\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.3007\n",
      "保存基于R2的最佳浓度模型，R2: 0.8916\n",
      "浓度模型 Epoch 9, Batch 0: Total Loss: 16.6602, Criterion Loss: 7.2352, MSE: 0.7048, KL Loss: 9.4250, L1 Reg: 653046.2500\n",
      "浓度模型 Epoch 009/500 | 训练损失: 16.4114 | 验证损失: 7.2748 | LR: 0.000277\n",
      "浓度验证指标 - MSE: 0.7628, RMSE: 0.8701, MAE: 0.1945, R2: 0.8929\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.2748\n",
      "保存基于R2的最佳浓度模型，R2: 0.8929\n",
      "浓度模型 Epoch 10, Batch 0: Total Loss: 15.8814, Criterion Loss: 7.1285, MSE: 0.6166, KL Loss: 8.7529, L1 Reg: 651197.9375\n",
      "浓度模型 Epoch 010/500 | 训练损失: 15.8285 | 验证损失: 7.2492 | LR: 0.000201\n",
      "浓度验证指标 - MSE: 0.7505, RMSE: 0.8629, MAE: 0.1927, R2: 0.8946\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.2492\n",
      "保存基于R2的最佳浓度模型，R2: 0.8946\n",
      "浓度模型 Epoch 11, Batch 0: Total Loss: 15.6680, Criterion Loss: 7.4038, MSE: 0.9051, KL Loss: 8.2642, L1 Reg: 649868.1250\n",
      "浓度模型 Epoch 011/500 | 训练损失: 15.4053 | 验证损失: 7.2404 | LR: 0.000133\n",
      "浓度验证指标 - MSE: 0.7519, RMSE: 0.8633, MAE: 0.1939, R2: 0.8946\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.2404\n",
      "浓度模型 Epoch 12, Batch 0: Total Loss: 15.2445, Criterion Loss: 7.3148, MSE: 0.8263, KL Loss: 7.9297, L1 Reg: 648851.9375\n",
      "浓度模型 Epoch 012/500 | 训练损失: 15.1075 | 验证损失: 7.2219 | LR: 0.000077\n",
      "浓度验证指标 - MSE: 0.7402, RMSE: 0.8574, MAE: 0.1880, R2: 0.8959\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.2219\n",
      "保存基于R2的最佳浓度模型，R2: 0.8959\n",
      "浓度模型 Epoch 13, Batch 0: Total Loss: 15.2144, Criterion Loss: 7.5003, MSE: 1.0186, KL Loss: 7.7141, L1 Reg: 648169.0000\n",
      "浓度模型 Epoch 013/500 | 训练损失: 14.9342 | 验证损失: 7.2100 | LR: 0.000036\n",
      "浓度验证指标 - MSE: 0.7318, RMSE: 0.8522, MAE: 0.1858, R2: 0.8972\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.2100\n",
      "保存基于R2的最佳浓度模型，R2: 0.8972\n",
      "浓度模型 Epoch 14, Batch 0: Total Loss: 14.8466, Criterion Loss: 7.2153, MSE: 0.7371, KL Loss: 7.6314, L1 Reg: 647817.8125\n",
      "浓度模型 Epoch 014/500 | 训练损失: 14.8429 | 验证损失: 7.2165 | LR: 0.000010\n",
      "浓度验证指标 - MSE: 0.7400, RMSE: 0.8571, MAE: 0.1836, R2: 0.8961\n",
      "浓度模型 Epoch 15, Batch 0: Total Loss: 14.8148, Criterion Loss: 7.2704, MSE: 0.7939, KL Loss: 7.5444, L1 Reg: 647646.3750\n",
      "浓度模型 Epoch 015/500 | 训练损失: 14.8003 | 验证损失: 7.2161 | LR: 0.000800\n",
      "浓度验证指标 - MSE: 0.7401, RMSE: 0.8569, MAE: 0.1891, R2: 0.8961\n",
      "浓度模型 Epoch 16, Batch 0: Total Loss: 14.8530, Criterion Loss: 7.3047, MSE: 0.8286, KL Loss: 7.5484, L1 Reg: 647601.8750\n",
      "浓度模型 Epoch 016/500 | 训练损失: 14.2692 | 验证损失: 7.1714 | LR: 0.000798\n",
      "浓度验证指标 - MSE: 0.7303, RMSE: 0.8518, MAE: 0.1880, R2: 0.8974\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.1714\n",
      "保存基于R2的最佳浓度模型，R2: 0.8974\n",
      "浓度模型 Epoch 17, Batch 0: Total Loss: 13.6697, Criterion Loss: 7.1889, MSE: 0.7478, KL Loss: 6.4809, L1 Reg: 644108.0625\n",
      "浓度模型 Epoch 017/500 | 训练损失: 13.2852 | 验证损失: 7.1615 | LR: 0.000791\n",
      "浓度验证指标 - MSE: 0.7539, RMSE: 0.8644, MAE: 0.1966, R2: 0.8945\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.1615\n",
      "浓度模型 Epoch 18, Batch 0: Total Loss: 12.9846, Criterion Loss: 7.3259, MSE: 0.9183, KL Loss: 5.6586, L1 Reg: 640764.5000\n",
      "浓度模型 Epoch 018/500 | 训练损失: 12.4944 | 验证损失: 7.0941 | LR: 0.000780\n",
      "浓度验证指标 - MSE: 0.7192, RMSE: 0.8448, MAE: 0.1809, R2: 0.8992\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.0941\n",
      "保存基于R2的最佳浓度模型，R2: 0.8992\n",
      "浓度模型 Epoch 19, Batch 0: Total Loss: 12.1082, Criterion Loss: 7.1676, MSE: 0.7927, KL Loss: 4.9405, L1 Reg: 637491.4375\n",
      "浓度模型 Epoch 019/500 | 训练损失: 11.8539 | 验证损失: 7.0700 | LR: 0.000765\n",
      "浓度验证指标 - MSE: 0.7249, RMSE: 0.8465, MAE: 0.1911, R2: 0.8988\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.0700\n",
      "浓度模型 Epoch 20, Batch 0: Total Loss: 11.4020, Criterion Loss: 6.9784, MSE: 0.6333, KL Loss: 4.4236, L1 Reg: 634509.3125\n",
      "浓度模型 Epoch 020/500 | 训练损失: 11.3723 | 验证损失: 7.0518 | LR: 0.000746\n",
      "浓度验证指标 - MSE: 0.7340, RMSE: 0.8524, MAE: 0.1767, R2: 0.8976\n",
      "保存基于损失的最佳浓度模型，验证损失: 7.0518\n",
      "浓度模型 Epoch 21, Batch 0: Total Loss: 11.3183, Criterion Loss: 7.2747, MSE: 0.9568, KL Loss: 4.0436, L1 Reg: 631784.1875\n",
      "浓度模型 Epoch 021/500 | 训练损失: 11.0040 | 验证损失: 6.9986 | LR: 0.000724\n",
      "浓度验证指标 - MSE: 0.7040, RMSE: 0.8361, MAE: 0.1601, R2: 0.9014\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.9986\n",
      "保存基于R2的最佳浓度模型，R2: 0.9014\n",
      "浓度模型 Epoch 22, Batch 0: Total Loss: 10.7153, Criterion Loss: 6.9605, MSE: 0.6659, KL Loss: 3.7549, L1 Reg: 629460.2500\n",
      "浓度模型 Epoch 022/500 | 训练损失: 10.7069 | 验证损失: 6.9971 | LR: 0.000697\n",
      "浓度验证指标 - MSE: 0.7258, RMSE: 0.8477, MAE: 0.1569, R2: 0.8986\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.9971\n",
      "浓度模型 Epoch 23, Batch 0: Total Loss: 10.4342, Criterion Loss: 6.9265, MSE: 0.6552, KL Loss: 3.5077, L1 Reg: 627128.5625\n",
      "浓度模型 Epoch 023/500 | 训练损失: 10.4644 | 验证损失: 6.9548 | LR: 0.000668\n",
      "浓度验证指标 - MSE: 0.7058, RMSE: 0.8374, MAE: 0.1508, R2: 0.9010\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.9548\n",
      "浓度模型 Epoch 24, Batch 0: Total Loss: 10.3923, Criterion Loss: 7.0998, MSE: 0.8508, KL Loss: 3.2925, L1 Reg: 624893.0000\n",
      "浓度模型 Epoch 024/500 | 训练损失: 10.2059 | 验证损失: 6.9564 | LR: 0.000635\n",
      "浓度验证指标 - MSE: 0.7281, RMSE: 0.8477, MAE: 0.1655, R2: 0.8984\n",
      "浓度模型 Epoch 25, Batch 0: Total Loss: 10.0546, Criterion Loss: 6.9259, MSE: 0.6976, KL Loss: 3.1287, L1 Reg: 622830.8750\n",
      "浓度模型 Epoch 025/500 | 训练损失: 10.0463 | 验证损失: 6.8933 | LR: 0.000600\n",
      "浓度验证指标 - MSE: 0.6851, RMSE: 0.8242, MAE: 0.1504, R2: 0.9042\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.8933\n",
      "保存基于R2的最佳浓度模型，R2: 0.9042\n",
      "浓度模型 Epoch 26, Batch 0: Total Loss: 9.9361, Criterion Loss: 6.9964, MSE: 0.7883, KL Loss: 2.9397, L1 Reg: 620812.9375\n",
      "浓度模型 Epoch 026/500 | 训练损失: 9.8951 | 验证损失: 6.8722 | LR: 0.000563\n",
      "浓度验证指标 - MSE: 0.6814, RMSE: 0.8219, MAE: 0.1436, R2: 0.9047\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.8722\n",
      "保存基于R2的最佳浓度模型，R2: 0.9047\n",
      "浓度模型 Epoch 27, Batch 0: Total Loss: 9.7420, Criterion Loss: 6.8887, MSE: 0.6979, KL Loss: 2.8532, L1 Reg: 619086.8750\n",
      "浓度模型 Epoch 027/500 | 训练损失: 9.7170 | 验证损失: 6.8509 | LR: 0.000524\n",
      "浓度验证指标 - MSE: 0.6768, RMSE: 0.8192, MAE: 0.1548, R2: 0.9053\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.8509\n",
      "保存基于R2的最佳浓度模型，R2: 0.9053\n",
      "浓度模型 Epoch 28, Batch 0: Total Loss: 9.6354, Criterion Loss: 6.8979, MSE: 0.7239, KL Loss: 2.7375, L1 Reg: 617407.5000\n",
      "浓度模型 Epoch 028/500 | 训练损失: 9.6306 | 验证损失: 6.8549 | LR: 0.000484\n",
      "浓度验证指标 - MSE: 0.6971, RMSE: 0.8312, MAE: 0.1478, R2: 0.9026\n",
      "浓度模型 Epoch 29, Batch 0: Total Loss: 9.5093, Criterion Loss: 6.8915, MSE: 0.7337, KL Loss: 2.6178, L1 Reg: 615776.5625\n",
      "浓度模型 Epoch 029/500 | 训练损失: 9.5222 | 验证损失: 6.8138 | LR: 0.000442\n",
      "浓度验证指标 - MSE: 0.6708, RMSE: 0.8154, MAE: 0.1387, R2: 0.9062\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.8138\n",
      "保存基于R2的最佳浓度模型，R2: 0.9062\n",
      "浓度模型 Epoch 30, Batch 0: Total Loss: 9.4701, Criterion Loss: 6.9517, MSE: 0.8087, KL Loss: 2.5184, L1 Reg: 614302.1250\n",
      "浓度模型 Epoch 030/500 | 训练损失: 9.4037 | 验证损失: 6.8004 | LR: 0.000401\n",
      "浓度验证指标 - MSE: 0.6708, RMSE: 0.8150, MAE: 0.1437, R2: 0.9063\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.8004\n",
      "保存基于R2的最佳浓度模型，R2: 0.9063\n",
      "浓度模型 Epoch 31, Batch 0: Total Loss: 9.4297, Criterion Loss: 7.0011, MSE: 0.8716, KL Loss: 2.4285, L1 Reg: 612955.9375\n",
      "浓度模型 Epoch 031/500 | 训练损失: 9.3601 | 验证损失: 6.7872 | LR: 0.000359\n",
      "浓度验证指标 - MSE: 0.6688, RMSE: 0.8137, MAE: 0.1437, R2: 0.9066\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.7872\n",
      "保存基于R2的最佳浓度模型，R2: 0.9066\n",
      "浓度模型 Epoch 32, Batch 0: Total Loss: 9.2526, Criterion Loss: 6.8431, MSE: 0.7247, KL Loss: 2.4095, L1 Reg: 611841.5625\n",
      "浓度模型 Epoch 032/500 | 训练损失: 9.2736 | 验证损失: 6.7824 | LR: 0.000317\n",
      "浓度验证指标 - MSE: 0.6745, RMSE: 0.8173, MAE: 0.1386, R2: 0.9057\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.7824\n",
      "浓度模型 Epoch 33, Batch 0: Total Loss: 9.1740, Criterion Loss: 6.7988, MSE: 0.6910, KL Loss: 2.3752, L1 Reg: 610783.5000\n",
      "浓度模型 Epoch 033/500 | 训练损失: 9.2230 | 验证损失: 6.7572 | LR: 0.000277\n",
      "浓度验证指标 - MSE: 0.6592, RMSE: 0.8082, MAE: 0.1472, R2: 0.9079\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.7572\n",
      "保存基于R2的最佳浓度模型，R2: 0.9079\n",
      "浓度模型 Epoch 34, Batch 0: Total Loss: 9.1406, Criterion Loss: 6.8228, MSE: 0.7248, KL Loss: 2.3178, L1 Reg: 609803.0000\n",
      "浓度模型 Epoch 034/500 | 训练损失: 9.2128 | 验证损失: 6.7751 | LR: 0.000238\n",
      "浓度验证指标 - MSE: 0.6842, RMSE: 0.8235, MAE: 0.1367, R2: 0.9043\n",
      "浓度模型 Epoch 35, Batch 0: Total Loss: 9.1218, Criterion Loss: 6.8558, MSE: 0.7648, KL Loss: 2.2659, L1 Reg: 609096.6875\n",
      "浓度模型 Epoch 035/500 | 训练损失: 9.1407 | 验证损失: 6.7707 | LR: 0.000201\n",
      "浓度验证指标 - MSE: 0.6858, RMSE: 0.8235, MAE: 0.1509, R2: 0.9044\n",
      "浓度模型 Epoch 36, Batch 0: Total Loss: 9.3134, Criterion Loss: 7.0714, MSE: 0.9865, KL Loss: 2.2419, L1 Reg: 608494.1875\n",
      "浓度模型 Epoch 036/500 | 训练损失: 9.1047 | 验证损失: 6.7573 | LR: 0.000166\n",
      "浓度验证指标 - MSE: 0.6780, RMSE: 0.8196, MAE: 0.1446, R2: 0.9053\n",
      "浓度模型 Epoch 37, Batch 0: Total Loss: 9.1039, Criterion Loss: 6.8878, MSE: 0.8086, KL Loss: 2.2161, L1 Reg: 607923.4375\n",
      "浓度模型 Epoch 037/500 | 训练损失: 9.0732 | 验证损失: 6.7325 | LR: 0.000133\n",
      "浓度验证指标 - MSE: 0.6577, RMSE: 0.8071, MAE: 0.1440, R2: 0.9081\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.7325\n",
      "保存基于R2的最佳浓度模型，R2: 0.9081\n",
      "浓度模型 Epoch 38, Batch 0: Total Loss: 8.9545, Criterion Loss: 6.7453, MSE: 0.6705, KL Loss: 2.2092, L1 Reg: 607479.5000\n",
      "浓度模型 Epoch 038/500 | 训练损失: 9.0335 | 验证损失: 6.7432 | LR: 0.000104\n",
      "浓度验证指标 - MSE: 0.6723, RMSE: 0.8159, MAE: 0.1422, R2: 0.9061\n",
      "浓度模型 Epoch 39, Batch 0: Total Loss: 9.0204, Criterion Loss: 6.8517, MSE: 0.7807, KL Loss: 2.1687, L1 Reg: 607095.5625\n",
      "浓度模型 Epoch 039/500 | 训练损失: 8.9967 | 验证损失: 6.7400 | LR: 0.000077\n",
      "浓度验证指标 - MSE: 0.6724, RMSE: 0.8160, MAE: 0.1449, R2: 0.9061\n",
      "浓度模型 Epoch 40, Batch 0: Total Loss: 8.9837, Criterion Loss: 6.8271, MSE: 0.7595, KL Loss: 2.1566, L1 Reg: 606765.5000\n",
      "浓度模型 Epoch 040/500 | 训练损失: 9.0752 | 验证损失: 6.7295 | LR: 0.000055\n",
      "浓度验证指标 - MSE: 0.6639, RMSE: 0.8109, MAE: 0.1477, R2: 0.9073\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.7295\n",
      "浓度模型 Epoch 41, Batch 0: Total Loss: 9.3429, Criterion Loss: 7.1686, MSE: 1.1029, KL Loss: 2.1743, L1 Reg: 606564.8750\n",
      "浓度模型 Epoch 041/500 | 训练损失: 9.0301 | 验证损失: 6.7296 | LR: 0.000036\n",
      "浓度验证指标 - MSE: 0.6653, RMSE: 0.8126, MAE: 0.1390, R2: 0.9069\n",
      "浓度模型 Epoch 42, Batch 0: Total Loss: 9.0747, Criterion Loss: 6.9251, MSE: 0.8608, KL Loss: 2.1495, L1 Reg: 606435.8125\n",
      "浓度模型 Epoch 042/500 | 训练损失: 9.0183 | 验证损失: 6.7275 | LR: 0.000021\n",
      "浓度验证指标 - MSE: 0.6640, RMSE: 0.8112, MAE: 0.1455, R2: 0.9073\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.7275\n",
      "浓度模型 Epoch 43, Batch 0: Total Loss: 8.9857, Criterion Loss: 6.8141, MSE: 0.7507, KL Loss: 2.1715, L1 Reg: 606344.5000\n",
      "浓度模型 Epoch 043/500 | 训练损失: 9.0272 | 验证损失: 6.7335 | LR: 0.000010\n",
      "浓度验证指标 - MSE: 0.6706, RMSE: 0.8146, MAE: 0.1423, R2: 0.9063\n",
      "浓度模型 Epoch 44, Batch 0: Total Loss: 8.9206, Criterion Loss: 6.7927, MSE: 0.7298, KL Loss: 2.1280, L1 Reg: 606286.7500\n",
      "浓度模型 Epoch 044/500 | 训练损失: 8.9812 | 验证损失: 6.7238 | LR: 0.000003\n",
      "浓度验证指标 - MSE: 0.6612, RMSE: 0.8097, MAE: 0.1400, R2: 0.9075\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.7238\n",
      "浓度模型 Epoch 45, Batch 0: Total Loss: 8.8890, Criterion Loss: 6.7380, MSE: 0.6755, KL Loss: 2.1509, L1 Reg: 606257.6875\n",
      "浓度模型 Epoch 045/500 | 训练损失: 8.9820 | 验证损失: 6.7188 | LR: 0.000800\n",
      "浓度验证指标 - MSE: 0.6563, RMSE: 0.8068, MAE: 0.1448, R2: 0.9082\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.7188\n",
      "保存基于R2的最佳浓度模型，R2: 0.9082\n",
      "浓度模型 Epoch 46, Batch 0: Total Loss: 8.7810, Criterion Loss: 6.6301, MSE: 0.5677, KL Loss: 2.1509, L1 Reg: 606247.9375\n",
      "浓度模型 Epoch 046/500 | 训练损失: 8.9460 | 验证损失: 6.6944 | LR: 0.000799\n",
      "浓度验证指标 - MSE: 0.6539, RMSE: 0.8050, MAE: 0.1347, R2: 0.9086\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.6944\n",
      "保存基于R2的最佳浓度模型，R2: 0.9086\n",
      "浓度模型 Epoch 47, Batch 0: Total Loss: 8.9659, Criterion Loss: 6.9223, MSE: 0.8818, KL Loss: 2.0436, L1 Reg: 604053.0625\n",
      "浓度模型 Epoch 047/500 | 训练损失: 8.8533 | 验证损失: 6.7000 | LR: 0.000798\n",
      "浓度验证指标 - MSE: 0.6807, RMSE: 0.8218, MAE: 0.1501, R2: 0.9048\n",
      "浓度模型 Epoch 48, Batch 0: Total Loss: 8.6997, Criterion Loss: 6.7291, MSE: 0.7098, KL Loss: 1.9705, L1 Reg: 601933.7500\n",
      "浓度模型 Epoch 048/500 | 训练损失: 8.8250 | 验证损失: 6.7617 | LR: 0.000795\n",
      "浓度验证指标 - MSE: 0.7612, RMSE: 0.8685, MAE: 0.1408, R2: 0.8937\n",
      "浓度模型 Epoch 49, Batch 0: Total Loss: 8.6991, Criterion Loss: 6.7881, MSE: 0.7876, KL Loss: 1.9111, L1 Reg: 600047.0000\n",
      "浓度模型 Epoch 049/500 | 训练损失: 8.7180 | 验证损失: 6.6732 | LR: 0.000791\n",
      "浓度验证指标 - MSE: 0.6906, RMSE: 0.8272, MAE: 0.1459, R2: 0.9036\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.6732\n",
      "浓度模型 Epoch 50, Batch 0: Total Loss: 8.6787, Criterion Loss: 6.8104, MSE: 0.8278, KL Loss: 1.8683, L1 Reg: 598253.1250\n",
      "浓度模型 Epoch 050/500 | 训练损失: 8.6472 | 验证损失: 6.6313 | LR: 0.000786\n",
      "浓度验证指标 - MSE: 0.6649, RMSE: 0.8125, MAE: 0.1509, R2: 0.9069\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.6313\n",
      "浓度模型 Epoch 51, Batch 0: Total Loss: 8.5574, Criterion Loss: 6.7340, MSE: 0.7675, KL Loss: 1.8235, L1 Reg: 596647.7500\n",
      "浓度模型 Epoch 051/500 | 训练损失: 8.5966 | 验证损失: 6.6644 | LR: 0.000780\n",
      "浓度验证指标 - MSE: 0.7159, RMSE: 0.8422, MAE: 0.1584, R2: 0.9001\n",
      "浓度模型 Epoch 52, Batch 0: Total Loss: 8.6406, Criterion Loss: 6.9207, MSE: 0.9722, KL Loss: 1.7199, L1 Reg: 594852.6250\n",
      "浓度模型 Epoch 052/500 | 训练损失: 8.5475 | 验证损失: 6.7402 | LR: 0.000773\n",
      "浓度验证指标 - MSE: 0.8090, RMSE: 0.8948, MAE: 0.1457, R2: 0.8870\n",
      "浓度模型 Epoch 53, Batch 0: Total Loss: 8.5011, Criterion Loss: 6.7983, MSE: 0.8670, KL Loss: 1.7028, L1 Reg: 593122.8125\n",
      "浓度模型 Epoch 053/500 | 训练损失: 8.5000 | 验证损失: 6.6243 | LR: 0.000765\n",
      "浓度验证指标 - MSE: 0.7090, RMSE: 0.8376, MAE: 0.1323, R2: 0.9011\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.6243\n",
      "浓度模型 Epoch 54, Batch 0: Total Loss: 8.4275, Criterion Loss: 6.7694, MSE: 0.8541, KL Loss: 1.6581, L1 Reg: 591534.2500\n",
      "浓度模型 Epoch 054/500 | 训练损失: 8.3926 | 验证损失: 6.5589 | LR: 0.000756\n",
      "浓度验证指标 - MSE: 0.6607, RMSE: 0.8099, MAE: 0.1325, R2: 0.9075\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.5589\n",
      "浓度模型 Epoch 55, Batch 0: Total Loss: 8.2437, Criterion Loss: 6.6308, MSE: 0.7326, KL Loss: 1.6129, L1 Reg: 589819.9375\n",
      "浓度模型 Epoch 055/500 | 训练损失: 8.3955 | 验证损失: 6.5477 | LR: 0.000746\n",
      "浓度验证指标 - MSE: 0.6655, RMSE: 0.8116, MAE: 0.1400, R2: 0.9071\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.5477\n",
      "浓度模型 Epoch 56, Batch 0: Total Loss: 8.3868, Criterion Loss: 6.8172, MSE: 0.9349, KL Loss: 1.5696, L1 Reg: 588226.5000\n",
      "浓度模型 Epoch 056/500 | 训练损失: 8.2433 | 验证损失: 6.5414 | LR: 0.000736\n",
      "浓度验证指标 - MSE: 0.6748, RMSE: 0.8176, MAE: 0.1631, R2: 0.9058\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.5414\n",
      "浓度模型 Epoch 57, Batch 0: Total Loss: 8.0318, Criterion Loss: 6.5105, MSE: 0.6439, KL Loss: 1.5213, L1 Reg: 586661.5000\n",
      "浓度模型 Epoch 057/500 | 训练损失: 8.2028 | 验证损失: 6.5310 | LR: 0.000724\n",
      "浓度验证指标 - MSE: 0.6787, RMSE: 0.8209, MAE: 0.1351, R2: 0.9051\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.5310\n",
      "浓度模型 Epoch 58, Batch 0: Total Loss: 8.2905, Criterion Loss: 6.8215, MSE: 0.9692, KL Loss: 1.4689, L1 Reg: 585231.6875\n",
      "浓度模型 Epoch 058/500 | 训练损失: 8.1385 | 验证损失: 6.5793 | LR: 0.000711\n",
      "浓度验证指标 - MSE: 0.7442, RMSE: 0.8607, MAE: 0.1543, R2: 0.8954\n",
      "浓度模型 Epoch 59, Batch 0: Total Loss: 8.2994, Criterion Loss: 6.8526, MSE: 1.0176, KL Loss: 1.4468, L1 Reg: 583508.3125\n",
      "浓度模型 Epoch 059/500 | 训练损失: 8.1779 | 验证损失: 6.5709 | LR: 0.000697\n",
      "浓度验证指标 - MSE: 0.7489, RMSE: 0.8593, MAE: 0.1444, R2: 0.8958\n",
      "浓度模型 Epoch 60, Batch 0: Total Loss: 8.2682, Criterion Loss: 6.8804, MSE: 1.0584, KL Loss: 1.3878, L1 Reg: 582200.3750\n",
      "浓度模型 Epoch 060/500 | 训练损失: 8.0911 | 验证损失: 6.4984 | LR: 0.000683\n",
      "浓度验证指标 - MSE: 0.6891, RMSE: 0.8257, MAE: 0.1408, R2: 0.9038\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.4984\n",
      "浓度模型 Epoch 61, Batch 0: Total Loss: 7.8118, Criterion Loss: 6.4461, MSE: 0.6368, KL Loss: 1.3658, L1 Reg: 580932.0625\n",
      "浓度模型 Epoch 061/500 | 训练损失: 8.0246 | 验证损失: 6.4676 | LR: 0.000668\n",
      "浓度验证指标 - MSE: 0.6737, RMSE: 0.8183, MAE: 0.1535, R2: 0.9057\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.4676\n",
      "浓度模型 Epoch 62, Batch 0: Total Loss: 7.8224, Criterion Loss: 6.4990, MSE: 0.7050, KL Loss: 1.3234, L1 Reg: 579391.8125\n",
      "浓度模型 Epoch 062/500 | 训练损失: 7.9553 | 验证损失: 6.4519 | LR: 0.000652\n",
      "浓度验证指标 - MSE: 0.6708, RMSE: 0.8153, MAE: 0.1320, R2: 0.9064\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.4519\n",
      "浓度模型 Epoch 63, Batch 0: Total Loss: 7.9889, Criterion Loss: 6.6753, MSE: 0.8942, KL Loss: 1.3136, L1 Reg: 578108.0000\n",
      "浓度模型 Epoch 063/500 | 训练损失: 7.9551 | 验证损失: 6.4292 | LR: 0.000635\n",
      "浓度验证指标 - MSE: 0.6616, RMSE: 0.8096, MAE: 0.1440, R2: 0.9075\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.4292\n",
      "浓度模型 Epoch 64, Batch 0: Total Loss: 8.0061, Criterion Loss: 6.7372, MSE: 0.9696, KL Loss: 1.2689, L1 Reg: 576757.5625\n",
      "浓度模型 Epoch 064/500 | 训练损失: 7.9346 | 验证损失: 6.4606 | LR: 0.000618\n",
      "浓度验证指标 - MSE: 0.7041, RMSE: 0.8343, MAE: 0.1340, R2: 0.9020\n",
      "浓度模型 Epoch 65, Batch 0: Total Loss: 7.6866, Criterion Loss: 6.4319, MSE: 0.6754, KL Loss: 1.2546, L1 Reg: 575650.3750\n",
      "浓度模型 Epoch 065/500 | 训练损失: 7.7901 | 验证损失: 6.4246 | LR: 0.000600\n",
      "浓度验证指标 - MSE: 0.6812, RMSE: 0.8230, MAE: 0.1334, R2: 0.9043\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.4246\n",
      "浓度模型 Epoch 66, Batch 0: Total Loss: 7.9843, Criterion Loss: 6.7800, MSE: 1.0366, KL Loss: 1.2043, L1 Reg: 574343.0000\n",
      "浓度模型 Epoch 066/500 | 训练损失: 7.8270 | 验证损失: 6.7086 | LR: 0.000582\n",
      "浓度验证指标 - MSE: 0.9790, RMSE: 0.9824, MAE: 0.1526, R2: 0.8639\n",
      "浓度模型 Epoch 67, Batch 0: Total Loss: 7.7295, Criterion Loss: 6.5408, MSE: 0.8112, KL Loss: 1.1887, L1 Reg: 572959.7500\n",
      "浓度模型 Epoch 067/500 | 训练损失: 7.9179 | 验证损失: 6.3749 | LR: 0.000563\n",
      "浓度验证指标 - MSE: 0.6557, RMSE: 0.8073, MAE: 0.1351, R2: 0.9081\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.3749\n",
      "浓度模型 Epoch 68, Batch 0: Total Loss: 7.6146, Criterion Loss: 6.4329, MSE: 0.7137, KL Loss: 1.1817, L1 Reg: 571921.4375\n",
      "浓度模型 Epoch 068/500 | 训练损失: 7.7094 | 验证损失: 6.3685 | LR: 0.000544\n",
      "浓度验证指标 - MSE: 0.6618, RMSE: 0.8101, MAE: 0.1447, R2: 0.9076\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.3685\n",
      "浓度模型 Epoch 69, Batch 0: Total Loss: 7.7581, Criterion Loss: 6.6165, MSE: 0.9098, KL Loss: 1.1416, L1 Reg: 570670.5000\n",
      "浓度模型 Epoch 069/500 | 训练损失: 7.6862 | 验证损失: 6.3672 | LR: 0.000524\n",
      "浓度验证指标 - MSE: 0.6712, RMSE: 0.8160, MAE: 0.1327, R2: 0.9063\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.3672\n",
      "浓度模型 Epoch 70, Batch 0: Total Loss: 7.5692, Criterion Loss: 6.4658, MSE: 0.7699, KL Loss: 1.1033, L1 Reg: 569596.3125\n",
      "浓度模型 Epoch 070/500 | 训练损失: 7.6553 | 验证损失: 6.3430 | LR: 0.000504\n",
      "浓度验证指标 - MSE: 0.6573, RMSE: 0.8069, MAE: 0.1347, R2: 0.9082\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.3430\n",
      "浓度模型 Epoch 71, Batch 0: Total Loss: 7.5054, Criterion Loss: 6.4114, MSE: 0.7257, KL Loss: 1.0941, L1 Reg: 568571.7500\n",
      "浓度模型 Epoch 071/500 | 训练损失: 7.6872 | 验证损失: 6.3332 | LR: 0.000484\n",
      "浓度验证指标 - MSE: 0.6591, RMSE: 0.8075, MAE: 0.1337, R2: 0.9080\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.3332\n",
      "浓度模型 Epoch 72, Batch 0: Total Loss: 7.7573, Criterion Loss: 6.6637, MSE: 0.9896, KL Loss: 1.0936, L1 Reg: 567406.8750\n",
      "浓度模型 Epoch 072/500 | 训练损失: 7.5751 | 验证损失: 6.3800 | LR: 0.000463\n",
      "浓度验证指标 - MSE: 0.7170, RMSE: 0.8424, MAE: 0.1356, R2: 0.9001\n",
      "浓度模型 Epoch 73, Batch 0: Total Loss: 7.7048, Criterion Loss: 6.6659, MSE: 1.0029, KL Loss: 1.0389, L1 Reg: 566299.5625\n",
      "浓度模型 Epoch 073/500 | 训练损失: 7.5860 | 验证损失: 6.3089 | LR: 0.000442\n",
      "浓度验证指标 - MSE: 0.6544, RMSE: 0.8059, MAE: 0.1355, R2: 0.9083\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.3089\n",
      "浓度模型 Epoch 74, Batch 0: Total Loss: 7.4021, Criterion Loss: 6.3872, MSE: 0.7327, KL Loss: 1.0149, L1 Reg: 565446.3125\n",
      "浓度模型 Epoch 074/500 | 训练损失: 7.6446 | 验证损失: 6.3440 | LR: 0.000421\n",
      "浓度验证指标 - MSE: 0.6968, RMSE: 0.8298, MAE: 0.1354, R2: 0.9029\n",
      "浓度模型 Epoch 75, Batch 0: Total Loss: 7.5760, Criterion Loss: 6.5755, MSE: 0.9283, KL Loss: 1.0005, L1 Reg: 564717.9375\n",
      "浓度模型 Epoch 075/500 | 训练损失: 7.5764 | 验证损失: 6.3180 | LR: 0.000401\n",
      "浓度验证指标 - MSE: 0.6777, RMSE: 0.8189, MAE: 0.1330, R2: 0.9056\n",
      "浓度模型 Epoch 76, Batch 0: Total Loss: 7.3663, Criterion Loss: 6.3491, MSE: 0.7088, KL Loss: 1.0173, L1 Reg: 564030.1875\n",
      "浓度模型 Epoch 076/500 | 训练损失: 7.5574 | 验证损失: 6.2931 | LR: 0.000380\n",
      "浓度验证指标 - MSE: 0.6603, RMSE: 0.8085, MAE: 0.1301, R2: 0.9078\n",
      "保存基于损失的最佳浓度模型，验证损失: 6.2931\n",
      "浓度模型早停触发! 在第76个epoch停止训练\n",
      "\n",
      "浓度模型训练完成!\n",
      "基于损失的最佳验证损失: 6.2931\n",
      "基于R2的最佳R2分数: 0.9086\n",
      "改进的双模型训练曲线已保存\n",
      "\n",
      "================================================================================\n",
      "双模型训练完成总结:\n",
      "水头模型 - 基于损失的最佳验证损失: 13.4348\n",
      "水头模型 - 基于R2的最佳R2分数: 0.8818\n",
      "浓度模型 - 基于损失的最佳验证损失: 6.2931\n",
      "浓度模型 - 基于R2的最佳R2分数: 0.9086\n",
      "评估将使用基于r2的模型\n",
      "================================================================================\n",
      "开始评估双模型性能（基于loss标准）...\n",
      "成功加载基于loss的最佳模型权重\n",
      "水头模型来自epoch 138, 验证损失: 13.4348, R2: 0.8812\n",
      "浓度模型来自epoch 75, 验证损失: 6.2931, R2: 0.9078\n",
      "开始处理验证数据...\n",
      "处理批次 0/8\n",
      "\n",
      "水头模型评估结果（基于loss）:\n",
      "  MSE: 12.4162\n",
      "  RMSE: 3.5237\n",
      "  MAE: 2.7420\n",
      "  R2: 0.8815\n",
      "\n",
      "浓度模型评估结果（基于loss）:\n",
      "  MSE: 0.6560\n",
      "  RMSE: 0.8099\n",
      "  MAE: 0.1323\n",
      "  R2: 0.9081\n",
      "生成可视化图表...\n",
      "\n",
      "评估结果已保存到: ./saved_models/blitz_bayesian_gnn_Sub/dual_model_evaluation_loss.npy\n",
      "预测结果CSV已保存到: ./saved_models/blitz_bayesian_gnn_Sub/evaluation_results/predictions_loss.csv\n",
      "不确定性结果CSV已保存到: ./saved_models/blitz_bayesian_gnn_Sub/evaluation_results/uncertainties_loss.csv\n",
      "\n",
      "📊 评估完成!\n",
      "📈 水头模型 - R2: 0.8815, RMSE: 3.5237\n",
      "📈 浓度模型 - R2: 0.9081, RMSE: 0.8099\n",
      "📁 所有结果已保存到: ./saved_models/blitz_bayesian_gnn_Sub/evaluation_results\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('conc_unconfine.csv')  # 替换为您的数据文件\n",
    "train_loader, val_loader = prepare_data(data, batch_size=4)\n",
    "head_model, conc_model, training_losses = train_dual_model_improved(train_loader, val_loader)\n",
    "evaluation_results = evaluate_dual_model_improved(head_model, conc_model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "078b5069-949d-45e3-9508-44eff04f2fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "未找到评估结果文件，尝试从CSV文件绘制\n",
      "从 predictions_loss.csv 加载数据\n",
      "数据形状: (799200, 7)\n",
      "改进的水头模型空间2D结果图已保存\n",
      "改进的浓度模型空间2D结果图已保存\n",
      "改进的综合空间2D分析图已保存\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import seaborn as sns\n",
    "from scipy.interpolate import griddata\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import os\n",
    "\n",
    "def interpolate_and_smooth_field(field_2d, mask_2d, nrow, ncol, sigma=1.0):\n",
    "    \"\"\"\n",
    "    First interpolate missing values, then apply smoothing, but keep original grid structure\n",
    "    \"\"\"\n",
    "    # Copy original field\n",
    "    result = field_2d.copy()\n",
    "    \n",
    "    # Create coordinate grids\n",
    "    rows, cols = np.mgrid[0:nrow, 0:ncol]\n",
    "    \n",
    "    # Get active cells\n",
    "    active_mask = (mask_2d > 0) & (~np.isnan(field_2d))\n",
    "    \n",
    "    if np.any(active_mask):\n",
    "        # Get active points and values\n",
    "        points = np.column_stack((rows[active_mask], cols[active_mask]))\n",
    "        values = field_2d[active_mask]\n",
    "        \n",
    "        # Create all grid points\n",
    "        all_points = np.column_stack((rows.ravel(), cols.ravel()))\n",
    "        \n",
    "        # Interpolate to fill any gaps\n",
    "        try:\n",
    "            interpolated_values = griddata(points, values, all_points, \n",
    "                                         method='cubic', fill_value=np.nan)\n",
    "            interpolated_field = interpolated_values.reshape(nrow, ncol)\n",
    "            \n",
    "            # Replace NaN values in original field with interpolated values\n",
    "            nan_mask = np.isnan(result)\n",
    "            result[nan_mask] = interpolated_field[nan_mask]\n",
    "            \n",
    "            # Apply Gaussian smoothing to the entire field\n",
    "            # Only smooth where we have valid data\n",
    "            valid_mask = ~np.isnan(result)\n",
    "            if np.any(valid_mask):\n",
    "                # Create a temporary field for smoothing\n",
    "                temp_field = result.copy()\n",
    "                temp_field[~valid_mask] = np.nanmean(result[valid_mask])  # Fill with mean for smoothing\n",
    "                \n",
    "                # Apply smoothing\n",
    "                smoothed = gaussian_filter(temp_field, sigma=sigma)\n",
    "                \n",
    "                # Only use smoothed values where we originally had data\n",
    "                result = smoothed\n",
    "                result[mask_2d <= 0] = np.nan  # Restore inactive areas as NaN\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Interpolation failed: {e}, using original field with basic smoothing\")\n",
    "            # Fallback: just apply basic smoothing\n",
    "            valid_mask = ~np.isnan(result) & (mask_2d > 0)\n",
    "            if np.any(valid_mask):\n",
    "                temp_field = result.copy()\n",
    "                temp_field[~valid_mask] = np.nanmean(result[valid_mask])\n",
    "                result = gaussian_filter(temp_field, sigma=sigma)\n",
    "                result[mask_2d <= 0] = np.nan\n",
    "    \n",
    "    return result\n",
    "\n",
    "def create_2d_field_from_points(df, field_name, nrow, ncol):\n",
    "    \"\"\"\n",
    "    Create 2D field from point data with proper indexing\n",
    "    \"\"\"\n",
    "    field_2d = np.full((nrow, ncol), np.nan)\n",
    "    mask_2d = np.zeros((nrow, ncol))\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        r, c = int(row['row']), int(row['col'])\n",
    "        if 0 <= r < nrow and 0 <= c < ncol:\n",
    "            field_2d[r, c] = row[field_name]\n",
    "            mask_2d[r, c] = 1\n",
    "    \n",
    "    return field_2d, mask_2d\n",
    "\n",
    "def plot_spatial_2d_fitting_results_improved(evaluation_results, save_path, time_step=None, model_type='both', sigma=1.5):\n",
    "    \"\"\"\n",
    "    绘制改进的基于空间坐标(x,y)的二维拟合效果图，使用MODFLOW网格方向和平滑插值\n",
    "    \n",
    "    Args:\n",
    "        evaluation_results: 评估结果字典\n",
    "        save_path: 保存路径\n",
    "        time_step: 指定时间步（如果为None，使用所有时间步的平均）\n",
    "        model_type: 'head', 'conc', 或 'both'\n",
    "        sigma: 高斯平滑参数\n",
    "    \"\"\"\n",
    "    \n",
    "    # 检查是否有详细预测结果\n",
    "    if 'detailed_predictions' not in evaluation_results:\n",
    "        print(\"警告: 评估结果中没有详细的空间信息，尝试从保存的CSV文件中读取\")\n",
    "        return load_and_plot_from_csv_improved(save_path, model_type, sigma)\n",
    "    \n",
    "    # 提取空间坐标和预测结果\n",
    "    all_data = []\n",
    "    \n",
    "    for batch_data in evaluation_results['detailed_predictions']:\n",
    "        if 'row' in batch_data and 'col' in batch_data:\n",
    "            batch_df = pd.DataFrame({\n",
    "                'row': batch_data['row'].flatten() if hasattr(batch_data['row'], 'flatten') else batch_data['row'],\n",
    "                'col': batch_data['col'].flatten() if hasattr(batch_data['col'], 'flatten') else batch_data['col'],\n",
    "                'pred_head': batch_data['pred_head'],\n",
    "                'true_head': batch_data['true_head'],\n",
    "                'pred_conc': batch_data['pred_conc'],\n",
    "                'true_conc': batch_data['true_conc'],\n",
    "            })\n",
    "            \n",
    "            if 'time_step' in batch_data:\n",
    "                batch_df['time_step'] = batch_data['time_step'].flatten() if hasattr(batch_data['time_step'], 'flatten') else batch_data['time_step']\n",
    "            \n",
    "            all_data.append(batch_df)\n",
    "    \n",
    "    if not all_data:\n",
    "        print(\"错误: 无法提取空间坐标信息\")\n",
    "        return\n",
    "    \n",
    "    # 合并所有数据\n",
    "    df = pd.concat(all_data, ignore_index=True)\n",
    "    \n",
    "    # 如果指定了时间步，筛选数据\n",
    "    if time_step is not None and 'time_step' in df.columns:\n",
    "        df = df[df['time_step'] == time_step]\n",
    "        time_suffix = f'_t{time_step}'\n",
    "    else:\n",
    "        # 使用所有时间步的平均值\n",
    "        df = df.groupby(['row', 'col']).agg({\n",
    "            'pred_head': 'mean',\n",
    "            'true_head': 'mean',\n",
    "            'pred_conc': 'mean',\n",
    "            'true_conc': 'mean'\n",
    "        }).reset_index()\n",
    "        time_suffix = '_all_time_avg'\n",
    "    \n",
    "    # 计算误差\n",
    "    df['head_error'] = np.abs(df['pred_head'] - df['true_head'])\n",
    "    df['conc_error'] = np.abs(df['pred_conc'] - df['true_conc'])\n",
    "    df['head_relative_error'] = df['head_error'] / (np.abs(df['true_head']) + 1e-8) * 100\n",
    "    df['conc_relative_error'] = df['conc_error'] / (np.abs(df['true_conc']) + 1e-8) * 100\n",
    "    \n",
    "    # 确定网格尺寸\n",
    "    nrow = int(df['row'].max()) + 1\n",
    "    ncol = int(df['col'].max()) + 1\n",
    "    \n",
    "    print(f\"共有 {len(df)} 个空间点\")\n",
    "    print(f\"网格尺寸: {nrow} rows x {ncol} cols\")\n",
    "    print(f\"空间范围: row [0, {nrow-1}], col [0, {ncol-1}]\")\n",
    "    \n",
    "    # 绘制图表\n",
    "    if model_type in ['head', 'both']:\n",
    "        plot_head_2d_results_improved(df, nrow, ncol, save_path, time_suffix, sigma)\n",
    "    \n",
    "    if model_type in ['conc', 'both']:\n",
    "        plot_conc_2d_results_improved(df, nrow, ncol, save_path, time_suffix, sigma)\n",
    "    \n",
    "    # 绘制综合比较图\n",
    "    if model_type == 'both':\n",
    "        plot_combined_2d_results_improved(df, nrow, ncol, save_path, time_suffix, sigma)\n",
    "\n",
    "def plot_head_2d_results_improved(df, nrow, ncol, save_path, time_suffix, sigma):\n",
    "    \"\"\"绘制水头模型的改进二维结果\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(24, 16))\n",
    "    fig.suptitle(f'Head Model Spatial 2D Results{time_suffix}', fontsize=20)\n",
    "    \n",
    "    # 创建2D场\n",
    "    true_head_2d, mask_2d = create_2d_field_from_points(df, 'true_head', nrow, ncol)\n",
    "    pred_head_2d, _ = create_2d_field_from_points(df, 'pred_head', nrow, ncol)\n",
    "    head_error_2d, _ = create_2d_field_from_points(df, 'head_error', nrow, ncol)\n",
    "    head_rel_error_2d, _ = create_2d_field_from_points(df, 'head_relative_error', nrow, ncol)\n",
    "    head_residual_2d = pred_head_2d - true_head_2d\n",
    "    \n",
    "    # 应用插值和平滑\n",
    "    true_head_smooth = interpolate_and_smooth_field(true_head_2d, mask_2d, nrow, ncol, sigma)\n",
    "    pred_head_smooth = interpolate_and_smooth_field(pred_head_2d, mask_2d, nrow, ncol, sigma)\n",
    "    head_error_smooth = interpolate_and_smooth_field(head_error_2d, mask_2d, nrow, ncol, sigma)\n",
    "    head_rel_error_smooth = interpolate_and_smooth_field(head_rel_error_2d, mask_2d, nrow, ncol, sigma)\n",
    "    head_residual_smooth = interpolate_and_smooth_field(head_residual_2d, mask_2d, nrow, ncol, sigma)\n",
    "    \n",
    "    # 1. 真实水头值\n",
    "    ax = axes[0, 0]\n",
    "    ax.set_title('True Head Values', fontsize=16)\n",
    "    masked_true = np.ma.masked_where(mask_2d <= 0, true_head_smooth)\n",
    "    valid_true = masked_true.compressed()\n",
    "    vmin_true, vmax_true = np.nanmin(valid_true), np.nanmax(valid_true) if len(valid_true) > 0 else (0, 1)\n",
    "    \n",
    "    im1 = ax.imshow(masked_true, cmap='viridis', aspect='equal', \n",
    "                   extent=[0, ncol-1, nrow-1, 0], origin='upper', \n",
    "                   interpolation='bilinear', vmin=vmin_true, vmax=vmax_true)\n",
    "    \n",
    "    divider1 = make_axes_locatable(ax)\n",
    "    cax1 = divider1.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    cbar1 = plt.colorbar(im1, cax=cax1)\n",
    "    cbar1.set_label('Head (m)', fontsize=12)\n",
    "    \n",
    "    # 添加统计信息\n",
    "    stats_text = f\"Min: {vmin_true:.2f}\\nMax: {vmax_true:.2f}\\nMean: {np.nanmean(valid_true):.2f}\"\n",
    "    ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=10,\n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    ax.set_xlim(0, ncol-1)\n",
    "    ax.set_ylim(nrow-1, 0)\n",
    "    ax.set_xlabel('Columns')\n",
    "    ax.set_ylabel('Rows')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. 预测水头值\n",
    "    ax = axes[0, 1]\n",
    "    ax.set_title('Predicted Head Values', fontsize=16)\n",
    "    masked_pred = np.ma.masked_where(mask_2d <= 0, pred_head_smooth)\n",
    "    valid_pred = masked_pred.compressed()\n",
    "    vmin_pred, vmax_pred = np.nanmin(valid_pred), np.nanmax(valid_pred) if len(valid_pred) > 0 else (0, 1)\n",
    "    \n",
    "    im2 = ax.imshow(masked_pred, cmap='viridis', aspect='equal',\n",
    "                   extent=[0, ncol-1, nrow-1, 0], origin='upper',\n",
    "                   interpolation='bilinear', vmin=vmin_pred, vmax=vmax_pred)\n",
    "    \n",
    "    divider2 = make_axes_locatable(ax)\n",
    "    cax2 = divider2.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    cbar2 = plt.colorbar(im2, cax=cax2)\n",
    "    cbar2.set_label('Head (m)', fontsize=12)\n",
    "    \n",
    "    stats_text = f\"Min: {vmin_pred:.2f}\\nMax: {vmax_pred:.2f}\\nMean: {np.nanmean(valid_pred):.2f}\"\n",
    "    ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=10,\n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    ax.set_xlim(0, ncol-1)\n",
    "    ax.set_ylim(nrow-1, 0)\n",
    "    ax.set_xlabel('Columns')\n",
    "    ax.set_ylabel('Rows')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. 绝对误差\n",
    "    ax = axes[0, 2]\n",
    "    ax.set_title('Absolute Error', fontsize=16)\n",
    "    masked_error = np.ma.masked_where(mask_2d <= 0, head_error_smooth)\n",
    "    valid_error = masked_error.compressed()\n",
    "    vmin_error, vmax_error = 0, np.nanmax(valid_error) if len(valid_error) > 0 else 1\n",
    "    \n",
    "    im3 = ax.imshow(masked_error, cmap='Reds', aspect='equal',\n",
    "                   extent=[0, ncol-1, nrow-1, 0], origin='upper',\n",
    "                   interpolation='bilinear', vmin=vmin_error, vmax=vmax_error)\n",
    "    \n",
    "    divider3 = make_axes_locatable(ax)\n",
    "    cax3 = divider3.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    cbar3 = plt.colorbar(im3, cax=cax3)\n",
    "    cbar3.set_label('Error (m)', fontsize=12)\n",
    "    \n",
    "    stats_text = f\"Min: {vmin_error:.2f}\\nMax: {vmax_error:.2f}\\nMean: {np.nanmean(valid_error):.2f}\"\n",
    "    ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=10,\n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    ax.set_xlim(0, ncol-1)\n",
    "    ax.set_ylim(nrow-1, 0)\n",
    "    ax.set_xlabel('Columns')\n",
    "    ax.set_ylabel('Rows')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. 相对误差\n",
    "    ax = axes[1, 0]\n",
    "    ax.set_title('Relative Error (%)', fontsize=16)\n",
    "    masked_rel_error = np.ma.masked_where(mask_2d <= 0, head_rel_error_smooth)\n",
    "    valid_rel_error = masked_rel_error.compressed()\n",
    "    vmin_rel, vmax_rel = 0, np.nanmax(valid_rel_error) if len(valid_rel_error) > 0 else 100\n",
    "    \n",
    "    im4 = ax.imshow(masked_rel_error, cmap='Reds', aspect='equal',\n",
    "                   extent=[0, ncol-1, nrow-1, 0], origin='upper',\n",
    "                   interpolation='bilinear', vmin=vmin_rel, vmax=vmax_rel)\n",
    "    \n",
    "    divider4 = make_axes_locatable(ax)\n",
    "    cax4 = divider4.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    cbar4 = plt.colorbar(im4, cax=cax4)\n",
    "    cbar4.set_label('Relative Error (%)', fontsize=12)\n",
    "    \n",
    "    stats_text = f\"Min: {vmin_rel:.1f}%\\nMax: {vmax_rel:.1f}%\\nMean: {np.nanmean(valid_rel_error):.1f}%\"\n",
    "    ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=10,\n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    ax.set_xlim(0, ncol-1)\n",
    "    ax.set_ylim(nrow-1, 0)\n",
    "    ax.set_xlabel('Columns')\n",
    "    ax.set_ylabel('Rows')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 5. 预测 vs 真实值散点图（按空间位置着色）\n",
    "    ax = axes[1, 1]\n",
    "    ax.set_title('Prediction vs Truth (colored by row)', fontsize=16)\n",
    "    scatter = ax.scatter(df['true_head'], df['pred_head'], \n",
    "                        c=df['row'], s=20, cmap='plasma', alpha=0.7)\n",
    "    min_val = min(df['true_head'].min(), df['pred_head'].min())\n",
    "    max_val = max(df['true_head'].max(), df['pred_head'].max())\n",
    "    ax.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2)\n",
    "    ax.set_xlabel('True Head Values (m)')\n",
    "    ax.set_ylabel('Predicted Head Values (m)')\n",
    "    \n",
    "    divider5 = make_axes_locatable(ax)\n",
    "    cax5 = divider5.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    plt.colorbar(scatter, cax=cax5, label='Row Index')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 6. 残差图\n",
    "    ax = axes[1, 2]\n",
    "    ax.set_title('Residuals (Pred - True)', fontsize=16)\n",
    "    masked_residual = np.ma.masked_where(mask_2d <= 0, head_residual_smooth)\n",
    "    valid_residual = masked_residual.compressed()\n",
    "    abs_max = np.nanmax(np.abs(valid_residual)) if len(valid_residual) > 0 else 1\n",
    "    \n",
    "    im6 = ax.imshow(masked_residual, cmap='RdBu_r', aspect='equal',\n",
    "                   extent=[0, ncol-1, nrow-1, 0], origin='upper',\n",
    "                   interpolation='bilinear', vmin=-abs_max, vmax=abs_max)\n",
    "    \n",
    "    divider6 = make_axes_locatable(ax)\n",
    "    cax6 = divider6.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    cbar6 = plt.colorbar(im6, cax=cax6)\n",
    "    cbar6.set_label('Residual (m)', fontsize=12)\n",
    "    \n",
    "    stats_text = f\"Min: {np.nanmin(valid_residual):.2f}\\nMax: {np.nanmax(valid_residual):.2f}\\nMean: {np.nanmean(valid_residual):.2f}\"\n",
    "    ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=10,\n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    ax.set_xlim(0, ncol-1)\n",
    "    ax.set_ylim(nrow-1, 0)\n",
    "    ax.set_xlabel('Columns')\n",
    "    ax.set_ylabel('Rows')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_path, f'head_spatial_2d_results_improved{time_suffix}.png'), \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"改进的水头模型空间2D结果图已保存\")\n",
    "\n",
    "def plot_conc_2d_results_improved(df, nrow, ncol, save_path, time_suffix, sigma):\n",
    "    \"\"\"绘制浓度模型的改进二维结果\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(24, 16))\n",
    "    fig.suptitle(f'Concentration Model Spatial 2D Results{time_suffix}', fontsize=20)\n",
    "    \n",
    "    # 创建2D场\n",
    "    true_conc_2d, mask_2d = create_2d_field_from_points(df, 'true_conc', nrow, ncol)\n",
    "    pred_conc_2d, _ = create_2d_field_from_points(df, 'pred_conc', nrow, ncol)\n",
    "    conc_error_2d, _ = create_2d_field_from_points(df, 'conc_error', nrow, ncol)\n",
    "    conc_rel_error_2d, _ = create_2d_field_from_points(df, 'conc_relative_error', nrow, ncol)\n",
    "    conc_residual_2d = pred_conc_2d - true_conc_2d\n",
    "    \n",
    "    # 应用插值和平滑\n",
    "    true_conc_smooth = interpolate_and_smooth_field(true_conc_2d, mask_2d, nrow, ncol, sigma)\n",
    "    pred_conc_smooth = interpolate_and_smooth_field(pred_conc_2d, mask_2d, nrow, ncol, sigma)\n",
    "    conc_error_smooth = interpolate_and_smooth_field(conc_error_2d, mask_2d, nrow, ncol, sigma)\n",
    "    conc_rel_error_smooth = interpolate_and_smooth_field(conc_rel_error_2d, mask_2d, nrow, ncol, sigma)\n",
    "    conc_residual_smooth = interpolate_and_smooth_field(conc_residual_2d, mask_2d, nrow, ncol, sigma)\n",
    "    \n",
    "    # 1. 真实浓度值\n",
    "    ax = axes[0, 0]\n",
    "    ax.set_title('True Concentration Values', fontsize=16)\n",
    "    masked_true = np.ma.masked_where(mask_2d <= 0, true_conc_smooth)\n",
    "    valid_true = masked_true.compressed()\n",
    "    vmin_true, vmax_true = np.nanmin(valid_true), np.nanmax(valid_true) if len(valid_true) > 0 else (0, 1)\n",
    "    \n",
    "    im1 = ax.imshow(masked_true, cmap='plasma', aspect='equal',\n",
    "                   extent=[0, ncol-1, nrow-1, 0], origin='upper',\n",
    "                   interpolation='bilinear', vmin=vmin_true, vmax=vmax_true)\n",
    "    \n",
    "    divider1 = make_axes_locatable(ax)\n",
    "    cax1 = divider1.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    cbar1 = plt.colorbar(im1, cax=cax1)\n",
    "    cbar1.set_label('Concentration(mg/L)', fontsize=12)\n",
    "    \n",
    "    stats_text = f\"Min: {vmin_true:.3f}\\nMax: {vmax_true:.3f}\\nMean: {np.nanmean(valid_true):.3f}\"\n",
    "    ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=10,\n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    ax.set_xlim(0, ncol-1)\n",
    "    ax.set_ylim(nrow-1, 0)\n",
    "    ax.set_xlabel('Columns')\n",
    "    ax.set_ylabel('Rows')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. 预测浓度值\n",
    "    ax = axes[0, 1]\n",
    "    ax.set_title('Predicted Concentration Values', fontsize=16)\n",
    "    masked_pred = np.ma.masked_where(mask_2d <= 0, pred_conc_smooth)\n",
    "    valid_pred = masked_pred.compressed()\n",
    "    vmin_pred, vmax_pred = np.nanmin(valid_pred), np.nanmax(valid_pred) if len(valid_pred) > 0 else (0, 1)\n",
    "    \n",
    "    im2 = ax.imshow(masked_pred, cmap='plasma', aspect='equal',\n",
    "                   extent=[0, ncol-1, nrow-1, 0], origin='upper',\n",
    "                   interpolation='bilinear', vmin=vmin_pred, vmax=vmax_pred)\n",
    "    \n",
    "    divider2 = make_axes_locatable(ax)\n",
    "    cax2 = divider2.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    cbar2 = plt.colorbar(im2, cax=cax2)\n",
    "    cbar2.set_label('Concentration(mg/L)', fontsize=12)\n",
    "    \n",
    "    stats_text = f\"Min: {vmin_pred:.3f}\\nMax: {vmax_pred:.3f}\\nMean: {np.nanmean(valid_pred):.3f}\"\n",
    "    ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=10,\n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    ax.set_xlim(0, ncol-1)\n",
    "    ax.set_ylim(nrow-1, 0)\n",
    "    ax.set_xlabel('Columns')\n",
    "    ax.set_ylabel('Rows')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. 绝对误差\n",
    "    ax = axes[0, 2]\n",
    "    ax.set_title('Absolute Error', fontsize=16)\n",
    "    masked_error = np.ma.masked_where(mask_2d <= 0, conc_error_smooth)\n",
    "    valid_error = masked_error.compressed()\n",
    "    vmin_error, vmax_error = 0, np.nanmax(valid_error) if len(valid_error) > 0 else 1\n",
    "    \n",
    "    im3 = ax.imshow(masked_error, cmap='Reds', aspect='equal',\n",
    "                   extent=[0, ncol-1, nrow-1, 0], origin='upper',\n",
    "                   interpolation='bilinear', vmin=vmin_error, vmax=vmax_error)\n",
    "    \n",
    "    divider3 = make_axes_locatable(ax)\n",
    "    cax3 = divider3.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    cbar3 = plt.colorbar(im3, cax=cax3)\n",
    "    cbar3.set_label('Error', fontsize=12)\n",
    "    \n",
    "    stats_text = f\"Min: {vmin_error:.3f}\\nMax: {vmax_error:.3f}\\nMean: {np.nanmean(valid_error):.3f}\"\n",
    "    ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=10,\n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    ax.set_xlim(0, ncol-1)\n",
    "    ax.set_ylim(nrow-1, 0)\n",
    "    ax.set_xlabel('Columns')\n",
    "    ax.set_ylabel('Rows')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. 相对误差\n",
    "    ax = axes[1, 0]\n",
    "    ax.set_title('Relative Error (%)', fontsize=16)\n",
    "    masked_rel_error = np.ma.masked_where(mask_2d <= 0, conc_rel_error_smooth)\n",
    "    valid_rel_error = masked_rel_error.compressed()\n",
    "    vmin_rel, vmax_rel = 0, np.nanmax(valid_rel_error) if len(valid_rel_error) > 0 else 100\n",
    "    \n",
    "    im4 = ax.imshow(masked_rel_error, cmap='Reds', aspect='equal',\n",
    "                   extent=[0, ncol-1, nrow-1, 0], origin='upper',\n",
    "                   interpolation='bilinear', vmin=vmin_rel, vmax=vmax_rel)\n",
    "    \n",
    "    divider4 = make_axes_locatable(ax)\n",
    "    cax4 = divider4.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    cbar4 = plt.colorbar(im4, cax=cax4)\n",
    "    cbar4.set_label('Relative Error (%)', fontsize=12)\n",
    "    \n",
    "    stats_text = f\"Min: {vmin_rel:.1f}%\\nMax: {vmax_rel:.1f}%\\nMean: {np.nanmean(valid_rel_error):.1f}%\"\n",
    "    ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=10,\n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    ax.set_xlim(0, ncol-1)\n",
    "    ax.set_ylim(nrow-1, 0)\n",
    "    ax.set_xlabel('Columns')\n",
    "    ax.set_ylabel('Rows')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 5. 预测 vs 真实值散点图（按空间位置着色）\n",
    "    ax = axes[1, 1]\n",
    "    ax.set_title('Prediction vs Truth (colored by column)', fontsize=16)\n",
    "    scatter = ax.scatter(df['true_conc'], df['pred_conc'],\n",
    "                        c=df['col'], s=20, cmap='viridis', alpha=0.7)\n",
    "    min_val = min(df['true_conc'].min(), df['pred_conc'].min())\n",
    "    max_val = max(df['true_conc'].max(), df['pred_conc'].max())\n",
    "    ax.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2)\n",
    "    ax.set_xlabel('True Concentration Values')\n",
    "    ax.set_ylabel('Predicted Concentration Values')\n",
    "    \n",
    "    divider5 = make_axes_locatable(ax)\n",
    "    cax5 = divider5.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    plt.colorbar(scatter, cax=cax5, label='Column Index')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 6. 残差图\n",
    "    ax = axes[1, 2]\n",
    "    ax.set_title('Residuals (Pred - True)', fontsize=16)\n",
    "    masked_residual = np.ma.masked_where(mask_2d <= 0, conc_residual_smooth)\n",
    "    valid_residual = masked_residual.compressed()\n",
    "    abs_max = np.nanmax(np.abs(valid_residual)) if len(valid_residual) > 0 else 1\n",
    "    \n",
    "    im6 = ax.imshow(masked_residual, cmap='RdBu_r', aspect='equal',\n",
    "                   extent=[0, ncol-1, nrow-1, 0], origin='upper',\n",
    "                   interpolation='bilinear', vmin=-abs_max, vmax=abs_max)\n",
    "    \n",
    "    divider6 = make_axes_locatable(ax)\n",
    "    cax6 = divider6.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    cbar6 = plt.colorbar(im6, cax=cax6)\n",
    "    cbar6.set_label('Residual(mg/L)', fontsize=12)\n",
    "    \n",
    "    stats_text = f\"Min: {np.nanmin(valid_residual):.3f}\\nMax: {np.nanmax(valid_residual):.3f}\\nMean: {np.nanmean(valid_residual):.3f}\"\n",
    "    ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=10,\n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    ax.set_xlim(0, ncol-1)\n",
    "    ax.set_ylim(nrow-1, 0)\n",
    "    ax.set_xlabel('Columns')\n",
    "    ax.set_ylabel('Rows')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_path, f'conc_spatial_2d_results_improved{time_suffix}.png'),\n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"改进的浓度模型空间2D结果图已保存\")\n",
    "\n",
    "def plot_combined_2d_results_improved(df, nrow, ncol, save_path, time_suffix, sigma):\n",
    "    \"\"\"绘制水头和浓度模型的改进综合比较图\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(20, 16))\n",
    "    fig.suptitle(f'Combined Spatial 2D Analysis{time_suffix}', fontsize=20)\n",
    "    \n",
    "    # 创建2D场\n",
    "    head_error_2d, mask_2d = create_2d_field_from_points(df, 'head_error', nrow, ncol)\n",
    "    conc_error_2d, _ = create_2d_field_from_points(df, 'conc_error', nrow, ncol)\n",
    "    combined_rel_error = (df['head_relative_error'] + df['conc_relative_error']) / 2\n",
    "    combined_error_2d, _ = create_2d_field_from_points(\n",
    "        df.assign(combined_rel_error=combined_rel_error), \n",
    "        'combined_rel_error', nrow, ncol\n",
    "    )\n",
    "    \n",
    "    # 应用插值和平滑\n",
    "    head_error_smooth = interpolate_and_smooth_field(head_error_2d, mask_2d, nrow, ncol, sigma)\n",
    "    conc_error_smooth = interpolate_and_smooth_field(conc_error_2d, mask_2d, nrow, ncol, sigma)\n",
    "    combined_error_smooth = interpolate_and_smooth_field(combined_error_2d, mask_2d, nrow, ncol, sigma)\n",
    "    \n",
    "    # 1. 水头误差分布\n",
    "    ax = axes[0, 0]\n",
    "    ax.set_title('Head Model: Absolute Error Distribution', fontsize=16)\n",
    "    masked_head_error = np.ma.masked_where(mask_2d <= 0, head_error_smooth)\n",
    "    valid_head_error = masked_head_error.compressed()\n",
    "    vmax_head_error = np.nanmax(valid_head_error) if len(valid_head_error) > 0 else 1\n",
    "    \n",
    "    im1 = ax.imshow(masked_head_error, cmap='Reds', aspect='equal',\n",
    "                   extent=[0, ncol-1, nrow-1, 0], origin='upper',\n",
    "                   interpolation='bilinear', vmin=0, vmax=vmax_head_error)\n",
    "    \n",
    "    divider1 = make_axes_locatable(ax)\n",
    "    cax1 = divider1.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    plt.colorbar(im1, cax=cax1, label='Head Error (m)')\n",
    "    \n",
    "    ax.set_xlim(0, ncol-1)\n",
    "    ax.set_ylim(nrow-1, 0)\n",
    "    ax.set_xlabel('Columns')\n",
    "    ax.set_ylabel('Rows')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. 浓度误差分布\n",
    "    ax = axes[0, 1]\n",
    "    ax.set_title('Concentration Model: Absolute Error Distribution', fontsize=16)\n",
    "    masked_conc_error = np.ma.masked_where(mask_2d <= 0, conc_error_smooth)\n",
    "    valid_conc_error = masked_conc_error.compressed()\n",
    "    vmax_conc_error = np.nanmax(valid_conc_error) if len(valid_conc_error) > 0 else 1\n",
    "    \n",
    "    im2 = ax.imshow(masked_conc_error, cmap='Reds', aspect='equal',\n",
    "                   extent=[0, ncol-1, nrow-1, 0], origin='upper',\n",
    "                   interpolation='bilinear', vmin=0, vmax=vmax_conc_error)\n",
    "    \n",
    "    divider2 = make_axes_locatable(ax)\n",
    "    cax2 = divider2.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    plt.colorbar(im2, cax=cax2, label='Concentration Error')\n",
    "    \n",
    "    ax.set_xlim(0, ncol-1)\n",
    "    ax.set_ylim(nrow-1, 0)\n",
    "    ax.set_xlabel('Columns')\n",
    "    ax.set_ylabel('Rows')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. 误差相关性分析\n",
    "    ax = axes[1, 0]\n",
    "    ax.set_title('Error Correlation (colored by row)', fontsize=16)\n",
    "    scatter = ax.scatter(df['head_error'], df['conc_error'], c=df['row'],\n",
    "                        s=30, cmap='viridis', alpha=0.7, edgecolors='black', linewidth=0.3)\n",
    "    ax.set_xlabel('Head Absolute Error')\n",
    "    ax.set_ylabel('Concentration Absolute Error')\n",
    "    \n",
    "    divider3 = make_axes_locatable(ax)\n",
    "    cax3 = divider3.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    plt.colorbar(scatter, cax=cax3, label='Row Index')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. 综合误差分布\n",
    "    ax = axes[1, 1]\n",
    "    ax.set_title('Combined Relative Error (%)', fontsize=16)\n",
    "    masked_combined = np.ma.masked_where(mask_2d <= 0, combined_error_smooth)\n",
    "    valid_combined = masked_combined.compressed()\n",
    "    vmax_combined = np.nanmax(valid_combined) if len(valid_combined) > 0 else 100\n",
    "    \n",
    "    im4 = ax.imshow(masked_combined, cmap='Reds', aspect='equal',\n",
    "                   extent=[0, ncol-1, nrow-1, 0], origin='upper',\n",
    "                   interpolation='bilinear', vmin=0, vmax=vmax_combined)\n",
    "    \n",
    "    divider4 = make_axes_locatable(ax)\n",
    "    cax4 = divider4.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    plt.colorbar(im4, cax=cax4, label='Combined Error (%)')\n",
    "    \n",
    "    stats_text = f\"Min: {np.nanmin(valid_combined):.1f}%\\nMax: {vmax_combined:.1f}%\\nMean: {np.nanmean(valid_combined):.1f}%\"\n",
    "    ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=10,\n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    ax.set_xlim(0, ncol-1)\n",
    "    ax.set_ylim(nrow-1, 0)\n",
    "    ax.set_xlabel('Columns')\n",
    "    ax.set_ylabel('Rows')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_path, f'combined_spatial_2d_results_improved{time_suffix}.png'),\n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"改进的综合空间2D分析图已保存\")\n",
    "\n",
    "def load_and_plot_from_csv_improved(save_path, model_type, sigma):\n",
    "    \"\"\"从CSV文件加载数据并绘制改进版图表\"\"\"\n",
    "    try:\n",
    "        results_dir = os.path.join(save_path, 'evaluation_results')\n",
    "        csv_files = [f for f in os.listdir(results_dir) if f.endswith('.csv') and 'predictions' in f]\n",
    "        \n",
    "        if not csv_files:\n",
    "            print(\"未找到预测结果CSV文件\")\n",
    "            return\n",
    "        \n",
    "        csv_file = csv_files[0]\n",
    "        df = pd.read_csv(os.path.join(results_dir, csv_file))\n",
    "        \n",
    "        print(f\"从 {csv_file} 加载数据\")\n",
    "        print(f\"数据形状: {df.shape}\")\n",
    "        \n",
    "        # 检查必要的列\n",
    "        required_cols = ['row', 'col', 'pred_head', 'true_head', 'pred_conc', 'true_conc']\n",
    "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "        \n",
    "        if missing_cols:\n",
    "            print(f\"缺少必要的列: {missing_cols}\")\n",
    "            return\n",
    "        \n",
    "        # 计算误差\n",
    "        df['head_error'] = np.abs(df['pred_head'] - df['true_head'])\n",
    "        df['conc_error'] = np.abs(df['pred_conc'] - df['true_conc'])\n",
    "        df['head_relative_error'] = df['head_error'] / (np.abs(df['true_head']) + 1e-8) * 100\n",
    "        df['conc_relative_error'] = df['conc_error'] / (np.abs(df['true_conc']) + 1e-8) * 100\n",
    "        \n",
    "        # 如果有多个时间步，取平均\n",
    "        if 'time_step' in df.columns:\n",
    "            df = df.groupby(['row', 'col']).agg({\n",
    "                'pred_head': 'mean',\n",
    "                'true_head': 'mean',\n",
    "                'pred_conc': 'mean',\n",
    "                'true_conc': 'mean',\n",
    "                'head_error': 'mean',\n",
    "                'conc_error': 'mean',\n",
    "                'head_relative_error': 'mean',\n",
    "                'conc_relative_error': 'mean'\n",
    "            }).reset_index()\n",
    "        \n",
    "        # 确定网格尺寸\n",
    "        nrow = int(df['row'].max()) + 1\n",
    "        ncol = int(df['col'].max()) + 1\n",
    "        \n",
    "        time_suffix = '_from_csv'\n",
    "        \n",
    "        # 绘制图表\n",
    "        if model_type in ['head', 'both']:\n",
    "            plot_head_2d_results_improved(df, nrow, ncol, results_dir, time_suffix, sigma)\n",
    "        \n",
    "        if model_type in ['conc', 'both']:\n",
    "            plot_conc_2d_results_improved(df, nrow, ncol, results_dir, time_suffix, sigma)\n",
    "        \n",
    "        if model_type == 'both':\n",
    "            plot_combined_2d_results_improved(df, nrow, ncol, results_dir, time_suffix, sigma)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"从CSV加载数据失败: {e}\")\n",
    "\n",
    "# 主函数\n",
    "def main():\n",
    "    \"\"\"主函数示例\"\"\"\n",
    "    save_path = './saved_models/blitz_bayesian_gnn_Sub'\n",
    "    evaluation_criterion = 'r2'\n",
    "    \n",
    "    try:\n",
    "        filename = f'dual_model_evaluation_{evaluation_criterion}.npy'\n",
    "        filepath = os.path.join(save_path, filename)\n",
    "        evaluation_results = np.load(filepath, allow_pickle=True).item()\n",
    "        \n",
    "        print(f\"成功加载评估结果: {filename}\")\n",
    "        \n",
    "        # 绘制改进的空间2D拟合效果图\n",
    "        plot_spatial_2d_fitting_results_improved(\n",
    "            evaluation_results,\n",
    "            save_path,\n",
    "            time_step=None,  # 使用所有时间步的平均\n",
    "            model_type='both',  # 'head', 'conc', 或 'both'\n",
    "            sigma=1.5  # 平滑参数\n",
    "        )\n",
    "        \n",
    "        print(\"改进的空间2D拟合效果图绘制完成!\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"未找到评估结果文件，尝试从CSV文件绘制\")\n",
    "        load_and_plot_from_csv_improved(save_path, 'both', sigma=1.5)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"加载评估结果失败: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3e689c-353e-41e2-8487-2e157c1d3538",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
