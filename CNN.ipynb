{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09d59dd7-b31a-4d92-a8fb-54dcba2e5b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score as sklearn_r2_score\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ConvLSTM Cell\n",
    "class ConvLSTMCell(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size, bias=True, dropout=0.3):\n",
    "        super(ConvLSTMCell, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = kernel_size // 2\n",
    "        self.bias = bias\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=input_dim + hidden_dim,\n",
    "            out_channels=4 * hidden_dim,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=self.padding,\n",
    "            bias=bias\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout) if dropout > 0 else nn.Identity()\n",
    "\n",
    "    def forward(self, input_tensor, cur_state):\n",
    "        h_cur, c_cur = cur_state\n",
    "        combined = torch.cat([input_tensor, h_cur], dim=1)\n",
    "        combined_conv = self.conv(combined)\n",
    "        combined_conv = self.dropout(combined_conv)\n",
    "        cc_i, cc_f, cc_o, cc_g = torch.split(combined_conv, self.hidden_dim, dim=1)\n",
    "        i = torch.sigmoid(cc_i)\n",
    "        f = torch.sigmoid(cc_f)\n",
    "        o = torch.sigmoid(cc_o)\n",
    "        g = torch.tanh(cc_g)\n",
    "        c_next = f * c_cur + i * g\n",
    "        h_next = o * torch.tanh(c_next)\n",
    "        return h_next, c_next\n",
    "\n",
    "    def init_hidden(self, batch_size, image_size):\n",
    "        height, width = image_size\n",
    "        return (torch.zeros(batch_size, self.hidden_dim, height, width, device=device),\n",
    "                torch.zeros(batch_size, self.hidden_dim, height, width, device=device))\n",
    "\n",
    "# ConvLSTM Module\n",
    "class ConvLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size, num_layers, batch_first=True, dropout=0.3):\n",
    "        super(ConvLSTM, self).__init__()\n",
    "        kernel_size = [kernel_size] * num_layers if isinstance(kernel_size, int) else kernel_size\n",
    "        hidden_dim = [hidden_dim] * num_layers if isinstance(hidden_dim, int) else hidden_dim\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_first = batch_first\n",
    "        self.cell_list = nn.ModuleList([\n",
    "            ConvLSTMCell(\n",
    "                input_dim=self.input_dim if i == 0 else self.hidden_dim[i-1],\n",
    "                hidden_dim=self.hidden_dim[i],\n",
    "                kernel_size=self.kernel_size[i],\n",
    "                bias=True,\n",
    "                dropout=dropout if i < num_layers-1 else 0\n",
    "            ) for i in range(self.num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, input_tensor, hidden_state=None):\n",
    "        if not self.batch_first:\n",
    "            input_tensor = input_tensor.permute(1, 0, 2, 3, 4)\n",
    "        b, t, c, h, w = input_tensor.size()\n",
    "        if hidden_state is None:\n",
    "            hidden_state = self._init_hidden(batch_size=b, image_size=(h, w))\n",
    "        layer_output_list = []\n",
    "        last_state_list = []\n",
    "        cur_layer_input = input_tensor\n",
    "        for layer_idx in range(self.num_layers):\n",
    "            h, c = hidden_state[layer_idx]\n",
    "            output_inner = []\n",
    "            for t_idx in range(t):\n",
    "                h, c = self.cell_list[layer_idx](cur_layer_input[:, t_idx, :, :, :], cur_state=[h, c])\n",
    "                output_inner.append(h)\n",
    "            layer_output = torch.stack(output_inner, dim=1)\n",
    "            cur_layer_input = layer_output\n",
    "            layer_output_list.append(layer_output)\n",
    "            last_state_list.append([h, c])\n",
    "        return layer_output_list[-1], last_state_list[-1]\n",
    "\n",
    "    def _init_hidden(self, batch_size, image_size):\n",
    "        return [self.cell_list[i].init_hidden(batch_size, image_size) for i in range(self.num_layers)]\n",
    "\n",
    "# 水头模型 - 16维输入\n",
    "class HeadCNN(nn.Module):\n",
    "    def __init__(self, input_dim=16, hidden_dim=32, dropout=0.3):\n",
    "        super(HeadCNN, self).__init__()\n",
    "        self.convlstm = ConvLSTM(input_dim=input_dim, hidden_dim=hidden_dim, kernel_size=3, num_layers=1, dropout=dropout)\n",
    "        self.out_conv = nn.Conv2d(hidden_dim, 1, kernel_size=1)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        layer_output, _ = self.convlstm(x)\n",
    "        b, t, c, h, w = layer_output.size()\n",
    "        layer_output = layer_output.view(b * t, c, h, w)\n",
    "        out = self.out_conv(layer_output)\n",
    "        out = self.activation(out)\n",
    "        out = out.view(b, t, 1, h, w)\n",
    "        return out\n",
    "\n",
    "# 浓度模型 - 19维输入（包含预测的水头）\n",
    "class ConcCNN(nn.Module):\n",
    "    def __init__(self, input_dim=20, hidden_dim=32, dropout=0.3):\n",
    "        super(ConcCNN, self).__init__()\n",
    "        self.convlstm = ConvLSTM(input_dim=input_dim, hidden_dim=hidden_dim, kernel_size=3, num_layers=1, dropout=dropout)\n",
    "        self.out_conv = nn.Conv2d(hidden_dim, 1, kernel_size=1)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        layer_output, _ = self.convlstm(x)\n",
    "        b, t, c, h, w = layer_output.size()\n",
    "        layer_output = layer_output.view(b * t, c, h, w)\n",
    "        out = self.out_conv(layer_output)\n",
    "        out = self.activation(out)\n",
    "        out = out.view(b, t, 1, h, w)\n",
    "        return out\n",
    "\n",
    "# Dataset Class - 修复索引问题\n",
    "class HydroCNNDataset(Dataset):\n",
    "    def __init__(self, data, grid_size, max_time_steps):\n",
    "        # 关键修复：重置索引并创建副本\n",
    "        self.data = data.reset_index(drop=True).copy()\n",
    "        self.grid_size = grid_size\n",
    "        self.max_time_steps = max_time_steps\n",
    "        self.models = self.data['model_name'].unique()\n",
    "        self.cached_data = {}\n",
    "        \n",
    "        # 基础特征列 - 与GNN保持一致 (14维)\n",
    "        self.base_feature_cols = [\n",
    "            'x', 'y', 'top', 'bottom', 'K', 'recharge', 'ET',\n",
    "            'river_stage', 'river_cond', 'river_rbot', 'well_rate', 'well_mask',\n",
    "            'chd_mask', 'lytyp'\n",
    "        ]\n",
    "        \n",
    "        # 浓度模型额外的基础特征 (15维，增加conc_mask)\n",
    "        self.conc_base_feature_cols = self.base_feature_cols + ['conc_mask']\n",
    "        \n",
    "        self._normalize_features()\n",
    "        self._preprocess_data()\n",
    "\n",
    "    def _normalize_features(self):\n",
    "        \"\"\"标准化特征，与GNN保持一致\"\"\"\n",
    "        print(\"开始特征标准化...\")\n",
    "        \n",
    "        # 只对浮点数特征进行标准化\n",
    "        float_cols = [col for col in self.base_feature_cols if col not in ['well_mask', 'chd_mask', 'lytyp']]\n",
    "        \n",
    "        for model_name in self.models:\n",
    "            model_df = self.data[self.data['model_name'] == model_name].copy()\n",
    "            \n",
    "            # 标准化基础浮点特征\n",
    "            if len(model_df) > 0:  # 确保模型数据不为空\n",
    "                scaler = StandardScaler()\n",
    "                float_data = model_df[float_cols].values\n",
    "                if float_data.size > 0:  # 确保数据不为空\n",
    "                    scaled_data = scaler.fit_transform(float_data)\n",
    "                    # 使用loc更新数据，避免索引问题\n",
    "                    mask = self.data['model_name'] == model_name\n",
    "                    self.data.loc[mask, float_cols] = scaled_data\n",
    "\n",
    "    def _preprocess_data(self):\n",
    "        \"\"\"预处理数据，构建与GNN一致的特征 - 优化版本\"\"\"\n",
    "        print(\"预处理CNN数据...\")\n",
    "        M, N = self.grid_size\n",
    "        T = self.max_time_steps\n",
    "        \n",
    "        for model_idx, model_name in enumerate(self.models):\n",
    "            print(f\"处理模型 {model_idx+1}/{len(self.models)}: {model_name}\")\n",
    "            \n",
    "            # 获取当前模型的数据并重置索引\n",
    "            model_df = self.data[self.data['model_name'] == model_name].copy().reset_index(drop=True)\n",
    "            \n",
    "            if len(model_df) == 0:\n",
    "                print(f\"警告: 模型 {model_name} 没有数据，跳过\")\n",
    "                continue\n",
    "            \n",
    "            # 时间步归一化\n",
    "            model_df['time_step'] = model_df['time_step'] - model_df['time_step'].min()\n",
    "            \n",
    "            # 计算历史特征 - 优化版本\n",
    "            model_df = model_df.sort_values(['row', 'col', 'time_step']).reset_index(drop=True)\n",
    "            \n",
    "            print(f\"  计算历史特征...\")\n",
    "            # 使用向量化操作计算历史特征\n",
    "            model_df['prev_head'] = 0.0\n",
    "            model_df['prev2_head'] = 0.0\n",
    "            model_df['prev_conc'] = 0.0\n",
    "            model_df['prev2_conc'] = 0.0\n",
    "            \n",
    "            # 按(row, col)分组，向量化计算历史特征\n",
    "            for (row, col), group in model_df.groupby(['row', 'col']):\n",
    "                group_sorted = group.sort_values('time_step')\n",
    "                indices = group_sorted.index\n",
    "                \n",
    "                if len(indices) > 0:\n",
    "                    head_vals = group_sorted['head'].values\n",
    "                    conc_vals = group_sorted['concentration'].values\n",
    "                    \n",
    "                    # 计算前一时间步\n",
    "                    prev_head_vals = np.concatenate([[head_vals[0]], head_vals[:-1]])\n",
    "                    prev_conc_vals = np.concatenate([[conc_vals[0]], conc_vals[:-1]])\n",
    "                    \n",
    "                    # 计算前两时间步\n",
    "                    if len(head_vals) >= 2:\n",
    "                        prev2_head_vals = np.concatenate([[head_vals[0]], [head_vals[0]], head_vals[:-2]])\n",
    "                        prev2_conc_vals = np.concatenate([[conc_vals[0]], [conc_vals[0]], conc_vals[:-2]])\n",
    "                    else:\n",
    "                        prev2_head_vals = np.full(len(head_vals), head_vals[0])\n",
    "                        prev2_conc_vals = np.full(len(conc_vals), conc_vals[0])\n",
    "                    \n",
    "                    model_df.loc[indices, 'prev_head'] = prev_head_vals\n",
    "                    model_df.loc[indices, 'prev2_head'] = prev2_head_vals\n",
    "                    model_df.loc[indices, 'prev_conc'] = prev_conc_vals\n",
    "                    model_df.loc[indices, 'prev2_conc'] = prev2_conc_vals\n",
    "            \n",
    "            # 构建特征列表\n",
    "            head_feature_cols = self.base_feature_cols + ['prev_head', 'prev2_head']\n",
    "            conc_feature_cols = self.conc_base_feature_cols + ['prev_head', 'prev2_head', 'prev_conc', 'prev2_conc']\n",
    "            \n",
    "            # 初始化数组\n",
    "            X_head = np.zeros((T, len(head_feature_cols), M, N), dtype=np.float32)\n",
    "            X_conc_base = np.zeros((T, len(conc_feature_cols) - 1, M, N), dtype=np.float32)\n",
    "            Y_head = np.zeros((T, 1, M, N), dtype=np.float32)\n",
    "            Y_conc = np.zeros((T, 1, M, N), dtype=np.float32)\n",
    "            mask = np.zeros((M, N), dtype=np.float32)\n",
    "            \n",
    "            print(f\"  填充网格数据...\")\n",
    "            \n",
    "            # 优化的填充过程 - 按时间步批量处理\n",
    "            max_t = min(T, model_df['time_step'].max() + 1)\n",
    "            for t in range(max_t):\n",
    "                if t % 50 == 0:  # 每50个时间步输出一次进度\n",
    "                    print(f\"    处理时间步 {t}/{max_t}\")\n",
    "                    \n",
    "                t_df = model_df[model_df['time_step'] == t]\n",
    "                if len(t_df) == 0:\n",
    "                    continue\n",
    "                \n",
    "                rows = t_df['row'].values.astype(int)\n",
    "                cols = t_df['col'].values.astype(int)\n",
    "                \n",
    "                # 检查索引范围\n",
    "                valid_mask = (rows >= 0) & (rows < M) & (cols >= 0) & (cols < N)\n",
    "                if not np.any(valid_mask):\n",
    "                    continue\n",
    "                    \n",
    "                rows = rows[valid_mask]\n",
    "                cols = cols[valid_mask]\n",
    "                t_df_valid = t_df.iloc[valid_mask]\n",
    "                \n",
    "                # 批量填充水头特征\n",
    "                head_data = t_df_valid[head_feature_cols].values  # Shape: (n_points, 16)\n",
    "                for feat_idx in range(len(head_feature_cols)):\n",
    "                    X_head[t, feat_idx, rows, cols] = head_data[:, feat_idx]\n",
    "                \n",
    "                # 批量填充浓度特征（除了预测水头）\n",
    "                conc_data = t_df_valid[conc_feature_cols[:-1]].values  # Shape: (n_points, 18)\n",
    "                for feat_idx in range(len(conc_feature_cols) - 1):\n",
    "                    X_conc_base[t, feat_idx, rows, cols] = conc_data[:, feat_idx]\n",
    "                \n",
    "                # 填充目标值\n",
    "                Y_head[t, 0, rows, cols] = t_df_valid['head'].values\n",
    "                Y_conc[t, 0, rows, cols] = t_df_valid['concentration'].values\n",
    "                \n",
    "                # 更新掩码\n",
    "                mask[rows, cols] = 1\n",
    "            \n",
    "            self.cached_data[model_name] = {\n",
    "                'X_head': torch.from_numpy(X_head),\n",
    "                'X_conc_base': torch.from_numpy(X_conc_base),\n",
    "                'Y_head': torch.from_numpy(Y_head),\n",
    "                'Y_conc': torch.from_numpy(Y_conc),\n",
    "                'mask': torch.from_numpy(mask),\n",
    "                'model_name': model_name\n",
    "            }\n",
    "            \n",
    "            print(f\"  模型 {model_name} 处理完成\")\n",
    "        \n",
    "        print(f\"预处理完成！处理了 {len(self.cached_data)} 个模型\")\n",
    "        if len(self.cached_data) > 0:\n",
    "            sample_data = list(self.cached_data.values())[0]\n",
    "            print(f\"特征维度 - 水头: {sample_data['X_head'].shape[1]}, 浓度基础: {sample_data['X_conc_base'].shape[1]}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.cached_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        model_name = list(self.cached_data.keys())[idx]\n",
    "        return self.cached_data[model_name]\n",
    "\n",
    "# Custom Collate Function\n",
    "def custom_collate_fn(batch):\n",
    "    fixed_keys = ['X_head', 'X_conc_base', 'Y_head', 'Y_conc', 'mask']\n",
    "    variable_keys = ['model_name']\n",
    "    collated = {}\n",
    "    for key in fixed_keys:\n",
    "        collated[key] = torch.stack([item[key] for item in batch])\n",
    "    for key in variable_keys:\n",
    "        collated[key] = [item[key] for item in batch]\n",
    "    return collated\n",
    "\n",
    "# Metrics Computation\n",
    "def compute_metrics(y_true, y_pred, mask, T):\n",
    "    \"\"\"计算指标，与GNN保持一致\"\"\"\n",
    "    if isinstance(y_true, torch.Tensor):\n",
    "        y_true = y_true.detach().cpu().numpy()\n",
    "    if isinstance(y_pred, torch.Tensor):\n",
    "        y_pred = y_pred.detach().cpu().numpy()\n",
    "    if isinstance(mask, torch.Tensor):\n",
    "        mask = mask.detach().cpu().numpy()\n",
    "\n",
    "    # 应用掩码\n",
    "    mask = mask[:, np.newaxis, np.newaxis, :, :]  # Shape: [B, 1, 1, M, N]\n",
    "    mask = np.repeat(mask, T, axis=1)  # Shape: [B, T, 1, M, N]\n",
    "\n",
    "    y_true = y_true[mask > 0]\n",
    "    y_pred = y_pred[mask > 0]\n",
    "\n",
    "    valid_mask = ~np.isnan(y_true) & ~np.isinf(y_true) & ~np.isnan(y_pred) & ~np.isinf(y_pred)\n",
    "    y_true = y_true[valid_mask]\n",
    "    y_pred = y_pred[valid_mask]\n",
    "\n",
    "    if len(y_true) == 0:\n",
    "        return {'mse': np.nan, 'rmse': np.nan, 'mae': np.nan, 'r2': np.nan}\n",
    "\n",
    "    mse = np.mean((y_true - y_pred) ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "    \n",
    "    # 计算R2\n",
    "    ss_res = np.sum((y_true - y_pred) ** 2)\n",
    "    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "    r2 = 1 - (ss_res / (ss_tot + 1e-8))\n",
    "\n",
    "    return {'mse': mse, 'rmse': rmse, 'mae': mae, 'r2': r2}\n",
    "\n",
    "# 训练函数 - 先训练水头，再训练浓度\n",
    "def train_dual_cnn(train_loader, val_loader, config):\n",
    "    \"\"\"分步训练：先训练水头模型，再训练浓度模型\"\"\"\n",
    "    \n",
    "    # 创建保存目录\n",
    "    os.makedirs(config['save_path'], exist_ok=True)\n",
    "    \n",
    "    print(\"🔹 开始训练水头模型...\")\n",
    "    \n",
    "    # ==================== 第一阶段：训练水头模型 ====================\n",
    "    head_model = HeadCNN(input_dim=16, hidden_dim=config['hidden_dim']).to(device)\n",
    "    head_optimizer = torch.optim.AdamW(\n",
    "        head_model.parameters(),\n",
    "        lr=config['lr'],\n",
    "        weight_decay=config['weight_decay']\n",
    "    )\n",
    "    head_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(head_optimizer, T_max=config['num_epochs'])\n",
    "    \n",
    "    best_head_val_loss = float('inf')\n",
    "    head_early_stop_counter = 0\n",
    "    \n",
    "    for epoch in range(config['num_epochs']):\n",
    "        # 训练水头模型\n",
    "        head_model.train()\n",
    "        total_head_loss = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            X_head = batch['X_head'].to(device)\n",
    "            Y_head = batch['Y_head'].to(device)\n",
    "            mask = batch['mask'].to(device).unsqueeze(1).unsqueeze(1)  # [B, 1, 1, M, N]\n",
    "            \n",
    "            head_optimizer.zero_grad()\n",
    "            pred_head = head_model(X_head)\n",
    "            \n",
    "            # 应用掩码计算损失\n",
    "            loss_head = F.mse_loss(pred_head * mask, Y_head * mask)\n",
    "            loss_head.backward()\n",
    "            \n",
    "            # 梯度裁剪\n",
    "            torch.nn.utils.clip_grad_norm_(head_model.parameters(), max_norm=1.0)\n",
    "            head_optimizer.step()\n",
    "            \n",
    "            total_head_loss += loss_head.item()\n",
    "        \n",
    "        # 验证水头模型\n",
    "        head_model.eval()\n",
    "        total_head_val_loss = 0\n",
    "        all_head_metrics = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                X_head = batch['X_head'].to(device)\n",
    "                Y_head = batch['Y_head'].to(device)\n",
    "                mask = batch['mask'].to(device).unsqueeze(1).unsqueeze(1)\n",
    "                \n",
    "                pred_head = head_model(X_head)\n",
    "                loss_head = F.mse_loss(pred_head * mask, Y_head * mask)\n",
    "                total_head_val_loss += loss_head.item()\n",
    "                \n",
    "                # 计算指标\n",
    "                head_metrics = compute_metrics(Y_head, pred_head, batch['mask'], config['max_time_steps'])\n",
    "                all_head_metrics.append(head_metrics)\n",
    "        \n",
    "        avg_head_train_loss = total_head_loss / len(train_loader)\n",
    "        avg_head_val_loss = total_head_val_loss / len(val_loader)\n",
    "        \n",
    "        # 计算平均指标\n",
    "        avg_head_r2 = np.nanmean([m['r2'] for m in all_head_metrics])\n",
    "        avg_head_rmse = np.nanmean([m['rmse'] for m in all_head_metrics])\n",
    "        \n",
    "        head_scheduler.step()\n",
    "        current_lr = head_scheduler.get_last_lr()[0]\n",
    "        \n",
    "        print(f\"水头模型 Epoch {epoch+1:03d}/{config['num_epochs']} | \"\n",
    "              f\"训练损失: {avg_head_train_loss:.4f} | 验证损失: {avg_head_val_loss:.4f} | \"\n",
    "              f\"R2: {avg_head_r2:.4f} | RMSE: {avg_head_rmse:.4f} | LR: {current_lr:.6f}\")\n",
    "        \n",
    "        # 保存最佳水头模型\n",
    "        if avg_head_val_loss < best_head_val_loss:\n",
    "            best_head_val_loss = avg_head_val_loss\n",
    "            head_early_stop_counter = 0\n",
    "            torch.save({\n",
    "                'model_state_dict': head_model.state_dict(),\n",
    "                'epoch': epoch,\n",
    "                'train_loss': avg_head_train_loss,\n",
    "                'val_loss': avg_head_val_loss,\n",
    "                'r2': avg_head_r2,\n",
    "                'config': config\n",
    "            }, os.path.join(config['save_path'], 'best_head_model.pth'))\n",
    "            print(f\"保存最佳水头模型，验证损失: {best_head_val_loss:.4f}\")\n",
    "        else:\n",
    "            head_early_stop_counter += 1\n",
    "        \n",
    "        # 早停检查\n",
    "        if head_early_stop_counter >= config['patience']:\n",
    "            print(f\"水头模型早停触发! 在第{epoch+1}个epoch停止训练\")\n",
    "            break\n",
    "    \n",
    "    # 加载最佳水头模型\n",
    "    best_head_checkpoint = torch.load(os.path.join(config['save_path'], 'best_head_model.pth'))\n",
    "    head_model.load_state_dict(best_head_checkpoint['model_state_dict'])\n",
    "    head_model.eval()\n",
    "    \n",
    "    print(f\"\\n🔹 水头模型训练完成！最佳验证损失: {best_head_val_loss:.4f}\")\n",
    "    print(\"🔹 开始训练浓度模型...\")\n",
    "    \n",
    "    # ==================== 第二阶段：训练浓度模型 ====================\n",
    "    conc_model = ConcCNN(input_dim=20, hidden_dim=config['hidden_dim']).to(device)\n",
    "    conc_optimizer = torch.optim.AdamW(\n",
    "        conc_model.parameters(),\n",
    "        lr=config['lr'],\n",
    "        weight_decay=config['weight_decay']\n",
    "    )\n",
    "    conc_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(conc_optimizer, T_max=config['num_epochs'])\n",
    "    \n",
    "    best_conc_val_loss = float('inf')\n",
    "    best_conc_r2 = float('-inf')\n",
    "    conc_early_stop_counter = 0\n",
    "    \n",
    "    for epoch in range(config['num_epochs']):\n",
    "        # 训练浓度模型\n",
    "        conc_model.train()\n",
    "        total_conc_loss = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            X_head = batch['X_head'].to(device)\n",
    "            X_conc_base = batch['X_conc_base'].to(device)\n",
    "            Y_conc = batch['Y_conc'].to(device)\n",
    "            mask = batch['mask'].to(device).unsqueeze(1).unsqueeze(1)\n",
    "            \n",
    "            # 使用固定的水头模型预测水头\n",
    "            with torch.no_grad():\n",
    "                pred_head = head_model(X_head)\n",
    "            \n",
    "            # 构建浓度模型输入（添加预测的水头作为第19个特征）\n",
    "            X_conc = torch.cat([X_conc_base, pred_head], dim=2)  # [B, T, 19, M, N]\n",
    "            \n",
    "            conc_optimizer.zero_grad()\n",
    "            pred_conc = conc_model(X_conc)\n",
    "            \n",
    "            # 应用掩码计算损失\n",
    "            loss_conc = F.mse_loss(pred_conc * mask, Y_conc * mask)\n",
    "            loss_conc.backward()\n",
    "            \n",
    "            # 梯度裁剪\n",
    "            torch.nn.utils.clip_grad_norm_(conc_model.parameters(), max_norm=1.0)\n",
    "            conc_optimizer.step()\n",
    "            \n",
    "            total_conc_loss += loss_conc.item()\n",
    "        \n",
    "        # 验证浓度模型\n",
    "        conc_model.eval()\n",
    "        total_conc_val_loss = 0\n",
    "        all_conc_metrics = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                X_head = batch['X_head'].to(device)\n",
    "                X_conc_base = batch['X_conc_base'].to(device)\n",
    "                Y_conc = batch['Y_conc'].to(device)\n",
    "                mask = batch['mask'].to(device).unsqueeze(1).unsqueeze(1)\n",
    "                \n",
    "                pred_head = head_model(X_head)\n",
    "                X_conc = torch.cat([X_conc_base, pred_head], dim=2)\n",
    "                pred_conc = conc_model(X_conc)\n",
    "                \n",
    "                loss_conc = F.mse_loss(pred_conc * mask, Y_conc * mask)\n",
    "                total_conc_val_loss += loss_conc.item()\n",
    "                \n",
    "                # 计算指标\n",
    "                conc_metrics = compute_metrics(Y_conc, pred_conc, batch['mask'], config['max_time_steps'])\n",
    "                all_conc_metrics.append(conc_metrics)\n",
    "        \n",
    "        avg_conc_train_loss = total_conc_loss / len(train_loader)\n",
    "        avg_conc_val_loss = total_conc_val_loss / len(val_loader)\n",
    "        \n",
    "        # 计算平均指标\n",
    "        avg_conc_r2 = np.nanmean([m['r2'] for m in all_conc_metrics])\n",
    "        avg_conc_rmse = np.nanmean([m['rmse'] for m in all_conc_metrics])\n",
    "        \n",
    "        conc_scheduler.step()\n",
    "        current_lr = conc_scheduler.get_last_lr()[0]\n",
    "        \n",
    "        print(f\"浓度模型 Epoch {epoch+1:03d}/{config['num_epochs']} | \"\n",
    "              f\"训练损失: {avg_conc_train_loss:.4f} | 验证损失: {avg_conc_val_loss:.4f} | \"\n",
    "              f\"R2: {avg_conc_r2:.4f} | RMSE: {avg_conc_rmse:.4f} | LR: {current_lr:.6f}\")\n",
    "        \n",
    "        # 保存最佳浓度模型（基于验证损失）\n",
    "        if avg_conc_val_loss < best_conc_val_loss:\n",
    "            best_conc_val_loss = avg_conc_val_loss\n",
    "            torch.save({\n",
    "                'head_model_state_dict': head_model.state_dict(),\n",
    "                'conc_model_state_dict': conc_model.state_dict(),\n",
    "                'epoch': epoch,\n",
    "                'train_loss': avg_conc_train_loss,\n",
    "                'val_loss': avg_conc_val_loss,\n",
    "                'r2': avg_conc_r2,\n",
    "                'config': config,\n",
    "                'criterion': 'loss'\n",
    "            }, os.path.join(config['save_path'], 'best_conc_model_loss.pth'))\n",
    "        \n",
    "        # 保存最佳浓度模型（基于R2）\n",
    "        if avg_conc_r2 > best_conc_r2:\n",
    "            best_conc_r2 = avg_conc_r2\n",
    "            conc_early_stop_counter = 0\n",
    "            torch.save({\n",
    "                'head_model_state_dict': head_model.state_dict(),\n",
    "                'conc_model_state_dict': conc_model.state_dict(),\n",
    "                'epoch': epoch,\n",
    "                'train_loss': avg_conc_train_loss,\n",
    "                'val_loss': avg_conc_val_loss,\n",
    "                'r2': avg_conc_r2,\n",
    "                'config': config,\n",
    "                'criterion': 'r2'\n",
    "            }, os.path.join(config['save_path'], 'best_conc_model_r2.pth'))\n",
    "            print(f\"保存基于R2的最佳浓度模型，R2: {best_conc_r2:.4f}\")\n",
    "        else:\n",
    "            conc_early_stop_counter += 1\n",
    "        \n",
    "        # 早停检查\n",
    "        if conc_early_stop_counter >= config['patience']:\n",
    "            print(f\"浓度模型早停触发! 在第{epoch+1}个epoch停止训练\")\n",
    "            break\n",
    "    \n",
    "    print(f\"\\n🔹 浓度模型训练完成！\")\n",
    "    print(f\"最佳验证损失: {best_conc_val_loss:.4f}\")\n",
    "    print(f\"最佳R2: {best_conc_r2:.4f}\")\n",
    "    \n",
    "    return head_model, conc_model\n",
    "\n",
    "# 评估函数\n",
    "def evaluate_dual_cnn(data_loader, config):\n",
    "    \"\"\"评估训练好的双模型\"\"\"\n",
    "    \n",
    "    # 加载最佳模型\n",
    "    checkpoint = torch.load(os.path.join(config['save_path'], 'best_conc_model_r2.pth'))\n",
    "    \n",
    "    head_model = HeadCNN(input_dim=16, hidden_dim=config['hidden_dim']).to(device)\n",
    "    conc_model = ConcCNN(input_dim=19, hidden_dim=config['hidden_dim']).to(device)\n",
    "    \n",
    "    head_model.load_state_dict(checkpoint['head_model_state_dict'])\n",
    "    conc_model.load_state_dict(checkpoint['conc_model_state_dict'])\n",
    "    \n",
    "    head_model.eval()\n",
    "    conc_model.eval()\n",
    "    \n",
    "    all_head_metrics = []\n",
    "    all_conc_metrics = []\n",
    "    all_predictions = []\n",
    "    \n",
    "    print(\"开始模型评估...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(data_loader):\n",
    "            X_head = batch['X_head'].to(device)\n",
    "            X_conc_base = batch['X_conc_base'].to(device)\n",
    "            Y_head = batch['Y_head'].to(device)\n",
    "            Y_conc = batch['Y_conc'].to(device)\n",
    "            mask = batch['mask'].to(device)\n",
    "            model_names = batch['model_name']\n",
    "            \n",
    "            # 预测水头\n",
    "            pred_head = head_model(X_head)\n",
    "            \n",
    "            # 预测浓度\n",
    "            X_conc = torch.cat([X_conc_base, pred_head], dim=2)\n",
    "            pred_conc = conc_model(X_conc)\n",
    "            \n",
    "            # 计算指标\n",
    "            for i in range(len(model_names)):\n",
    "                head_metrics = compute_metrics(Y_head[i:i+1], pred_head[i:i+1], mask[i:i+1], config['max_time_steps'])\n",
    "                conc_metrics = compute_metrics(Y_conc[i:i+1], pred_conc[i:i+1], mask[i:i+1], config['max_time_steps'])\n",
    "                \n",
    "                all_head_metrics.append(head_metrics)\n",
    "                all_conc_metrics.append(conc_metrics)\n",
    "                \n",
    "                # 保存预测结果（简化版，仅保存关键指标）\n",
    "                all_predictions.append({\n",
    "                    'model_name': model_names[i],\n",
    "                    'head_r2': head_metrics['r2'],\n",
    "                    'head_rmse': head_metrics['rmse'],\n",
    "                    'conc_r2': conc_metrics['r2'],\n",
    "                    'conc_rmse': conc_metrics['rmse']\n",
    "                })\n",
    "    \n",
    "    # 计算平均指标\n",
    "    avg_head_metrics = {\n",
    "        'mse': np.nanmean([m['mse'] for m in all_head_metrics]),\n",
    "        'rmse': np.nanmean([m['rmse'] for m in all_head_metrics]),\n",
    "        'mae': np.nanmean([m['mae'] for m in all_head_metrics]),\n",
    "        'r2': np.nanmean([m['r2'] for m in all_head_metrics])\n",
    "    }\n",
    "    \n",
    "    avg_conc_metrics = {\n",
    "        'mse': np.nanmean([m['mse'] for m in all_conc_metrics]),\n",
    "        'rmse': np.nanmean([m['rmse'] for m in all_conc_metrics]),\n",
    "        'mae': np.nanmean([m['mae'] for m in all_conc_metrics]),\n",
    "        'r2': np.nanmean([m['r2'] for m in all_conc_metrics])\n",
    "    }\n",
    "    \n",
    "    # 输出结果\n",
    "    print(\"\\n📊 CNN模型验证结果:\")\n",
    "    print(\"\\n🔹 水头指标:\")\n",
    "    for k, v in avg_head_metrics.items():\n",
    "        print(f\"{k.upper():<5}: {v:.4f}\")\n",
    "    print(\"\\n🔹 浓度指标:\")\n",
    "    for k, v in avg_conc_metrics.items():\n",
    "        print(f\"{k.upper():<5}: {v:.4f}\")\n",
    "    \n",
    "    # 保存预测结果\n",
    "    predictions_df = pd.DataFrame(all_predictions)\n",
    "    predictions_df.to_csv(os.path.join(config['save_path'], 'val_predictions_cnn.csv'), index=False)\n",
    "    print(f\"\\n预测结果已保存到: {os.path.join(config['save_path'], 'val_predictions_cnn.csv')}\")\n",
    "    \n",
    "    return avg_head_metrics, avg_conc_metrics\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    # 加载数据\n",
    "    cleaned_data = pd.read_csv('conc_dual_guass.csv')\n",
    "    print(\"数据统计:\")\n",
    "    print(cleaned_data[['head', 'concentration']].describe())\n",
    "    \n",
    "    # 检查必要的列\n",
    "    required_cols = [\n",
    "        'row', 'col', 'time_step', 'x', 'y', 'top', 'bottom', 'K', 'recharge', 'ET',\n",
    "        'river_stage', 'river_cond', 'river_rbot', 'well_rate', 'well_mask',\n",
    "        'chd_mask', 'lytyp', 'conc_mask', 'head', 'concentration', 'model_name'\n",
    "    ]\n",
    "    \n",
    "    missing_cols = [col for col in required_cols if col not in cleaned_data.columns]\n",
    "    if missing_cols:\n",
    "        raise KeyError(f\"缺少必要的列: {missing_cols}\")\n",
    "    \n",
    "    # 数据集参数\n",
    "    M = cleaned_data['row'].max() + 1\n",
    "    N = cleaned_data['col'].max() + 1\n",
    "    T = cleaned_data['time_step'].max() + 1 - cleaned_data['time_step'].min()\n",
    "    \n",
    "    print(f\"网格大小: {M} x {N}, 时间步数: {T}\")\n",
    "    \n",
    "    # 数据划分 - 与GNN保持一致的7:3划分\n",
    "    unique_models = cleaned_data['model_name'].unique()\n",
    "    print(f\"总模型数: {len(unique_models)}\")\n",
    "    \n",
    "    # 7:3 划分训练集和验证集（与GNN保持一致）\n",
    "    train_models, val_models = train_test_split(unique_models, test_size=0.3, random_state=42)\n",
    "    \n",
    "    train_data = cleaned_data[cleaned_data['model_name'].isin(train_models)]\n",
    "    val_data = cleaned_data[cleaned_data['model_name'].isin(val_models)]\n",
    "    \n",
    "    print(f\"训练集: {len(train_models)} 个模型 ({len(train_models)/len(unique_models)*100:.1f}%)\")\n",
    "    print(f\"验证集: {len(val_models)} 个模型 ({len(val_models)/len(unique_models)*100:.1f}%)\")\n",
    "    \n",
    "    # 创建数据集\n",
    "    train_dataset = HydroCNNDataset(train_data, (M, N), T)\n",
    "    val_dataset = HydroCNNDataset(val_data, (M, N), T)\n",
    "    \n",
    "    # 检查数据集是否为空\n",
    "    if len(train_dataset) == 0 or len(val_dataset) == 0:\n",
    "        print(\"错误: 某个数据集为空！\")\n",
    "        print(f\"训练集大小: {len(train_dataset)}\")\n",
    "        print(f\"验证集大小: {len(val_dataset)}\")\n",
    "        exit(1)\n",
    "    \n",
    "    # 创建数据加载器\n",
    "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=custom_collate_fn)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=4, collate_fn=custom_collate_fn)\n",
    "    \n",
    "    # 训练配置 - 与GNN保持一致\n",
    "    config = {\n",
    "        'hidden_dim': 96,        # 与GNN保持一致\n",
    "        'num_epochs': 500,\n",
    "        'lr': 1e-3,              # 与GNN保持一致\n",
    "        'weight_decay': 1e-4,\n",
    "        'patience': 30,\n",
    "        'save_path': './saved_models/cnn_dual_sequential',\n",
    "        'max_time_steps': T\n",
    "    }\n",
    "    \n",
    "    print(\"开始训练CNN模型...\")\n",
    "    print(f\"配置: {config}\")\n",
    "    \n",
    "    # 训练模型\n",
    "    head_model, conc_model = train_dual_cnn(train_loader, val_loader, config)\n",
    "    \n",
    "    # 评估模型（使用验证集）\n",
    "    print(\"\\n开始最终评估（使用验证集）...\")\n",
    "    head_metrics, conc_metrics = evaluate_dual_cnn(val_loader, config)\n",
    "    \n",
    "    print(\"\\n🎉 CNN模型训练和评估完成！\")\n",
    "    print(\"\\n📊 最终结果总结:\")\n",
    "    print(f\"📈 水头模型 - R2: {head_metrics['r2']:.4f}, RMSE: {head_metrics['rmse']:.4f}\")\n",
    "    print(f\"📈 浓度模型 - R2: {conc_metrics['r2']:.4f}, RMSE: {conc_metrics['rmse']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1787c8db-624d-4c4a-94c0-4fbea2d45c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 开始训练水头模型...\n",
      "水头模型 Epoch 001/500 | 训练损失: 5373.6399 | 验证损失: 5198.3797 | R2: -267.7979 | RMSE: 93.7048 | LR: 0.001000\n",
      "保存最佳水头模型，验证损失: 5198.3797\n",
      "水头模型 Epoch 002/500 | 训练损失: 5109.2276 | 验证损失: 4989.8930 | R2: -257.0076 | RMSE: 91.8065 | LR: 0.001000\n",
      "保存最佳水头模型，验证损失: 4989.8930\n",
      "水头模型 Epoch 003/500 | 训练损失: 4909.7512 | 验证损失: 4798.4414 | R2: -247.0991 | RMSE: 90.0279 | LR: 0.001000\n",
      "保存最佳水头模型，验证损失: 4798.4414\n",
      "水头模型 Epoch 004/500 | 训练损失: 4721.7006 | 验证损失: 4615.4959 | R2: -237.6307 | RMSE: 88.2950 | LR: 0.001000\n",
      "保存最佳水头模型，验证损失: 4615.4959\n",
      "水头模型 Epoch 005/500 | 训练损失: 4536.7331 | 验证损失: 4431.2030 | R2: -228.0930 | RMSE: 86.5141 | LR: 0.001000\n",
      "保存最佳水头模型，验证损失: 4431.2030\n",
      "水头模型 Epoch 006/500 | 训练损失: 4364.7646 | 验证损失: 4265.3370 | R2: -219.5089 | RMSE: 84.8794 | LR: 0.001000\n",
      "保存最佳水头模型，验证损失: 4265.3370\n",
      "水头模型 Epoch 007/500 | 训练损失: 4201.4710 | 验证损失: 4099.9967 | R2: -210.9523 | RMSE: 83.2179 | LR: 0.001000\n",
      "保存最佳水头模型，验证损失: 4099.9967\n",
      "水头模型 Epoch 008/500 | 训练损失: 4035.5202 | 验证损失: 3932.0897 | R2: -202.2630 | RMSE: 81.4960 | LR: 0.000999\n",
      "保存最佳水头模型，验证损失: 3932.0897\n",
      "水头模型 Epoch 009/500 | 训练损失: 3870.3829 | 验证损失: 3776.9440 | R2: -194.2342 | RMSE: 79.8719 | LR: 0.000999\n",
      "保存最佳水头模型，验证损失: 3776.9440\n",
      "水头模型 Epoch 010/500 | 训练损失: 3714.0823 | 验证损失: 3626.9388 | R2: -186.4716 | RMSE: 78.2696 | LR: 0.000999\n",
      "保存最佳水头模型，验证损失: 3626.9388\n",
      "水头模型 Epoch 011/500 | 训练损失: 3569.8838 | 验证损失: 3481.5813 | R2: -178.9497 | RMSE: 76.6851 | LR: 0.000999\n",
      "保存最佳水头模型，验证损失: 3481.5813\n",
      "水头模型 Epoch 012/500 | 训练损失: 3424.6257 | 验证损失: 3340.3628 | R2: -171.6422 | RMSE: 75.1136 | LR: 0.000999\n",
      "保存最佳水头模型，验证损失: 3340.3628\n",
      "水头模型 Epoch 013/500 | 训练损失: 3285.2158 | 验证损失: 3202.9471 | R2: -164.5316 | RMSE: 73.5522 | LR: 0.000998\n",
      "保存最佳水头模型，验证损失: 3202.9471\n",
      "水头模型 Epoch 014/500 | 训练损失: 3150.9433 | 验证损失: 3069.1100 | R2: -157.6063 | RMSE: 71.9990 | LR: 0.000998\n",
      "保存最佳水头模型，验证损失: 3069.1100\n",
      "水头模型 Epoch 015/500 | 训练损失: 3015.3176 | 验证损失: 2938.6930 | R2: -150.8582 | RMSE: 70.4525 | LR: 0.000998\n",
      "保存最佳水头模型，验证损失: 2938.6930\n",
      "水头模型 Epoch 016/500 | 训练损失: 2883.9534 | 验证损失: 2811.5800 | R2: -144.2811 | RMSE: 68.9118 | LR: 0.000997\n",
      "保存最佳水头模型，验证损失: 2811.5800\n",
      "水头模型 Epoch 017/500 | 训练损失: 2765.5568 | 验证损失: 2687.6811 | R2: -137.8706 | RMSE: 67.3761 | LR: 0.000997\n",
      "保存最佳水头模型，验证损失: 2687.6811\n",
      "水头模型 Epoch 018/500 | 训练损失: 2638.7521 | 验证损失: 2566.9264 | R2: -131.6229 | RMSE: 65.8450 | LR: 0.000997\n",
      "保存最佳水头模型，验证损失: 2566.9264\n",
      "水头模型 Epoch 019/500 | 训练损失: 2514.7759 | 验证损失: 2449.2580 | R2: -125.5351 | RMSE: 64.3180 | LR: 0.000996\n",
      "保存最佳水头模型，验证损失: 2449.2580\n",
      "水头模型 Epoch 020/500 | 训练损失: 2403.5322 | 验证损失: 2334.6292 | R2: -119.6047 | RMSE: 62.7947 | LR: 0.000996\n",
      "保存最佳水头模型，验证损失: 2334.6292\n",
      "水头模型 Epoch 021/500 | 训练损失: 2289.9076 | 验证损失: 2223.0003 | R2: -113.8297 | RMSE: 61.2748 | LR: 0.000996\n",
      "保存最佳水头模型，验证损失: 2223.0003\n",
      "水头模型 Epoch 022/500 | 训练损失: 2181.4810 | 验证损失: 2114.3382 | R2: -108.2084 | RMSE: 59.7583 | LR: 0.000995\n",
      "保存最佳水头模型，验证损失: 2114.3382\n",
      "水头模型 Epoch 023/500 | 训练损失: 2071.0948 | 验证损失: 2008.5932 | R2: -102.7382 | RMSE: 58.2446 | LR: 0.000995\n",
      "保存最佳水头模型，验证损失: 2008.5932\n",
      "水头模型 Epoch 024/500 | 训练损失: 1963.4988 | 验证损失: 1896.8666 | R2: -96.9588 | RMSE: 56.6013 | LR: 0.000994\n",
      "保存最佳水头模型，验证损失: 1896.8666\n",
      "水头模型 Epoch 025/500 | 训练损失: 1853.3654 | 验证损失: 1793.4299 | R2: -91.6084 | RMSE: 55.0361 | LR: 0.000994\n",
      "保存最佳水头模型，验证损失: 1793.4299\n",
      "水头模型 Epoch 026/500 | 训练损失: 1757.1387 | 验证损失: 1693.7267 | R2: -86.4513 | RMSE: 53.4842 | LR: 0.000993\n",
      "保存最佳水头模型，验证损失: 1693.7267\n",
      "水头模型 Epoch 027/500 | 训练损失: 1654.8303 | 验证损失: 1597.5254 | R2: -81.4756 | RMSE: 51.9428 | LR: 0.000993\n",
      "保存最佳水头模型，验证损失: 1597.5254\n",
      "水头模型 Epoch 028/500 | 训练损失: 1558.1929 | 验证损失: 1504.6002 | R2: -76.6696 | RMSE: 50.4092 | LR: 0.000992\n",
      "保存最佳水头模型，验证损失: 1504.6002\n",
      "水头模型 Epoch 029/500 | 训练损失: 1469.8526 | 验证损失: 1414.8141 | R2: -72.0262 | RMSE: 48.8817 | LR: 0.000992\n",
      "保存最佳水头模型，验证损失: 1414.8141\n",
      "水头模型 Epoch 030/500 | 训练损失: 1382.3527 | 验证损失: 1328.0815 | R2: -67.5409 | RMSE: 47.3593 | LR: 0.000991\n",
      "保存最佳水头模型，验证损失: 1328.0815\n",
      "水头模型 Epoch 031/500 | 训练损失: 1296.1056 | 验证损失: 1244.3435 | R2: -63.2108 | RMSE: 45.8417 | LR: 0.000991\n",
      "保存最佳水头模型，验证损失: 1244.3435\n",
      "水头模型 Epoch 032/500 | 训练损失: 1211.5636 | 验证损失: 1163.5573 | R2: -59.0335 | RMSE: 44.3282 | LR: 0.000990\n",
      "保存最佳水头模型，验证损失: 1163.5573\n",
      "水头模型 Epoch 033/500 | 训练损失: 1135.6175 | 验证损失: 1085.6895 | R2: -55.0074 | RMSE: 42.8189 | LR: 0.000989\n",
      "保存最佳水头模型，验证损失: 1085.6895\n",
      "水头模型 Epoch 034/500 | 训练损失: 1056.7475 | 验证损失: 1010.7137 | R2: -51.1311 | RMSE: 41.3135 | LR: 0.000989\n",
      "保存最佳水头模型，验证损失: 1010.7137\n",
      "水头模型 Epoch 035/500 | 训练损失: 980.3409 | 验证损失: 938.6073 | R2: -47.4034 | RMSE: 39.8121 | LR: 0.000988\n",
      "保存最佳水头模型，验证损失: 938.6073\n",
      "水头模型 Epoch 036/500 | 训练损失: 913.7539 | 验证损失: 869.3512 | R2: -43.8234 | RMSE: 38.3147 | LR: 0.000987\n",
      "保存最佳水头模型，验证损失: 869.3512\n",
      "水头模型 Epoch 037/500 | 训练损失: 842.6155 | 验证损失: 802.9284 | R2: -40.3901 | RMSE: 36.8213 | LR: 0.000987\n",
      "保存最佳水头模型，验证损失: 802.9284\n",
      "水头模型 Epoch 038/500 | 训练损失: 778.0720 | 验证损失: 739.3230 | R2: -37.1027 | RMSE: 35.3322 | LR: 0.000986\n",
      "保存最佳水头模型，验证损失: 739.3230\n",
      "水头模型 Epoch 039/500 | 训练损失: 716.4286 | 验证损失: 678.5212 | R2: -33.9606 | RMSE: 33.8476 | LR: 0.000985\n",
      "保存最佳水头模型，验证损失: 678.5212\n",
      "水头模型 Epoch 040/500 | 训练损失: 656.6140 | 验证损失: 620.5102 | R2: -30.9631 | RMSE: 32.3676 | LR: 0.000984\n",
      "保存最佳水头模型，验证损失: 620.5102\n",
      "水头模型 Epoch 041/500 | 训练损失: 600.0453 | 验证损失: 565.2772 | R2: -28.1094 | RMSE: 30.8928 | LR: 0.000984\n",
      "保存最佳水头模型，验证损失: 565.2772\n",
      "水头模型 Epoch 042/500 | 训练损失: 546.2514 | 验证损失: 512.8098 | R2: -25.3990 | RMSE: 29.4233 | LR: 0.000983\n",
      "保存最佳水头模型，验证损失: 512.8098\n",
      "水头模型 Epoch 043/500 | 训练损失: 493.2916 | 验证损失: 463.0973 | R2: -22.8313 | RMSE: 27.9599 | LR: 0.000982\n",
      "保存最佳水头模型，验证损失: 463.0973\n",
      "水头模型 Epoch 044/500 | 训练损失: 445.2068 | 验证损失: 416.1278 | R2: -20.4056 | RMSE: 26.5030 | LR: 0.000981\n",
      "保存最佳水头模型，验证损失: 416.1278\n",
      "水头模型 Epoch 045/500 | 训练损失: 398.6940 | 验证损失: 371.8916 | R2: -18.1216 | RMSE: 25.0536 | LR: 0.000980\n",
      "保存最佳水头模型，验证损失: 371.8916\n",
      "水头模型 Epoch 046/500 | 训练损失: 357.3240 | 验证损失: 330.3779 | R2: -15.9786 | RMSE: 23.6126 | LR: 0.000979\n",
      "保存最佳水头模型，验证损失: 330.3779\n",
      "水头模型 Epoch 047/500 | 训练损失: 316.1899 | 验证损失: 291.5766 | R2: -13.9760 | RMSE: 22.1813 | LR: 0.000978\n",
      "保存最佳水头模型，验证损失: 291.5766\n",
      "水头模型 Epoch 048/500 | 训练损失: 279.0174 | 验证损失: 255.4775 | R2: -12.1135 | RMSE: 20.7612 | LR: 0.000977\n",
      "保存最佳水头模型，验证损失: 255.4775\n",
      "水头模型 Epoch 049/500 | 训练损失: 242.8344 | 验证损失: 222.0708 | R2: -10.3904 | RMSE: 19.3544 | LR: 0.000976\n",
      "保存最佳水头模型，验证损失: 222.0708\n",
      "水头模型 Epoch 050/500 | 训练损失: 211.0411 | 验证损失: 191.3469 | R2: -8.8063 | RMSE: 17.9636 | LR: 0.000976\n",
      "保存最佳水头模型，验证损失: 191.3469\n",
      "水头模型 Epoch 051/500 | 训练损失: 181.1283 | 验证损失: 163.2956 | R2: -7.3606 | RMSE: 16.5923 | LR: 0.000975\n",
      "保存最佳水头模型，验证损失: 163.2956\n",
      "水头模型 Epoch 052/500 | 训练损失: 153.7791 | 验证损失: 137.9072 | R2: -6.0528 | RMSE: 15.2452 | LR: 0.000974\n",
      "保存最佳水头模型，验证损失: 137.9072\n",
      "水头模型 Epoch 053/500 | 训练损失: 129.3940 | 验证损失: 115.1720 | R2: -4.8825 | RMSE: 13.9288 | LR: 0.000973\n",
      "保存最佳水头模型，验证损失: 115.1720\n",
      "水头模型 Epoch 054/500 | 训练损失: 109.1520 | 验证损失: 95.0798 | R2: -3.8491 | RMSE: 12.6520 | LR: 0.000971\n",
      "保存最佳水头模型，验证损失: 95.0798\n",
      "水头模型 Epoch 055/500 | 训练损失: 89.3079 | 验证损失: 77.6211 | R2: -2.9520 | RMSE: 11.4275 | LR: 0.000970\n",
      "保存最佳水头模型，验证损失: 77.6211\n",
      "水头模型 Epoch 056/500 | 训练损失: 72.2869 | 验证损失: 62.7855 | R2: -2.1909 | RMSE: 10.2734 | LR: 0.000969\n",
      "保存最佳水头模型，验证损失: 62.7855\n",
      "水头模型 Epoch 057/500 | 训练损失: 58.7897 | 验证损失: 50.5633 | R2: -1.5651 | RMSE: 9.2153 | LR: 0.000968\n",
      "保存最佳水头模型，验证损失: 50.5633\n",
      "水头模型 Epoch 058/500 | 训练损失: 48.2436 | 验证损失: 40.9443 | R2: -1.0742 | RMSE: 8.2895 | LR: 0.000967\n",
      "保存最佳水头模型，验证损失: 40.9443\n",
      "水头模型 Epoch 059/500 | 训练损失: 39.0726 | 验证损失: 33.9184 | R2: -0.7176 | RMSE: 7.5442 | LR: 0.000966\n",
      "保存最佳水头模型，验证损失: 33.9184\n",
      "水头模型 Epoch 060/500 | 训练损失: 33.1159 | 验证损失: 29.4752 | R2: -0.4948 | RMSE: 7.0356 | LR: 0.000965\n",
      "保存最佳水头模型，验证损失: 29.4752\n",
      "水头模型 Epoch 061/500 | 训练损失: 29.8818 | 验证损失: 27.3242 | R2: -0.3892 | RMSE: 6.7783 | LR: 0.000964\n",
      "保存最佳水头模型，验证损失: 27.3242\n",
      "水头模型 Epoch 062/500 | 训练损失: 33.6362 | 验证损失: 28.5353 | R2: -0.4451 | RMSE: 6.9200 | LR: 0.000963\n",
      "水头模型 Epoch 063/500 | 训练损失: 29.6410 | 验证损失: 26.4032 | R2: -0.3368 | RMSE: 6.6560 | LR: 0.000961\n",
      "保存最佳水头模型，验证损失: 26.4032\n",
      "水头模型 Epoch 064/500 | 训练损失: 31.9787 | 验证损失: 23.3279 | R2: -0.1784 | RMSE: 6.2523 | LR: 0.000960\n",
      "保存最佳水头模型，验证损失: 23.3279\n",
      "水头模型 Epoch 065/500 | 训练损失: 25.5218 | 验证损失: 24.1073 | R2: -0.2211 | RMSE: 6.3606 | LR: 0.000959\n",
      "水头模型 Epoch 066/500 | 训练损失: 22.4116 | 验证损失: 18.8879 | R2: 0.0473 | RMSE: 5.6232 | LR: 0.000958\n",
      "保存最佳水头模型，验证损失: 18.8879\n",
      "水头模型 Epoch 067/500 | 训练损失: 18.4616 | 验证损失: 17.0143 | R2: 0.1385 | RMSE: 5.3429 | LR: 0.000956\n",
      "保存最佳水头模型，验证损失: 17.0143\n",
      "水头模型 Epoch 068/500 | 训练损失: 18.8469 | 验证损失: 17.3988 | R2: 0.1125 | RMSE: 5.4127 | LR: 0.000955\n",
      "水头模型 Epoch 069/500 | 训练损失: 15.5539 | 验证损失: 13.3406 | R2: 0.3258 | RMSE: 4.7285 | LR: 0.000954\n",
      "保存最佳水头模型，验证损失: 13.3406\n",
      "水头模型 Epoch 070/500 | 训练损失: 13.8058 | 验证损失: 12.4391 | R2: 0.3712 | RMSE: 4.5663 | LR: 0.000952\n",
      "保存最佳水头模型，验证损失: 12.4391\n",
      "水头模型 Epoch 071/500 | 训练损失: 13.1074 | 验证损失: 12.1807 | R2: 0.3838 | RMSE: 4.5197 | LR: 0.000951\n",
      "保存最佳水头模型，验证损失: 12.1807\n",
      "水头模型 Epoch 072/500 | 训练损失: 13.0479 | 验证损失: 12.9029 | R2: 0.3458 | RMSE: 4.6548 | LR: 0.000950\n",
      "水头模型 Epoch 073/500 | 训练损失: 13.0537 | 验证损失: 11.2409 | R2: 0.4313 | RMSE: 4.3419 | LR: 0.000948\n",
      "保存最佳水头模型，验证损失: 11.2409\n",
      "水头模型 Epoch 074/500 | 训练损失: 12.1854 | 验证损失: 11.2763 | R2: 0.4307 | RMSE: 4.3461 | LR: 0.000947\n",
      "水头模型 Epoch 075/500 | 训练损失: 11.8315 | 验证损失: 11.0025 | R2: 0.4437 | RMSE: 4.2947 | LR: 0.000946\n",
      "保存最佳水头模型，验证损失: 11.0025\n",
      "水头模型 Epoch 076/500 | 训练损失: 11.3731 | 验证损失: 11.1335 | R2: 0.4357 | RMSE: 4.3231 | LR: 0.000944\n",
      "水头模型 Epoch 077/500 | 训练损失: 11.1615 | 验证损失: 10.1800 | R2: 0.4853 | RMSE: 4.1312 | LR: 0.000943\n",
      "保存最佳水头模型，验证损失: 10.1800\n",
      "水头模型 Epoch 078/500 | 训练损失: 10.9384 | 验证损失: 10.0988 | R2: 0.4892 | RMSE: 4.1151 | LR: 0.000941\n",
      "保存最佳水头模型，验证损失: 10.0988\n",
      "水头模型 Epoch 079/500 | 训练损失: 10.3894 | 验证损失: 9.6197 | R2: 0.5146 | RMSE: 4.0135 | LR: 0.000940\n",
      "保存最佳水头模型，验证损失: 9.6197\n",
      "水头模型 Epoch 080/500 | 训练损失: 10.0901 | 验证损失: 9.2274 | R2: 0.5349 | RMSE: 3.9293 | LR: 0.000938\n",
      "保存最佳水头模型，验证损失: 9.2274\n",
      "水头模型 Epoch 081/500 | 训练损失: 9.6855 | 验证损失: 8.8137 | R2: 0.5558 | RMSE: 3.8400 | LR: 0.000937\n",
      "保存最佳水头模型，验证损失: 8.8137\n",
      "水头模型 Epoch 082/500 | 训练损失: 9.4039 | 验证损失: 9.0460 | R2: 0.5437 | RMSE: 3.8915 | LR: 0.000935\n",
      "水头模型 Epoch 083/500 | 训练损失: 9.3562 | 验证损失: 8.7903 | R2: 0.5564 | RMSE: 3.8365 | LR: 0.000934\n",
      "保存最佳水头模型，验证损失: 8.7903\n",
      "水头模型 Epoch 084/500 | 训练损失: 9.2058 | 验证损失: 8.3361 | R2: 0.5793 | RMSE: 3.7361 | LR: 0.000932\n",
      "保存最佳水头模型，验证损失: 8.3361\n",
      "水头模型 Epoch 085/500 | 训练损失: 8.9858 | 验证损失: 8.8708 | R2: 0.5500 | RMSE: 3.8597 | LR: 0.000930\n",
      "水头模型 Epoch 086/500 | 训练损失: 8.8071 | 验证损失: 8.0224 | R2: 0.5946 | RMSE: 3.6666 | LR: 0.000929\n",
      "保存最佳水头模型，验证损失: 8.0224\n",
      "水头模型 Epoch 087/500 | 训练损失: 8.6551 | 验证损失: 8.3355 | R2: 0.5775 | RMSE: 3.7407 | LR: 0.000927\n",
      "水头模型 Epoch 088/500 | 训练损失: 8.3853 | 验证损失: 7.6698 | R2: 0.6124 | RMSE: 3.5851 | LR: 0.000925\n",
      "保存最佳水头模型，验证损失: 7.6698\n",
      "水头模型 Epoch 089/500 | 训练损失: 8.3841 | 验证损失: 7.7347 | R2: 0.6085 | RMSE: 3.6021 | LR: 0.000924\n",
      "水头模型 Epoch 090/500 | 训练损失: 8.3300 | 验证损失: 7.7087 | R2: 0.6092 | RMSE: 3.5976 | LR: 0.000922\n",
      "水头模型 Epoch 091/500 | 训练损失: 8.1747 | 验证损失: 7.5145 | R2: 0.6206 | RMSE: 3.5477 | LR: 0.000920\n",
      "保存最佳水头模型，验证损失: 7.5145\n",
      "水头模型 Epoch 092/500 | 训练损失: 8.0079 | 验证损失: 7.5711 | R2: 0.6166 | RMSE: 3.5641 | LR: 0.000919\n",
      "水头模型 Epoch 093/500 | 训练损失: 7.9339 | 验证损失: 8.1376 | R2: 0.5863 | RMSE: 3.6988 | LR: 0.000917\n",
      "水头模型 Epoch 094/500 | 训练损失: 7.6725 | 验证损失: 7.0094 | R2: 0.6446 | RMSE: 3.4305 | LR: 0.000915\n",
      "保存最佳水头模型，验证损失: 7.0094\n",
      "水头模型 Epoch 095/500 | 训练损失: 7.6745 | 验证损失: 7.1628 | R2: 0.6373 | RMSE: 3.4668 | LR: 0.000914\n",
      "水头模型 Epoch 096/500 | 训练损失: 7.4147 | 验证损失: 6.8198 | R2: 0.6546 | RMSE: 3.3827 | LR: 0.000912\n",
      "保存最佳水头模型，验证损失: 6.8198\n",
      "水头模型 Epoch 097/500 | 训练损失: 7.5614 | 验证损失: 7.2680 | R2: 0.6314 | RMSE: 3.4935 | LR: 0.000910\n",
      "水头模型 Epoch 098/500 | 训练损失: 7.5158 | 验证损失: 6.8995 | R2: 0.6511 | RMSE: 3.4010 | LR: 0.000908\n",
      "水头模型 Epoch 099/500 | 训练损失: 7.3438 | 验证损失: 7.0048 | R2: 0.6448 | RMSE: 3.4295 | LR: 0.000906\n",
      "水头模型 Epoch 100/500 | 训练损失: 6.9244 | 验证损失: 6.4841 | R2: 0.6728 | RMSE: 3.2949 | LR: 0.000905\n",
      "保存最佳水头模型，验证损失: 6.4841\n",
      "水头模型 Epoch 101/500 | 训练损失: 6.8202 | 验证损失: 6.5676 | R2: 0.6682 | RMSE: 3.3173 | LR: 0.000903\n",
      "水头模型 Epoch 102/500 | 训练损失: 6.7369 | 验证损失: 6.5392 | R2: 0.6699 | RMSE: 3.3093 | LR: 0.000901\n",
      "水头模型 Epoch 103/500 | 训练损失: 6.4497 | 验证损失: 5.7686 | R2: 0.7089 | RMSE: 3.1078 | LR: 0.000899\n",
      "保存最佳水头模型，验证损失: 5.7686\n",
      "水头模型 Epoch 104/500 | 训练损失: 6.4764 | 验证损失: 5.5319 | R2: 0.7215 | RMSE: 3.0411 | LR: 0.000897\n",
      "保存最佳水头模型，验证损失: 5.5319\n",
      "水头模型 Epoch 105/500 | 训练损失: 6.2261 | 验证损失: 6.2391 | R2: 0.6833 | RMSE: 3.2373 | LR: 0.000895\n",
      "水头模型 Epoch 106/500 | 训练损失: 6.1691 | 验证损失: 5.4351 | R2: 0.7257 | RMSE: 3.0167 | LR: 0.000893\n",
      "保存最佳水头模型，验证损失: 5.4351\n",
      "水头模型 Epoch 107/500 | 训练损失: 5.9281 | 验证损失: 5.7605 | R2: 0.7089 | RMSE: 3.1069 | LR: 0.000891\n",
      "水头模型 Epoch 108/500 | 训练损失: 5.8193 | 验证损失: 5.3775 | R2: 0.7273 | RMSE: 3.0049 | LR: 0.000889\n",
      "保存最佳水头模型，验证损失: 5.3775\n",
      "水头模型 Epoch 109/500 | 训练损失: 5.5374 | 验证损失: 5.0174 | R2: 0.7470 | RMSE: 2.8977 | LR: 0.000887\n",
      "保存最佳水头模型，验证损失: 5.0174\n",
      "水头模型 Epoch 110/500 | 训练损失: 5.7087 | 验证损失: 5.1519 | R2: 0.7391 | RMSE: 2.9399 | LR: 0.000885\n",
      "水头模型 Epoch 111/500 | 训练损失: 5.4629 | 验证损失: 5.0165 | R2: 0.7464 | RMSE: 2.8998 | LR: 0.000883\n",
      "保存最佳水头模型，验证损失: 5.0165\n",
      "水头模型 Epoch 112/500 | 训练损失: 5.2138 | 验证损失: 5.1021 | R2: 0.7425 | RMSE: 2.9226 | LR: 0.000881\n",
      "水头模型 Epoch 113/500 | 训练损失: 5.1763 | 验证损失: 4.6423 | R2: 0.7649 | RMSE: 2.7909 | LR: 0.000879\n",
      "保存最佳水头模型，验证损失: 4.6423\n",
      "水头模型 Epoch 114/500 | 训练损失: 5.0404 | 验证损失: 4.5384 | R2: 0.7699 | RMSE: 2.7603 | LR: 0.000877\n",
      "保存最佳水头模型，验证损失: 4.5384\n",
      "水头模型 Epoch 115/500 | 训练损失: 4.9481 | 验证损失: 4.5454 | R2: 0.7704 | RMSE: 2.7594 | LR: 0.000875\n",
      "水头模型 Epoch 116/500 | 训练损失: 4.9902 | 验证损失: 4.4610 | R2: 0.7748 | RMSE: 2.7330 | LR: 0.000873\n",
      "保存最佳水头模型，验证损失: 4.4610\n",
      "水头模型 Epoch 117/500 | 训练损失: 4.9234 | 验证损失: 4.5722 | R2: 0.7680 | RMSE: 2.7711 | LR: 0.000871\n",
      "水头模型 Epoch 118/500 | 训练损失: 4.6936 | 验证损失: 4.4830 | R2: 0.7726 | RMSE: 2.7437 | LR: 0.000869\n",
      "水头模型 Epoch 119/500 | 训练损失: 4.6561 | 验证损失: 4.1606 | R2: 0.7896 | RMSE: 2.6410 | LR: 0.000867\n",
      "保存最佳水头模型，验证损失: 4.1606\n",
      "水头模型 Epoch 120/500 | 训练损失: 4.5188 | 验证损失: 4.5876 | R2: 0.7669 | RMSE: 2.7765 | LR: 0.000864\n",
      "水头模型 Epoch 121/500 | 训练损失: 4.6314 | 验证损失: 4.3479 | R2: 0.7794 | RMSE: 2.7021 | LR: 0.000862\n",
      "水头模型 Epoch 122/500 | 训练损失: 4.9118 | 验证损失: 3.9586 | R2: 0.7999 | RMSE: 2.5757 | LR: 0.000860\n",
      "保存最佳水头模型，验证损失: 3.9586\n",
      "水头模型 Epoch 123/500 | 训练损失: 4.4816 | 验证损失: 4.2692 | R2: 0.7827 | RMSE: 2.6796 | LR: 0.000858\n",
      "水头模型 Epoch 124/500 | 训练损失: 4.2141 | 验证损失: 4.6554 | R2: 0.7629 | RMSE: 2.7987 | LR: 0.000856\n",
      "水头模型 Epoch 125/500 | 训练损失: 4.2793 | 验证损失: 3.7355 | R2: 0.8104 | RMSE: 2.5049 | LR: 0.000854\n",
      "保存最佳水头模型，验证损失: 3.7355\n",
      "水头模型 Epoch 126/500 | 训练损失: 3.9293 | 验证损失: 3.6359 | R2: 0.8159 | RMSE: 2.4697 | LR: 0.000851\n",
      "保存最佳水头模型，验证损失: 3.6359\n",
      "水头模型 Epoch 127/500 | 训练损失: 3.9878 | 验证损失: 3.8023 | R2: 0.8063 | RMSE: 2.5294 | LR: 0.000849\n",
      "水头模型 Epoch 128/500 | 训练损失: 3.7684 | 验证损失: 3.7894 | R2: 0.8082 | RMSE: 2.5210 | LR: 0.000847\n",
      "水头模型 Epoch 129/500 | 训练损失: 3.8742 | 验证损失: 3.4736 | R2: 0.8246 | RMSE: 2.4119 | LR: 0.000845\n",
      "保存最佳水头模型，验证损失: 3.4736\n",
      "水头模型 Epoch 130/500 | 训练损失: 3.6755 | 验证损失: 3.3424 | R2: 0.8309 | RMSE: 2.3670 | LR: 0.000842\n",
      "保存最佳水头模型，验证损失: 3.3424\n",
      "水头模型 Epoch 131/500 | 训练损失: 3.9146 | 验证损失: 3.5469 | R2: 0.8205 | RMSE: 2.4389 | LR: 0.000840\n",
      "水头模型 Epoch 132/500 | 训练损失: 4.0318 | 验证损失: 3.3248 | R2: 0.8311 | RMSE: 2.3636 | LR: 0.000838\n",
      "保存最佳水头模型，验证损失: 3.3248\n",
      "水头模型 Epoch 133/500 | 训练损失: 3.5600 | 验证损失: 3.3013 | R2: 0.8326 | RMSE: 2.3540 | LR: 0.000835\n",
      "保存最佳水头模型，验证损失: 3.3013\n",
      "水头模型 Epoch 134/500 | 训练损失: 3.8704 | 验证损失: 4.8528 | R2: 0.7505 | RMSE: 2.8618 | LR: 0.000833\n",
      "水头模型 Epoch 135/500 | 训练损失: 3.7145 | 验证损失: 3.1504 | R2: 0.8402 | RMSE: 2.2997 | LR: 0.000831\n",
      "保存最佳水头模型，验证损失: 3.1504\n",
      "水头模型 Epoch 136/500 | 训练损失: 3.3362 | 验证损失: 3.0059 | R2: 0.8475 | RMSE: 2.2464 | LR: 0.000828\n",
      "保存最佳水头模型，验证损失: 3.0059\n",
      "水头模型 Epoch 137/500 | 训练损失: 3.3681 | 验证损失: 2.9973 | R2: 0.8478 | RMSE: 2.2436 | LR: 0.000826\n",
      "保存最佳水头模型，验证损失: 2.9973\n",
      "水头模型 Epoch 138/500 | 训练损失: 3.2523 | 验证损失: 2.9535 | R2: 0.8500 | RMSE: 2.2275 | LR: 0.000824\n",
      "保存最佳水头模型，验证损失: 2.9535\n",
      "水头模型 Epoch 139/500 | 训练损失: 3.2285 | 验证损失: 2.9637 | R2: 0.8498 | RMSE: 2.2300 | LR: 0.000821\n",
      "水头模型 Epoch 140/500 | 训练损失: 3.2248 | 验证损失: 2.9690 | R2: 0.8489 | RMSE: 2.2342 | LR: 0.000819\n",
      "水头模型 Epoch 141/500 | 训练损失: 3.1321 | 验证损失: 2.7784 | R2: 0.8588 | RMSE: 2.1606 | LR: 0.000816\n",
      "保存最佳水头模型，验证损失: 2.7784\n",
      "水头模型 Epoch 142/500 | 训练损失: 3.0458 | 验证损失: 2.7594 | R2: 0.8599 | RMSE: 2.1530 | LR: 0.000814\n",
      "保存最佳水头模型，验证损失: 2.7594\n",
      "水头模型 Epoch 143/500 | 训练损失: 2.9148 | 验证损失: 2.6978 | R2: 0.8629 | RMSE: 2.1291 | LR: 0.000811\n",
      "保存最佳水头模型，验证损失: 2.6978\n",
      "水头模型 Epoch 144/500 | 训练损失: 2.8838 | 验证损失: 2.6714 | R2: 0.8644 | RMSE: 2.1179 | LR: 0.000809\n",
      "保存最佳水头模型，验证损失: 2.6714\n",
      "水头模型 Epoch 145/500 | 训练损失: 2.7456 | 验证损失: 2.5010 | R2: 0.8727 | RMSE: 2.0508 | LR: 0.000806\n",
      "保存最佳水头模型，验证损失: 2.5010\n",
      "水头模型 Epoch 146/500 | 训练损失: 2.6962 | 验证损失: 2.3490 | R2: 0.8806 | RMSE: 1.9866 | LR: 0.000804\n",
      "保存最佳水头模型，验证损失: 2.3490\n",
      "水头模型 Epoch 147/500 | 训练损失: 2.6295 | 验证损失: 2.5916 | R2: 0.8681 | RMSE: 2.0875 | LR: 0.000801\n",
      "水头模型 Epoch 148/500 | 训练损失: 2.8164 | 验证损失: 2.6748 | R2: 0.8631 | RMSE: 2.1231 | LR: 0.000799\n",
      "水头模型 Epoch 149/500 | 训练损失: 2.5157 | 验证损失: 2.1999 | R2: 0.8880 | RMSE: 1.9232 | LR: 0.000796\n",
      "保存最佳水头模型，验证损失: 2.1999\n",
      "水头模型 Epoch 150/500 | 训练损失: 2.6109 | 验证损失: 2.6996 | R2: 0.8622 | RMSE: 2.1320 | LR: 0.000794\n",
      "水头模型 Epoch 151/500 | 训练损失: 2.6791 | 验证损失: 2.4029 | R2: 0.8771 | RMSE: 2.0119 | LR: 0.000791\n",
      "水头模型 Epoch 152/500 | 训练损失: 3.3090 | 验证损失: 2.6407 | R2: 0.8657 | RMSE: 2.1068 | LR: 0.000789\n",
      "水头模型 Epoch 153/500 | 训练损失: 2.4756 | 验证损失: 2.1761 | R2: 0.8890 | RMSE: 1.9135 | LR: 0.000786\n",
      "保存最佳水头模型，验证损失: 2.1761\n",
      "水头模型 Epoch 154/500 | 训练损失: 2.3849 | 验证损失: 2.0598 | R2: 0.8951 | RMSE: 1.8611 | LR: 0.000784\n",
      "保存最佳水头模型，验证损失: 2.0598\n",
      "水头模型 Epoch 155/500 | 训练损失: 2.4585 | 验证损失: 2.4537 | R2: 0.8742 | RMSE: 2.0338 | LR: 0.000781\n",
      "水头模型 Epoch 156/500 | 训练损失: 2.4378 | 验证损失: 2.0030 | R2: 0.8982 | RMSE: 1.8346 | LR: 0.000778\n",
      "保存最佳水头模型，验证损失: 2.0030\n",
      "水头模型 Epoch 157/500 | 训练损失: 2.3802 | 验证损失: 2.5386 | R2: 0.8705 | RMSE: 2.0669 | LR: 0.000776\n",
      "水头模型 Epoch 158/500 | 训练损失: 2.4035 | 验证损失: 2.0815 | R2: 0.8942 | RMSE: 1.8703 | LR: 0.000773\n",
      "水头模型 Epoch 159/500 | 训练损失: 2.3647 | 验证损失: 2.5846 | R2: 0.8674 | RMSE: 2.0878 | LR: 0.000771\n",
      "水头模型 Epoch 160/500 | 训练损失: 2.3793 | 验证损失: 1.9992 | R2: 0.8981 | RMSE: 1.8340 | LR: 0.000768\n",
      "保存最佳水头模型，验证损失: 1.9992\n",
      "水头模型 Epoch 161/500 | 训练损失: 2.2996 | 验证损失: 2.3101 | R2: 0.8824 | RMSE: 1.9711 | LR: 0.000765\n",
      "水头模型 Epoch 162/500 | 训练损失: 2.3258 | 验证损失: 2.0283 | R2: 0.8968 | RMSE: 1.8464 | LR: 0.000763\n",
      "水头模型 Epoch 163/500 | 训练损失: 2.2943 | 验证损失: 2.0843 | R2: 0.8935 | RMSE: 1.8735 | LR: 0.000760\n",
      "水头模型 Epoch 164/500 | 训练损失: 2.3215 | 验证损失: 1.8941 | R2: 0.9035 | RMSE: 1.7850 | LR: 0.000757\n",
      "保存最佳水头模型，验证损失: 1.8941\n",
      "水头模型 Epoch 165/500 | 训练损失: 2.2735 | 验证损失: 2.3407 | R2: 0.8806 | RMSE: 1.9848 | LR: 0.000755\n",
      "水头模型 Epoch 166/500 | 训练损失: 2.3186 | 验证损失: 2.0407 | R2: 0.8961 | RMSE: 1.8523 | LR: 0.000752\n",
      "水头模型 Epoch 167/500 | 训练损失: 2.2496 | 验证损失: 2.0751 | R2: 0.8939 | RMSE: 1.8696 | LR: 0.000749\n",
      "水头模型 Epoch 168/500 | 训练损失: 2.1949 | 验证损失: 1.8470 | R2: 0.9059 | RMSE: 1.7626 | LR: 0.000746\n",
      "保存最佳水头模型，验证损失: 1.8470\n",
      "水头模型 Epoch 169/500 | 训练损失: 2.1575 | 验证损失: 2.2576 | R2: 0.8848 | RMSE: 1.9496 | LR: 0.000744\n",
      "水头模型 Epoch 170/500 | 训练损失: 2.1731 | 验证损失: 1.8525 | R2: 0.9057 | RMSE: 1.7648 | LR: 0.000741\n",
      "水头模型 Epoch 171/500 | 训练损失: 2.1391 | 验证损失: 1.9562 | R2: 0.9000 | RMSE: 1.8152 | LR: 0.000738\n",
      "水头模型 Epoch 172/500 | 训练损失: 2.1554 | 验证损失: 1.7684 | R2: 0.9099 | RMSE: 1.7247 | LR: 0.000735\n",
      "保存最佳水头模型，验证损失: 1.7684\n",
      "水头模型 Epoch 173/500 | 训练损失: 2.1398 | 验证损失: 2.0290 | R2: 0.8965 | RMSE: 1.8477 | LR: 0.000733\n",
      "水头模型 Epoch 174/500 | 训练损失: 2.1045 | 验证损失: 1.7273 | R2: 0.9120 | RMSE: 1.7042 | LR: 0.000730\n",
      "保存最佳水头模型，验证损失: 1.7273\n",
      "水头模型 Epoch 175/500 | 训练损失: 2.0534 | 验证损失: 2.0522 | R2: 0.8948 | RMSE: 1.8599 | LR: 0.000727\n",
      "水头模型 Epoch 176/500 | 训练损失: 2.0458 | 验证损失: 1.7091 | R2: 0.9128 | RMSE: 1.6958 | LR: 0.000724\n",
      "保存最佳水头模型，验证损失: 1.7091\n",
      "水头模型 Epoch 177/500 | 训练损失: 2.0141 | 验证损失: 2.2297 | R2: 0.8861 | RMSE: 1.9377 | LR: 0.000721\n",
      "水头模型 Epoch 178/500 | 训练损失: 2.0844 | 验证损失: 1.9400 | R2: 0.9011 | RMSE: 1.8066 | LR: 0.000719\n",
      "水头模型 Epoch 179/500 | 训练损失: 1.9562 | 验证损失: 1.9749 | R2: 0.8988 | RMSE: 1.8245 | LR: 0.000716\n",
      "水头模型 Epoch 180/500 | 训练损失: 2.1325 | 验证损失: 2.3043 | R2: 0.8822 | RMSE: 1.9701 | LR: 0.000713\n",
      "水头模型 Epoch 181/500 | 训练损失: 1.9013 | 验证损失: 1.7447 | R2: 0.9108 | RMSE: 1.7142 | LR: 0.000710\n",
      "水头模型 Epoch 182/500 | 训练损失: 1.8948 | 验证损失: 1.6466 | R2: 0.9161 | RMSE: 1.6640 | LR: 0.000707\n",
      "保存最佳水头模型，验证损失: 1.6466\n",
      "水头模型 Epoch 183/500 | 训练损失: 1.8482 | 验证损失: 1.5235 | R2: 0.9224 | RMSE: 1.6007 | LR: 0.000704\n",
      "保存最佳水头模型，验证损失: 1.5235\n",
      "水头模型 Epoch 184/500 | 训练损失: 1.7255 | 验证损失: 1.8791 | R2: 0.9041 | RMSE: 1.7785 | LR: 0.000701\n",
      "水头模型 Epoch 185/500 | 训练损失: 1.8801 | 验证损失: 1.8932 | R2: 0.9029 | RMSE: 1.7866 | LR: 0.000699\n",
      "水头模型 Epoch 186/500 | 训练损失: 1.9953 | 验证损失: 1.4857 | R2: 0.9242 | RMSE: 1.5812 | LR: 0.000696\n",
      "保存最佳水头模型，验证损失: 1.4857\n",
      "水头模型 Epoch 187/500 | 训练损失: 1.6163 | 验证损失: 1.4437 | R2: 0.9264 | RMSE: 1.5584 | LR: 0.000693\n",
      "保存最佳水头模型，验证损失: 1.4437\n",
      "水头模型 Epoch 188/500 | 训练损失: 1.7995 | 验证损失: 1.7170 | R2: 0.9123 | RMSE: 1.7002 | LR: 0.000690\n",
      "水头模型 Epoch 189/500 | 训练损失: 1.9245 | 验证损失: 2.2733 | R2: 0.8836 | RMSE: 1.9573 | LR: 0.000687\n",
      "水头模型 Epoch 190/500 | 训练损失: 1.8818 | 验证损失: 1.4136 | R2: 0.9279 | RMSE: 1.5421 | LR: 0.000684\n",
      "保存最佳水头模型，验证损失: 1.4136\n",
      "水头模型 Epoch 191/500 | 训练损失: 1.5500 | 验证损失: 1.5564 | R2: 0.9208 | RMSE: 1.6176 | LR: 0.000681\n",
      "水头模型 Epoch 192/500 | 训练损失: 1.6672 | 验证损失: 1.3635 | R2: 0.9304 | RMSE: 1.5147 | LR: 0.000678\n",
      "保存最佳水头模型，验证损失: 1.3635\n",
      "水头模型 Epoch 193/500 | 训练损失: 1.4882 | 验证损失: 1.5399 | R2: 0.9213 | RMSE: 1.6102 | LR: 0.000675\n",
      "水头模型 Epoch 194/500 | 训练损失: 1.4871 | 验证损失: 1.4985 | R2: 0.9235 | RMSE: 1.5882 | LR: 0.000672\n",
      "水头模型 Epoch 195/500 | 训练损失: 1.4340 | 验证损失: 1.2726 | R2: 0.9351 | RMSE: 1.4632 | LR: 0.000669\n",
      "保存最佳水头模型，验证损失: 1.2726\n",
      "水头模型 Epoch 196/500 | 训练损失: 1.3905 | 验证损失: 1.3795 | R2: 0.9295 | RMSE: 1.5241 | LR: 0.000666\n",
      "水头模型 Epoch 197/500 | 训练损失: 1.3949 | 验证损失: 1.3218 | R2: 0.9326 | RMSE: 1.4912 | LR: 0.000663\n",
      "水头模型 Epoch 198/500 | 训练损失: 1.3643 | 验证损失: 1.3236 | R2: 0.9323 | RMSE: 1.4930 | LR: 0.000660\n",
      "水头模型 Epoch 199/500 | 训练损失: 1.4215 | 验证损失: 1.1642 | R2: 0.9406 | RMSE: 1.3994 | LR: 0.000657\n",
      "保存最佳水头模型，验证损失: 1.1642\n",
      "水头模型 Epoch 200/500 | 训练损失: 1.3750 | 验证损失: 1.2303 | R2: 0.9371 | RMSE: 1.4392 | LR: 0.000655\n",
      "水头模型 Epoch 201/500 | 训练损失: 1.3097 | 验证损失: 1.1572 | R2: 0.9410 | RMSE: 1.3949 | LR: 0.000652\n",
      "保存最佳水头模型，验证损失: 1.1572\n",
      "水头模型 Epoch 202/500 | 训练损失: 1.3843 | 验证损失: 1.2269 | R2: 0.9373 | RMSE: 1.4371 | LR: 0.000649\n",
      "水头模型 Epoch 203/500 | 训练损失: 1.2211 | 验证损失: 1.1667 | R2: 0.9405 | RMSE: 1.4010 | LR: 0.000646\n",
      "水头模型 Epoch 204/500 | 训练损失: 1.4482 | 验证损失: 1.1613 | R2: 0.9407 | RMSE: 1.3980 | LR: 0.000643\n",
      "水头模型 Epoch 205/500 | 训练损失: 1.2528 | 验证损失: 1.1957 | R2: 0.9389 | RMSE: 1.4186 | LR: 0.000639\n",
      "水头模型 Epoch 206/500 | 训练损失: 1.3065 | 验证损失: 1.1269 | R2: 0.9427 | RMSE: 1.3763 | LR: 0.000636\n",
      "保存最佳水头模型，验证损失: 1.1269\n",
      "水头模型 Epoch 207/500 | 训练损失: 1.2779 | 验证损失: 1.0405 | R2: 0.9470 | RMSE: 1.3228 | LR: 0.000633\n",
      "保存最佳水头模型，验证损失: 1.0405\n",
      "水头模型 Epoch 208/500 | 训练损失: 1.2205 | 验证损失: 1.1481 | R2: 0.9413 | RMSE: 1.3903 | LR: 0.000630\n",
      "水头模型 Epoch 209/500 | 训练损失: 1.3094 | 验证损失: 1.2088 | R2: 0.9380 | RMSE: 1.4273 | LR: 0.000627\n",
      "水头模型 Epoch 210/500 | 训练损失: 1.2499 | 验证损失: 1.1894 | R2: 0.9392 | RMSE: 1.4154 | LR: 0.000624\n",
      "水头模型 Epoch 211/500 | 训练损失: 1.1840 | 验证损失: 0.9771 | R2: 0.9501 | RMSE: 1.2821 | LR: 0.000621\n",
      "保存最佳水头模型，验证损失: 0.9771\n",
      "水头模型 Epoch 212/500 | 训练损失: 1.0428 | 验证损失: 0.9519 | R2: 0.9515 | RMSE: 1.2651 | LR: 0.000618\n",
      "保存最佳水头模型，验证损失: 0.9519\n",
      "水头模型 Epoch 213/500 | 训练损失: 1.0159 | 验证损失: 1.1048 | R2: 0.9436 | RMSE: 1.3635 | LR: 0.000615\n",
      "水头模型 Epoch 214/500 | 训练损失: 1.0367 | 验证损失: 1.0070 | R2: 0.9485 | RMSE: 1.3021 | LR: 0.000612\n",
      "水头模型 Epoch 215/500 | 训练损失: 1.0131 | 验证损失: 0.9501 | R2: 0.9515 | RMSE: 1.2642 | LR: 0.000609\n",
      "保存最佳水头模型，验证损失: 0.9501\n",
      "水头模型 Epoch 216/500 | 训练损失: 1.0765 | 验证损失: 1.1040 | R2: 0.9434 | RMSE: 1.3641 | LR: 0.000606\n",
      "水头模型 Epoch 217/500 | 训练损失: 1.0099 | 验证损失: 0.8768 | R2: 0.9553 | RMSE: 1.2143 | LR: 0.000603\n",
      "保存最佳水头模型，验证损失: 0.8768\n",
      "水头模型 Epoch 218/500 | 训练损失: 0.9616 | 验证损失: 0.8512 | R2: 0.9566 | RMSE: 1.1965 | LR: 0.000600\n",
      "保存最佳水头模型，验证损失: 0.8512\n",
      "水头模型 Epoch 219/500 | 训练损失: 0.9430 | 验证损失: 0.8227 | R2: 0.9581 | RMSE: 1.1759 | LR: 0.000597\n",
      "保存最佳水头模型，验证损失: 0.8227\n",
      "水头模型 Epoch 220/500 | 训练损失: 0.8941 | 验证损失: 0.7949 | R2: 0.9595 | RMSE: 1.1559 | LR: 0.000594\n",
      "保存最佳水头模型，验证损失: 0.7949\n",
      "水头模型 Epoch 221/500 | 训练损失: 0.9416 | 验证损失: 0.9711 | R2: 0.9505 | RMSE: 1.2782 | LR: 0.000591\n",
      "水头模型 Epoch 222/500 | 训练损失: 1.0326 | 验证损失: 1.2104 | R2: 0.9380 | RMSE: 1.4281 | LR: 0.000588\n",
      "水头模型 Epoch 223/500 | 训练损失: 0.9988 | 验证损失: 0.8817 | R2: 0.9549 | RMSE: 1.2183 | LR: 0.000584\n",
      "水头模型 Epoch 224/500 | 训练损失: 0.9785 | 验证损失: 0.9167 | R2: 0.9531 | RMSE: 1.2425 | LR: 0.000581\n",
      "水头模型 Epoch 225/500 | 训练损失: 0.9713 | 验证损失: 0.8472 | R2: 0.9568 | RMSE: 1.1934 | LR: 0.000578\n",
      "水头模型 Epoch 226/500 | 训练损失: 0.9612 | 验证损失: 0.9488 | R2: 0.9515 | RMSE: 1.2637 | LR: 0.000575\n",
      "水头模型 Epoch 227/500 | 训练损失: 0.9301 | 验证损失: 0.7938 | R2: 0.9594 | RMSE: 1.1558 | LR: 0.000572\n",
      "保存最佳水头模型，验证损失: 0.7938\n",
      "水头模型 Epoch 228/500 | 训练损失: 0.9208 | 验证损失: 0.8612 | R2: 0.9559 | RMSE: 1.2043 | LR: 0.000569\n",
      "水头模型 Epoch 229/500 | 训练损失: 0.9064 | 验证损失: 0.8454 | R2: 0.9569 | RMSE: 1.1921 | LR: 0.000566\n",
      "水头模型 Epoch 230/500 | 训练损失: 0.9393 | 验证损失: 0.9966 | R2: 0.9491 | RMSE: 1.2953 | LR: 0.000563\n",
      "水头模型 Epoch 231/500 | 训练损失: 0.8773 | 验证损失: 0.6880 | R2: 0.9650 | RMSE: 1.0751 | LR: 0.000560\n",
      "保存最佳水头模型，验证损失: 0.6880\n",
      "水头模型 Epoch 232/500 | 训练损失: 0.7674 | 验证损失: 0.6741 | R2: 0.9657 | RMSE: 1.0642 | LR: 0.000556\n",
      "保存最佳水头模型，验证损失: 0.6741\n",
      "水头模型 Epoch 233/500 | 训练损失: 0.7712 | 验证损失: 0.7562 | R2: 0.9614 | RMSE: 1.1280 | LR: 0.000553\n",
      "水头模型 Epoch 234/500 | 训练损失: 0.9738 | 验证损失: 0.6553 | R2: 0.9666 | RMSE: 1.0493 | LR: 0.000550\n",
      "保存最佳水头模型，验证损失: 0.6553\n",
      "水头模型 Epoch 235/500 | 训练损失: 0.8071 | 验证损失: 1.1595 | R2: 0.9406 | RMSE: 1.3979 | LR: 0.000547\n",
      "水头模型 Epoch 236/500 | 训练损失: 1.0019 | 验证损失: 1.0127 | R2: 0.9480 | RMSE: 1.3066 | LR: 0.000544\n",
      "水头模型 Epoch 237/500 | 训练损失: 0.9146 | 验证损失: 1.1202 | R2: 0.9424 | RMSE: 1.3748 | LR: 0.000541\n",
      "水头模型 Epoch 238/500 | 训练损失: 0.8895 | 验证损失: 0.6420 | R2: 0.9673 | RMSE: 1.0385 | LR: 0.000538\n",
      "保存最佳水头模型，验证损失: 0.6420\n",
      "水头模型 Epoch 239/500 | 训练损失: 0.9351 | 验证损失: 0.6084 | R2: 0.9690 | RMSE: 1.0107 | LR: 0.000535\n",
      "保存最佳水头模型，验证损失: 0.6084\n",
      "水头模型 Epoch 240/500 | 训练损失: 0.7497 | 验证损失: 0.6388 | R2: 0.9674 | RMSE: 1.0362 | LR: 0.000531\n",
      "水头模型 Epoch 241/500 | 训练损失: 0.6929 | 验证损失: 0.5820 | R2: 0.9704 | RMSE: 0.9884 | LR: 0.000528\n",
      "保存最佳水头模型，验证损失: 0.5820\n",
      "水头模型 Epoch 242/500 | 训练损失: 0.7560 | 验证损失: 0.7431 | R2: 0.9621 | RMSE: 1.1183 | LR: 0.000525\n",
      "水头模型 Epoch 243/500 | 训练损失: 0.8024 | 验证损失: 0.6407 | R2: 0.9673 | RMSE: 1.0378 | LR: 0.000522\n",
      "水头模型 Epoch 244/500 | 训练损失: 0.7754 | 验证损失: 0.5531 | R2: 0.9719 | RMSE: 0.9632 | LR: 0.000519\n",
      "保存最佳水头模型，验证损失: 0.5531\n",
      "水头模型 Epoch 245/500 | 训练损失: 0.6502 | 验证损失: 0.5982 | R2: 0.9696 | RMSE: 1.0021 | LR: 0.000516\n",
      "水头模型 Epoch 246/500 | 训练损失: 0.7042 | 验证损失: 0.5643 | R2: 0.9714 | RMSE: 0.9729 | LR: 0.000513\n",
      "水头模型 Epoch 247/500 | 训练损失: 0.6356 | 验证损失: 0.5564 | R2: 0.9717 | RMSE: 0.9664 | LR: 0.000509\n",
      "水头模型 Epoch 248/500 | 训练损失: 0.6006 | 验证损失: 0.5341 | R2: 0.9728 | RMSE: 0.9469 | LR: 0.000506\n",
      "保存最佳水头模型，验证损失: 0.5341\n",
      "水头模型 Epoch 249/500 | 训练损失: 0.5778 | 验证损失: 0.5272 | R2: 0.9732 | RMSE: 0.9407 | LR: 0.000503\n",
      "保存最佳水头模型，验证损失: 0.5272\n",
      "水头模型 Epoch 250/500 | 训练损失: 0.6125 | 验证损失: 0.6241 | R2: 0.9681 | RMSE: 1.0249 | LR: 0.000500\n",
      "水头模型 Epoch 251/500 | 训练损失: 0.6589 | 验证损失: 0.5684 | R2: 0.9711 | RMSE: 0.9769 | LR: 0.000497\n",
      "水头模型 Epoch 252/500 | 训练损失: 0.6662 | 验证损失: 0.5254 | R2: 0.9733 | RMSE: 0.9393 | LR: 0.000494\n",
      "保存最佳水头模型，验证损失: 0.5254\n",
      "水头模型 Epoch 253/500 | 训练损失: 0.5848 | 验证损失: 0.4854 | R2: 0.9754 | RMSE: 0.9022 | LR: 0.000491\n",
      "保存最佳水头模型，验证损失: 0.4854\n",
      "水头模型 Epoch 254/500 | 训练损失: 0.5223 | 验证损失: 0.4610 | R2: 0.9766 | RMSE: 0.8790 | LR: 0.000487\n",
      "保存最佳水头模型，验证损失: 0.4610\n",
      "水头模型 Epoch 255/500 | 训练损失: 0.5109 | 验证损失: 0.4371 | R2: 0.9778 | RMSE: 0.8558 | LR: 0.000484\n",
      "保存最佳水头模型，验证损失: 0.4371\n",
      "水头模型 Epoch 256/500 | 训练损失: 0.5005 | 验证损失: 0.4692 | R2: 0.9762 | RMSE: 0.8871 | LR: 0.000481\n",
      "水头模型 Epoch 257/500 | 训练损失: 0.6047 | 验证损失: 0.4237 | R2: 0.9785 | RMSE: 0.8426 | LR: 0.000478\n",
      "保存最佳水头模型，验证损失: 0.4237\n",
      "水头模型 Epoch 258/500 | 训练损失: 0.5791 | 验证损失: 0.5371 | R2: 0.9726 | RMSE: 0.9501 | LR: 0.000475\n",
      "水头模型 Epoch 259/500 | 训练损失: 0.5759 | 验证损失: 0.4701 | R2: 0.9761 | RMSE: 0.8879 | LR: 0.000472\n",
      "水头模型 Epoch 260/500 | 训练损失: 0.5668 | 验证损失: 0.5933 | R2: 0.9698 | RMSE: 0.9988 | LR: 0.000469\n",
      "水头模型 Epoch 261/500 | 训练损失: 0.5652 | 验证损失: 0.4436 | R2: 0.9775 | RMSE: 0.8628 | LR: 0.000465\n",
      "水头模型 Epoch 262/500 | 训练损失: 0.5587 | 验证损失: 0.4918 | R2: 0.9749 | RMSE: 0.9090 | LR: 0.000462\n",
      "水头模型 Epoch 263/500 | 训练损失: 0.5554 | 验证损失: 0.4837 | R2: 0.9754 | RMSE: 0.9011 | LR: 0.000459\n",
      "水头模型 Epoch 264/500 | 训练损失: 0.5610 | 验证损失: 0.5150 | R2: 0.9738 | RMSE: 0.9298 | LR: 0.000456\n",
      "水头模型 Epoch 265/500 | 训练损失: 0.5426 | 验证损失: 0.4513 | R2: 0.9770 | RMSE: 0.8705 | LR: 0.000453\n",
      "水头模型 Epoch 266/500 | 训练损失: 0.5445 | 验证损失: 0.5234 | R2: 0.9733 | RMSE: 0.9381 | LR: 0.000450\n",
      "水头模型 Epoch 267/500 | 训练损失: 0.5390 | 验证损失: 0.4568 | R2: 0.9768 | RMSE: 0.8752 | LR: 0.000447\n",
      "水头模型 Epoch 268/500 | 训练损失: 0.5371 | 验证损失: 0.5560 | R2: 0.9717 | RMSE: 0.9667 | LR: 0.000444\n",
      "水头模型 Epoch 269/500 | 训练损失: 0.5431 | 验证损失: 0.4099 | R2: 0.9792 | RMSE: 0.8291 | LR: 0.000440\n",
      "保存最佳水头模型，验证损失: 0.4099\n",
      "水头模型 Epoch 270/500 | 训练损失: 0.5302 | 验证损失: 0.4633 | R2: 0.9764 | RMSE: 0.8824 | LR: 0.000437\n",
      "水头模型 Epoch 271/500 | 训练损失: 0.5267 | 验证损失: 0.4785 | R2: 0.9757 | RMSE: 0.8963 | LR: 0.000434\n",
      "水头模型 Epoch 272/500 | 训练损失: 0.5276 | 验证损失: 0.5241 | R2: 0.9734 | RMSE: 0.9382 | LR: 0.000431\n",
      "水头模型 Epoch 273/500 | 训练损失: 0.5242 | 验证损失: 0.4191 | R2: 0.9787 | RMSE: 0.8386 | LR: 0.000428\n",
      "水头模型 Epoch 274/500 | 训练损失: 0.5165 | 验证损失: 0.4544 | R2: 0.9769 | RMSE: 0.8737 | LR: 0.000425\n",
      "水头模型 Epoch 275/500 | 训练损失: 0.5109 | 验证损失: 0.4531 | R2: 0.9770 | RMSE: 0.8720 | LR: 0.000422\n",
      "水头模型 Epoch 276/500 | 训练损失: 0.5189 | 验证损失: 0.5256 | R2: 0.9732 | RMSE: 0.9399 | LR: 0.000419\n",
      "水头模型 Epoch 277/500 | 训练损失: 0.5118 | 验证损失: 0.4042 | R2: 0.9795 | RMSE: 0.8235 | LR: 0.000416\n",
      "保存最佳水头模型，验证损失: 0.4042\n",
      "水头模型 Epoch 278/500 | 训练损失: 0.5112 | 验证损失: 0.4469 | R2: 0.9772 | RMSE: 0.8666 | LR: 0.000412\n",
      "水头模型 Epoch 279/500 | 训练损失: 0.4930 | 验证损失: 0.4378 | R2: 0.9778 | RMSE: 0.8567 | LR: 0.000409\n",
      "水头模型 Epoch 280/500 | 训练损失: 0.5012 | 验证损失: 0.4996 | R2: 0.9746 | RMSE: 0.9161 | LR: 0.000406\n",
      "水头模型 Epoch 281/500 | 训练损失: 0.5112 | 验证损失: 0.3967 | R2: 0.9799 | RMSE: 0.8157 | LR: 0.000403\n",
      "保存最佳水头模型，验证损失: 0.3967\n",
      "水头模型 Epoch 282/500 | 训练损失: 0.4933 | 验证损失: 0.4278 | R2: 0.9782 | RMSE: 0.8477 | LR: 0.000400\n",
      "水头模型 Epoch 283/500 | 训练损失: 0.4864 | 验证损失: 0.4580 | R2: 0.9767 | RMSE: 0.8767 | LR: 0.000397\n",
      "水头模型 Epoch 284/500 | 训练损失: 0.5004 | 验证损失: 0.4816 | R2: 0.9755 | RMSE: 0.8994 | LR: 0.000394\n",
      "水头模型 Epoch 285/500 | 训练损失: 0.4991 | 验证损失: 0.3826 | R2: 0.9806 | RMSE: 0.8010 | LR: 0.000391\n",
      "保存最佳水头模型，验证损失: 0.3826\n",
      "水头模型 Epoch 286/500 | 训练损失: 0.4785 | 验证损失: 0.4121 | R2: 0.9790 | RMSE: 0.8319 | LR: 0.000388\n",
      "水头模型 Epoch 287/500 | 训练损失: 0.4794 | 验证损失: 0.4154 | R2: 0.9789 | RMSE: 0.8346 | LR: 0.000385\n",
      "水头模型 Epoch 288/500 | 训练损失: 0.4758 | 验证损失: 0.4532 | R2: 0.9770 | RMSE: 0.8723 | LR: 0.000382\n",
      "水头模型 Epoch 289/500 | 训练损失: 0.4761 | 验证损失: 0.3784 | R2: 0.9808 | RMSE: 0.7968 | LR: 0.000379\n",
      "保存最佳水头模型，验证损失: 0.3784\n",
      "水头模型 Epoch 290/500 | 训练损失: 0.4747 | 验证损失: 0.4189 | R2: 0.9787 | RMSE: 0.8389 | LR: 0.000376\n",
      "水头模型 Epoch 291/500 | 训练损失: 0.4541 | 验证损失: 0.4214 | R2: 0.9786 | RMSE: 0.8407 | LR: 0.000373\n",
      "水头模型 Epoch 292/500 | 训练损失: 0.4744 | 验证损失: 0.4686 | R2: 0.9762 | RMSE: 0.8873 | LR: 0.000370\n",
      "水头模型 Epoch 293/500 | 训练损失: 0.4628 | 验证损失: 0.3813 | R2: 0.9806 | RMSE: 0.7999 | LR: 0.000367\n",
      "水头模型 Epoch 294/500 | 训练损失: 0.4623 | 验证损失: 0.4285 | R2: 0.9782 | RMSE: 0.8486 | LR: 0.000364\n",
      "水头模型 Epoch 295/500 | 训练损失: 0.4497 | 验证损失: 0.4148 | R2: 0.9789 | RMSE: 0.8343 | LR: 0.000361\n",
      "水头模型 Epoch 296/500 | 训练损失: 0.4639 | 验证损失: 0.4808 | R2: 0.9755 | RMSE: 0.8989 | LR: 0.000357\n",
      "水头模型 Epoch 297/500 | 训练损失: 0.4581 | 验证损失: 0.3538 | R2: 0.9820 | RMSE: 0.7701 | LR: 0.000354\n",
      "保存最佳水头模型，验证损失: 0.3538\n",
      "水头模型 Epoch 298/500 | 训练损失: 0.4419 | 验证损失: 0.3883 | R2: 0.9802 | RMSE: 0.8075 | LR: 0.000351\n",
      "水头模型 Epoch 299/500 | 训练损失: 0.4441 | 验证损失: 0.3755 | R2: 0.9809 | RMSE: 0.7935 | LR: 0.000348\n",
      "水头模型 Epoch 300/500 | 训练损失: 0.4451 | 验证损失: 0.4051 | R2: 0.9794 | RMSE: 0.8245 | LR: 0.000345\n",
      "水头模型 Epoch 301/500 | 训练损失: 0.4456 | 验证损失: 0.3634 | R2: 0.9815 | RMSE: 0.7806 | LR: 0.000343\n",
      "水头模型 Epoch 302/500 | 训练损失: 0.4357 | 验证损失: 0.3943 | R2: 0.9799 | RMSE: 0.8138 | LR: 0.000340\n",
      "水头模型 Epoch 303/500 | 训练损失: 0.4385 | 验证损失: 0.3704 | R2: 0.9812 | RMSE: 0.7881 | LR: 0.000337\n",
      "水头模型 Epoch 304/500 | 训练损失: 0.4322 | 验证损失: 0.4069 | R2: 0.9793 | RMSE: 0.8264 | LR: 0.000334\n",
      "水头模型 Epoch 305/500 | 训练损失: 0.4307 | 验证损失: 0.3416 | R2: 0.9827 | RMSE: 0.7568 | LR: 0.000331\n",
      "保存最佳水头模型，验证损失: 0.3416\n",
      "水头模型 Epoch 306/500 | 训练损失: 0.4209 | 验证损失: 0.3646 | R2: 0.9815 | RMSE: 0.7823 | LR: 0.000328\n",
      "水头模型 Epoch 307/500 | 训练损失: 0.4165 | 验证损失: 0.3694 | R2: 0.9813 | RMSE: 0.7869 | LR: 0.000325\n",
      "水头模型 Epoch 308/500 | 训练损失: 0.4181 | 验证损失: 0.3907 | R2: 0.9802 | RMSE: 0.8097 | LR: 0.000322\n",
      "水头模型 Epoch 309/500 | 训练损失: 0.4143 | 验证损失: 0.3318 | R2: 0.9832 | RMSE: 0.7458 | LR: 0.000319\n",
      "保存最佳水头模型，验证损失: 0.3318\n",
      "水头模型 Epoch 310/500 | 训练损失: 0.4075 | 验证损失: 0.3597 | R2: 0.9817 | RMSE: 0.7769 | LR: 0.000316\n",
      "水头模型 Epoch 311/500 | 训练损失: 0.4079 | 验证损失: 0.3463 | R2: 0.9825 | RMSE: 0.7617 | LR: 0.000313\n",
      "水头模型 Epoch 312/500 | 训练损失: 0.4036 | 验证损失: 0.3887 | R2: 0.9803 | RMSE: 0.8075 | LR: 0.000310\n",
      "水头模型 Epoch 313/500 | 训练损失: 0.4039 | 验证损失: 0.3231 | R2: 0.9836 | RMSE: 0.7358 | LR: 0.000307\n",
      "保存最佳水头模型，验证损失: 0.3231\n",
      "水头模型 Epoch 314/500 | 训练损失: 0.3979 | 验证损失: 0.3472 | R2: 0.9824 | RMSE: 0.7632 | LR: 0.000304\n",
      "水头模型 Epoch 315/500 | 训练损失: 0.3939 | 验证损失: 0.3390 | R2: 0.9828 | RMSE: 0.7538 | LR: 0.000301\n",
      "水头模型 Epoch 316/500 | 训练损失: 0.3999 | 验证损失: 0.3835 | R2: 0.9805 | RMSE: 0.8024 | LR: 0.000299\n",
      "水头模型 Epoch 317/500 | 训练损失: 0.3896 | 验证损失: 0.3191 | R2: 0.9838 | RMSE: 0.7314 | LR: 0.000296\n",
      "保存最佳水头模型，验证损失: 0.3191\n",
      "水头模型 Epoch 318/500 | 训练损失: 0.3966 | 验证损失: 0.3406 | R2: 0.9827 | RMSE: 0.7560 | LR: 0.000293\n",
      "水头模型 Epoch 319/500 | 训练损失: 0.3846 | 验证损失: 0.3314 | R2: 0.9832 | RMSE: 0.7451 | LR: 0.000290\n",
      "水头模型 Epoch 320/500 | 训练损失: 0.3815 | 验证损失: 0.3474 | R2: 0.9824 | RMSE: 0.7632 | LR: 0.000287\n",
      "水头模型 Epoch 321/500 | 训练损失: 0.3872 | 验证损失: 0.3205 | R2: 0.9837 | RMSE: 0.7331 | LR: 0.000284\n",
      "水头模型 Epoch 322/500 | 训练损失: 0.3826 | 验证损失: 0.3413 | R2: 0.9827 | RMSE: 0.7569 | LR: 0.000281\n",
      "水头模型 Epoch 323/500 | 训练损失: 0.3726 | 验证损失: 0.3231 | R2: 0.9836 | RMSE: 0.7358 | LR: 0.000279\n",
      "水头模型 Epoch 324/500 | 训练损失: 0.3801 | 验证损失: 0.3544 | R2: 0.9820 | RMSE: 0.7711 | LR: 0.000276\n",
      "水头模型 Epoch 325/500 | 训练损失: 0.3736 | 验证损失: 0.3138 | R2: 0.9841 | RMSE: 0.7253 | LR: 0.000273\n",
      "保存最佳水头模型，验证损失: 0.3138\n",
      "水头模型 Epoch 326/500 | 训练损失: 0.3745 | 验证损失: 0.3345 | R2: 0.9830 | RMSE: 0.7493 | LR: 0.000270\n",
      "水头模型 Epoch 327/500 | 训练损失: 0.3670 | 验证损失: 0.3148 | R2: 0.9840 | RMSE: 0.7263 | LR: 0.000267\n",
      "水头模型 Epoch 328/500 | 训练损失: 0.3674 | 验证损失: 0.3405 | R2: 0.9827 | RMSE: 0.7555 | LR: 0.000265\n",
      "水头模型 Epoch 329/500 | 训练损失: 0.3622 | 验证损失: 0.3024 | R2: 0.9847 | RMSE: 0.7121 | LR: 0.000262\n",
      "保存最佳水头模型，验证损失: 0.3024\n",
      "水头模型 Epoch 330/500 | 训练损失: 0.3660 | 验证损失: 0.3202 | R2: 0.9837 | RMSE: 0.7330 | LR: 0.000259\n",
      "水头模型 Epoch 331/500 | 训练损失: 0.3631 | 验证损失: 0.3060 | R2: 0.9845 | RMSE: 0.7160 | LR: 0.000256\n",
      "水头模型 Epoch 332/500 | 训练损失: 0.3600 | 验证损失: 0.3213 | R2: 0.9837 | RMSE: 0.7339 | LR: 0.000254\n",
      "水头模型 Epoch 333/500 | 训练损失: 0.3584 | 验证损失: 0.3030 | R2: 0.9846 | RMSE: 0.7128 | LR: 0.000251\n",
      "水头模型 Epoch 334/500 | 训练损失: 0.3558 | 验证损失: 0.3244 | R2: 0.9835 | RMSE: 0.7379 | LR: 0.000248\n",
      "水头模型 Epoch 335/500 | 训练损失: 0.3622 | 验证损失: 0.2962 | R2: 0.9850 | RMSE: 0.7044 | LR: 0.000245\n",
      "保存最佳水头模型，验证损失: 0.2962\n",
      "水头模型 Epoch 336/500 | 训练损失: 0.3533 | 验证损失: 0.3143 | R2: 0.9841 | RMSE: 0.7259 | LR: 0.000243\n",
      "水头模型 Epoch 337/500 | 训练损失: 0.3630 | 验证损失: 0.2912 | R2: 0.9852 | RMSE: 0.6986 | LR: 0.000240\n",
      "保存最佳水头模型，验证损失: 0.2912\n",
      "水头模型 Epoch 338/500 | 训练损失: 0.3477 | 验证损失: 0.3132 | R2: 0.9841 | RMSE: 0.7249 | LR: 0.000237\n",
      "水头模型 Epoch 339/500 | 训练损失: 0.3448 | 验证损失: 0.2904 | R2: 0.9853 | RMSE: 0.6976 | LR: 0.000235\n",
      "保存最佳水头模型，验证损失: 0.2904\n",
      "水头模型 Epoch 340/500 | 训练损失: 0.3432 | 验证损失: 0.3077 | R2: 0.9844 | RMSE: 0.7183 | LR: 0.000232\n",
      "水头模型 Epoch 341/500 | 训练损失: 0.3392 | 验证损失: 0.2858 | R2: 0.9855 | RMSE: 0.6921 | LR: 0.000229\n",
      "保存最佳水头模型，验证损失: 0.2858\n",
      "水头模型 Epoch 342/500 | 训练损失: 0.3366 | 验证损失: 0.2972 | R2: 0.9849 | RMSE: 0.7061 | LR: 0.000227\n",
      "水头模型 Epoch 343/500 | 训练损失: 0.3287 | 验证损失: 0.2697 | R2: 0.9864 | RMSE: 0.6717 | LR: 0.000224\n",
      "保存最佳水头模型，验证损失: 0.2697\n",
      "水头模型 Epoch 344/500 | 训练损失: 0.3300 | 验证损失: 0.2879 | R2: 0.9854 | RMSE: 0.6945 | LR: 0.000222\n",
      "水头模型 Epoch 345/500 | 训练损失: 0.3175 | 验证损失: 0.2632 | R2: 0.9867 | RMSE: 0.6638 | LR: 0.000219\n",
      "保存最佳水头模型，验证损失: 0.2632\n",
      "水头模型 Epoch 346/500 | 训练损失: 0.3216 | 验证损失: 0.2769 | R2: 0.9860 | RMSE: 0.6812 | LR: 0.000216\n",
      "水头模型 Epoch 347/500 | 训练损失: 0.3178 | 验证损失: 0.2567 | R2: 0.9870 | RMSE: 0.6553 | LR: 0.000214\n",
      "保存最佳水头模型，验证损失: 0.2567\n",
      "水头模型 Epoch 348/500 | 训练损失: 0.3128 | 验证损失: 0.2668 | R2: 0.9865 | RMSE: 0.6683 | LR: 0.000211\n",
      "水头模型 Epoch 349/500 | 训练损失: 0.3063 | 验证损失: 0.2616 | R2: 0.9868 | RMSE: 0.6617 | LR: 0.000209\n",
      "水头模型 Epoch 350/500 | 训练损失: 0.3109 | 验证损失: 0.2704 | R2: 0.9863 | RMSE: 0.6729 | LR: 0.000206\n",
      "水头模型 Epoch 351/500 | 训练损失: 0.3086 | 验证损失: 0.2546 | R2: 0.9871 | RMSE: 0.6528 | LR: 0.000204\n",
      "保存最佳水头模型，验证损失: 0.2546\n",
      "水头模型 Epoch 352/500 | 训练损失: 0.3141 | 验证损失: 0.2602 | R2: 0.9868 | RMSE: 0.6600 | LR: 0.000201\n",
      "水头模型 Epoch 353/500 | 训练损失: 0.3013 | 验证损失: 0.2537 | R2: 0.9871 | RMSE: 0.6517 | LR: 0.000199\n",
      "保存最佳水头模型，验证损失: 0.2537\n",
      "水头模型 Epoch 354/500 | 训练损失: 0.2966 | 验证损失: 0.2544 | R2: 0.9871 | RMSE: 0.6526 | LR: 0.000196\n",
      "水头模型 Epoch 355/500 | 训练损失: 0.2899 | 验证损失: 0.2399 | R2: 0.9879 | RMSE: 0.6336 | LR: 0.000194\n",
      "保存最佳水头模型，验证损失: 0.2399\n",
      "水头模型 Epoch 356/500 | 训练损失: 0.2980 | 验证损失: 0.2680 | R2: 0.9864 | RMSE: 0.6693 | LR: 0.000191\n",
      "水头模型 Epoch 357/500 | 训练损失: 0.3011 | 验证损失: 0.2383 | R2: 0.9879 | RMSE: 0.6316 | LR: 0.000189\n",
      "保存最佳水头模型，验证损失: 0.2383\n",
      "水头模型 Epoch 358/500 | 训练损失: 0.3780 | 验证损失: 0.4245 | R2: 0.9783 | RMSE: 0.8455 | LR: 0.000186\n",
      "水头模型 Epoch 359/500 | 训练损失: 0.3217 | 验证损失: 0.2307 | R2: 0.9883 | RMSE: 0.6212 | LR: 0.000184\n",
      "保存最佳水头模型，验证损失: 0.2307\n",
      "水头模型 Epoch 360/500 | 训练损失: 0.2779 | 验证损失: 0.2274 | R2: 0.9885 | RMSE: 0.6167 | LR: 0.000181\n",
      "保存最佳水头模型，验证损失: 0.2274\n",
      "水头模型 Epoch 361/500 | 训练损失: 0.2676 | 验证损失: 0.2221 | R2: 0.9888 | RMSE: 0.6093 | LR: 0.000179\n",
      "保存最佳水头模型，验证损失: 0.2221\n",
      "水头模型 Epoch 362/500 | 训练损失: 0.2644 | 验证损失: 0.2174 | R2: 0.9890 | RMSE: 0.6030 | LR: 0.000176\n",
      "保存最佳水头模型，验证损失: 0.2174\n",
      "水头模型 Epoch 363/500 | 训练损失: 0.2597 | 验证损失: 0.2216 | R2: 0.9888 | RMSE: 0.6093 | LR: 0.000174\n",
      "水头模型 Epoch 364/500 | 训练损失: 0.2762 | 验证损失: 0.2141 | R2: 0.9892 | RMSE: 0.5986 | LR: 0.000172\n",
      "保存最佳水头模型，验证损失: 0.2141\n",
      "水头模型 Epoch 365/500 | 训练损失: 0.2526 | 验证损失: 0.2108 | R2: 0.9893 | RMSE: 0.5941 | LR: 0.000169\n",
      "保存最佳水头模型，验证损失: 0.2108\n",
      "水头模型 Epoch 366/500 | 训练损失: 0.2611 | 验证损失: 0.2154 | R2: 0.9891 | RMSE: 0.6004 | LR: 0.000167\n",
      "水头模型 Epoch 367/500 | 训练损失: 0.2598 | 验证损失: 0.2139 | R2: 0.9892 | RMSE: 0.5987 | LR: 0.000165\n",
      "水头模型 Epoch 368/500 | 训练损失: 0.2677 | 验证损失: 0.2810 | R2: 0.9857 | RMSE: 0.6872 | LR: 0.000162\n",
      "水头模型 Epoch 369/500 | 训练损失: 0.2976 | 验证损失: 0.2661 | R2: 0.9865 | RMSE: 0.6686 | LR: 0.000160\n",
      "水头模型 Epoch 370/500 | 训练损失: 0.2552 | 验证损失: 0.2079 | R2: 0.9895 | RMSE: 0.5900 | LR: 0.000158\n",
      "保存最佳水头模型，验证损失: 0.2079\n",
      "水头模型 Epoch 371/500 | 训练损失: 0.2482 | 验证损失: 0.2038 | R2: 0.9897 | RMSE: 0.5841 | LR: 0.000155\n",
      "保存最佳水头模型，验证损失: 0.2038\n",
      "水头模型 Epoch 372/500 | 训练损失: 0.2453 | 验证损失: 0.2069 | R2: 0.9895 | RMSE: 0.5887 | LR: 0.000153\n",
      "水头模型 Epoch 373/500 | 训练损失: 0.2550 | 验证损失: 0.2322 | R2: 0.9882 | RMSE: 0.6243 | LR: 0.000151\n",
      "水头模型 Epoch 374/500 | 训练损失: 0.2693 | 验证损失: 0.2356 | R2: 0.9880 | RMSE: 0.6285 | LR: 0.000149\n",
      "水头模型 Epoch 375/500 | 训练损失: 0.2480 | 验证损失: 0.2203 | R2: 0.9888 | RMSE: 0.6080 | LR: 0.000146\n",
      "水头模型 Epoch 376/500 | 训练损失: 0.2550 | 验证损失: 0.2771 | R2: 0.9859 | RMSE: 0.6826 | LR: 0.000144\n",
      "水头模型 Epoch 377/500 | 训练损失: 0.2660 | 验证损失: 0.2008 | R2: 0.9898 | RMSE: 0.5800 | LR: 0.000142\n",
      "保存最佳水头模型，验证损失: 0.2008\n",
      "水头模型 Epoch 378/500 | 训练损失: 0.2367 | 验证损失: 0.1975 | R2: 0.9900 | RMSE: 0.5752 | LR: 0.000140\n",
      "保存最佳水头模型，验证损失: 0.1975\n",
      "水头模型 Epoch 379/500 | 训练损失: 0.2358 | 验证损失: 0.1987 | R2: 0.9899 | RMSE: 0.5772 | LR: 0.000138\n",
      "水头模型 Epoch 380/500 | 训练损失: 0.2536 | 验证损失: 0.2049 | R2: 0.9896 | RMSE: 0.5857 | LR: 0.000136\n",
      "水头模型 Epoch 381/500 | 训练损失: 0.2408 | 验证损失: 0.2058 | R2: 0.9896 | RMSE: 0.5874 | LR: 0.000133\n",
      "水头模型 Epoch 382/500 | 训练损失: 0.2377 | 验证损失: 0.1973 | R2: 0.9900 | RMSE: 0.5751 | LR: 0.000131\n",
      "保存最佳水头模型，验证损失: 0.1973\n",
      "水头模型 Epoch 383/500 | 训练损失: 0.2367 | 验证损失: 0.1970 | R2: 0.9900 | RMSE: 0.5746 | LR: 0.000129\n",
      "保存最佳水头模型，验证损失: 0.1970\n",
      "水头模型 Epoch 384/500 | 训练损失: 0.2522 | 验证损失: 0.2033 | R2: 0.9897 | RMSE: 0.5840 | LR: 0.000127\n",
      "水头模型 Epoch 385/500 | 训练损失: 0.2353 | 验证损失: 0.1967 | R2: 0.9900 | RMSE: 0.5742 | LR: 0.000125\n",
      "保存最佳水头模型，验证损失: 0.1967\n",
      "水头模型 Epoch 386/500 | 训练损失: 0.2418 | 验证损失: 0.2001 | R2: 0.9898 | RMSE: 0.5794 | LR: 0.000123\n",
      "水头模型 Epoch 387/500 | 训练损失: 0.2308 | 验证损失: 0.1931 | R2: 0.9902 | RMSE: 0.5690 | LR: 0.000121\n",
      "保存最佳水头模型，验证损失: 0.1931\n",
      "水头模型 Epoch 388/500 | 训练损失: 0.2309 | 验证损失: 0.1957 | R2: 0.9901 | RMSE: 0.5728 | LR: 0.000119\n",
      "水头模型 Epoch 389/500 | 训练损失: 0.2339 | 验证损失: 0.1992 | R2: 0.9899 | RMSE: 0.5781 | LR: 0.000117\n",
      "水头模型 Epoch 390/500 | 训练损失: 0.2325 | 验证损失: 0.1848 | R2: 0.9906 | RMSE: 0.5563 | LR: 0.000115\n",
      "保存最佳水头模型，验证损失: 0.1848\n",
      "水头模型 Epoch 391/500 | 训练损失: 0.2198 | 验证损失: 0.1853 | R2: 0.9906 | RMSE: 0.5572 | LR: 0.000113\n",
      "水头模型 Epoch 392/500 | 训练损失: 0.2190 | 验证损失: 0.1859 | R2: 0.9906 | RMSE: 0.5582 | LR: 0.000111\n",
      "水头模型 Epoch 393/500 | 训练损失: 0.2181 | 验证损失: 0.1820 | R2: 0.9908 | RMSE: 0.5519 | LR: 0.000109\n",
      "保存最佳水头模型，验证损失: 0.1820\n",
      "水头模型 Epoch 394/500 | 训练损失: 0.2208 | 验证损失: 0.1898 | R2: 0.9904 | RMSE: 0.5641 | LR: 0.000107\n",
      "水头模型 Epoch 395/500 | 训练损失: 0.2176 | 验证损失: 0.1839 | R2: 0.9907 | RMSE: 0.5550 | LR: 0.000105\n",
      "水头模型 Epoch 396/500 | 训练损失: 0.2259 | 验证损失: 0.1875 | R2: 0.9905 | RMSE: 0.5605 | LR: 0.000103\n",
      "水头模型 Epoch 397/500 | 训练损失: 0.2159 | 验证损失: 0.1794 | R2: 0.9909 | RMSE: 0.5481 | LR: 0.000101\n",
      "保存最佳水头模型，验证损失: 0.1794\n",
      "水头模型 Epoch 398/500 | 训练损失: 0.2128 | 验证损失: 0.1766 | R2: 0.9911 | RMSE: 0.5438 | LR: 0.000099\n",
      "保存最佳水头模型，验证损失: 0.1766\n",
      "水头模型 Epoch 399/500 | 训练损失: 0.2147 | 验证损失: 0.1851 | R2: 0.9906 | RMSE: 0.5573 | LR: 0.000097\n",
      "水头模型 Epoch 400/500 | 训练损失: 0.2156 | 验证损失: 0.1799 | R2: 0.9909 | RMSE: 0.5484 | LR: 0.000095\n",
      "水头模型 Epoch 401/500 | 训练损失: 0.2181 | 验证损失: 0.1761 | R2: 0.9911 | RMSE: 0.5433 | LR: 0.000094\n",
      "保存最佳水头模型，验证损失: 0.1761\n",
      "水头模型 Epoch 402/500 | 训练损失: 0.2112 | 验证损失: 0.1853 | R2: 0.9906 | RMSE: 0.5573 | LR: 0.000092\n",
      "水头模型 Epoch 403/500 | 训练损失: 0.2116 | 验证损失: 0.1773 | R2: 0.9910 | RMSE: 0.5451 | LR: 0.000090\n",
      "水头模型 Epoch 404/500 | 训练损失: 0.2102 | 验证损失: 0.1728 | R2: 0.9912 | RMSE: 0.5381 | LR: 0.000088\n",
      "保存最佳水头模型，验证损失: 0.1728\n",
      "水头模型 Epoch 405/500 | 训练损失: 0.2101 | 验证损失: 0.1723 | R2: 0.9913 | RMSE: 0.5369 | LR: 0.000086\n",
      "保存最佳水头模型，验证损失: 0.1723\n",
      "水头模型 Epoch 406/500 | 训练损失: 0.2135 | 验证损失: 0.1775 | R2: 0.9910 | RMSE: 0.5458 | LR: 0.000085\n",
      "水头模型 Epoch 407/500 | 训练损失: 0.2102 | 验证损失: 0.1708 | R2: 0.9913 | RMSE: 0.5348 | LR: 0.000083\n",
      "保存最佳水头模型，验证损失: 0.1708\n",
      "水头模型 Epoch 408/500 | 训练损失: 0.2022 | 验证损失: 0.1671 | R2: 0.9915 | RMSE: 0.5292 | LR: 0.000081\n",
      "保存最佳水头模型，验证损失: 0.1671\n",
      "水头模型 Epoch 409/500 | 训练损失: 0.2011 | 验证损失: 0.1667 | R2: 0.9916 | RMSE: 0.5285 | LR: 0.000080\n",
      "保存最佳水头模型，验证损失: 0.1667\n",
      "水头模型 Epoch 410/500 | 训练损失: 0.1986 | 验证损失: 0.1649 | R2: 0.9916 | RMSE: 0.5255 | LR: 0.000078\n",
      "保存最佳水头模型，验证损失: 0.1649\n",
      "水头模型 Epoch 411/500 | 训练损失: 0.1981 | 验证损失: 0.1662 | R2: 0.9916 | RMSE: 0.5279 | LR: 0.000076\n",
      "水头模型 Epoch 412/500 | 训练损失: 0.1978 | 验证损失: 0.1624 | R2: 0.9918 | RMSE: 0.5216 | LR: 0.000075\n",
      "保存最佳水头模型，验证损失: 0.1624\n",
      "水头模型 Epoch 413/500 | 训练损失: 0.2003 | 验证损失: 0.1634 | R2: 0.9917 | RMSE: 0.5231 | LR: 0.000073\n",
      "水头模型 Epoch 414/500 | 训练损失: 0.1944 | 验证损失: 0.1647 | R2: 0.9916 | RMSE: 0.5256 | LR: 0.000071\n",
      "水头模型 Epoch 415/500 | 训练损失: 0.1996 | 验证损失: 0.1610 | R2: 0.9918 | RMSE: 0.5193 | LR: 0.000070\n",
      "保存最佳水头模型，验证损失: 0.1610\n",
      "水头模型 Epoch 416/500 | 训练损失: 0.1947 | 验证损失: 0.1589 | R2: 0.9919 | RMSE: 0.5159 | LR: 0.000068\n",
      "保存最佳水头模型，验证损失: 0.1589\n",
      "水头模型 Epoch 417/500 | 训练损失: 0.1921 | 验证损失: 0.1584 | R2: 0.9920 | RMSE: 0.5152 | LR: 0.000066\n",
      "保存最佳水头模型，验证损失: 0.1584\n",
      "水头模型 Epoch 418/500 | 训练损失: 0.1923 | 验证损失: 0.1608 | R2: 0.9918 | RMSE: 0.5192 | LR: 0.000065\n",
      "水头模型 Epoch 419/500 | 训练损失: 0.1956 | 验证损失: 0.1576 | R2: 0.9920 | RMSE: 0.5139 | LR: 0.000063\n",
      "保存最佳水头模型，验证损失: 0.1576\n",
      "水头模型 Epoch 420/500 | 训练损失: 0.1905 | 验证损失: 0.1577 | R2: 0.9920 | RMSE: 0.5140 | LR: 0.000062\n",
      "水头模型 Epoch 421/500 | 训练损失: 0.1900 | 验证损失: 0.1568 | R2: 0.9921 | RMSE: 0.5125 | LR: 0.000060\n",
      "保存最佳水头模型，验证损失: 0.1568\n",
      "水头模型 Epoch 422/500 | 训练损失: 0.1920 | 验证损失: 0.1572 | R2: 0.9920 | RMSE: 0.5132 | LR: 0.000059\n",
      "水头模型 Epoch 423/500 | 训练损失: 0.1906 | 验证损失: 0.1571 | R2: 0.9920 | RMSE: 0.5132 | LR: 0.000057\n",
      "水头模型 Epoch 424/500 | 训练损失: 0.1881 | 验证损失: 0.1564 | R2: 0.9921 | RMSE: 0.5120 | LR: 0.000056\n",
      "保存最佳水头模型，验证损失: 0.1564\n",
      "水头模型 Epoch 425/500 | 训练损失: 0.1893 | 验证损失: 0.1579 | R2: 0.9920 | RMSE: 0.5147 | LR: 0.000054\n",
      "水头模型 Epoch 426/500 | 训练损失: 0.1903 | 验证损失: 0.1581 | R2: 0.9920 | RMSE: 0.5150 | LR: 0.000053\n",
      "水头模型 Epoch 427/500 | 训练损失: 0.1890 | 验证损失: 0.1558 | R2: 0.9921 | RMSE: 0.5111 | LR: 0.000052\n",
      "保存最佳水头模型，验证损失: 0.1558\n",
      "水头模型 Epoch 428/500 | 训练损失: 0.1875 | 验证损失: 0.1559 | R2: 0.9921 | RMSE: 0.5114 | LR: 0.000050\n",
      "水头模型 Epoch 429/500 | 训练损失: 0.1966 | 验证损失: 0.1542 | R2: 0.9922 | RMSE: 0.5084 | LR: 0.000049\n",
      "保存最佳水头模型，验证损失: 0.1542\n",
      "水头模型 Epoch 430/500 | 训练损失: 0.1866 | 验证损失: 0.1544 | R2: 0.9922 | RMSE: 0.5089 | LR: 0.000048\n",
      "水头模型 Epoch 431/500 | 训练损失: 0.1854 | 验证损失: 0.1542 | R2: 0.9922 | RMSE: 0.5086 | LR: 0.000046\n",
      "水头模型 Epoch 432/500 | 训练损失: 0.1858 | 验证损失: 0.1548 | R2: 0.9921 | RMSE: 0.5096 | LR: 0.000045\n",
      "水头模型 Epoch 433/500 | 训练损失: 0.1849 | 验证损失: 0.1547 | R2: 0.9921 | RMSE: 0.5096 | LR: 0.000044\n",
      "水头模型 Epoch 434/500 | 训练损失: 0.1853 | 验证损失: 0.1529 | R2: 0.9922 | RMSE: 0.5065 | LR: 0.000042\n",
      "保存最佳水头模型，验证损失: 0.1529\n",
      "水头模型 Epoch 435/500 | 训练损失: 0.1863 | 验证损失: 0.1537 | R2: 0.9922 | RMSE: 0.5079 | LR: 0.000041\n",
      "水头模型 Epoch 436/500 | 训练损失: 0.1834 | 验证损失: 0.1515 | R2: 0.9923 | RMSE: 0.5039 | LR: 0.000040\n",
      "保存最佳水头模型，验证损失: 0.1515\n",
      "水头模型 Epoch 437/500 | 训练损失: 0.1842 | 验证损失: 0.1529 | R2: 0.9922 | RMSE: 0.5066 | LR: 0.000039\n",
      "水头模型 Epoch 438/500 | 训练损失: 0.1825 | 验证损失: 0.1513 | R2: 0.9923 | RMSE: 0.5035 | LR: 0.000037\n",
      "保存最佳水头模型，验证损失: 0.1513\n",
      "水头模型 Epoch 439/500 | 训练损失: 0.1819 | 验证损失: 0.1527 | R2: 0.9922 | RMSE: 0.5062 | LR: 0.000036\n",
      "水头模型 Epoch 440/500 | 训练损失: 0.1862 | 验证损失: 0.1505 | R2: 0.9924 | RMSE: 0.5024 | LR: 0.000035\n",
      "保存最佳水头模型，验证损失: 0.1505\n",
      "水头模型 Epoch 441/500 | 训练损失: 0.1814 | 验证损失: 0.1502 | R2: 0.9924 | RMSE: 0.5018 | LR: 0.000034\n",
      "保存最佳水头模型，验证损失: 0.1502\n",
      "水头模型 Epoch 442/500 | 训练损失: 0.1823 | 验证损失: 0.1502 | R2: 0.9924 | RMSE: 0.5019 | LR: 0.000033\n",
      "水头模型 Epoch 443/500 | 训练损失: 0.1802 | 验证损失: 0.1500 | R2: 0.9924 | RMSE: 0.5016 | LR: 0.000032\n",
      "保存最佳水头模型，验证损失: 0.1500\n",
      "水头模型 Epoch 444/500 | 训练损失: 0.1871 | 验证损失: 0.1502 | R2: 0.9924 | RMSE: 0.5019 | LR: 0.000031\n",
      "水头模型 Epoch 445/500 | 训练损失: 0.1843 | 验证损失: 0.1490 | R2: 0.9924 | RMSE: 0.4997 | LR: 0.000030\n",
      "保存最佳水头模型，验证损失: 0.1490\n",
      "水头模型 Epoch 446/500 | 训练损失: 0.1818 | 验证损失: 0.1497 | R2: 0.9924 | RMSE: 0.5012 | LR: 0.000029\n",
      "水头模型 Epoch 447/500 | 训练损失: 0.1793 | 验证损失: 0.1492 | R2: 0.9924 | RMSE: 0.5001 | LR: 0.000027\n",
      "水头模型 Epoch 448/500 | 训练损失: 0.1800 | 验证损失: 0.1489 | R2: 0.9924 | RMSE: 0.4998 | LR: 0.000026\n",
      "保存最佳水头模型，验证损失: 0.1489\n",
      "水头模型 Epoch 449/500 | 训练损失: 0.1795 | 验证损失: 0.1483 | R2: 0.9925 | RMSE: 0.4985 | LR: 0.000025\n",
      "保存最佳水头模型，验证损失: 0.1483\n",
      "水头模型 Epoch 450/500 | 训练损失: 0.1809 | 验证损失: 0.1489 | R2: 0.9924 | RMSE: 0.4997 | LR: 0.000024\n",
      "水头模型 Epoch 451/500 | 训练损失: 0.1790 | 验证损失: 0.1488 | R2: 0.9924 | RMSE: 0.4996 | LR: 0.000024\n",
      "水头模型 Epoch 452/500 | 训练损失: 0.1784 | 验证损失: 0.1496 | R2: 0.9924 | RMSE: 0.5012 | LR: 0.000023\n",
      "水头模型 Epoch 453/500 | 训练损失: 0.1794 | 验证损失: 0.1476 | R2: 0.9925 | RMSE: 0.4974 | LR: 0.000022\n",
      "保存最佳水头模型，验证损失: 0.1476\n",
      "水头模型 Epoch 454/500 | 训练损失: 0.1789 | 验证损失: 0.1475 | R2: 0.9925 | RMSE: 0.4974 | LR: 0.000021\n",
      "保存最佳水头模型，验证损失: 0.1475\n",
      "水头模型 Epoch 455/500 | 训练损失: 0.1773 | 验证损失: 0.1482 | R2: 0.9925 | RMSE: 0.4987 | LR: 0.000020\n",
      "水头模型 Epoch 456/500 | 训练损失: 0.1831 | 验证损失: 0.1478 | R2: 0.9925 | RMSE: 0.4979 | LR: 0.000019\n",
      "水头模型 Epoch 457/500 | 训练损失: 0.1817 | 验证损失: 0.1472 | R2: 0.9925 | RMSE: 0.4970 | LR: 0.000018\n",
      "保存最佳水头模型，验证损失: 0.1472\n",
      "水头模型 Epoch 458/500 | 训练损失: 0.1779 | 验证损失: 0.1463 | R2: 0.9926 | RMSE: 0.4953 | LR: 0.000017\n",
      "保存最佳水头模型，验证损失: 0.1463\n",
      "水头模型 Epoch 459/500 | 训练损失: 0.1770 | 验证损失: 0.1469 | R2: 0.9925 | RMSE: 0.4964 | LR: 0.000016\n",
      "水头模型 Epoch 460/500 | 训练损失: 0.1832 | 验证损失: 0.1463 | R2: 0.9926 | RMSE: 0.4954 | LR: 0.000016\n",
      "保存最佳水头模型，验证损失: 0.1463\n",
      "水头模型 Epoch 461/500 | 训练损失: 0.1767 | 验证损失: 0.1463 | R2: 0.9926 | RMSE: 0.4954 | LR: 0.000015\n",
      "保存最佳水头模型，验证损失: 0.1463\n",
      "水头模型 Epoch 462/500 | 训练损失: 0.1753 | 验证损失: 0.1463 | R2: 0.9926 | RMSE: 0.4954 | LR: 0.000014\n",
      "水头模型 Epoch 463/500 | 训练损失: 0.1749 | 验证损失: 0.1456 | R2: 0.9926 | RMSE: 0.4942 | LR: 0.000013\n",
      "保存最佳水头模型，验证损失: 0.1456\n",
      "水头模型 Epoch 464/500 | 训练损失: 0.1755 | 验证损失: 0.1461 | R2: 0.9926 | RMSE: 0.4951 | LR: 0.000013\n",
      "水头模型 Epoch 465/500 | 训练损失: 0.1752 | 验证损失: 0.1452 | R2: 0.9926 | RMSE: 0.4935 | LR: 0.000012\n",
      "保存最佳水头模型，验证损失: 0.1452\n",
      "水头模型 Epoch 466/500 | 训练损失: 0.1744 | 验证损失: 0.1453 | R2: 0.9926 | RMSE: 0.4937 | LR: 0.000011\n",
      "水头模型 Epoch 467/500 | 训练损失: 0.1783 | 验证损失: 0.1449 | R2: 0.9926 | RMSE: 0.4930 | LR: 0.000011\n",
      "保存最佳水头模型，验证损失: 0.1449\n",
      "水头模型 Epoch 468/500 | 训练损失: 0.1790 | 验证损失: 0.1453 | R2: 0.9926 | RMSE: 0.4937 | LR: 0.000010\n",
      "水头模型 Epoch 469/500 | 训练损失: 0.1743 | 验证损失: 0.1449 | R2: 0.9926 | RMSE: 0.4930 | LR: 0.000009\n",
      "保存最佳水头模型，验证损失: 0.1449\n",
      "水头模型 Epoch 470/500 | 训练损失: 0.1756 | 验证损失: 0.1449 | R2: 0.9926 | RMSE: 0.4931 | LR: 0.000009\n",
      "水头模型 Epoch 471/500 | 训练损失: 0.1747 | 验证损失: 0.1445 | R2: 0.9927 | RMSE: 0.4923 | LR: 0.000008\n",
      "保存最佳水头模型，验证损失: 0.1445\n",
      "水头模型 Epoch 472/500 | 训练损失: 0.1741 | 验证损失: 0.1443 | R2: 0.9927 | RMSE: 0.4919 | LR: 0.000008\n",
      "保存最佳水头模型，验证损失: 0.1443\n",
      "水头模型 Epoch 473/500 | 训练损失: 0.1741 | 验证损失: 0.1439 | R2: 0.9927 | RMSE: 0.4912 | LR: 0.000007\n",
      "保存最佳水头模型，验证损失: 0.1439\n",
      "水头模型 Epoch 474/500 | 训练损失: 0.1733 | 验证损失: 0.1437 | R2: 0.9927 | RMSE: 0.4909 | LR: 0.000007\n",
      "保存最佳水头模型，验证损失: 0.1437\n",
      "水头模型 Epoch 475/500 | 训练损失: 0.1749 | 验证损失: 0.1436 | R2: 0.9927 | RMSE: 0.4908 | LR: 0.000006\n",
      "保存最佳水头模型，验证损失: 0.1436\n",
      "水头模型 Epoch 476/500 | 训练损失: 0.1750 | 验证损失: 0.1436 | R2: 0.9927 | RMSE: 0.4907 | LR: 0.000006\n",
      "保存最佳水头模型，验证损失: 0.1436\n",
      "水头模型 Epoch 477/500 | 训练损失: 0.1741 | 验证损失: 0.1434 | R2: 0.9927 | RMSE: 0.4904 | LR: 0.000005\n",
      "保存最佳水头模型，验证损失: 0.1434\n",
      "水头模型 Epoch 478/500 | 训练损失: 0.1805 | 验证损失: 0.1433 | R2: 0.9927 | RMSE: 0.4903 | LR: 0.000005\n",
      "保存最佳水头模型，验证损失: 0.1433\n",
      "水头模型 Epoch 479/500 | 训练损失: 0.1729 | 验证损失: 0.1430 | R2: 0.9927 | RMSE: 0.4898 | LR: 0.000004\n",
      "保存最佳水头模型，验证损失: 0.1430\n",
      "水头模型 Epoch 480/500 | 训练损失: 0.1741 | 验证损失: 0.1429 | R2: 0.9927 | RMSE: 0.4896 | LR: 0.000004\n",
      "保存最佳水头模型，验证损失: 0.1429\n",
      "水头模型 Epoch 481/500 | 训练损失: 0.1715 | 验证损失: 0.1429 | R2: 0.9927 | RMSE: 0.4895 | LR: 0.000004\n",
      "保存最佳水头模型，验证损失: 0.1429\n",
      "水头模型 Epoch 482/500 | 训练损失: 0.1722 | 验证损失: 0.1429 | R2: 0.9928 | RMSE: 0.4895 | LR: 0.000003\n",
      "保存最佳水头模型，验证损失: 0.1429\n",
      "水头模型 Epoch 483/500 | 训练损失: 0.1721 | 验证损失: 0.1427 | R2: 0.9928 | RMSE: 0.4892 | LR: 0.000003\n",
      "保存最佳水头模型，验证损失: 0.1427\n",
      "水头模型 Epoch 484/500 | 训练损失: 0.1724 | 验证损失: 0.1427 | R2: 0.9928 | RMSE: 0.4892 | LR: 0.000003\n",
      "保存最佳水头模型，验证损失: 0.1427\n",
      "水头模型 Epoch 485/500 | 训练损失: 0.1719 | 验证损失: 0.1428 | R2: 0.9928 | RMSE: 0.4894 | LR: 0.000002\n",
      "水头模型 Epoch 486/500 | 训练损失: 0.1770 | 验证损失: 0.1427 | R2: 0.9928 | RMSE: 0.4893 | LR: 0.000002\n",
      "水头模型 Epoch 487/500 | 训练损失: 0.1718 | 验证损失: 0.1427 | R2: 0.9928 | RMSE: 0.4893 | LR: 0.000002\n",
      "水头模型 Epoch 488/500 | 训练损失: 0.1734 | 验证损失: 0.1426 | R2: 0.9928 | RMSE: 0.4891 | LR: 0.000001\n",
      "保存最佳水头模型，验证损失: 0.1426\n",
      "水头模型 Epoch 489/500 | 训练损失: 0.1746 | 验证损失: 0.1427 | R2: 0.9928 | RMSE: 0.4893 | LR: 0.000001\n",
      "水头模型 Epoch 490/500 | 训练损失: 0.1717 | 验证损失: 0.1426 | R2: 0.9928 | RMSE: 0.4891 | LR: 0.000001\n",
      "保存最佳水头模型，验证损失: 0.1426\n",
      "水头模型 Epoch 491/500 | 训练损失: 0.1740 | 验证损失: 0.1426 | R2: 0.9928 | RMSE: 0.4890 | LR: 0.000001\n",
      "保存最佳水头模型，验证损失: 0.1426\n",
      "水头模型 Epoch 492/500 | 训练损失: 0.1731 | 验证损失: 0.1426 | R2: 0.9928 | RMSE: 0.4890 | LR: 0.000001\n",
      "保存最佳水头模型，验证损失: 0.1426\n",
      "水头模型 Epoch 493/500 | 训练损失: 0.1733 | 验证损失: 0.1426 | R2: 0.9928 | RMSE: 0.4890 | LR: 0.000000\n",
      "水头模型 Epoch 494/500 | 训练损失: 0.1731 | 验证损失: 0.1426 | R2: 0.9928 | RMSE: 0.4890 | LR: 0.000000\n",
      "水头模型 Epoch 495/500 | 训练损失: 0.1719 | 验证损失: 0.1426 | R2: 0.9928 | RMSE: 0.4890 | LR: 0.000000\n",
      "水头模型 Epoch 496/500 | 训练损失: 0.1721 | 验证损失: 0.1426 | R2: 0.9928 | RMSE: 0.4891 | LR: 0.000000\n",
      "水头模型 Epoch 497/500 | 训练损失: 0.1742 | 验证损失: 0.1426 | R2: 0.9928 | RMSE: 0.4890 | LR: 0.000000\n",
      "水头模型 Epoch 498/500 | 训练损失: 0.1717 | 验证损失: 0.1426 | R2: 0.9928 | RMSE: 0.4890 | LR: 0.000000\n",
      "水头模型 Epoch 499/500 | 训练损失: 0.1727 | 验证损失: 0.1426 | R2: 0.9928 | RMSE: 0.4890 | LR: 0.000000\n",
      "水头模型 Epoch 500/500 | 训练损失: 0.1740 | 验证损失: 0.1426 | R2: 0.9928 | RMSE: 0.4890 | LR: 0.000000\n",
      "\n",
      "🔹 水头模型训练完成！最佳验证损失: 0.1426\n",
      "🔹 开始训练浓度模型...\n",
      "浓度模型 Epoch 001/500 | 训练损失: 5.7829 | 验证损失: 5.4440 | R2: 0.0337 | RMSE: 3.0306 | LR: 0.001000\n",
      "保存基于R2的最佳浓度模型，R2: 0.0337\n",
      "浓度模型 Epoch 002/500 | 训练损失: 5.5326 | 验证损失: 5.1427 | R2: 0.0874 | RMSE: 2.9454 | LR: 0.001000\n",
      "保存基于R2的最佳浓度模型，R2: 0.0874\n",
      "浓度模型 Epoch 003/500 | 训练损失: 5.3067 | 验证损失: 4.9263 | R2: 0.1259 | RMSE: 2.8826 | LR: 0.001000\n",
      "保存基于R2的最佳浓度模型，R2: 0.1259\n",
      "浓度模型 Epoch 004/500 | 训练损失: 5.0921 | 验证损失: 4.8102 | R2: 0.1465 | RMSE: 2.8484 | LR: 0.001000\n",
      "保存基于R2的最佳浓度模型，R2: 0.1465\n",
      "浓度模型 Epoch 005/500 | 训练损失: 4.8723 | 验证损失: 4.4787 | R2: 0.2056 | RMSE: 2.7482 | LR: 0.001000\n",
      "保存基于R2的最佳浓度模型，R2: 0.2056\n",
      "浓度模型 Epoch 006/500 | 训练损失: 4.6270 | 验证损失: 4.3214 | R2: 0.2336 | RMSE: 2.6995 | LR: 0.001000\n",
      "保存基于R2的最佳浓度模型，R2: 0.2336\n",
      "浓度模型 Epoch 007/500 | 训练损失: 4.4284 | 验证损失: 4.0394 | R2: 0.2838 | RMSE: 2.6096 | LR: 0.001000\n",
      "保存基于R2的最佳浓度模型，R2: 0.2838\n",
      "浓度模型 Epoch 008/500 | 训练损失: 4.2081 | 验证损失: 3.8603 | R2: 0.3157 | RMSE: 2.5510 | LR: 0.000999\n",
      "保存基于R2的最佳浓度模型，R2: 0.3157\n",
      "浓度模型 Epoch 009/500 | 训练损失: 3.9885 | 验证损失: 3.6152 | R2: 0.3593 | RMSE: 2.4685 | LR: 0.000999\n",
      "保存基于R2的最佳浓度模型，R2: 0.3593\n",
      "浓度模型 Epoch 010/500 | 训练损失: 3.7135 | 验证损失: 3.3342 | R2: 0.4093 | RMSE: 2.3704 | LR: 0.000999\n",
      "保存基于R2的最佳浓度模型，R2: 0.4093\n",
      "浓度模型 Epoch 011/500 | 训练损失: 3.4260 | 验证损失: 3.0263 | R2: 0.4640 | RMSE: 2.2579 | LR: 0.000999\n",
      "保存基于R2的最佳浓度模型，R2: 0.4640\n",
      "浓度模型 Epoch 012/500 | 训练损失: 3.1230 | 验证损失: 2.8053 | R2: 0.5033 | RMSE: 2.1736 | LR: 0.000999\n",
      "保存基于R2的最佳浓度模型，R2: 0.5033\n",
      "浓度模型 Epoch 013/500 | 训练损失: 2.8571 | 验证损失: 2.4689 | R2: 0.5631 | RMSE: 2.0386 | LR: 0.000998\n",
      "保存基于R2的最佳浓度模型，R2: 0.5631\n",
      "浓度模型 Epoch 014/500 | 训练损失: 2.7702 | 验证损失: 2.3340 | R2: 0.5871 | RMSE: 1.9819 | LR: 0.000998\n",
      "保存基于R2的最佳浓度模型，R2: 0.5871\n",
      "浓度模型 Epoch 015/500 | 训练损失: 2.5036 | 验证损失: 2.2163 | R2: 0.6079 | RMSE: 1.9311 | LR: 0.000998\n",
      "保存基于R2的最佳浓度模型，R2: 0.6079\n",
      "浓度模型 Epoch 016/500 | 训练损失: 2.3276 | 验证损失: 2.0361 | R2: 0.6400 | RMSE: 1.8505 | LR: 0.000997\n",
      "保存基于R2的最佳浓度模型，R2: 0.6400\n",
      "浓度模型 Epoch 017/500 | 训练损失: 2.1669 | 验证损失: 1.8702 | R2: 0.6694 | RMSE: 1.7731 | LR: 0.000997\n",
      "保存基于R2的最佳浓度模型，R2: 0.6694\n",
      "浓度模型 Epoch 018/500 | 训练损失: 2.0889 | 验证损失: 1.7370 | R2: 0.6931 | RMSE: 1.7084 | LR: 0.000997\n",
      "保存基于R2的最佳浓度模型，R2: 0.6931\n",
      "浓度模型 Epoch 019/500 | 训练损失: 1.9277 | 验证损失: 1.7273 | R2: 0.6949 | RMSE: 1.7035 | LR: 0.000996\n",
      "保存基于R2的最佳浓度模型，R2: 0.6949\n",
      "浓度模型 Epoch 020/500 | 训练损失: 1.8696 | 验证损失: 1.6134 | R2: 0.7149 | RMSE: 1.6463 | LR: 0.000996\n",
      "保存基于R2的最佳浓度模型，R2: 0.7149\n",
      "浓度模型 Epoch 021/500 | 训练损失: 1.9023 | 验证损失: 1.5077 | R2: 0.7337 | RMSE: 1.5911 | LR: 0.000996\n",
      "保存基于R2的最佳浓度模型，R2: 0.7337\n",
      "浓度模型 Epoch 022/500 | 训练损失: 1.6769 | 验证损失: 1.3732 | R2: 0.7577 | RMSE: 1.5177 | LR: 0.000995\n",
      "保存基于R2的最佳浓度模型，R2: 0.7577\n",
      "浓度模型 Epoch 023/500 | 训练损失: 1.7947 | 验证损失: 1.3378 | R2: 0.7640 | RMSE: 1.4978 | LR: 0.000995\n",
      "保存基于R2的最佳浓度模型，R2: 0.7640\n",
      "浓度模型 Epoch 024/500 | 训练损失: 1.4885 | 验证损失: 1.2428 | R2: 0.7809 | RMSE: 1.4430 | LR: 0.000994\n",
      "保存基于R2的最佳浓度模型，R2: 0.7809\n",
      "浓度模型 Epoch 025/500 | 训练损失: 1.4311 | 验证损失: 1.2017 | R2: 0.7881 | RMSE: 1.4189 | LR: 0.000994\n",
      "保存基于R2的最佳浓度模型，R2: 0.7881\n",
      "浓度模型 Epoch 026/500 | 训练损失: 1.3543 | 验证损失: 1.1016 | R2: 0.8058 | RMSE: 1.3581 | LR: 0.000993\n",
      "保存基于R2的最佳浓度模型，R2: 0.8058\n",
      "浓度模型 Epoch 027/500 | 训练损失: 1.3110 | 验证损失: 1.0352 | R2: 0.8175 | RMSE: 1.3162 | LR: 0.000993\n",
      "保存基于R2的最佳浓度模型，R2: 0.8175\n",
      "浓度模型 Epoch 028/500 | 训练损失: 1.2659 | 验证损失: 1.0191 | R2: 0.8204 | RMSE: 1.3055 | LR: 0.000992\n",
      "保存基于R2的最佳浓度模型，R2: 0.8204\n",
      "浓度模型 Epoch 029/500 | 训练损失: 1.2514 | 验证损失: 0.9601 | R2: 0.8307 | RMSE: 1.2670 | LR: 0.000992\n",
      "保存基于R2的最佳浓度模型，R2: 0.8307\n",
      "浓度模型 Epoch 030/500 | 训练损失: 1.1444 | 验证损失: 0.8689 | R2: 0.8469 | RMSE: 1.2043 | LR: 0.000991\n",
      "保存基于R2的最佳浓度模型，R2: 0.8469\n",
      "浓度模型 Epoch 031/500 | 训练损失: 1.1002 | 验证损失: 0.8189 | R2: 0.8558 | RMSE: 1.1690 | LR: 0.000991\n",
      "保存基于R2的最佳浓度模型，R2: 0.8558\n",
      "浓度模型 Epoch 032/500 | 训练损失: 1.0890 | 验证损失: 0.7823 | R2: 0.8623 | RMSE: 1.1418 | LR: 0.000990\n",
      "保存基于R2的最佳浓度模型，R2: 0.8623\n",
      "浓度模型 Epoch 033/500 | 训练损失: 1.0034 | 验证损失: 0.7808 | R2: 0.8626 | RMSE: 1.1395 | LR: 0.000989\n",
      "保存基于R2的最佳浓度模型，R2: 0.8626\n",
      "浓度模型 Epoch 034/500 | 训练损失: 0.9634 | 验证损失: 0.7071 | R2: 0.8755 | RMSE: 1.0846 | LR: 0.000989\n",
      "保存基于R2的最佳浓度模型，R2: 0.8755\n",
      "浓度模型 Epoch 035/500 | 训练损失: 0.9304 | 验证损失: 0.6650 | R2: 0.8830 | RMSE: 1.0512 | LR: 0.000988\n",
      "保存基于R2的最佳浓度模型，R2: 0.8830\n",
      "浓度模型 Epoch 036/500 | 训练损失: 0.8899 | 验证损失: 0.6467 | R2: 0.8862 | RMSE: 1.0366 | LR: 0.000987\n",
      "保存基于R2的最佳浓度模型，R2: 0.8862\n",
      "浓度模型 Epoch 037/500 | 训练损失: 0.8624 | 验证损失: 0.6071 | R2: 0.8932 | RMSE: 1.0042 | LR: 0.000987\n",
      "保存基于R2的最佳浓度模型，R2: 0.8932\n",
      "浓度模型 Epoch 038/500 | 训练损失: 0.8339 | 验证损失: 0.6367 | R2: 0.8880 | RMSE: 1.0282 | LR: 0.000986\n",
      "浓度模型 Epoch 039/500 | 训练损失: 0.8563 | 验证损失: 0.6559 | R2: 0.8843 | RMSE: 1.0449 | LR: 0.000985\n",
      "浓度模型 Epoch 040/500 | 训练损失: 0.8016 | 验证损失: 0.6090 | R2: 0.8929 | RMSE: 1.0054 | LR: 0.000984\n",
      "浓度模型 Epoch 041/500 | 训练损失: 0.8266 | 验证损失: 0.6599 | R2: 0.8839 | RMSE: 1.0482 | LR: 0.000984\n",
      "浓度模型 Epoch 042/500 | 训练损失: 0.8456 | 验证损失: 0.6094 | R2: 0.8927 | RMSE: 1.0069 | LR: 0.000983\n",
      "浓度模型 Epoch 043/500 | 训练损失: 0.7655 | 验证损失: 0.5221 | R2: 0.9082 | RMSE: 0.9298 | LR: 0.000982\n",
      "保存基于R2的最佳浓度模型，R2: 0.9082\n",
      "浓度模型 Epoch 044/500 | 训练损失: 0.7409 | 验证损失: 0.5555 | R2: 0.9022 | RMSE: 0.9599 | LR: 0.000981\n",
      "浓度模型 Epoch 045/500 | 训练损失: 0.7232 | 验证损失: 0.5288 | R2: 0.9071 | RMSE: 0.9357 | LR: 0.000980\n",
      "浓度模型 Epoch 046/500 | 训练损失: 0.7220 | 验证损失: 0.4681 | R2: 0.9177 | RMSE: 0.8795 | LR: 0.000979\n",
      "保存基于R2的最佳浓度模型，R2: 0.9177\n",
      "浓度模型 Epoch 047/500 | 训练损失: 0.6936 | 验证损失: 0.4546 | R2: 0.9201 | RMSE: 0.8661 | LR: 0.000978\n",
      "保存基于R2的最佳浓度模型，R2: 0.9201\n",
      "浓度模型 Epoch 048/500 | 训练损失: 0.6763 | 验证损失: 0.4555 | R2: 0.9200 | RMSE: 0.8672 | LR: 0.000977\n",
      "浓度模型 Epoch 049/500 | 训练损失: 0.6652 | 验证损失: 0.4441 | R2: 0.9220 | RMSE: 0.8562 | LR: 0.000976\n",
      "保存基于R2的最佳浓度模型，R2: 0.9220\n",
      "浓度模型 Epoch 050/500 | 训练损失: 0.6431 | 验证损失: 0.4263 | R2: 0.9250 | RMSE: 0.8384 | LR: 0.000976\n",
      "保存基于R2的最佳浓度模型，R2: 0.9250\n",
      "浓度模型 Epoch 051/500 | 训练损失: 0.6477 | 验证损失: 0.4415 | R2: 0.9224 | RMSE: 0.8535 | LR: 0.000975\n",
      "浓度模型 Epoch 052/500 | 训练损失: 0.6656 | 验证损失: 0.4403 | R2: 0.9227 | RMSE: 0.8525 | LR: 0.000974\n",
      "浓度模型 Epoch 053/500 | 训练损失: 0.6411 | 验证损失: 0.4229 | R2: 0.9258 | RMSE: 0.8348 | LR: 0.000973\n",
      "保存基于R2的最佳浓度模型，R2: 0.9258\n",
      "浓度模型 Epoch 054/500 | 训练损失: 0.6279 | 验证损失: 0.3925 | R2: 0.9310 | RMSE: 0.8038 | LR: 0.000971\n",
      "保存基于R2的最佳浓度模型，R2: 0.9310\n",
      "浓度模型 Epoch 055/500 | 训练损失: 0.6175 | 验证损失: 0.3889 | R2: 0.9317 | RMSE: 0.7995 | LR: 0.000970\n",
      "保存基于R2的最佳浓度模型，R2: 0.9317\n",
      "浓度模型 Epoch 056/500 | 训练损失: 0.6109 | 验证损失: 0.3751 | R2: 0.9342 | RMSE: 0.7853 | LR: 0.000969\n",
      "保存基于R2的最佳浓度模型，R2: 0.9342\n",
      "浓度模型 Epoch 057/500 | 训练损失: 0.5867 | 验证损失: 0.3628 | R2: 0.9363 | RMSE: 0.7716 | LR: 0.000968\n",
      "保存基于R2的最佳浓度模型，R2: 0.9363\n",
      "浓度模型 Epoch 058/500 | 训练损失: 0.5849 | 验证损失: 0.4010 | R2: 0.9296 | RMSE: 0.8129 | LR: 0.000967\n",
      "浓度模型 Epoch 059/500 | 训练损失: 0.5811 | 验证损失: 0.3776 | R2: 0.9337 | RMSE: 0.7885 | LR: 0.000966\n",
      "浓度模型 Epoch 060/500 | 训练损失: 0.7651 | 验证损失: 0.3370 | R2: 0.9409 | RMSE: 0.7430 | LR: 0.000965\n",
      "保存基于R2的最佳浓度模型，R2: 0.9409\n",
      "浓度模型 Epoch 061/500 | 训练损失: 0.5605 | 验证损失: 0.3333 | R2: 0.9415 | RMSE: 0.7382 | LR: 0.000964\n",
      "保存基于R2的最佳浓度模型，R2: 0.9415\n",
      "浓度模型 Epoch 062/500 | 训练损失: 0.5463 | 验证损失: 0.3311 | R2: 0.9418 | RMSE: 0.7364 | LR: 0.000963\n",
      "保存基于R2的最佳浓度模型，R2: 0.9418\n",
      "浓度模型 Epoch 063/500 | 训练损失: 0.5540 | 验证损失: 0.3543 | R2: 0.9378 | RMSE: 0.7612 | LR: 0.000961\n",
      "浓度模型 Epoch 064/500 | 训练损失: 0.5459 | 验证损失: 0.3451 | R2: 0.9394 | RMSE: 0.7523 | LR: 0.000960\n",
      "浓度模型 Epoch 065/500 | 训练损失: 0.5190 | 验证损失: 0.3211 | R2: 0.9436 | RMSE: 0.7246 | LR: 0.000959\n",
      "保存基于R2的最佳浓度模型，R2: 0.9436\n",
      "浓度模型 Epoch 066/500 | 训练损失: 0.5136 | 验证损失: 0.3642 | R2: 0.9360 | RMSE: 0.7746 | LR: 0.000958\n",
      "浓度模型 Epoch 067/500 | 训练损失: 0.5244 | 验证损失: 0.3247 | R2: 0.9430 | RMSE: 0.7298 | LR: 0.000956\n",
      "浓度模型 Epoch 068/500 | 训练损失: 0.5468 | 验证损失: 0.2866 | R2: 0.9497 | RMSE: 0.6824 | LR: 0.000955\n",
      "保存基于R2的最佳浓度模型，R2: 0.9497\n",
      "浓度模型 Epoch 069/500 | 训练损失: 0.4955 | 验证损失: 0.2886 | R2: 0.9493 | RMSE: 0.6856 | LR: 0.000954\n",
      "浓度模型 Epoch 070/500 | 训练损失: 0.4968 | 验证损失: 0.2971 | R2: 0.9478 | RMSE: 0.6972 | LR: 0.000952\n",
      "浓度模型 Epoch 071/500 | 训练损失: 0.4877 | 验证损失: 0.2931 | R2: 0.9486 | RMSE: 0.6913 | LR: 0.000951\n",
      "浓度模型 Epoch 072/500 | 训练损失: 0.5084 | 验证损失: 0.2853 | R2: 0.9498 | RMSE: 0.6821 | LR: 0.000950\n",
      "保存基于R2的最佳浓度模型，R2: 0.9498\n",
      "浓度模型 Epoch 073/500 | 训练损失: 0.4773 | 验证损失: 0.2806 | R2: 0.9507 | RMSE: 0.6760 | LR: 0.000948\n",
      "保存基于R2的最佳浓度模型，R2: 0.9507\n",
      "浓度模型 Epoch 074/500 | 训练损失: 0.4858 | 验证损失: 0.2786 | R2: 0.9511 | RMSE: 0.6742 | LR: 0.000947\n",
      "保存基于R2的最佳浓度模型，R2: 0.9511\n",
      "浓度模型 Epoch 075/500 | 训练损失: 0.4652 | 验证损失: 0.2720 | R2: 0.9523 | RMSE: 0.6660 | LR: 0.000946\n",
      "保存基于R2的最佳浓度模型，R2: 0.9523\n",
      "浓度模型 Epoch 076/500 | 训练损失: 0.4522 | 验证损失: 0.2850 | R2: 0.9500 | RMSE: 0.6821 | LR: 0.000944\n",
      "浓度模型 Epoch 077/500 | 训练损失: 0.4564 | 验证损失: 0.2608 | R2: 0.9542 | RMSE: 0.6518 | LR: 0.000943\n",
      "保存基于R2的最佳浓度模型，R2: 0.9542\n",
      "浓度模型 Epoch 078/500 | 训练损失: 0.4621 | 验证损失: 0.2546 | R2: 0.9553 | RMSE: 0.6430 | LR: 0.000941\n",
      "保存基于R2的最佳浓度模型，R2: 0.9553\n",
      "浓度模型 Epoch 079/500 | 训练损失: 0.4488 | 验证损失: 0.2503 | R2: 0.9560 | RMSE: 0.6381 | LR: 0.000940\n",
      "保存基于R2的最佳浓度模型，R2: 0.9560\n",
      "浓度模型 Epoch 080/500 | 训练损失: 0.4383 | 验证损失: 0.2396 | R2: 0.9579 | RMSE: 0.6225 | LR: 0.000938\n",
      "保存基于R2的最佳浓度模型，R2: 0.9579\n",
      "浓度模型 Epoch 081/500 | 训练损失: 0.4378 | 验证损失: 0.2373 | R2: 0.9583 | RMSE: 0.6204 | LR: 0.000937\n",
      "保存基于R2的最佳浓度模型，R2: 0.9583\n",
      "浓度模型 Epoch 082/500 | 训练损失: 0.4349 | 验证损失: 0.2264 | R2: 0.9603 | RMSE: 0.6047 | LR: 0.000935\n",
      "保存基于R2的最佳浓度模型，R2: 0.9603\n",
      "浓度模型 Epoch 083/500 | 训练损失: 0.4238 | 验证损失: 0.2201 | R2: 0.9614 | RMSE: 0.5964 | LR: 0.000934\n",
      "保存基于R2的最佳浓度模型，R2: 0.9614\n",
      "浓度模型 Epoch 084/500 | 训练损失: 0.4294 | 验证损失: 0.2740 | R2: 0.9519 | RMSE: 0.6640 | LR: 0.000932\n",
      "浓度模型 Epoch 085/500 | 训练损失: 0.4334 | 验证损失: 0.2487 | R2: 0.9563 | RMSE: 0.6361 | LR: 0.000930\n",
      "浓度模型 Epoch 086/500 | 训练损失: 0.4256 | 验证损失: 0.2283 | R2: 0.9599 | RMSE: 0.6075 | LR: 0.000929\n",
      "浓度模型 Epoch 087/500 | 训练损失: 0.4175 | 验证损失: 0.2162 | R2: 0.9620 | RMSE: 0.5905 | LR: 0.000927\n",
      "保存基于R2的最佳浓度模型，R2: 0.9620\n",
      "浓度模型 Epoch 088/500 | 训练损失: 0.4091 | 验证损失: 0.2340 | R2: 0.9589 | RMSE: 0.6167 | LR: 0.000925\n",
      "浓度模型 Epoch 089/500 | 训练损失: 0.4158 | 验证损失: 0.2237 | R2: 0.9607 | RMSE: 0.6008 | LR: 0.000924\n",
      "浓度模型 Epoch 090/500 | 训练损失: 0.4209 | 验证损失: 0.2092 | R2: 0.9633 | RMSE: 0.5802 | LR: 0.000922\n",
      "保存基于R2的最佳浓度模型，R2: 0.9633\n",
      "浓度模型 Epoch 091/500 | 训练损失: 0.4068 | 验证损失: 0.2143 | R2: 0.9624 | RMSE: 0.5868 | LR: 0.000920\n",
      "浓度模型 Epoch 092/500 | 训练损失: 0.4247 | 验证损失: 0.2120 | R2: 0.9628 | RMSE: 0.5851 | LR: 0.000919\n",
      "浓度模型 Epoch 093/500 | 训练损失: 0.4404 | 验证损失: 0.3537 | R2: 0.9373 | RMSE: 0.7643 | LR: 0.000917\n",
      "浓度模型 Epoch 094/500 | 训练损失: 0.4897 | 验证损失: 0.2368 | R2: 0.9583 | RMSE: 0.6205 | LR: 0.000915\n",
      "浓度模型 Epoch 095/500 | 训练损失: 0.4367 | 验证损失: 0.2823 | R2: 0.9501 | RMSE: 0.6797 | LR: 0.000914\n",
      "浓度模型 Epoch 096/500 | 训练损失: 0.4116 | 验证损失: 0.2075 | R2: 0.9636 | RMSE: 0.5789 | LR: 0.000912\n",
      "保存基于R2的最佳浓度模型，R2: 0.9636\n",
      "浓度模型 Epoch 097/500 | 训练损失: 0.3846 | 验证损失: 0.1977 | R2: 0.9653 | RMSE: 0.5637 | LR: 0.000910\n",
      "保存基于R2的最佳浓度模型，R2: 0.9653\n",
      "浓度模型 Epoch 098/500 | 训练损失: 0.4072 | 验证损失: 0.2134 | R2: 0.9625 | RMSE: 0.5878 | LR: 0.000908\n",
      "浓度模型 Epoch 099/500 | 训练损失: 0.3901 | 验证损失: 0.2039 | R2: 0.9643 | RMSE: 0.5739 | LR: 0.000906\n",
      "浓度模型 Epoch 100/500 | 训练损失: 0.3802 | 验证损失: 0.1945 | R2: 0.9659 | RMSE: 0.5598 | LR: 0.000905\n",
      "保存基于R2的最佳浓度模型，R2: 0.9659\n",
      "浓度模型 Epoch 101/500 | 训练损失: 0.3940 | 验证损失: 0.1994 | R2: 0.9649 | RMSE: 0.5670 | LR: 0.000903\n",
      "浓度模型 Epoch 102/500 | 训练损失: 0.3804 | 验证损失: 0.2084 | R2: 0.9633 | RMSE: 0.5816 | LR: 0.000901\n",
      "浓度模型 Epoch 103/500 | 训练损失: 0.3776 | 验证损失: 0.1992 | R2: 0.9650 | RMSE: 0.5669 | LR: 0.000899\n",
      "浓度模型 Epoch 104/500 | 训练损失: 0.3742 | 验证损失: 0.2018 | R2: 0.9645 | RMSE: 0.5707 | LR: 0.000897\n",
      "浓度模型 Epoch 105/500 | 训练损失: 0.3711 | 验证损失: 0.1973 | R2: 0.9653 | RMSE: 0.5647 | LR: 0.000895\n",
      "浓度模型 Epoch 106/500 | 训练损失: 0.3671 | 验证损失: 0.1863 | R2: 0.9673 | RMSE: 0.5474 | LR: 0.000893\n",
      "保存基于R2的最佳浓度模型，R2: 0.9673\n",
      "浓度模型 Epoch 107/500 | 训练损失: 0.3902 | 验证损失: 0.1972 | R2: 0.9654 | RMSE: 0.5646 | LR: 0.000891\n",
      "浓度模型 Epoch 108/500 | 训练损失: 0.3739 | 验证损失: 0.1943 | R2: 0.9658 | RMSE: 0.5605 | LR: 0.000889\n",
      "浓度模型 Epoch 109/500 | 训练损失: 0.3632 | 验证损失: 0.1854 | R2: 0.9675 | RMSE: 0.5454 | LR: 0.000887\n",
      "保存基于R2的最佳浓度模型，R2: 0.9675\n",
      "浓度模型 Epoch 110/500 | 训练损失: 0.3635 | 验证损失: 0.1794 | R2: 0.9685 | RMSE: 0.5366 | LR: 0.000885\n",
      "保存基于R2的最佳浓度模型，R2: 0.9685\n",
      "浓度模型 Epoch 111/500 | 训练损失: 0.3574 | 验证损失: 0.1924 | R2: 0.9662 | RMSE: 0.5581 | LR: 0.000883\n",
      "浓度模型 Epoch 112/500 | 训练损失: 0.3644 | 验证损失: 0.2175 | R2: 0.9616 | RMSE: 0.5955 | LR: 0.000881\n",
      "浓度模型 Epoch 113/500 | 训练损失: 0.3746 | 验证损失: 0.1875 | R2: 0.9671 | RMSE: 0.5500 | LR: 0.000879\n",
      "浓度模型 Epoch 114/500 | 训练损失: 0.3632 | 验证损失: 0.2094 | R2: 0.9632 | RMSE: 0.5828 | LR: 0.000877\n",
      "浓度模型 Epoch 115/500 | 训练损失: 0.3656 | 验证损失: 0.2021 | R2: 0.9645 | RMSE: 0.5722 | LR: 0.000875\n",
      "浓度模型 Epoch 116/500 | 训练损失: 0.3682 | 验证损失: 0.1865 | R2: 0.9672 | RMSE: 0.5482 | LR: 0.000873\n",
      "浓度模型 Epoch 117/500 | 训练损失: 0.3586 | 验证损失: 0.1833 | R2: 0.9678 | RMSE: 0.5438 | LR: 0.000871\n",
      "浓度模型 Epoch 118/500 | 训练损失: 0.3751 | 验证损失: 0.1997 | R2: 0.9649 | RMSE: 0.5692 | LR: 0.000869\n",
      "浓度模型 Epoch 119/500 | 训练损失: 0.3726 | 验证损失: 0.1826 | R2: 0.9679 | RMSE: 0.5430 | LR: 0.000867\n",
      "浓度模型 Epoch 120/500 | 训练损失: 0.3511 | 验证损失: 0.1884 | R2: 0.9669 | RMSE: 0.5519 | LR: 0.000864\n",
      "浓度模型 Epoch 121/500 | 训练损失: 0.3473 | 验证损失: 0.1737 | R2: 0.9695 | RMSE: 0.5291 | LR: 0.000862\n",
      "保存基于R2的最佳浓度模型，R2: 0.9695\n",
      "浓度模型 Epoch 122/500 | 训练损失: 0.3500 | 验证损失: 0.1713 | R2: 0.9699 | RMSE: 0.5256 | LR: 0.000860\n",
      "保存基于R2的最佳浓度模型，R2: 0.9699\n",
      "浓度模型 Epoch 123/500 | 训练损失: 0.5123 | 验证损失: 0.1790 | R2: 0.9685 | RMSE: 0.5385 | LR: 0.000858\n",
      "浓度模型 Epoch 124/500 | 训练损失: 0.3445 | 验证损失: 0.1799 | R2: 0.9684 | RMSE: 0.5386 | LR: 0.000856\n",
      "浓度模型 Epoch 125/500 | 训练损失: 0.3530 | 验证损失: 0.1947 | R2: 0.9657 | RMSE: 0.5627 | LR: 0.000854\n",
      "浓度模型 Epoch 126/500 | 训练损失: 0.3519 | 验证损失: 0.1664 | R2: 0.9708 | RMSE: 0.5175 | LR: 0.000851\n",
      "保存基于R2的最佳浓度模型，R2: 0.9708\n",
      "浓度模型 Epoch 127/500 | 训练损失: 0.3377 | 验证损失: 0.1796 | R2: 0.9685 | RMSE: 0.5388 | LR: 0.000849\n",
      "浓度模型 Epoch 128/500 | 训练损失: 0.3447 | 验证损失: 0.1661 | R2: 0.9708 | RMSE: 0.5170 | LR: 0.000847\n",
      "保存基于R2的最佳浓度模型，R2: 0.9708\n",
      "浓度模型 Epoch 129/500 | 训练损失: 0.3360 | 验证损失: 0.1824 | R2: 0.9679 | RMSE: 0.5435 | LR: 0.000845\n",
      "浓度模型 Epoch 130/500 | 训练损失: 0.3345 | 验证损失: 0.1869 | R2: 0.9671 | RMSE: 0.5504 | LR: 0.000842\n",
      "浓度模型 Epoch 131/500 | 训练损失: 0.3401 | 验证损失: 0.2117 | R2: 0.9626 | RMSE: 0.5882 | LR: 0.000840\n",
      "浓度模型 Epoch 132/500 | 训练损失: 0.4175 | 验证损失: 0.1807 | R2: 0.9683 | RMSE: 0.5414 | LR: 0.000838\n",
      "浓度模型 Epoch 133/500 | 训练损失: 0.3989 | 验证损失: 0.1855 | R2: 0.9674 | RMSE: 0.5487 | LR: 0.000835\n",
      "浓度模型 Epoch 134/500 | 训练损失: 0.3330 | 验证损失: 0.1734 | R2: 0.9695 | RMSE: 0.5298 | LR: 0.000833\n",
      "浓度模型 Epoch 135/500 | 训练损失: 0.3300 | 验证损失: 0.1657 | R2: 0.9708 | RMSE: 0.5174 | LR: 0.000831\n",
      "保存基于R2的最佳浓度模型，R2: 0.9708\n",
      "浓度模型 Epoch 136/500 | 训练损失: 0.3221 | 验证损失: 0.1614 | R2: 0.9716 | RMSE: 0.5093 | LR: 0.000828\n",
      "保存基于R2的最佳浓度模型，R2: 0.9716\n",
      "浓度模型 Epoch 137/500 | 训练损失: 0.3254 | 验证损失: 0.1658 | R2: 0.9709 | RMSE: 0.5174 | LR: 0.000826\n",
      "浓度模型 Epoch 138/500 | 训练损失: 0.3195 | 验证损失: 0.1574 | R2: 0.9723 | RMSE: 0.5044 | LR: 0.000824\n",
      "保存基于R2的最佳浓度模型，R2: 0.9723\n",
      "浓度模型 Epoch 139/500 | 训练损失: 0.3179 | 验证损失: 0.1577 | R2: 0.9723 | RMSE: 0.5048 | LR: 0.000821\n",
      "浓度模型 Epoch 140/500 | 训练损失: 0.3241 | 验证损失: 0.1636 | R2: 0.9712 | RMSE: 0.5140 | LR: 0.000819\n",
      "浓度模型 Epoch 141/500 | 训练损失: 0.4762 | 验证损失: 0.1637 | R2: 0.9713 | RMSE: 0.5147 | LR: 0.000816\n",
      "浓度模型 Epoch 142/500 | 训练损失: 0.3172 | 验证损失: 0.1705 | R2: 0.9700 | RMSE: 0.5257 | LR: 0.000814\n",
      "浓度模型 Epoch 143/500 | 训练损失: 0.3178 | 验证损失: 0.1640 | R2: 0.9712 | RMSE: 0.5148 | LR: 0.000811\n",
      "浓度模型 Epoch 144/500 | 训练损失: 0.3237 | 验证损失: 0.1920 | R2: 0.9662 | RMSE: 0.5598 | LR: 0.000809\n",
      "浓度模型 Epoch 145/500 | 训练损失: 0.3202 | 验证损失: 0.1601 | R2: 0.9718 | RMSE: 0.5095 | LR: 0.000806\n",
      "浓度模型 Epoch 146/500 | 训练损失: 0.3092 | 验证损失: 0.1566 | R2: 0.9724 | RMSE: 0.5030 | LR: 0.000804\n",
      "保存基于R2的最佳浓度模型，R2: 0.9724\n",
      "浓度模型 Epoch 147/500 | 训练损失: 0.3201 | 验证损失: 0.1649 | R2: 0.9710 | RMSE: 0.5175 | LR: 0.000801\n",
      "浓度模型 Epoch 148/500 | 训练损失: 0.3108 | 验证损失: 0.1601 | R2: 0.9718 | RMSE: 0.5092 | LR: 0.000799\n",
      "浓度模型 Epoch 149/500 | 训练损失: 0.3125 | 验证损失: 0.1615 | R2: 0.9716 | RMSE: 0.5115 | LR: 0.000796\n",
      "浓度模型 Epoch 150/500 | 训练损失: 0.3037 | 验证损失: 0.1637 | R2: 0.9712 | RMSE: 0.5154 | LR: 0.000794\n",
      "浓度模型 Epoch 151/500 | 训练损失: 0.3082 | 验证损失: 0.1597 | R2: 0.9720 | RMSE: 0.5081 | LR: 0.000791\n",
      "浓度模型 Epoch 152/500 | 训练损失: 0.3018 | 验证损失: 0.1490 | R2: 0.9738 | RMSE: 0.4912 | LR: 0.000789\n",
      "保存基于R2的最佳浓度模型，R2: 0.9738\n",
      "浓度模型 Epoch 153/500 | 训练损失: 0.3245 | 验证损失: 0.2048 | R2: 0.9638 | RMSE: 0.5797 | LR: 0.000786\n",
      "浓度模型 Epoch 154/500 | 训练损失: 0.3312 | 验证损失: 0.1592 | R2: 0.9720 | RMSE: 0.5084 | LR: 0.000784\n",
      "浓度模型 Epoch 155/500 | 训练损失: 0.3042 | 验证损失: 0.1533 | R2: 0.9731 | RMSE: 0.4980 | LR: 0.000781\n",
      "浓度模型 Epoch 156/500 | 训练损失: 0.3029 | 验证损失: 0.1671 | R2: 0.9706 | RMSE: 0.5225 | LR: 0.000778\n",
      "浓度模型 Epoch 157/500 | 训练损失: 0.3035 | 验证损失: 0.1893 | R2: 0.9666 | RMSE: 0.5579 | LR: 0.000776\n",
      "浓度模型 Epoch 158/500 | 训练损失: 0.3108 | 验证损失: 0.1836 | R2: 0.9677 | RMSE: 0.5487 | LR: 0.000773\n",
      "浓度模型 Epoch 159/500 | 训练损失: 0.3177 | 验证损失: 0.1532 | R2: 0.9731 | RMSE: 0.4973 | LR: 0.000771\n",
      "浓度模型 Epoch 160/500 | 训练损失: 0.2957 | 验证损失: 0.1695 | R2: 0.9702 | RMSE: 0.5257 | LR: 0.000768\n",
      "浓度模型 Epoch 161/500 | 训练损失: 0.2969 | 验证损失: 0.1646 | R2: 0.9711 | RMSE: 0.5182 | LR: 0.000765\n",
      "浓度模型 Epoch 162/500 | 训练损失: 0.3036 | 验证损失: 0.1556 | R2: 0.9727 | RMSE: 0.5026 | LR: 0.000763\n",
      "浓度模型 Epoch 163/500 | 训练损失: 0.2941 | 验证损失: 0.1540 | R2: 0.9729 | RMSE: 0.5001 | LR: 0.000760\n",
      "浓度模型 Epoch 164/500 | 训练损失: 0.3498 | 验证损失: 0.1514 | R2: 0.9733 | RMSE: 0.4959 | LR: 0.000757\n",
      "浓度模型 Epoch 165/500 | 训练损失: 0.2915 | 验证损失: 0.1492 | R2: 0.9738 | RMSE: 0.4923 | LR: 0.000755\n",
      "浓度模型 Epoch 166/500 | 训练损失: 0.2915 | 验证损失: 0.1448 | R2: 0.9746 | RMSE: 0.4844 | LR: 0.000752\n",
      "保存基于R2的最佳浓度模型，R2: 0.9746\n",
      "浓度模型 Epoch 167/500 | 训练损失: 0.2892 | 验证损失: 0.1563 | R2: 0.9725 | RMSE: 0.5043 | LR: 0.000749\n",
      "浓度模型 Epoch 168/500 | 训练损失: 0.2932 | 验证损失: 0.1679 | R2: 0.9704 | RMSE: 0.5239 | LR: 0.000746\n",
      "浓度模型 Epoch 169/500 | 训练损失: 0.2947 | 验证损失: 0.1460 | R2: 0.9743 | RMSE: 0.4868 | LR: 0.000744\n",
      "浓度模型 Epoch 170/500 | 训练损失: 0.4421 | 验证损失: 0.1582 | R2: 0.9722 | RMSE: 0.5079 | LR: 0.000741\n",
      "浓度模型 Epoch 171/500 | 训练损失: 0.2923 | 验证损失: 0.1558 | R2: 0.9726 | RMSE: 0.5040 | LR: 0.000738\n",
      "浓度模型 Epoch 172/500 | 训练损失: 0.2897 | 验证损失: 0.1561 | R2: 0.9725 | RMSE: 0.5042 | LR: 0.000735\n",
      "浓度模型 Epoch 173/500 | 训练损失: 0.2822 | 验证损失: 0.1567 | R2: 0.9724 | RMSE: 0.5054 | LR: 0.000733\n",
      "浓度模型 Epoch 174/500 | 训练损失: 0.2971 | 验证损失: 0.1599 | R2: 0.9719 | RMSE: 0.5108 | LR: 0.000730\n",
      "浓度模型 Epoch 175/500 | 训练损失: 0.2880 | 验证损失: 0.1530 | R2: 0.9731 | RMSE: 0.4996 | LR: 0.000727\n",
      "浓度模型 Epoch 176/500 | 训练损失: 0.2958 | 验证损失: 0.1598 | R2: 0.9718 | RMSE: 0.5111 | LR: 0.000724\n",
      "浓度模型 Epoch 177/500 | 训练损失: 0.2896 | 验证损失: 0.1575 | R2: 0.9723 | RMSE: 0.5060 | LR: 0.000721\n",
      "浓度模型 Epoch 178/500 | 训练损失: 0.2819 | 验证损失: 0.1481 | R2: 0.9739 | RMSE: 0.4915 | LR: 0.000719\n",
      "浓度模型 Epoch 179/500 | 训练损失: 0.2815 | 验证损失: 0.1412 | R2: 0.9752 | RMSE: 0.4791 | LR: 0.000716\n",
      "保存基于R2的最佳浓度模型，R2: 0.9752\n",
      "浓度模型 Epoch 180/500 | 训练损失: 0.2802 | 验证损失: 0.1436 | R2: 0.9747 | RMSE: 0.4836 | LR: 0.000713\n",
      "浓度模型 Epoch 181/500 | 训练损失: 0.2839 | 验证损失: 0.1581 | R2: 0.9722 | RMSE: 0.5080 | LR: 0.000710\n",
      "浓度模型 Epoch 182/500 | 训练损失: 0.2757 | 验证损失: 0.1461 | R2: 0.9743 | RMSE: 0.4879 | LR: 0.000707\n",
      "浓度模型 Epoch 183/500 | 训练损失: 0.2789 | 验证损失: 0.1565 | R2: 0.9725 | RMSE: 0.5061 | LR: 0.000704\n",
      "浓度模型 Epoch 184/500 | 训练损失: 0.2813 | 验证损失: 0.1645 | R2: 0.9710 | RMSE: 0.5198 | LR: 0.000701\n",
      "浓度模型 Epoch 185/500 | 训练损失: 0.2847 | 验证损失: 0.1499 | R2: 0.9736 | RMSE: 0.4950 | LR: 0.000699\n",
      "浓度模型 Epoch 186/500 | 训练损失: 0.2768 | 验证损失: 0.1410 | R2: 0.9752 | RMSE: 0.4798 | LR: 0.000696\n",
      "浓度模型 Epoch 187/500 | 训练损失: 0.2779 | 验证损失: 0.1530 | R2: 0.9731 | RMSE: 0.4999 | LR: 0.000693\n",
      "浓度模型 Epoch 188/500 | 训练损失: 0.2790 | 验证损失: 0.1463 | R2: 0.9742 | RMSE: 0.4890 | LR: 0.000690\n",
      "浓度模型 Epoch 189/500 | 训练损失: 0.2757 | 验证损失: 0.1512 | R2: 0.9734 | RMSE: 0.4969 | LR: 0.000687\n",
      "浓度模型 Epoch 190/500 | 训练损失: 0.2699 | 验证损失: 0.1465 | R2: 0.9742 | RMSE: 0.4898 | LR: 0.000684\n",
      "浓度模型 Epoch 191/500 | 训练损失: 0.3257 | 验证损失: 0.1427 | R2: 0.9749 | RMSE: 0.4822 | LR: 0.000681\n",
      "浓度模型 Epoch 192/500 | 训练损失: 0.2688 | 验证损失: 0.1450 | R2: 0.9745 | RMSE: 0.4865 | LR: 0.000678\n",
      "浓度模型 Epoch 193/500 | 训练损失: 0.2703 | 验证损失: 0.1397 | R2: 0.9754 | RMSE: 0.4773 | LR: 0.000675\n",
      "保存基于R2的最佳浓度模型，R2: 0.9754\n",
      "浓度模型 Epoch 194/500 | 训练损失: 0.2678 | 验证损失: 0.1415 | R2: 0.9751 | RMSE: 0.4809 | LR: 0.000672\n",
      "浓度模型 Epoch 195/500 | 训练损失: 0.2684 | 验证损失: 0.1647 | R2: 0.9710 | RMSE: 0.5203 | LR: 0.000669\n",
      "浓度模型 Epoch 196/500 | 训练损失: 0.4139 | 验证损失: 0.1386 | R2: 0.9756 | RMSE: 0.4766 | LR: 0.000666\n",
      "保存基于R2的最佳浓度模型，R2: 0.9756\n",
      "浓度模型 Epoch 197/500 | 训练损失: 0.2620 | 验证损失: 0.1430 | R2: 0.9748 | RMSE: 0.4832 | LR: 0.000663\n",
      "浓度模型 Epoch 198/500 | 训练损失: 0.2706 | 验证损失: 0.1460 | R2: 0.9743 | RMSE: 0.4887 | LR: 0.000660\n",
      "浓度模型 Epoch 199/500 | 训练损失: 0.2696 | 验证损失: 0.1437 | R2: 0.9747 | RMSE: 0.4848 | LR: 0.000657\n",
      "浓度模型 Epoch 200/500 | 训练损失: 0.2627 | 验证损失: 0.1396 | R2: 0.9754 | RMSE: 0.4781 | LR: 0.000655\n",
      "浓度模型 Epoch 201/500 | 训练损失: 0.2657 | 验证损失: 0.1385 | R2: 0.9756 | RMSE: 0.4760 | LR: 0.000652\n",
      "保存基于R2的最佳浓度模型，R2: 0.9756\n",
      "浓度模型 Epoch 202/500 | 训练损失: 0.2700 | 验证损失: 0.1590 | R2: 0.9720 | RMSE: 0.5103 | LR: 0.000649\n",
      "浓度模型 Epoch 203/500 | 训练损失: 0.2674 | 验证损失: 0.1364 | R2: 0.9760 | RMSE: 0.4721 | LR: 0.000646\n",
      "保存基于R2的最佳浓度模型，R2: 0.9760\n",
      "浓度模型 Epoch 204/500 | 训练损失: 0.2589 | 验证损失: 0.1430 | R2: 0.9748 | RMSE: 0.4843 | LR: 0.000643\n",
      "浓度模型 Epoch 205/500 | 训练损失: 0.2601 | 验证损失: 0.1524 | R2: 0.9731 | RMSE: 0.5003 | LR: 0.000639\n",
      "浓度模型 Epoch 206/500 | 训练损失: 0.2659 | 验证损失: 0.1372 | R2: 0.9758 | RMSE: 0.4738 | LR: 0.000636\n",
      "浓度模型 Epoch 207/500 | 训练损失: 0.2550 | 验证损失: 0.1422 | R2: 0.9750 | RMSE: 0.4825 | LR: 0.000633\n",
      "浓度模型 Epoch 208/500 | 训练损失: 0.2656 | 验证损失: 0.1351 | R2: 0.9762 | RMSE: 0.4701 | LR: 0.000630\n",
      "保存基于R2的最佳浓度模型，R2: 0.9762\n",
      "浓度模型 Epoch 209/500 | 训练损失: 0.2618 | 验证损失: 0.1332 | R2: 0.9766 | RMSE: 0.4673 | LR: 0.000627\n",
      "保存基于R2的最佳浓度模型，R2: 0.9766\n",
      "浓度模型 Epoch 210/500 | 训练损失: 0.2603 | 验证损失: 0.1428 | R2: 0.9749 | RMSE: 0.4824 | LR: 0.000624\n",
      "浓度模型 Epoch 211/500 | 训练损失: 0.2655 | 验证损失: 0.1427 | R2: 0.9749 | RMSE: 0.4838 | LR: 0.000621\n",
      "浓度模型 Epoch 212/500 | 训练损失: 0.2670 | 验证损失: 0.1331 | R2: 0.9766 | RMSE: 0.4660 | LR: 0.000618\n",
      "保存基于R2的最佳浓度模型，R2: 0.9766\n",
      "浓度模型 Epoch 213/500 | 训练损失: 0.2622 | 验证损失: 0.1372 | R2: 0.9759 | RMSE: 0.4733 | LR: 0.000615\n",
      "浓度模型 Epoch 214/500 | 训练损失: 0.2673 | 验证损失: 0.1442 | R2: 0.9746 | RMSE: 0.4855 | LR: 0.000612\n",
      "浓度模型 Epoch 215/500 | 训练损失: 0.2597 | 验证损失: 0.1393 | R2: 0.9755 | RMSE: 0.4776 | LR: 0.000609\n",
      "浓度模型 Epoch 216/500 | 训练损失: 0.2548 | 验证损失: 0.1442 | R2: 0.9746 | RMSE: 0.4864 | LR: 0.000606\n",
      "浓度模型 Epoch 217/500 | 训练损失: 0.2568 | 验证损失: 0.1357 | R2: 0.9761 | RMSE: 0.4707 | LR: 0.000603\n",
      "浓度模型 Epoch 218/500 | 训练损失: 0.2539 | 验证损失: 0.1381 | R2: 0.9757 | RMSE: 0.4758 | LR: 0.000600\n",
      "浓度模型 Epoch 219/500 | 训练损失: 0.2562 | 验证损失: 0.1440 | R2: 0.9746 | RMSE: 0.4862 | LR: 0.000597\n",
      "浓度模型 Epoch 220/500 | 训练损失: 0.2617 | 验证损失: 0.1385 | R2: 0.9756 | RMSE: 0.4764 | LR: 0.000594\n",
      "浓度模型 Epoch 221/500 | 训练损失: 0.2586 | 验证损失: 0.1410 | R2: 0.9752 | RMSE: 0.4808 | LR: 0.000591\n",
      "浓度模型 Epoch 222/500 | 训练损失: 0.2538 | 验证损失: 0.1444 | R2: 0.9745 | RMSE: 0.4870 | LR: 0.000588\n",
      "浓度模型 Epoch 223/500 | 训练损失: 0.2537 | 验证损失: 0.1405 | R2: 0.9753 | RMSE: 0.4796 | LR: 0.000584\n",
      "浓度模型 Epoch 224/500 | 训练损失: 0.2518 | 验证损失: 0.1376 | R2: 0.9758 | RMSE: 0.4749 | LR: 0.000581\n",
      "浓度模型 Epoch 225/500 | 训练损失: 0.2560 | 验证损失: 0.1472 | R2: 0.9741 | RMSE: 0.4912 | LR: 0.000578\n",
      "浓度模型 Epoch 226/500 | 训练损失: 0.2547 | 验证损失: 0.1405 | R2: 0.9753 | RMSE: 0.4799 | LR: 0.000575\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 训练模型\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m head_model, conc_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dual_cnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 评估模型（使用验证集）\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m开始最终评估（使用验证集）...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 489\u001b[0m, in \u001b[0;36mtrain_dual_cnn\u001b[0;34m(train_loader, val_loader, config)\u001b[0m\n\u001b[1;32m    486\u001b[0m X_conc \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([X_conc_base, pred_head], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# [B, T, 19, M, N]\u001b[39;00m\n\u001b[1;32m    488\u001b[0m conc_optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 489\u001b[0m pred_conc \u001b[38;5;241m=\u001b[39m \u001b[43mconc_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_conc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;66;03m# 应用掩码计算损失\u001b[39;00m\n\u001b[1;32m    492\u001b[0m loss_conc \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmse_loss(pred_conc \u001b[38;5;241m*\u001b[39m mask, Y_conc \u001b[38;5;241m*\u001b[39m mask)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[4], line 124\u001b[0m, in \u001b[0;36mConcCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 124\u001b[0m     layer_output, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m     b, t, c, h, w \u001b[38;5;241m=\u001b[39m layer_output\u001b[38;5;241m.\u001b[39msize()\n\u001b[1;32m    126\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m layer_output\u001b[38;5;241m.\u001b[39mview(b \u001b[38;5;241m*\u001b[39m t, c, h, w)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[4], line 87\u001b[0m, in \u001b[0;36mConvLSTM.forward\u001b[0;34m(self, input_tensor, hidden_state)\u001b[0m\n\u001b[1;32m     85\u001b[0m output_inner \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(t):\n\u001b[0;32m---> 87\u001b[0m     h, c \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcell_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcur_layer_input\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcur_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m     output_inner\u001b[38;5;241m.\u001b[39mappend(h)\n\u001b[1;32m     89\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(output_inner, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[4], line 37\u001b[0m, in \u001b[0;36mConvLSTMCell.forward\u001b[0;34m(self, input_tensor, cur_state)\u001b[0m\n\u001b[1;32m     35\u001b[0m h_cur, c_cur \u001b[38;5;241m=\u001b[39m cur_state\n\u001b[1;32m     36\u001b[0m combined \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([input_tensor, h_cur], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m combined_conv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m combined_conv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(combined_conv)\n\u001b[1;32m     39\u001b[0m cc_i, cc_f, cc_o, cc_g \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msplit(combined_conv, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_dim, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    548\u001b[0m     )\n\u001b[0;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "head_model, conc_model = train_dual_cnn(train_loader, val_loader, config)\n",
    "\n",
    "# 评估模型（使用验证集）\n",
    "print(\"\\n开始最终评估（使用验证集）...\")\n",
    "head_metrics, conc_metrics = evaluate_dual_cnn(val_loader, config)\n",
    "\n",
    "print(\"\\n🎉 CNN模型训练和评估完成！\")\n",
    "print(\"\\n📊 最终结果总结:\")\n",
    "print(f\"📈 水头模型 - R2: {head_metrics['r2']:.4f}, RMSE: {head_metrics['rmse']:.4f}\")\n",
    "print(f\"📈 浓度模型 - R2: {conc_metrics['r2']:.4f}, RMSE: {conc_metrics['rmse']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67477373-2613-474f-a289-d8dbed980878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    # 加载数据\n",
    "    cleaned_data = pd.read_csv('conc_dual_guass.csv')\n",
    "    print(\"数据统计:\")\n",
    "    print(cleaned_data[['head', 'concentration']].describe())\n",
    "    \n",
    "    # 检查必要的列\n",
    "    required_cols = [\n",
    "        'row', 'col', 'time_step', 'x', 'y', 'top', 'bottom', 'K', 'recharge', 'ET',\n",
    "        'river_stage', 'river_cond', 'river_rbot', 'well_rate', 'well_mask',\n",
    "        'chd_mask', 'lytyp', 'conc_mask', 'head', 'concentration', 'model_name'\n",
    "    ]\n",
    "    \n",
    "    missing_cols = [col for col in required_cols if col not in cleaned_data.columns]\n",
    "    if missing_cols:\n",
    "        raise KeyError(f\"缺少必要的列: {missing_cols}\")\n",
    "    \n",
    "    # 数据集参数\n",
    "    M = cleaned_data['row'].max() + 1\n",
    "    N = cleaned_data['col'].max() + 1\n",
    "    T = cleaned_data['time_step'].max() + 1 - cleaned_data['time_step'].min()\n",
    "    \n",
    "    print(f\"网格大小: {M} x {N}, 时间步数: {T}\")\n",
    "    \n",
    "    # 数据划分 - 与GNN保持一致的7:3划分\n",
    "    unique_models = cleaned_data['model_name'].unique()\n",
    "    print(f\"总模型数: {len(unique_models)}\")\n",
    "    \n",
    "    # 7:3 划分训练集和验证集（与GNN保持一致）\n",
    "    train_models, val_models = train_test_split(unique_models, test_size=0.3, random_state=42)\n",
    "    \n",
    "    train_data = cleaned_data[cleaned_data['model_name'].isin(train_models)]\n",
    "    val_data = cleaned_data[cleaned_data['model_name'].isin(val_models)]\n",
    "    \n",
    "    print(f\"训练集: {len(train_models)} 个模型 ({len(train_models)/len(unique_models)*100:.1f}%)\")\n",
    "    print(f\"验证集: {len(val_models)} 个模型 ({len(val_models)/len(unique_models)*100:.1f}%)\")\n",
    "    \n",
    "    # 创建数据集\n",
    "    train_dataset = HydroCNNDataset(train_data, (M, N), T)\n",
    "    val_dataset = HydroCNNDataset(val_data, (M, N), T)\n",
    "    \n",
    "    # 检查数据集是否为空\n",
    "    if len(train_dataset) == 0 or len(val_dataset) == 0:\n",
    "        print(\"错误: 某个数据集为空！\")\n",
    "        print(f\"训练集大小: {len(train_dataset)}\")\n",
    "        print(f\"验证集大小: {len(val_dataset)}\")\n",
    "        exit(1)\n",
    "    \n",
    "    # 创建数据加载器\n",
    "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=custom_collate_fn)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=4, collate_fn=custom_collate_fn)\n",
    "    \n",
    "    # 训练配置 - 与GNN保持一致\n",
    "    config = {\n",
    "        'hidden_dim': 96,        # 与GNN保持一致\n",
    "        'num_epochs': 500,\n",
    "        'lr': 1e-3,              # 与GNN保持一致\n",
    "        'weight_decay': 1e-4,\n",
    "        'patience': 30,\n",
    "        'save_path': './saved_models/cnn_dual_sequential',\n",
    "        'max_time_steps': T\n",
    "    }\n",
    "    \n",
    "    print(\"开始训练CNN模型...\")\n",
    "    print(f\"配置: {config}\")\n",
    "    \n",
    "    # 训练模型\n",
    "    head_model, conc_model = train_dual_cnn(train_loader, val_loader, config)\n",
    "    \n",
    "    # 评估模型（使用验证集）\n",
    "    print(\"\\n开始最终评估（使用验证集）...\")\n",
    "    head_metrics, conc_metrics = evaluate_dual_cnn(val_loader, config)\n",
    "    \n",
    "    print(\"\\n🎉 CNN模型训练和评估完成！\")\n",
    "    print(\"\\n📊 最终结果总结:\")\n",
    "    print(f\"📈 水头模型 - R2: {head_metrics['r2']:.4f}, RMSE: {head_metrics['rmse']:.4f}\")\n",
    "    print(f\"📈 浓度模型 - R2: {conc_metrics['r2']:.4f}, RMSE: {conc_metrics['rmse']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77b87422-7da9-4a91-864a-4f8ac19c864e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:2\n",
      "数据统计:\n",
      "               head  concentration\n",
      "count  5.328000e+06   5.328000e+06\n",
      "mean   9.752326e+01   3.256942e-01\n",
      "std    5.914362e+00   3.125932e+00\n",
      "min    7.999980e+01   0.000000e+00\n",
      "25%    9.476521e+01   0.000000e+00\n",
      "50%    9.840869e+01   1.826313e-13\n",
      "75%    1.010800e+02   7.200300e-06\n",
      "max    1.325345e+02   6.359028e+02\n",
      "网格大小: 30 x 50, 时间步数: 30\n",
      "总模型数: 100\n",
      "训练集: 70 个模型 (70.0%)\n",
      "验证集: 30 个模型 (30.0%)\n",
      "开始特征标准化...\n",
      "预处理CNN数据...\n",
      "处理模型 1/70: dual_93\n",
      "    处理时间步 0/30\n",
      "  模型 dual_93 处理完成\n",
      "处理模型 2/70: dual_71\n",
      "    处理时间步 0/30\n",
      "  模型 dual_71 处理完成\n",
      "处理模型 3/70: dual_31\n",
      "    处理时间步 0/30\n",
      "  模型 dual_31 处理完成\n",
      "处理模型 4/70: dual_15\n",
      "    处理时间步 0/30\n",
      "  模型 dual_15 处理完成\n",
      "处理模型 5/70: dual_88\n",
      "    处理时间步 0/30\n",
      "  模型 dual_88 处理完成\n",
      "处理模型 6/70: dual_40\n",
      "    处理时间步 0/30\n",
      "  模型 dual_40 处理完成\n",
      "处理模型 7/70: dual_20\n",
      "    处理时间步 0/30\n",
      "  模型 dual_20 处理完成\n",
      "处理模型 8/70: dual_84\n",
      "    处理时间步 0/30\n",
      "  模型 dual_84 处理完成\n",
      "处理模型 9/70: dual_10\n",
      "    处理时间步 0/30\n",
      "  模型 dual_10 处理完成\n",
      "处理模型 10/70: dual_21\n",
      "    处理时间步 0/30\n",
      "  模型 dual_21 处理完成\n",
      "处理模型 11/70: dual_29\n",
      "    处理时间步 0/30\n",
      "  模型 dual_29 处理完成\n",
      "处理模型 12/70: dual_49\n",
      "    处理时间步 0/30\n",
      "  模型 dual_49 处理完成\n",
      "处理模型 13/70: dual_23\n",
      "    处理时间步 0/30\n",
      "  模型 dual_23 处理完成\n",
      "处理模型 14/70: dual_61\n",
      "    处理时间步 0/30\n",
      "  模型 dual_61 处理完成\n",
      "处理模型 15/70: dual_68\n",
      "    处理时间步 0/30\n",
      "  模型 dual_68 处理完成\n",
      "处理模型 16/70: dual_66\n",
      "    处理时间步 0/30\n",
      "  模型 dual_66 处理完成\n",
      "处理模型 17/70: dual_17\n",
      "    处理时间步 0/30\n",
      "  模型 dual_17 处理完成\n",
      "处理模型 18/70: dual_51\n",
      "    处理时间步 0/30\n",
      "  模型 dual_51 处理完成\n",
      "处理模型 19/70: dual_48\n",
      "    处理时间步 0/30\n",
      "  模型 dual_48 处理完成\n",
      "处理模型 20/70: dual_34\n",
      "    处理时间步 0/30\n",
      "  模型 dual_34 处理完成\n",
      "处理模型 21/70: dual_47\n",
      "    处理时间步 0/30\n",
      "  模型 dual_47 处理完成\n",
      "处理模型 22/70: dual_67\n",
      "    处理时间步 0/30\n",
      "  模型 dual_67 处理完成\n",
      "处理模型 23/70: dual_55\n",
      "    处理时间步 0/30\n",
      "  模型 dual_55 处理完成\n",
      "处理模型 24/70: dual_87\n",
      "    处理时间步 0/30\n",
      "  模型 dual_87 处理完成\n",
      "处理模型 25/70: dual_90\n",
      "    处理时间步 0/30\n",
      "  模型 dual_90 处理完成\n",
      "处理模型 26/70: dual_8\n",
      "    处理时间步 0/30\n",
      "  模型 dual_8 处理完成\n",
      "处理模型 27/70: dual_6\n",
      "    处理时间步 0/30\n",
      "  模型 dual_6 处理完成\n",
      "处理模型 28/70: dual_16\n",
      "    处理时间步 0/30\n",
      "  模型 dual_16 处理完成\n",
      "处理模型 29/70: dual_33\n",
      "    处理时间步 0/30\n",
      "  模型 dual_33 处理完成\n",
      "处理模型 30/70: dual_72\n",
      "    处理时间步 0/30\n",
      "  模型 dual_72 处理完成\n",
      "处理模型 31/70: dual_35\n",
      "    处理时间步 0/30\n",
      "  模型 dual_35 处理完成\n",
      "处理模型 32/70: dual_91\n",
      "    处理时间步 0/30\n",
      "  模型 dual_91 处理完成\n",
      "处理模型 33/70: dual_26\n",
      "    处理时间步 0/30\n",
      "  模型 dual_26 处理完成\n",
      "处理模型 34/70: dual_39\n",
      "    处理时间步 0/30\n",
      "  模型 dual_39 处理完成\n",
      "处理模型 35/70: dual_81\n",
      "    处理时间步 0/30\n",
      "  模型 dual_81 处理完成\n",
      "处理模型 36/70: dual_74\n",
      "    处理时间步 0/30\n",
      "  模型 dual_74 处理完成\n",
      "处理模型 37/70: dual_52\n",
      "    处理时间步 0/30\n",
      "  模型 dual_52 处理完成\n",
      "处理模型 38/70: dual_38\n",
      "    处理时间步 0/30\n",
      "  模型 dual_38 处理完成\n",
      "处理模型 39/70: dual_3\n",
      "    处理时间步 0/30\n",
      "  模型 dual_3 处理完成\n",
      "处理模型 40/70: dual_44\n",
      "    处理时间步 0/30\n",
      "  模型 dual_44 处理完成\n",
      "处理模型 41/70: dual_83\n",
      "    处理时间步 0/30\n",
      "  模型 dual_83 处理完成\n",
      "处理模型 42/70: dual_82\n",
      "    处理时间步 0/30\n",
      "  模型 dual_82 处理完成\n",
      "处理模型 43/70: dual_97\n",
      "    处理时间步 0/30\n",
      "  模型 dual_97 处理完成\n",
      "处理模型 44/70: dual_5\n",
      "    处理时间步 0/30\n",
      "  模型 dual_5 处理完成\n",
      "处理模型 45/70: dual_57\n",
      "    处理时间步 0/30\n",
      "  模型 dual_57 处理完成\n",
      "处理模型 46/70: dual_45\n",
      "    处理时间步 0/30\n",
      "  模型 dual_45 处理完成\n",
      "处理模型 47/70: dual_73\n",
      "    处理时间步 0/30\n",
      "  模型 dual_73 处理完成\n",
      "处理模型 48/70: dual_12\n",
      "    处理时间步 0/30\n",
      "  模型 dual_12 处理完成\n",
      "处理模型 49/70: dual_27\n",
      "    处理时间步 0/30\n",
      "  模型 dual_27 处理完成\n",
      "处理模型 50/70: dual_11\n",
      "    处理时间步 0/30\n",
      "  模型 dual_11 处理完成\n",
      "处理模型 51/70: dual_79\n",
      "    处理时间步 0/30\n",
      "  模型 dual_79 处理完成\n",
      "处理模型 52/70: dual_92\n",
      "    处理时间步 0/30\n",
      "  模型 dual_92 处理完成\n",
      "处理模型 53/70: dual_98\n",
      "    处理时间步 0/30\n",
      "  模型 dual_98 处理完成\n",
      "处理模型 54/70: dual_1\n",
      "    处理时间步 0/30\n",
      "  模型 dual_1 处理完成\n",
      "处理模型 55/70: dual_59\n",
      "    处理时间步 0/30\n",
      "  模型 dual_59 处理完成\n",
      "处理模型 56/70: dual_69\n",
      "    处理时间步 0/30\n",
      "  模型 dual_69 处理完成\n",
      "处理模型 57/70: dual_70\n",
      "    处理时间步 0/30\n",
      "  模型 dual_70 处理完成\n",
      "处理模型 58/70: dual_64\n",
      "    处理时间步 0/30\n",
      "  模型 dual_64 处理完成\n",
      "处理模型 59/70: dual_58\n",
      "    处理时间步 0/30\n",
      "  模型 dual_58 处理完成\n",
      "处理模型 60/70: dual_4\n",
      "    处理时间步 0/30\n",
      "  模型 dual_4 处理完成\n",
      "处理模型 61/70: dual_86\n",
      "    处理时间步 0/30\n",
      "  模型 dual_86 处理完成\n",
      "处理模型 62/70: dual_25\n",
      "    处理时间步 0/30\n",
      "  模型 dual_25 处理完成\n",
      "处理模型 63/70: dual_95\n",
      "    处理时间步 0/30\n",
      "  模型 dual_95 处理完成\n",
      "处理模型 64/70: dual_9\n",
      "    处理时间步 0/30\n",
      "  模型 dual_9 处理完成\n",
      "处理模型 65/70: dual_78\n",
      "    处理时间步 0/30\n",
      "  模型 dual_78 处理完成\n",
      "处理模型 66/70: dual_2\n",
      "    处理时间步 0/30\n",
      "  模型 dual_2 处理完成\n",
      "处理模型 67/70: dual_75\n",
      "    处理时间步 0/30\n",
      "  模型 dual_75 处理完成\n",
      "处理模型 68/70: dual_53\n",
      "    处理时间步 0/30\n",
      "  模型 dual_53 处理完成\n",
      "处理模型 69/70: dual_30\n",
      "    处理时间步 0/30\n",
      "  模型 dual_30 处理完成\n",
      "处理模型 70/70: dual_80\n",
      "    处理时间步 0/30\n",
      "  模型 dual_80 处理完成\n",
      "预处理完成！处理了 70 个模型\n",
      "特征维度 - 水头: 16, 浓度基础: 19\n",
      "开始特征标准化...\n",
      "预处理CNN数据...\n",
      "处理模型 1/30: dual_42\n",
      "    处理时间步 0/30\n",
      "  模型 dual_42 处理完成\n",
      "处理模型 2/30: dual_60\n",
      "    处理时间步 0/30\n",
      "  模型 dual_60 处理完成\n",
      "处理模型 3/30: dual_94\n",
      "    处理时间步 0/30\n",
      "  模型 dual_94 处理完成\n",
      "处理模型 4/30: dual_76\n",
      "    处理时间步 0/30\n",
      "  模型 dual_76 处理完成\n",
      "处理模型 5/30: dual_62\n",
      "    处理时间步 0/30\n",
      "  模型 dual_62 处理完成\n",
      "处理模型 6/30: dual_0\n",
      "    处理时间步 0/30\n",
      "  模型 dual_0 处理完成\n",
      "处理模型 7/30: dual_37\n",
      "    处理时间步 0/30\n",
      "  模型 dual_37 处理完成\n",
      "处理模型 8/30: dual_18\n",
      "    处理时间步 0/30\n",
      "  模型 dual_18 处理完成\n",
      "处理模型 9/30: dual_36\n",
      "    处理时间步 0/30\n",
      "  模型 dual_36 处理完成\n",
      "处理模型 10/30: dual_24\n",
      "    处理时间步 0/30\n",
      "  模型 dual_24 处理完成\n",
      "处理模型 11/30: dual_85\n",
      "    处理时间步 0/30\n",
      "  模型 dual_85 处理完成\n",
      "处理模型 12/30: dual_54\n",
      "    处理时间步 0/30\n",
      "  模型 dual_54 处理完成\n",
      "处理模型 13/30: dual_7\n",
      "    处理时间步 0/30\n",
      "  模型 dual_7 处理完成\n",
      "处理模型 14/30: dual_99\n",
      "    处理时间步 0/30\n",
      "  模型 dual_99 处理完成\n",
      "处理模型 15/30: dual_32\n",
      "    处理时间步 0/30\n",
      "  模型 dual_32 处理完成\n",
      "处理模型 16/30: dual_43\n",
      "    处理时间步 0/30\n",
      "  模型 dual_43 处理完成\n",
      "处理模型 17/30: dual_63\n",
      "    处理时间步 0/30\n",
      "  模型 dual_63 处理完成\n",
      "处理模型 18/30: dual_96\n",
      "    处理时间步 0/30\n",
      "  模型 dual_96 处理完成\n",
      "处理模型 19/30: dual_19\n",
      "    处理时间步 0/30\n",
      "  模型 dual_19 处理完成\n",
      "处理模型 20/30: dual_50\n",
      "    处理时间步 0/30\n",
      "  模型 dual_50 处理完成\n",
      "处理模型 21/30: dual_41\n",
      "    处理时间步 0/30\n",
      "  模型 dual_41 处理完成\n",
      "处理模型 22/30: dual_13\n",
      "    处理时间步 0/30\n",
      "  模型 dual_13 处理完成\n",
      "处理模型 23/30: dual_77\n",
      "    处理时间步 0/30\n",
      "  模型 dual_77 处理完成\n",
      "处理模型 24/30: dual_89\n",
      "    处理时间步 0/30\n",
      "  模型 dual_89 处理完成\n",
      "处理模型 25/30: dual_28\n",
      "    处理时间步 0/30\n",
      "  模型 dual_28 处理完成\n",
      "处理模型 26/30: dual_56\n",
      "    处理时间步 0/30\n",
      "  模型 dual_56 处理完成\n",
      "处理模型 27/30: dual_65\n",
      "    处理时间步 0/30\n",
      "  模型 dual_65 处理完成\n",
      "处理模型 28/30: dual_22\n",
      "    处理时间步 0/30\n",
      "  模型 dual_22 处理完成\n",
      "处理模型 29/30: dual_46\n",
      "    处理时间步 0/30\n",
      "  模型 dual_46 处理完成\n",
      "处理模型 30/30: dual_14\n",
      "    处理时间步 0/30\n",
      "  模型 dual_14 处理完成\n",
      "预处理完成！处理了 30 个模型\n",
      "特征维度 - 水头: 16, 浓度基础: 19\n",
      "开始训练经典2D CNN模型...\n",
      "配置: {'hidden_dim': 96, 'num_epochs': 300, 'lr': 0.001, 'weight_decay': 0.0001, 'patience': 30, 'save_path': './saved_models/classic_2d_cnn_dual_original_preprocess', 'max_time_steps': 30}\n",
      "🔹 开始训练经典2D CNN水头模型...\n",
      "水头2D CNN Epoch 001/300 | 训练损失: 5408.4418 | 验证损失: 4904.2038 | R2: -252.6297 | RMSE: 91.0153 | LR: 0.001000\n",
      "保存最佳2D CNN水头模型，验证损失: 4904.2038\n",
      "水头2D CNN Epoch 002/300 | 训练损失: 5272.4601 | 验证损失: 5248.8878 | R2: -270.4308 | RMSE: 94.1592 | LR: 0.001000\n",
      "水头2D CNN Epoch 003/300 | 训练损失: 5162.4355 | 验证损失: 5192.1315 | R2: -267.4887 | RMSE: 93.6487 | LR: 0.001000\n",
      "水头2D CNN Epoch 004/300 | 训练损失: 5050.4689 | 验证损失: 4966.5410 | R2: -255.8176 | RMSE: 91.5916 | LR: 0.001000\n",
      "水头2D CNN Epoch 005/300 | 训练损失: 4920.2123 | 验证损失: 4846.7936 | R2: -249.6243 | RMSE: 90.4806 | LR: 0.000999\n",
      "保存最佳2D CNN水头模型，验证损失: 4846.7936\n",
      "水头2D CNN Epoch 006/300 | 训练损失: 4781.7463 | 验证损失: 4719.5078 | R2: -243.0399 | RMSE: 89.2846 | LR: 0.000999\n",
      "保存最佳2D CNN水头模型，验证损失: 4719.5078\n",
      "水头2D CNN Epoch 007/300 | 训练损失: 4633.2913 | 验证损失: 4547.6600 | R2: -234.1455 | RMSE: 87.6439 | LR: 0.000999\n",
      "保存最佳2D CNN水头模型，验证损失: 4547.6600\n",
      "水头2D CNN Epoch 008/300 | 训练损失: 4481.0651 | 验证损失: 4328.9007 | R2: -222.8348 | RMSE: 85.5100 | LR: 0.000998\n",
      "保存最佳2D CNN水头模型，验证损失: 4328.9007\n",
      "水头2D CNN Epoch 009/300 | 训练损失: 4320.9236 | 验证损失: 4195.2612 | R2: -215.9143 | RMSE: 84.1796 | LR: 0.000998\n",
      "保存最佳2D CNN水头模型，验证损失: 4195.2612\n",
      "水头2D CNN Epoch 010/300 | 训练损失: 4159.1210 | 验证损失: 4061.8934 | R2: -209.0192 | RMSE: 82.8307 | LR: 0.000997\n",
      "保存最佳2D CNN水头模型，验证损失: 4061.8934\n",
      "水头2D CNN Epoch 011/300 | 训练损失: 3983.9596 | 验证损失: 3881.4487 | R2: -199.6816 | RMSE: 80.9699 | LR: 0.000997\n",
      "保存最佳2D CNN水头模型，验证损失: 3881.4487\n",
      "水头2D CNN Epoch 012/300 | 训练损失: 3828.0542 | 验证损失: 3697.8367 | R2: -190.1898 | RMSE: 79.0316 | LR: 0.000996\n",
      "保存最佳2D CNN水头模型，验证损失: 3697.8367\n",
      "水头2D CNN Epoch 013/300 | 训练损失: 3658.1982 | 验证损失: 3553.1012 | R2: -182.6966 | RMSE: 77.4694 | LR: 0.000995\n",
      "保存最佳2D CNN水头模型，验证损失: 3553.1012\n",
      "水头2D CNN Epoch 014/300 | 训练损失: 3477.9604 | 验证损失: 3383.8101 | R2: -173.9386 | RMSE: 75.6012 | LR: 0.000995\n",
      "保存最佳2D CNN水头模型，验证损失: 3383.8101\n",
      "水头2D CNN Epoch 015/300 | 训练损失: 3293.7435 | 验证损失: 3165.4559 | R2: -162.6392 | RMSE: 73.1212 | LR: 0.000994\n",
      "保存最佳2D CNN水头模型，验证损失: 3165.4559\n",
      "水头2D CNN Epoch 016/300 | 训练损失: 3117.4640 | 验证损失: 3001.3804 | R2: -154.1622 | RMSE: 71.2010 | LR: 0.000993\n",
      "保存最佳2D CNN水头模型，验证损失: 3001.3804\n",
      "水头2D CNN Epoch 017/300 | 训练损失: 2943.8626 | 验证损失: 2756.4086 | R2: -141.4917 | RMSE: 68.2333 | LR: 0.000992\n",
      "保存最佳2D CNN水头模型，验证损失: 2756.4086\n",
      "水头2D CNN Epoch 018/300 | 训练损失: 2753.0642 | 验证损失: 2645.0597 | R2: -135.7380 | RMSE: 66.8410 | LR: 0.000991\n",
      "保存最佳2D CNN水头模型，验证损失: 2645.0597\n",
      "水头2D CNN Epoch 019/300 | 训练损失: 2563.9715 | 验证损失: 2555.7372 | R2: -131.1389 | RMSE: 65.7030 | LR: 0.000990\n",
      "保存最佳2D CNN水头模型，验证损失: 2555.7372\n",
      "水头2D CNN Epoch 020/300 | 训练损失: 2377.8006 | 验证损失: 2242.6039 | R2: -114.9222 | RMSE: 61.5460 | LR: 0.000989\n",
      "保存最佳2D CNN水头模型，验证损失: 2242.6039\n",
      "水头2D CNN Epoch 021/300 | 训练损失: 2186.9145 | 验证损失: 2066.0237 | R2: -105.8015 | RMSE: 59.0735 | LR: 0.000988\n",
      "保存最佳2D CNN水头模型，验证损失: 2066.0237\n",
      "水头2D CNN Epoch 022/300 | 训练损失: 2013.3209 | 验证损失: 1860.1570 | R2: -95.1440 | RMSE: 56.0528 | LR: 0.000987\n",
      "保存最佳2D CNN水头模型，验证损失: 1860.1570\n",
      "水头2D CNN Epoch 023/300 | 训练损失: 1840.4122 | 验证损失: 1695.9451 | R2: -86.6522 | RMSE: 53.5214 | LR: 0.000986\n",
      "保存最佳2D CNN水头模型，验证损失: 1695.9451\n",
      "水头2D CNN Epoch 024/300 | 训练损失: 1660.1839 | 验证损失: 1528.1544 | R2: -77.9740 | RMSE: 50.8047 | LR: 0.000984\n",
      "保存最佳2D CNN水头模型，验证损失: 1528.1544\n",
      "水头2D CNN Epoch 025/300 | 训练损失: 1485.8341 | 验证损失: 1412.7377 | R2: -72.0183 | RMSE: 48.8487 | LR: 0.000983\n",
      "保存最佳2D CNN水头模型，验证损失: 1412.7377\n",
      "水头2D CNN Epoch 026/300 | 训练损失: 1332.3805 | 验证损失: 1220.4858 | R2: -62.0757 | RMSE: 45.4033 | LR: 0.000982\n",
      "保存最佳2D CNN水头模型，验证损失: 1220.4858\n",
      "水头2D CNN Epoch 027/300 | 训练损失: 1168.9925 | 验证损失: 1122.0156 | R2: -56.9846 | RMSE: 43.5331 | LR: 0.000980\n",
      "保存最佳2D CNN水头模型，验证损失: 1122.0156\n",
      "水头2D CNN Epoch 028/300 | 训练损失: 1033.4136 | 验证损失: 992.7633 | R2: -50.3283 | RMSE: 40.9496 | LR: 0.000979\n",
      "保存最佳2D CNN水头模型，验证损失: 992.7633\n",
      "水头2D CNN Epoch 029/300 | 训练损失: 896.2611 | 验证损失: 2130.4183 | R2: -109.3085 | RMSE: 59.9889 | LR: 0.000977\n",
      "水头2D CNN Epoch 030/300 | 训练损失: 621.9635 | 验证损失: 313.6619 | R2: -15.1453 | RMSE: 23.0113 | LR: 0.000976\n",
      "保存最佳2D CNN水头模型，验证损失: 313.6619\n",
      "水头2D CNN Epoch 031/300 | 训练损失: 458.3118 | 验证损失: 339.3410 | R2: -16.4801 | RMSE: 23.9363 | LR: 0.000974\n",
      "水头2D CNN Epoch 032/300 | 训练损失: 347.7563 | 验证损失: 251.2026 | R2: -11.9319 | RMSE: 20.5934 | LR: 0.000972\n",
      "保存最佳2D CNN水头模型，验证损失: 251.2026\n",
      "水头2D CNN Epoch 033/300 | 训练损失: 252.4717 | 验证损失: 175.1223 | R2: -8.0082 | RMSE: 17.1932 | LR: 0.000970\n",
      "保存最佳2D CNN水头模型，验证损失: 175.1223\n",
      "水头2D CNN Epoch 034/300 | 训练损失: 169.9322 | 验证损失: 118.0672 | R2: -5.0638 | RMSE: 14.1149 | LR: 0.000969\n",
      "保存最佳2D CNN水头模型，验证损失: 118.0672\n",
      "水头2D CNN Epoch 035/300 | 训练损失: 114.3004 | 验证损失: 37.9504 | R2: -0.9354 | RMSE: 7.9934 | LR: 0.000967\n",
      "保存最佳2D CNN水头模型，验证损失: 37.9504\n",
      "水头2D CNN Epoch 036/300 | 训练损失: 68.6657 | 验证损失: 12.3024 | R2: 0.3814 | RMSE: 4.5336 | LR: 0.000965\n",
      "保存最佳2D CNN水头模型，验证损失: 12.3024\n",
      "水头2D CNN Epoch 037/300 | 训练损失: 47.8183 | 验证损失: 7.6376 | R2: 0.5986 | RMSE: 3.5843 | LR: 0.000963\n",
      "保存最佳2D CNN水头模型，验证损失: 7.6376\n",
      "水头2D CNN Epoch 038/300 | 训练损失: 43.2110 | 验证损失: 11.8454 | R2: 0.3799 | RMSE: 4.4681 | LR: 0.000961\n",
      "水头2D CNN Epoch 039/300 | 训练损失: 44.1460 | 验证损失: 7.0706 | R2: 0.6296 | RMSE: 3.4506 | LR: 0.000959\n",
      "保存最佳2D CNN水头模型，验证损失: 7.0706\n",
      "水头2D CNN Epoch 040/300 | 训练损失: 43.2026 | 验证损失: 3.4802 | R2: 0.8222 | RMSE: 2.4210 | LR: 0.000957\n",
      "保存最佳2D CNN水头模型，验证损失: 3.4802\n",
      "水头2D CNN Epoch 041/300 | 训练损失: 41.1555 | 验证损失: 9.7052 | R2: 0.4920 | RMSE: 4.0441 | LR: 0.000955\n",
      "水头2D CNN Epoch 042/300 | 训练损失: 43.5864 | 验证损失: 2.6699 | R2: 0.8681 | RMSE: 2.0961 | LR: 0.000952\n",
      "保存最佳2D CNN水头模型，验证损失: 2.6699\n",
      "水头2D CNN Epoch 043/300 | 训练损失: 40.9973 | 验证损失: 1.5818 | R2: 0.9202 | RMSE: 1.6252 | LR: 0.000950\n",
      "保存最佳2D CNN水头模型，验证损失: 1.5818\n",
      "水头2D CNN Epoch 044/300 | 训练损失: 41.7153 | 验证损失: 3.4908 | R2: 0.8274 | RMSE: 2.3981 | LR: 0.000948\n",
      "水头2D CNN Epoch 045/300 | 训练损失: 40.6106 | 验证损失: 2.5337 | R2: 0.8716 | RMSE: 2.0619 | LR: 0.000946\n",
      "水头2D CNN Epoch 046/300 | 训练损失: 42.0840 | 验证损失: 3.6619 | R2: 0.8083 | RMSE: 2.4840 | LR: 0.000943\n",
      "水头2D CNN Epoch 047/300 | 训练损失: 42.7156 | 验证损失: 2.7188 | R2: 0.8592 | RMSE: 2.1423 | LR: 0.000941\n",
      "水头2D CNN Epoch 048/300 | 训练损失: 41.1474 | 验证损失: 2.5293 | R2: 0.8689 | RMSE: 2.0663 | LR: 0.000938\n",
      "水头2D CNN Epoch 049/300 | 训练损失: 40.7594 | 验证损失: 4.6148 | R2: 0.7589 | RMSE: 2.7895 | LR: 0.000936\n",
      "水头2D CNN Epoch 050/300 | 训练损失: 39.6186 | 验证损失: 2.8432 | R2: 0.8590 | RMSE: 2.1674 | LR: 0.000933\n",
      "水头2D CNN Epoch 051/300 | 训练损失: 40.4622 | 验证损失: 1.3212 | R2: 0.9331 | RMSE: 1.4879 | LR: 0.000930\n",
      "保存最佳2D CNN水头模型，验证损失: 1.3212\n",
      "水头2D CNN Epoch 052/300 | 训练损失: 41.4784 | 验证损失: 3.5598 | R2: 0.8178 | RMSE: 2.4496 | LR: 0.000928\n",
      "水头2D CNN Epoch 053/300 | 训练损失: 38.4646 | 验证损失: 1.6222 | R2: 0.9185 | RMSE: 1.6446 | LR: 0.000925\n",
      "水头2D CNN Epoch 054/300 | 训练损失: 38.1384 | 验证损失: 2.2953 | R2: 0.8811 | RMSE: 1.9684 | LR: 0.000922\n",
      "水头2D CNN Epoch 055/300 | 训练损失: 38.6285 | 验证损失: 1.3377 | R2: 0.9334 | RMSE: 1.4878 | LR: 0.000919\n",
      "水头2D CNN Epoch 056/300 | 训练损失: 40.1378 | 验证损失: 7.1407 | R2: 0.6249 | RMSE: 3.4666 | LR: 0.000916\n",
      "水头2D CNN Epoch 057/300 | 训练损失: 39.3991 | 验证损失: 1.7365 | R2: 0.9132 | RMSE: 1.6988 | LR: 0.000914\n",
      "水头2D CNN Epoch 058/300 | 训练损失: 39.4724 | 验证损失: 4.7443 | R2: 0.7506 | RMSE: 2.8248 | LR: 0.000911\n",
      "水头2D CNN Epoch 059/300 | 训练损失: 38.8443 | 验证损失: 1.3734 | R2: 0.9302 | RMSE: 1.5184 | LR: 0.000908\n",
      "水头2D CNN Epoch 060/300 | 训练损失: 40.0664 | 验证损失: 3.7770 | R2: 0.8017 | RMSE: 2.5211 | LR: 0.000905\n",
      "水头2D CNN Epoch 061/300 | 训练损失: 40.5381 | 验证损失: 8.2874 | R2: 0.5654 | RMSE: 3.7364 | LR: 0.000901\n",
      "水头2D CNN Epoch 062/300 | 训练损失: 40.2453 | 验证损失: 2.0061 | R2: 0.9000 | RMSE: 1.8245 | LR: 0.000898\n",
      "水头2D CNN Epoch 063/300 | 训练损失: 39.4169 | 验证损失: 1.8827 | R2: 0.9029 | RMSE: 1.7824 | LR: 0.000895\n",
      "水头2D CNN Epoch 064/300 | 训练损失: 40.1299 | 验证损失: 12.0650 | R2: 0.3668 | RMSE: 4.5073 | LR: 0.000892\n",
      "水头2D CNN Epoch 065/300 | 训练损失: 36.9980 | 验证损失: 3.3576 | R2: 0.8238 | RMSE: 2.3772 | LR: 0.000889\n",
      "水头2D CNN Epoch 066/300 | 训练损失: 37.5092 | 验证损失: 1.7349 | R2: 0.9147 | RMSE: 1.6844 | LR: 0.000885\n",
      "水头2D CNN Epoch 067/300 | 训练损失: 40.1081 | 验证损失: 1.9251 | R2: 0.9002 | RMSE: 1.8026 | LR: 0.000882\n",
      "水头2D CNN Epoch 068/300 | 训练损失: 41.0050 | 验证损失: 2.0864 | R2: 0.8968 | RMSE: 1.8542 | LR: 0.000878\n",
      "水头2D CNN Epoch 069/300 | 训练损失: 39.1543 | 验证损失: 3.3845 | R2: 0.8225 | RMSE: 2.3873 | LR: 0.000875\n",
      "水头2D CNN Epoch 070/300 | 训练损失: 40.8873 | 验证损失: 1.3709 | R2: 0.9323 | RMSE: 1.5016 | LR: 0.000872\n",
      "水头2D CNN Epoch 071/300 | 训练损失: 41.4620 | 验证损失: 1.3167 | R2: 0.9344 | RMSE: 1.4771 | LR: 0.000868\n",
      "保存最佳2D CNN水头模型，验证损失: 1.3167\n",
      "水头2D CNN Epoch 072/300 | 训练损失: 38.5888 | 验证损失: 1.5713 | R2: 0.9224 | RMSE: 1.6075 | LR: 0.000864\n",
      "水头2D CNN Epoch 073/300 | 训练损失: 40.3613 | 验证损失: 2.3025 | R2: 0.8862 | RMSE: 1.9472 | LR: 0.000861\n",
      "水头2D CNN Epoch 074/300 | 训练损失: 37.1106 | 验证损失: 1.7038 | R2: 0.9157 | RMSE: 1.6750 | LR: 0.000857\n",
      "水头2D CNN Epoch 075/300 | 训练损失: 40.6469 | 验证损失: 1.5592 | R2: 0.9195 | RMSE: 1.6220 | LR: 0.000854\n",
      "水头2D CNN Epoch 076/300 | 训练损失: 40.1199 | 验证损失: 1.4329 | R2: 0.9288 | RMSE: 1.5394 | LR: 0.000850\n",
      "水头2D CNN Epoch 077/300 | 训练损失: 39.8700 | 验证损失: 1.3077 | R2: 0.9342 | RMSE: 1.4779 | LR: 0.000846\n",
      "保存最佳2D CNN水头模型，验证损失: 1.3077\n",
      "水头2D CNN Epoch 078/300 | 训练损失: 39.5255 | 验证损失: 1.7920 | R2: 0.9065 | RMSE: 1.7383 | LR: 0.000842\n",
      "水头2D CNN Epoch 079/300 | 训练损失: 35.9529 | 验证损失: 0.9365 | R2: 0.9522 | RMSE: 1.2553 | LR: 0.000838\n",
      "保存最佳2D CNN水头模型，验证损失: 0.9365\n",
      "水头2D CNN Epoch 080/300 | 训练损失: 38.4023 | 验证损失: 1.9251 | R2: 0.9033 | RMSE: 1.7930 | LR: 0.000835\n",
      "水头2D CNN Epoch 081/300 | 训练损失: 38.1308 | 验证损失: 1.0463 | R2: 0.9471 | RMSE: 1.3240 | LR: 0.000831\n",
      "水头2D CNN Epoch 082/300 | 训练损失: 40.1027 | 验证损失: 3.1722 | R2: 0.8422 | RMSE: 2.2920 | LR: 0.000827\n",
      "水头2D CNN Epoch 083/300 | 训练损失: 36.7286 | 验证损失: 1.5446 | R2: 0.9214 | RMSE: 1.6112 | LR: 0.000823\n",
      "水头2D CNN Epoch 084/300 | 训练损失: 37.8601 | 验证损失: 3.0904 | R2: 0.8457 | RMSE: 2.2660 | LR: 0.000819\n",
      "水头2D CNN Epoch 085/300 | 训练损失: 36.5673 | 验证损失: 2.4827 | R2: 0.8763 | RMSE: 2.0292 | LR: 0.000815\n",
      "水头2D CNN Epoch 086/300 | 训练损失: 37.2789 | 验证损失: 1.4732 | R2: 0.9271 | RMSE: 1.5576 | LR: 0.000811\n",
      "水头2D CNN Epoch 087/300 | 训练损失: 38.7513 | 验证损失: 1.2657 | R2: 0.9361 | RMSE: 1.4561 | LR: 0.000806\n",
      "水头2D CNN Epoch 088/300 | 训练损失: 38.1236 | 验证损失: 1.6084 | R2: 0.9163 | RMSE: 1.6475 | LR: 0.000802\n",
      "水头2D CNN Epoch 089/300 | 训练损失: 38.7930 | 验证损失: 4.7879 | R2: 0.7485 | RMSE: 2.8388 | LR: 0.000798\n",
      "水头2D CNN Epoch 090/300 | 训练损失: 37.6807 | 验证损失: 2.0368 | R2: 0.8942 | RMSE: 1.8540 | LR: 0.000794\n",
      "水头2D CNN Epoch 091/300 | 训练损失: 37.8817 | 验证损失: 1.8647 | R2: 0.9077 | RMSE: 1.7537 | LR: 0.000790\n",
      "水头2D CNN Epoch 092/300 | 训练损失: 37.7460 | 验证损失: 2.1799 | R2: 0.8855 | RMSE: 1.9150 | LR: 0.000785\n",
      "水头2D CNN Epoch 093/300 | 训练损失: 36.6693 | 验证损失: 5.1294 | R2: 0.7307 | RMSE: 2.9387 | LR: 0.000781\n",
      "水头2D CNN Epoch 094/300 | 训练损失: 39.0284 | 验证损失: 1.3163 | R2: 0.9317 | RMSE: 1.4905 | LR: 0.000777\n",
      "水头2D CNN Epoch 095/300 | 训练损失: 37.2862 | 验证损失: 0.9273 | R2: 0.9531 | RMSE: 1.2460 | LR: 0.000772\n",
      "保存最佳2D CNN水头模型，验证损失: 0.9273\n",
      "水头2D CNN Epoch 096/300 | 训练损失: 40.1845 | 验证损失: 1.0980 | R2: 0.9451 | RMSE: 1.3513 | LR: 0.000768\n",
      "水头2D CNN Epoch 097/300 | 训练损失: 38.4603 | 验证损失: 1.0232 | R2: 0.9475 | RMSE: 1.3134 | LR: 0.000763\n",
      "水头2D CNN Epoch 098/300 | 训练损失: 39.6796 | 验证损失: 2.0583 | R2: 0.8922 | RMSE: 1.8625 | LR: 0.000759\n",
      "水头2D CNN Epoch 099/300 | 训练损失: 37.6319 | 验证损失: 2.1096 | R2: 0.8939 | RMSE: 1.8778 | LR: 0.000755\n",
      "水头2D CNN Epoch 100/300 | 训练损失: 38.9291 | 验证损失: 1.4021 | R2: 0.9302 | RMSE: 1.5239 | LR: 0.000750\n",
      "水头2D CNN Epoch 101/300 | 训练损失: 38.2373 | 验证损失: 0.9614 | R2: 0.9511 | RMSE: 1.2708 | LR: 0.000745\n",
      "水头2D CNN Epoch 102/300 | 训练损失: 38.9862 | 验证损失: 1.4765 | R2: 0.9231 | RMSE: 1.5781 | LR: 0.000741\n",
      "水头2D CNN Epoch 103/300 | 训练损失: 36.5994 | 验证损失: 2.7773 | R2: 0.8546 | RMSE: 2.1635 | LR: 0.000736\n",
      "水头2D CNN Epoch 104/300 | 训练损失: 37.1204 | 验证损失: 7.1053 | R2: 0.6274 | RMSE: 3.4600 | LR: 0.000732\n",
      "水头2D CNN Epoch 105/300 | 训练损失: 36.4919 | 验证损失: 1.3297 | R2: 0.9310 | RMSE: 1.4981 | LR: 0.000727\n",
      "水头2D CNN Epoch 106/300 | 训练损失: 38.0683 | 验证损失: 0.9152 | R2: 0.9534 | RMSE: 1.2405 | LR: 0.000722\n",
      "保存最佳2D CNN水头模型，验证损失: 0.9152\n",
      "水头2D CNN Epoch 107/300 | 训练损失: 37.1129 | 验证损失: 3.6519 | R2: 0.8172 | RMSE: 2.4661 | LR: 0.000718\n",
      "水头2D CNN Epoch 108/300 | 训练损失: 37.8956 | 验证损失: 0.9535 | R2: 0.9509 | RMSE: 1.2684 | LR: 0.000713\n",
      "水头2D CNN Epoch 109/300 | 训练损失: 38.0820 | 验证损失: 8.2722 | R2: 0.5669 | RMSE: 3.7345 | LR: 0.000708\n",
      "水头2D CNN Epoch 110/300 | 训练损失: 38.0353 | 验证损失: 1.1497 | R2: 0.9427 | RMSE: 1.3804 | LR: 0.000703\n",
      "水头2D CNN Epoch 111/300 | 训练损失: 39.4400 | 验证损失: 1.1287 | R2: 0.9437 | RMSE: 1.3689 | LR: 0.000699\n",
      "水头2D CNN Epoch 112/300 | 训练损失: 37.6135 | 验证损失: 1.0059 | R2: 0.9488 | RMSE: 1.3002 | LR: 0.000694\n",
      "水头2D CNN Epoch 113/300 | 训练损失: 39.3719 | 验证损失: 2.4972 | R2: 0.8693 | RMSE: 2.0515 | LR: 0.000689\n",
      "水头2D CNN Epoch 114/300 | 训练损失: 37.9322 | 验证损失: 3.8964 | R2: 0.7956 | RMSE: 2.5617 | LR: 0.000684\n",
      "水头2D CNN Epoch 115/300 | 训练损失: 37.3981 | 验证损失: 1.9401 | R2: 0.9024 | RMSE: 1.8009 | LR: 0.000679\n",
      "水头2D CNN Epoch 116/300 | 训练损失: 38.6127 | 验证损失: 3.1157 | R2: 0.8365 | RMSE: 2.2908 | LR: 0.000674\n",
      "水头2D CNN Epoch 117/300 | 训练损失: 37.5145 | 验证损失: 5.2483 | R2: 0.7249 | RMSE: 2.9739 | LR: 0.000669\n",
      "水头2D CNN Epoch 118/300 | 训练损失: 38.0481 | 验证损失: 1.5718 | R2: 0.9177 | RMSE: 1.6275 | LR: 0.000664\n",
      "水头2D CNN Epoch 119/300 | 训练损失: 36.8042 | 验证损失: 0.7937 | R2: 0.9600 | RMSE: 1.1518 | LR: 0.000659\n",
      "保存最佳2D CNN水头模型，验证损失: 0.7937\n",
      "水头2D CNN Epoch 120/300 | 训练损失: 39.0479 | 验证损失: 0.9296 | R2: 0.9533 | RMSE: 1.2451 | LR: 0.000655\n",
      "水头2D CNN Epoch 121/300 | 训练损失: 37.6189 | 验证损失: 2.2383 | R2: 0.8875 | RMSE: 1.9334 | LR: 0.000650\n",
      "水头2D CNN Epoch 122/300 | 训练损失: 36.0393 | 验证损失: 1.7092 | R2: 0.9143 | RMSE: 1.6882 | LR: 0.000645\n",
      "水头2D CNN Epoch 123/300 | 训练损失: 37.5403 | 验证损失: 0.8847 | R2: 0.9558 | RMSE: 1.2128 | LR: 0.000639\n",
      "水头2D CNN Epoch 124/300 | 训练损失: 39.3840 | 验证损失: 1.4209 | R2: 0.9259 | RMSE: 1.5482 | LR: 0.000634\n",
      "水头2D CNN Epoch 125/300 | 训练损失: 38.0426 | 验证损失: 0.8970 | R2: 0.9550 | RMSE: 1.2228 | LR: 0.000629\n",
      "水头2D CNN Epoch 126/300 | 训练损失: 38.5664 | 验证损失: 0.7424 | R2: 0.9622 | RMSE: 1.1171 | LR: 0.000624\n",
      "保存最佳2D CNN水头模型，验证损失: 0.7424\n",
      "水头2D CNN Epoch 127/300 | 训练损失: 36.0138 | 验证损失: 0.9935 | R2: 0.9487 | RMSE: 1.2950 | LR: 0.000619\n",
      "水头2D CNN Epoch 128/300 | 训练损失: 37.7920 | 验证损失: 1.1710 | R2: 0.9412 | RMSE: 1.3973 | LR: 0.000614\n",
      "水头2D CNN Epoch 129/300 | 训练损失: 38.3008 | 验证损失: 4.4750 | R2: 0.7653 | RMSE: 2.7456 | LR: 0.000609\n",
      "水头2D CNN Epoch 130/300 | 训练损失: 39.0626 | 验证损失: 1.3793 | R2: 0.9311 | RMSE: 1.5145 | LR: 0.000604\n",
      "水头2D CNN Epoch 131/300 | 训练损失: 37.2868 | 验证损失: 1.5811 | R2: 0.9201 | RMSE: 1.6277 | LR: 0.000599\n",
      "水头2D CNN Epoch 132/300 | 训练损失: 37.4325 | 验证损失: 1.0555 | R2: 0.9467 | RMSE: 1.3294 | LR: 0.000594\n",
      "水头2D CNN Epoch 133/300 | 训练损失: 38.0774 | 验证损失: 2.1527 | R2: 0.8917 | RMSE: 1.8969 | LR: 0.000589\n",
      "水头2D CNN Epoch 134/300 | 训练损失: 36.5633 | 验证损失: 1.0725 | R2: 0.9464 | RMSE: 1.3357 | LR: 0.000583\n",
      "水头2D CNN Epoch 135/300 | 训练损失: 39.6232 | 验证损失: 0.9395 | R2: 0.9524 | RMSE: 1.2555 | LR: 0.000578\n",
      "水头2D CNN Epoch 136/300 | 训练损失: 37.1954 | 验证损失: 1.1611 | R2: 0.9395 | RMSE: 1.3998 | LR: 0.000573\n",
      "水头2D CNN Epoch 137/300 | 训练损失: 36.5979 | 验证损失: 0.8696 | R2: 0.9554 | RMSE: 1.2109 | LR: 0.000568\n",
      "水头2D CNN Epoch 138/300 | 训练损失: 36.8402 | 验证损失: 1.8898 | R2: 0.9061 | RMSE: 1.7681 | LR: 0.000563\n",
      "水头2D CNN Epoch 139/300 | 训练损失: 38.2099 | 验证损失: 3.9433 | R2: 0.7931 | RMSE: 2.5770 | LR: 0.000557\n",
      "水头2D CNN Epoch 140/300 | 训练损失: 38.5129 | 验证损失: 0.7403 | R2: 0.9620 | RMSE: 1.1172 | LR: 0.000552\n",
      "保存最佳2D CNN水头模型，验证损失: 0.7403\n",
      "水头2D CNN Epoch 141/300 | 训练损失: 39.5363 | 验证损失: 1.0284 | R2: 0.9484 | RMSE: 1.3099 | LR: 0.000547\n",
      "水头2D CNN Epoch 142/300 | 训练损失: 37.6047 | 验证损失: 1.2162 | R2: 0.9391 | RMSE: 1.4228 | LR: 0.000542\n",
      "水头2D CNN Epoch 143/300 | 训练损失: 37.5758 | 验证损失: 0.9978 | R2: 0.9498 | RMSE: 1.2915 | LR: 0.000537\n",
      "水头2D CNN Epoch 144/300 | 训练损失: 36.1416 | 验证损失: 0.7837 | R2: 0.9595 | RMSE: 1.1502 | LR: 0.000531\n",
      "水头2D CNN Epoch 145/300 | 训练损失: 36.8356 | 验证损失: 0.8771 | R2: 0.9545 | RMSE: 1.2168 | LR: 0.000526\n",
      "水头2D CNN Epoch 146/300 | 训练损失: 36.6050 | 验证损失: 1.0246 | R2: 0.9479 | RMSE: 1.3122 | LR: 0.000521\n",
      "水头2D CNN Epoch 147/300 | 训练损失: 37.3371 | 验证损失: 1.0795 | R2: 0.9458 | RMSE: 1.3417 | LR: 0.000516\n",
      "水头2D CNN Epoch 148/300 | 训练损失: 39.0504 | 验证损失: 0.9357 | R2: 0.9515 | RMSE: 1.2569 | LR: 0.000510\n",
      "水头2D CNN Epoch 149/300 | 训练损失: 37.4724 | 验证损失: 0.8360 | R2: 0.9579 | RMSE: 1.1823 | LR: 0.000505\n",
      "水头2D CNN Epoch 150/300 | 训练损失: 38.0683 | 验证损失: 2.5344 | R2: 0.8717 | RMSE: 2.0622 | LR: 0.000500\n",
      "水头2D CNN Epoch 151/300 | 训练损失: 36.0116 | 验证损失: 0.8793 | R2: 0.9557 | RMSE: 1.2130 | LR: 0.000495\n",
      "水头2D CNN Epoch 152/300 | 训练损失: 37.0422 | 验证损失: 0.8079 | R2: 0.9588 | RMSE: 1.1657 | LR: 0.000490\n",
      "水头2D CNN Epoch 153/300 | 训练损失: 36.1055 | 验证损失: 1.1470 | R2: 0.9424 | RMSE: 1.3832 | LR: 0.000484\n",
      "水头2D CNN Epoch 154/300 | 训练损失: 36.3036 | 验证损失: 1.0334 | R2: 0.9462 | RMSE: 1.3207 | LR: 0.000479\n",
      "水头2D CNN Epoch 155/300 | 训练损失: 39.3259 | 验证损失: 0.9666 | R2: 0.9510 | RMSE: 1.2733 | LR: 0.000474\n",
      "水头2D CNN Epoch 156/300 | 训练损失: 35.7761 | 验证损失: 2.0174 | R2: 0.8982 | RMSE: 1.8382 | LR: 0.000469\n",
      "水头2D CNN Epoch 157/300 | 训练损失: 38.8012 | 验证损失: 1.5659 | R2: 0.9182 | RMSE: 1.6253 | LR: 0.000463\n",
      "水头2D CNN Epoch 158/300 | 训练损失: 36.7670 | 验证损失: 1.5477 | R2: 0.9221 | RMSE: 1.6086 | LR: 0.000458\n",
      "水头2D CNN Epoch 159/300 | 训练损失: 36.8849 | 验证损失: 0.8403 | R2: 0.9566 | RMSE: 1.1909 | LR: 0.000453\n",
      "水头2D CNN Epoch 160/300 | 训练损失: 37.5207 | 验证损失: 1.0841 | R2: 0.9436 | RMSE: 1.3528 | LR: 0.000448\n",
      "水头2D CNN Epoch 161/300 | 训练损失: 37.1780 | 验证损失: 0.7313 | R2: 0.9630 | RMSE: 1.1068 | LR: 0.000443\n",
      "保存最佳2D CNN水头模型，验证损失: 0.7313\n",
      "水头2D CNN Epoch 162/300 | 训练损失: 37.0384 | 验证损失: 0.6990 | R2: 0.9645 | RMSE: 1.0831 | LR: 0.000437\n",
      "保存最佳2D CNN水头模型，验证损失: 0.6990\n",
      "水头2D CNN Epoch 163/300 | 训练损失: 36.3895 | 验证损失: 1.6794 | R2: 0.9154 | RMSE: 1.6762 | LR: 0.000432\n",
      "水头2D CNN Epoch 164/300 | 训练损失: 37.2076 | 验证损失: 1.7718 | R2: 0.9119 | RMSE: 1.7130 | LR: 0.000427\n",
      "水头2D CNN Epoch 165/300 | 训练损失: 37.0902 | 验证损失: 0.7466 | R2: 0.9622 | RMSE: 1.1187 | LR: 0.000422\n",
      "水头2D CNN Epoch 166/300 | 训练损失: 37.7620 | 验证损失: 0.9003 | R2: 0.9549 | RMSE: 1.2249 | LR: 0.000417\n",
      "水头2D CNN Epoch 167/300 | 训练损失: 37.8307 | 验证损失: 1.2370 | R2: 0.9379 | RMSE: 1.4369 | LR: 0.000411\n",
      "水头2D CNN Epoch 168/300 | 训练损失: 37.1429 | 验证损失: 1.0332 | R2: 0.9485 | RMSE: 1.3086 | LR: 0.000406\n",
      "水头2D CNN Epoch 169/300 | 训练损失: 36.4766 | 验证损失: 1.1840 | R2: 0.9383 | RMSE: 1.4135 | LR: 0.000401\n",
      "水头2D CNN Epoch 170/300 | 训练损失: 36.8269 | 验证损失: 4.0149 | R2: 0.7967 | RMSE: 2.5955 | LR: 0.000396\n",
      "水头2D CNN Epoch 171/300 | 训练损失: 36.5887 | 验证损失: 0.7556 | R2: 0.9617 | RMSE: 1.1259 | LR: 0.000391\n",
      "水头2D CNN Epoch 172/300 | 训练损失: 36.4820 | 验证损失: 0.6815 | R2: 0.9654 | RMSE: 1.0697 | LR: 0.000386\n",
      "保存最佳2D CNN水头模型，验证损失: 0.6815\n",
      "水头2D CNN Epoch 173/300 | 训练损失: 40.6243 | 验证损失: 0.7162 | R2: 0.9638 | RMSE: 1.0951 | LR: 0.000381\n",
      "水头2D CNN Epoch 174/300 | 训练损失: 36.9269 | 验证损失: 2.0281 | R2: 0.8975 | RMSE: 1.8441 | LR: 0.000376\n",
      "水头2D CNN Epoch 175/300 | 训练损失: 33.8311 | 验证损失: 1.5405 | R2: 0.9218 | RMSE: 1.6090 | LR: 0.000371\n",
      "水头2D CNN Epoch 176/300 | 训练损失: 38.5664 | 验证损失: 0.8747 | R2: 0.9548 | RMSE: 1.2149 | LR: 0.000366\n",
      "水头2D CNN Epoch 177/300 | 训练损失: 37.5391 | 验证损失: 0.7085 | R2: 0.9638 | RMSE: 1.0922 | LR: 0.000361\n",
      "水头2D CNN Epoch 178/300 | 训练损失: 37.7059 | 验证损失: 1.8790 | R2: 0.9048 | RMSE: 1.7758 | LR: 0.000355\n",
      "水头2D CNN Epoch 179/300 | 训练损失: 36.9076 | 验证损失: 2.4470 | R2: 0.8716 | RMSE: 2.0304 | LR: 0.000350\n",
      "水头2D CNN Epoch 180/300 | 训练损失: 38.3674 | 验证损失: 0.7916 | R2: 0.9600 | RMSE: 1.1511 | LR: 0.000345\n",
      "水头2D CNN Epoch 181/300 | 训练损失: 37.0292 | 验证损失: 0.8278 | R2: 0.9583 | RMSE: 1.1763 | LR: 0.000341\n",
      "水头2D CNN Epoch 182/300 | 训练损失: 35.6480 | 验证损失: 0.6831 | R2: 0.9653 | RMSE: 1.0710 | LR: 0.000336\n",
      "水头2D CNN Epoch 183/300 | 训练损失: 39.9930 | 验证损失: 4.0969 | R2: 0.7853 | RMSE: 2.6277 | LR: 0.000331\n",
      "水头2D CNN Epoch 184/300 | 训练损失: 35.6470 | 验证损失: 1.3430 | R2: 0.9323 | RMSE: 1.4986 | LR: 0.000326\n",
      "水头2D CNN Epoch 185/300 | 训练损失: 38.4949 | 验证损失: 0.8517 | R2: 0.9571 | RMSE: 1.1931 | LR: 0.000321\n",
      "水头2D CNN Epoch 186/300 | 训练损失: 36.7001 | 验证损失: 0.7994 | R2: 0.9598 | RMSE: 1.1552 | LR: 0.000316\n",
      "水头2D CNN Epoch 187/300 | 训练损失: 37.7082 | 验证损失: 1.4594 | R2: 0.9264 | RMSE: 1.5628 | LR: 0.000311\n",
      "水头2D CNN Epoch 188/300 | 训练损失: 36.7323 | 验证损失: 0.6510 | R2: 0.9669 | RMSE: 1.0455 | LR: 0.000306\n",
      "保存最佳2D CNN水头模型，验证损失: 0.6510\n",
      "水头2D CNN Epoch 189/300 | 训练损失: 35.0488 | 验证损失: 0.6457 | R2: 0.9671 | RMSE: 1.0419 | LR: 0.000301\n",
      "保存最佳2D CNN水头模型，验证损失: 0.6457\n",
      "水头2D CNN Epoch 190/300 | 训练损失: 38.2451 | 验证损失: 3.4018 | R2: 0.8221 | RMSE: 2.3954 | LR: 0.000297\n",
      "水头2D CNN Epoch 191/300 | 训练损失: 37.4281 | 验证损失: 1.9334 | R2: 0.9020 | RMSE: 1.8016 | LR: 0.000292\n",
      "水头2D CNN Epoch 192/300 | 训练损失: 38.2689 | 验证损失: 1.2638 | R2: 0.9359 | RMSE: 1.4564 | LR: 0.000287\n",
      "水头2D CNN Epoch 193/300 | 训练损失: 36.6756 | 验证损失: 0.9276 | R2: 0.9529 | RMSE: 1.2483 | LR: 0.000282\n",
      "水头2D CNN Epoch 194/300 | 训练损失: 35.9428 | 验证损失: 0.7026 | R2: 0.9646 | RMSE: 1.0840 | LR: 0.000278\n",
      "水头2D CNN Epoch 195/300 | 训练损失: 36.5951 | 验证损失: 0.8639 | R2: 0.9564 | RMSE: 1.2027 | LR: 0.000273\n",
      "水头2D CNN Epoch 196/300 | 训练损失: 38.1350 | 验证损失: 0.8975 | R2: 0.9538 | RMSE: 1.2303 | LR: 0.000268\n",
      "水头2D CNN Epoch 197/300 | 训练损失: 38.1319 | 验证损失: 1.6082 | R2: 0.9185 | RMSE: 1.6431 | LR: 0.000264\n",
      "水头2D CNN Epoch 198/300 | 训练损失: 37.4575 | 验证损失: 0.9066 | R2: 0.9544 | RMSE: 1.2303 | LR: 0.000259\n",
      "水头2D CNN Epoch 199/300 | 训练损失: 36.0348 | 验证损失: 0.7533 | R2: 0.9619 | RMSE: 1.1232 | LR: 0.000255\n",
      "水头2D CNN Epoch 200/300 | 训练损失: 36.5696 | 验证损失: 0.6717 | R2: 0.9656 | RMSE: 1.0636 | LR: 0.000250\n",
      "水头2D CNN Epoch 201/300 | 训练损失: 36.3292 | 验证损失: 0.9899 | R2: 0.9499 | RMSE: 1.2880 | LR: 0.000245\n",
      "水头2D CNN Epoch 202/300 | 训练损失: 33.9814 | 验证损失: 0.7045 | R2: 0.9637 | RMSE: 1.0903 | LR: 0.000241\n",
      "水头2D CNN Epoch 203/300 | 训练损失: 35.6496 | 验证损失: 1.9765 | R2: 0.9000 | RMSE: 1.8205 | LR: 0.000237\n",
      "水头2D CNN Epoch 204/300 | 训练损失: 36.0210 | 验证损失: 0.6658 | R2: 0.9659 | RMSE: 1.0593 | LR: 0.000232\n",
      "水头2D CNN Epoch 205/300 | 训练损失: 35.4354 | 验证损失: 1.0103 | R2: 0.9487 | RMSE: 1.3025 | LR: 0.000228\n",
      "水头2D CNN Epoch 206/300 | 训练损失: 35.5019 | 验证损失: 0.7557 | R2: 0.9615 | RMSE: 1.1272 | LR: 0.000223\n",
      "水头2D CNN Epoch 207/300 | 训练损失: 36.5260 | 验证损失: 0.8429 | R2: 0.9574 | RMSE: 1.1886 | LR: 0.000219\n",
      "水头2D CNN Epoch 208/300 | 训练损失: 38.7478 | 验证损失: 0.6501 | R2: 0.9666 | RMSE: 1.0472 | LR: 0.000215\n",
      "水头2D CNN Epoch 209/300 | 训练损失: 35.6476 | 验证损失: 1.3922 | R2: 0.9296 | RMSE: 1.5278 | LR: 0.000210\n",
      "水头2D CNN Epoch 210/300 | 训练损失: 36.4464 | 验证损失: 0.6643 | R2: 0.9662 | RMSE: 1.0567 | LR: 0.000206\n",
      "水头2D CNN Epoch 211/300 | 训练损失: 37.1521 | 验证损失: 0.6616 | R2: 0.9661 | RMSE: 1.0557 | LR: 0.000202\n",
      "水头2D CNN Epoch 212/300 | 训练损失: 36.7217 | 验证损失: 1.9354 | R2: 0.9014 | RMSE: 1.8049 | LR: 0.000198\n",
      "水头2D CNN Epoch 213/300 | 训练损失: 38.1934 | 验证损失: 0.9419 | R2: 0.9510 | RMSE: 1.2610 | LR: 0.000194\n",
      "水头2D CNN Epoch 214/300 | 训练损失: 35.1292 | 验证损失: 0.9124 | R2: 0.9538 | RMSE: 1.2370 | LR: 0.000189\n",
      "水头2D CNN Epoch 215/300 | 训练损失: 35.7083 | 验证损失: 0.7470 | R2: 0.9613 | RMSE: 1.1229 | LR: 0.000185\n",
      "水头2D CNN Epoch 216/300 | 训练损失: 36.4761 | 验证损失: 1.5519 | R2: 0.9216 | RMSE: 1.6128 | LR: 0.000181\n",
      "水头2D CNN Epoch 217/300 | 训练损失: 36.8502 | 验证损失: 0.6669 | R2: 0.9660 | RMSE: 1.0592 | LR: 0.000177\n",
      "水头2D CNN Epoch 218/300 | 训练损失: 35.0478 | 验证损失: 1.0000 | R2: 0.9494 | RMSE: 1.2946 | LR: 0.000173\n",
      "水头2D CNN Epoch 219/300 | 训练损失: 37.0963 | 验证损失: 1.8890 | R2: 0.9036 | RMSE: 1.7836 | LR: 0.000169\n",
      "水头模型早停触发! 在第219个epoch停止训练\n",
      "\n",
      "🔹 2D CNN水头模型训练完成！最佳验证损失: 0.6457\n",
      "🔹 开始训练2D CNN浓度模型...\n",
      "浓度2D CNN Epoch 001/300 | 训练损失: 5.8886 | 验证损失: 5.6281 | R2: 0.0009 | RMSE: 3.0815 | LR: 0.001000\n",
      "保存基于R2的最佳2D CNN浓度模型，R2: 0.0009\n",
      "浓度2D CNN Epoch 002/300 | 训练损失: 5.8619 | 验证损失: 5.6013 | R2: 0.0057 | RMSE: 3.0741 | LR: 0.001000\n",
      "保存基于R2的最佳2D CNN浓度模型，R2: 0.0057\n",
      "浓度2D CNN Epoch 003/300 | 训练损失: 5.7116 | 验证损失: 5.5260 | R2: 0.0191 | RMSE: 3.0534 | LR: 0.001000\n",
      "保存基于R2的最佳2D CNN浓度模型，R2: 0.0191\n",
      "浓度2D CNN Epoch 004/300 | 训练损失: 5.5261 | 验证损失: 5.4406 | R2: 0.0341 | RMSE: 3.0298 | LR: 0.001000\n",
      "保存基于R2的最佳2D CNN浓度模型，R2: 0.0341\n",
      "浓度2D CNN Epoch 005/300 | 训练损失: 5.4446 | 验证损失: 5.1949 | R2: 0.0778 | RMSE: 2.9605 | LR: 0.000999\n",
      "保存基于R2的最佳2D CNN浓度模型，R2: 0.0778\n",
      "浓度2D CNN Epoch 006/300 | 训练损失: 5.3155 | 验证损失: 4.9693 | R2: 0.1181 | RMSE: 2.8952 | LR: 0.000999\n",
      "保存基于R2的最佳2D CNN浓度模型，R2: 0.1181\n",
      "浓度2D CNN Epoch 007/300 | 训练损失: 5.1668 | 验证损失: 4.8887 | R2: 0.1324 | RMSE: 2.8716 | LR: 0.000999\n",
      "保存基于R2的最佳2D CNN浓度模型，R2: 0.1324\n",
      "浓度2D CNN Epoch 008/300 | 训练损失: 5.0969 | 验证损失: 4.8366 | R2: 0.1414 | RMSE: 2.8564 | LR: 0.000998\n",
      "保存基于R2的最佳2D CNN浓度模型，R2: 0.1414\n",
      "浓度2D CNN Epoch 009/300 | 训练损失: 5.1134 | 验证损失: 4.8666 | R2: 0.1364 | RMSE: 2.8651 | LR: 0.000998\n",
      "浓度2D CNN Epoch 010/300 | 训练损失: 5.0171 | 验证损失: 4.7447 | R2: 0.1577 | RMSE: 2.8293 | LR: 0.000997\n",
      "保存基于R2的最佳2D CNN浓度模型，R2: 0.1577\n",
      "浓度2D CNN Epoch 011/300 | 训练损失: 5.0394 | 验证损失: 4.8045 | R2: 0.1475 | RMSE: 2.8467 | LR: 0.000997\n",
      "浓度2D CNN Epoch 012/300 | 训练损失: 4.9572 | 验证损失: 4.7775 | R2: 0.1521 | RMSE: 2.8389 | LR: 0.000996\n",
      "浓度2D CNN Epoch 013/300 | 训练损失: 4.9108 | 验证损失: 4.7258 | R2: 0.1611 | RMSE: 2.8235 | LR: 0.000995\n",
      "保存基于R2的最佳2D CNN浓度模型，R2: 0.1611\n",
      "浓度2D CNN Epoch 014/300 | 训练损失: 4.8656 | 验证损失: 4.6067 | R2: 0.1824 | RMSE: 2.7876 | LR: 0.000995\n",
      "保存基于R2的最佳2D CNN浓度模型，R2: 0.1824\n",
      "浓度2D CNN Epoch 015/300 | 训练损失: 4.8671 | 验证损失: 4.6458 | R2: 0.1754 | RMSE: 2.7995 | LR: 0.000994\n",
      "浓度2D CNN Epoch 016/300 | 训练损失: 4.8416 | 验证损失: 4.5596 | R2: 0.1906 | RMSE: 2.7735 | LR: 0.000993\n",
      "保存基于R2的最佳2D CNN浓度模型，R2: 0.1906\n",
      "浓度2D CNN Epoch 017/300 | 训练损失: 4.8083 | 验证损失: 4.6108 | R2: 0.1821 | RMSE: 2.7885 | LR: 0.000992\n",
      "浓度2D CNN Epoch 018/300 | 训练损失: 4.8225 | 验证损失: 4.7021 | R2: 0.1659 | RMSE: 2.8159 | LR: 0.000991\n",
      "浓度2D CNN Epoch 019/300 | 训练损失: 4.8187 | 验证损失: 4.5451 | R2: 0.1937 | RMSE: 2.7686 | LR: 0.000990\n",
      "保存基于R2的最佳2D CNN浓度模型，R2: 0.1937\n",
      "浓度2D CNN Epoch 020/300 | 训练损失: 4.8022 | 验证损失: 5.1163 | R2: 0.0922 | RMSE: 2.9377 | LR: 0.000989\n",
      "浓度2D CNN Epoch 021/300 | 训练损失: 4.9609 | 验证损失: 4.8980 | R2: 0.1308 | RMSE: 2.8744 | LR: 0.000988\n",
      "浓度2D CNN Epoch 022/300 | 训练损失: 4.7738 | 验证损失: 4.5266 | R2: 0.1968 | RMSE: 2.7632 | LR: 0.000987\n",
      "保存基于R2的最佳2D CNN浓度模型，R2: 0.1968\n",
      "浓度2D CNN Epoch 023/300 | 训练损失: 4.7084 | 验证损失: 4.6020 | R2: 0.1831 | RMSE: 2.7862 | LR: 0.000986\n",
      "浓度2D CNN Epoch 024/300 | 训练损失: 4.7273 | 验证损失: 4.6455 | R2: 0.1761 | RMSE: 2.7987 | LR: 0.000984\n",
      "浓度2D CNN Epoch 025/300 | 训练损失: 4.7816 | 验证损失: 4.6238 | R2: 0.1796 | RMSE: 2.7926 | LR: 0.000983\n",
      "浓度2D CNN Epoch 026/300 | 训练损失: 4.6966 | 验证损失: 4.4687 | R2: 0.2069 | RMSE: 2.7455 | LR: 0.000982\n",
      "保存基于R2的最佳2D CNN浓度模型，R2: 0.2069\n",
      "浓度2D CNN Epoch 027/300 | 训练损失: 4.6681 | 验证损失: 4.4423 | R2: 0.2120 | RMSE: 2.7370 | LR: 0.000980\n",
      "保存基于R2的最佳2D CNN浓度模型，R2: 0.2120\n",
      "浓度2D CNN Epoch 028/300 | 训练损失: 4.6428 | 验证损失: 4.4928 | R2: 0.2026 | RMSE: 2.7528 | LR: 0.000979\n",
      "浓度2D CNN Epoch 029/300 | 训练损失: 4.6321 | 验证损失: 4.3812 | R2: 0.2226 | RMSE: 2.7184 | LR: 0.000977\n",
      "保存基于R2的最佳2D CNN浓度模型，R2: 0.2226\n",
      "浓度2D CNN Epoch 030/300 | 训练损失: 4.6412 | 验证损失: 4.4698 | R2: 0.2070 | RMSE: 2.7457 | LR: 0.000976\n",
      "浓度2D CNN Epoch 031/300 | 训练损失: 4.6811 | 验证损失: 4.4807 | R2: 0.2050 | RMSE: 2.7490 | LR: 0.000974\n",
      "浓度2D CNN Epoch 032/300 | 训练损失: 4.6041 | 验证损失: 4.5045 | R2: 0.2008 | RMSE: 2.7563 | LR: 0.000972\n",
      "浓度2D CNN Epoch 033/300 | 训练损失: 4.6191 | 验证损失: 4.4286 | R2: 0.2143 | RMSE: 2.7329 | LR: 0.000970\n",
      "浓度2D CNN Epoch 034/300 | 训练损失: 4.5861 | 验证损失: 4.4450 | R2: 0.2113 | RMSE: 2.7380 | LR: 0.000969\n",
      "浓度2D CNN Epoch 035/300 | 训练损失: 4.5894 | 验证损失: 4.4902 | R2: 0.2031 | RMSE: 2.7522 | LR: 0.000967\n",
      "浓度2D CNN Epoch 036/300 | 训练损失: 4.5971 | 验证损失: 4.4454 | R2: 0.2114 | RMSE: 2.7381 | LR: 0.000965\n",
      "浓度2D CNN Epoch 037/300 | 训练损失: 4.6239 | 验证损失: 4.4040 | R2: 0.2186 | RMSE: 2.7254 | LR: 0.000963\n",
      "浓度2D CNN Epoch 038/300 | 训练损失: 4.5924 | 验证损失: 4.5621 | R2: 0.1903 | RMSE: 2.7741 | LR: 0.000961\n",
      "浓度2D CNN Epoch 039/300 | 训练损失: 4.5475 | 验证损失: 4.4928 | R2: 0.2029 | RMSE: 2.7527 | LR: 0.000959\n",
      "浓度2D CNN Epoch 040/300 | 训练损失: 4.5415 | 验证损失: 4.4023 | R2: 0.2188 | RMSE: 2.7250 | LR: 0.000957\n",
      "浓度2D CNN Epoch 041/300 | 训练损失: 4.5381 | 验证损失: 4.5632 | R2: 0.1902 | RMSE: 2.7744 | LR: 0.000955\n",
      "浓度2D CNN Epoch 042/300 | 训练损失: 4.5590 | 验证损失: 4.6540 | R2: 0.1734 | RMSE: 2.8023 | LR: 0.000952\n",
      "浓度2D CNN Epoch 043/300 | 训练损失: 4.5188 | 验证损失: 4.3826 | R2: 0.2225 | RMSE: 2.7187 | LR: 0.000950\n",
      "浓度2D CNN Epoch 044/300 | 训练损失: 4.5263 | 验证损失: 4.3654 | R2: 0.2253 | RMSE: 2.7135 | LR: 0.000948\n",
      "保存基于R2的最佳2D CNN浓度模型，R2: 0.2253\n",
      "浓度2D CNN Epoch 045/300 | 训练损失: 4.5074 | 验证损失: 4.4137 | R2: 0.2168 | RMSE: 2.7284 | LR: 0.000946\n",
      "浓度2D CNN Epoch 046/300 | 训练损失: 4.5203 | 验证损失: 4.3306 | R2: 0.2316 | RMSE: 2.7026 | LR: 0.000943\n",
      "保存基于R2的最佳2D CNN浓度模型，R2: 0.2316\n",
      "浓度2D CNN Epoch 047/300 | 训练损失: 4.5010 | 验证损失: 4.3919 | R2: 0.2208 | RMSE: 2.7214 | LR: 0.000941\n",
      "浓度2D CNN Epoch 048/300 | 训练损失: 4.5064 | 验证损失: 4.3754 | R2: 0.2238 | RMSE: 2.7164 | LR: 0.000938\n",
      "浓度2D CNN Epoch 049/300 | 训练损失: 4.4918 | 验证损失: 4.3638 | R2: 0.2260 | RMSE: 2.7126 | LR: 0.000936\n",
      "浓度2D CNN Epoch 050/300 | 训练损失: 4.4636 | 验证损失: 4.3920 | R2: 0.2209 | RMSE: 2.7214 | LR: 0.000933\n",
      "浓度2D CNN Epoch 051/300 | 训练损失: 4.4732 | 验证损失: 4.3433 | R2: 0.2298 | RMSE: 2.7061 | LR: 0.000930\n",
      "浓度2D CNN Epoch 052/300 | 训练损失: 4.4366 | 验证损失: 4.3526 | R2: 0.2275 | RMSE: 2.7095 | LR: 0.000928\n",
      "浓度2D CNN Epoch 053/300 | 训练损失: 4.4657 | 验证损失: 4.3405 | R2: 0.2297 | RMSE: 2.7058 | LR: 0.000925\n",
      "浓度2D CNN Epoch 054/300 | 训练损失: 4.4610 | 验证损失: 4.3569 | R2: 0.2265 | RMSE: 2.7112 | LR: 0.000922\n",
      "浓度2D CNN Epoch 055/300 | 训练损失: 4.4516 | 验证损失: 4.3671 | R2: 0.2255 | RMSE: 2.7136 | LR: 0.000919\n",
      "浓度2D CNN Epoch 056/300 | 训练损失: 4.4544 | 验证损失: 4.6329 | R2: 0.1780 | RMSE: 2.7953 | LR: 0.000916\n",
      "浓度2D CNN Epoch 057/300 | 训练损失: 4.4397 | 验证损失: 4.3393 | R2: 0.2301 | RMSE: 2.7053 | LR: 0.000914\n",
      "浓度2D CNN Epoch 058/300 | 训练损失: 4.4404 | 验证损失: 4.3809 | R2: 0.2224 | RMSE: 2.7183 | LR: 0.000911\n",
      "浓度2D CNN Epoch 059/300 | 训练损失: 4.4345 | 验证损失: 4.3486 | R2: 0.2284 | RMSE: 2.7081 | LR: 0.000908\n",
      "浓度2D CNN Epoch 060/300 | 训练损失: 4.4170 | 验证损失: 4.3800 | R2: 0.2227 | RMSE: 2.7179 | LR: 0.000905\n",
      "浓度2D CNN Epoch 061/300 | 训练损失: 4.4474 | 验证损失: 4.3524 | R2: 0.2279 | RMSE: 2.7090 | LR: 0.000901\n",
      "浓度2D CNN Epoch 062/300 | 训练损失: 4.4599 | 验证损失: 4.5714 | R2: 0.1880 | RMSE: 2.7774 | LR: 0.000898\n",
      "浓度2D CNN Epoch 063/300 | 训练损失: 4.4475 | 验证损失: 4.3997 | R2: 0.2190 | RMSE: 2.7243 | LR: 0.000895\n",
      "浓度2D CNN Epoch 064/300 | 训练损失: 4.7266 | 验证损失: 4.5059 | R2: 0.2001 | RMSE: 2.7570 | LR: 0.000892\n",
      "浓度2D CNN Epoch 065/300 | 训练损失: 4.5575 | 验证损失: 4.4188 | R2: 0.2158 | RMSE: 2.7300 | LR: 0.000889\n",
      "浓度2D CNN Epoch 066/300 | 训练损失: 4.4692 | 验证损失: 4.3799 | R2: 0.2227 | RMSE: 2.7179 | LR: 0.000885\n",
      "浓度2D CNN Epoch 067/300 | 训练损失: 4.4272 | 验证损失: 4.3311 | R2: 0.2316 | RMSE: 2.7026 | LR: 0.000882\n",
      "浓度2D CNN Epoch 068/300 | 训练损失: 4.4202 | 验证损失: 4.3245 | R2: 0.2326 | RMSE: 2.7007 | LR: 0.000878\n",
      "保存基于R2的最佳2D CNN浓度模型，R2: 0.2326\n",
      "浓度2D CNN Epoch 069/300 | 训练损失: 4.3677 | 验证损失: 4.3749 | R2: 0.2232 | RMSE: 2.7168 | LR: 0.000875\n",
      "浓度2D CNN Epoch 070/300 | 训练损失: 4.5159 | 验证损失: 4.4472 | R2: 0.2103 | RMSE: 2.7393 | LR: 0.000872\n",
      "浓度2D CNN Epoch 071/300 | 训练损失: 4.4028 | 验证损失: 4.3558 | R2: 0.2269 | RMSE: 2.7106 | LR: 0.000868\n",
      "浓度2D CNN Epoch 072/300 | 训练损失: 4.3663 | 验证损失: 4.3630 | R2: 0.2255 | RMSE: 2.7130 | LR: 0.000864\n",
      "浓度2D CNN Epoch 073/300 | 训练损失: 4.4008 | 验证损失: 4.6373 | R2: 0.1770 | RMSE: 2.7967 | LR: 0.000861\n",
      "浓度2D CNN Epoch 074/300 | 训练损失: 4.3946 | 验证损失: 4.4712 | R2: 0.2067 | RMSE: 2.7461 | LR: 0.000857\n",
      "浓度2D CNN Epoch 075/300 | 训练损失: 4.3796 | 验证损失: 4.2925 | R2: 0.2383 | RMSE: 2.6906 | LR: 0.000854\n",
      "保存基于R2的最佳2D CNN浓度模型，R2: 0.2383\n",
      "浓度2D CNN Epoch 076/300 | 训练损失: 4.3652 | 验证损失: 4.2922 | R2: 0.2385 | RMSE: 2.6904 | LR: 0.000850\n",
      "保存基于R2的最佳2D CNN浓度模型，R2: 0.2385\n",
      "浓度2D CNN Epoch 077/300 | 训练损失: 4.3600 | 验证损失: 4.3187 | R2: 0.2338 | RMSE: 2.6986 | LR: 0.000846\n",
      "浓度2D CNN Epoch 078/300 | 训练损失: 4.3672 | 验证损失: 4.4878 | R2: 0.2031 | RMSE: 2.7516 | LR: 0.000842\n",
      "浓度2D CNN Epoch 079/300 | 训练损失: 4.3508 | 验证损失: 4.3350 | R2: 0.2309 | RMSE: 2.7038 | LR: 0.000838\n",
      "浓度2D CNN Epoch 080/300 | 训练损失: 4.3533 | 验证损失: 4.3866 | R2: 0.2214 | RMSE: 2.7202 | LR: 0.000835\n",
      "浓度2D CNN Epoch 081/300 | 训练损失: 4.3567 | 验证损失: 4.3383 | R2: 0.2300 | RMSE: 2.7049 | LR: 0.000831\n",
      "浓度2D CNN Epoch 082/300 | 训练损失: 4.3539 | 验证损失: 4.3599 | R2: 0.2265 | RMSE: 2.7115 | LR: 0.000827\n",
      "浓度2D CNN Epoch 083/300 | 训练损失: 4.3151 | 验证损失: 4.3171 | R2: 0.2339 | RMSE: 2.6983 | LR: 0.000823\n",
      "浓度2D CNN Epoch 084/300 | 训练损失: 4.3102 | 验证损失: 4.2875 | R2: 0.2392 | RMSE: 2.6890 | LR: 0.000819\n",
      "保存基于R2的最佳2D CNN浓度模型，R2: 0.2392\n",
      "浓度2D CNN Epoch 085/300 | 训练损失: 4.2922 | 验证损失: 4.3301 | R2: 0.2314 | RMSE: 2.7025 | LR: 0.000815\n",
      "浓度2D CNN Epoch 086/300 | 训练损失: 4.3019 | 验证损失: 4.2694 | R2: 0.2420 | RMSE: 2.6837 | LR: 0.000811\n",
      "保存基于R2的最佳2D CNN浓度模型，R2: 0.2420\n",
      "浓度2D CNN Epoch 087/300 | 训练损失: 4.2970 | 验证损失: 4.3207 | R2: 0.2335 | RMSE: 2.6992 | LR: 0.000806\n",
      "浓度2D CNN Epoch 088/300 | 训练损失: 4.2888 | 验证损失: 4.4036 | R2: 0.2177 | RMSE: 2.7259 | LR: 0.000802\n",
      "浓度2D CNN Epoch 089/300 | 训练损失: 4.4169 | 验证损失: 4.3223 | R2: 0.2327 | RMSE: 2.7003 | LR: 0.000798\n",
      "浓度2D CNN Epoch 090/300 | 训练损失: 4.2892 | 验证损失: 4.2771 | R2: 0.2411 | RMSE: 2.6856 | LR: 0.000794\n",
      "浓度2D CNN Epoch 091/300 | 训练损失: 4.2803 | 验证损失: 4.2765 | R2: 0.2410 | RMSE: 2.6859 | LR: 0.000790\n",
      "浓度2D CNN Epoch 092/300 | 训练损失: 4.2607 | 验证损失: 4.5125 | R2: 0.1995 | RMSE: 2.7586 | LR: 0.000785\n",
      "浓度2D CNN Epoch 093/300 | 训练损失: 4.2768 | 验证损失: 4.3317 | R2: 0.2309 | RMSE: 2.7034 | LR: 0.000781\n",
      "浓度2D CNN Epoch 094/300 | 训练损失: 4.2677 | 验证损失: 4.2962 | R2: 0.2378 | RMSE: 2.6917 | LR: 0.000777\n",
      "浓度2D CNN Epoch 095/300 | 训练损失: 4.2551 | 验证损失: 4.4014 | R2: 0.2193 | RMSE: 2.7243 | LR: 0.000772\n",
      "浓度2D CNN Epoch 096/300 | 训练损失: 4.2767 | 验证损失: 4.3762 | R2: 0.2238 | RMSE: 2.7165 | LR: 0.000768\n",
      "浓度2D CNN Epoch 097/300 | 训练损失: 4.2508 | 验证损失: 4.3001 | R2: 0.2371 | RMSE: 2.6928 | LR: 0.000763\n",
      "浓度2D CNN Epoch 098/300 | 训练损失: 4.2249 | 验证损失: 4.2734 | R2: 0.2417 | RMSE: 2.6846 | LR: 0.000759\n",
      "浓度2D CNN Epoch 099/300 | 训练损失: 4.2375 | 验证损失: 4.2873 | R2: 0.2389 | RMSE: 2.6892 | LR: 0.000755\n",
      "浓度2D CNN Epoch 100/300 | 训练损失: 4.2305 | 验证损失: 4.3058 | R2: 0.2358 | RMSE: 2.6948 | LR: 0.000750\n",
      "浓度2D CNN Epoch 101/300 | 训练损失: 4.2337 | 验证损失: 4.2775 | R2: 0.2411 | RMSE: 2.6858 | LR: 0.000745\n",
      "浓度2D CNN Epoch 102/300 | 训练损失: 4.2320 | 验证损失: 4.2583 | R2: 0.2443 | RMSE: 2.6800 | LR: 0.000741\n",
      "保存基于R2的最佳2D CNN浓度模型，R2: 0.2443\n",
      "浓度2D CNN Epoch 103/300 | 训练损失: 4.2029 | 验证损失: 4.3412 | R2: 0.2301 | RMSE: 2.7055 | LR: 0.000736\n",
      "浓度2D CNN Epoch 104/300 | 训练损失: 4.2320 | 验证损失: 4.3240 | R2: 0.2323 | RMSE: 2.7008 | LR: 0.000732\n",
      "浓度2D CNN Epoch 105/300 | 训练损失: 4.2488 | 验证损失: 4.2900 | R2: 0.2389 | RMSE: 2.6898 | LR: 0.000727\n",
      "浓度2D CNN Epoch 106/300 | 训练损失: 4.2199 | 验证损失: 4.3426 | R2: 0.2289 | RMSE: 2.7068 | LR: 0.000722\n",
      "浓度2D CNN Epoch 107/300 | 训练损失: 4.2295 | 验证损失: 4.2609 | R2: 0.2439 | RMSE: 2.6806 | LR: 0.000718\n",
      "浓度2D CNN Epoch 108/300 | 训练损失: 4.2189 | 验证损失: 4.3281 | R2: 0.2323 | RMSE: 2.7015 | LR: 0.000713\n",
      "浓度2D CNN Epoch 109/300 | 训练损失: 4.2135 | 验证损失: 4.2820 | R2: 0.2402 | RMSE: 2.6873 | LR: 0.000708\n",
      "浓度2D CNN Epoch 110/300 | 训练损失: 4.2103 | 验证损失: 4.2779 | R2: 0.2411 | RMSE: 2.6858 | LR: 0.000703\n",
      "浓度2D CNN Epoch 111/300 | 训练损失: 4.2063 | 验证损失: 4.3074 | R2: 0.2359 | RMSE: 2.6951 | LR: 0.000699\n",
      "浓度2D CNN Epoch 112/300 | 训练损失: 4.2061 | 验证损失: 4.2899 | R2: 0.2388 | RMSE: 2.6897 | LR: 0.000694\n",
      "浓度2D CNN Epoch 113/300 | 训练损失: 4.2069 | 验证损失: 4.3035 | R2: 0.2361 | RMSE: 2.6942 | LR: 0.000689\n",
      "浓度2D CNN Epoch 114/300 | 训练损失: 4.2146 | 验证损失: 4.2966 | R2: 0.2374 | RMSE: 2.6919 | LR: 0.000684\n",
      "浓度2D CNN Epoch 115/300 | 训练损失: 4.3986 | 验证损失: 4.2560 | R2: 0.2447 | RMSE: 2.6792 | LR: 0.000679\n",
      "保存基于R2的最佳2D CNN浓度模型，R2: 0.2447\n",
      "浓度2D CNN Epoch 116/300 | 训练损失: 4.2063 | 验证损失: 4.2659 | R2: 0.2428 | RMSE: 2.6825 | LR: 0.000674\n",
      "浓度2D CNN Epoch 117/300 | 训练损失: 4.1858 | 验证损失: 4.2499 | R2: 0.2459 | RMSE: 2.6772 | LR: 0.000669\n",
      "保存基于R2的最佳2D CNN浓度模型，R2: 0.2459\n",
      "浓度2D CNN Epoch 118/300 | 训练损失: 4.2027 | 验证损失: 4.3590 | R2: 0.2258 | RMSE: 2.7119 | LR: 0.000664\n",
      "浓度2D CNN Epoch 119/300 | 训练损失: 4.1807 | 验证损失: 4.3757 | R2: 0.2237 | RMSE: 2.7164 | LR: 0.000659\n",
      "浓度2D CNN Epoch 120/300 | 训练损失: 4.1880 | 验证损失: 4.3941 | R2: 0.2192 | RMSE: 2.7231 | LR: 0.000655\n",
      "浓度2D CNN Epoch 121/300 | 训练损失: 4.2136 | 验证损失: 4.2449 | R2: 0.2467 | RMSE: 2.6757 | LR: 0.000650\n",
      "保存基于R2的最佳2D CNN浓度模型，R2: 0.2467\n",
      "浓度2D CNN Epoch 122/300 | 训练损失: 4.1892 | 验证损失: 4.2673 | R2: 0.2424 | RMSE: 2.6830 | LR: 0.000645\n",
      "浓度2D CNN Epoch 123/300 | 训练损失: 4.1761 | 验证损失: 4.2425 | R2: 0.2468 | RMSE: 2.6752 | LR: 0.000639\n",
      "保存基于R2的最佳2D CNN浓度模型，R2: 0.2468\n",
      "浓度2D CNN Epoch 124/300 | 训练损失: 4.1680 | 验证损失: 4.2500 | R2: 0.2458 | RMSE: 2.6772 | LR: 0.000634\n",
      "浓度2D CNN Epoch 125/300 | 训练损失: 4.3051 | 验证损失: 4.3142 | R2: 0.2340 | RMSE: 2.6978 | LR: 0.000629\n",
      "浓度2D CNN Epoch 126/300 | 训练损失: 4.2058 | 验证损失: 4.2725 | R2: 0.2419 | RMSE: 2.6843 | LR: 0.000624\n",
      "浓度2D CNN Epoch 127/300 | 训练损失: 4.1731 | 验证损失: 4.3147 | R2: 0.2337 | RMSE: 2.6980 | LR: 0.000619\n",
      "浓度2D CNN Epoch 128/300 | 训练损失: 4.1883 | 验证损失: 4.2761 | R2: 0.2414 | RMSE: 2.6853 | LR: 0.000614\n",
      "浓度2D CNN Epoch 129/300 | 训练损失: 4.1857 | 验证损失: 4.2538 | R2: 0.2451 | RMSE: 2.6785 | LR: 0.000609\n",
      "浓度2D CNN Epoch 130/300 | 训练损失: 4.1575 | 验证损失: 4.2483 | R2: 0.2459 | RMSE: 2.6769 | LR: 0.000604\n",
      "浓度2D CNN Epoch 131/300 | 训练损失: 4.1697 | 验证损失: 4.2412 | R2: 0.2473 | RMSE: 2.6745 | LR: 0.000599\n",
      "保存基于R2的最佳2D CNN浓度模型，R2: 0.2473\n",
      "浓度2D CNN Epoch 132/300 | 训练损失: 4.1347 | 验证损失: 4.2655 | R2: 0.2431 | RMSE: 2.6821 | LR: 0.000594\n",
      "浓度2D CNN Epoch 133/300 | 训练损失: 4.1551 | 验证损失: 4.2329 | R2: 0.2486 | RMSE: 2.6721 | LR: 0.000589\n",
      "保存基于R2的最佳2D CNN浓度模型，R2: 0.2486\n",
      "浓度2D CNN Epoch 134/300 | 训练损失: 4.1447 | 验证损失: 4.2557 | R2: 0.2449 | RMSE: 2.6790 | LR: 0.000583\n",
      "浓度2D CNN Epoch 135/300 | 训练损失: 4.1602 | 验证损失: 4.2947 | R2: 0.2375 | RMSE: 2.6915 | LR: 0.000578\n",
      "浓度2D CNN Epoch 136/300 | 训练损失: 4.1496 | 验证损失: 4.2353 | R2: 0.2484 | RMSE: 2.6726 | LR: 0.000573\n",
      "浓度2D CNN Epoch 137/300 | 训练损失: 4.1765 | 验证损失: 4.2994 | R2: 0.2364 | RMSE: 2.6933 | LR: 0.000568\n",
      "浓度2D CNN Epoch 138/300 | 训练损失: 4.1573 | 验证损失: 4.2586 | R2: 0.2441 | RMSE: 2.6801 | LR: 0.000563\n",
      "浓度2D CNN Epoch 139/300 | 训练损失: 4.1745 | 验证损失: 4.2566 | R2: 0.2446 | RMSE: 2.6794 | LR: 0.000557\n",
      "浓度2D CNN Epoch 140/300 | 训练损失: 4.1660 | 验证损失: 4.2565 | R2: 0.2447 | RMSE: 2.6793 | LR: 0.000552\n",
      "浓度2D CNN Epoch 141/300 | 训练损失: 4.1375 | 验证损失: 4.2570 | R2: 0.2442 | RMSE: 2.6798 | LR: 0.000547\n",
      "浓度2D CNN Epoch 142/300 | 训练损失: 4.1463 | 验证损失: 4.5574 | R2: 0.1895 | RMSE: 2.7737 | LR: 0.000542\n",
      "浓度2D CNN Epoch 143/300 | 训练损失: 4.1456 | 验证损失: 4.2406 | R2: 0.2474 | RMSE: 2.6744 | LR: 0.000537\n",
      "浓度2D CNN Epoch 144/300 | 训练损失: 4.1180 | 验证损失: 4.3183 | R2: 0.2329 | RMSE: 2.6994 | LR: 0.000531\n",
      "浓度2D CNN Epoch 145/300 | 训练损失: 4.1488 | 验证损失: 4.2481 | R2: 0.2461 | RMSE: 2.6767 | LR: 0.000526\n",
      "浓度2D CNN Epoch 146/300 | 训练损失: 4.1462 | 验证损失: 4.2647 | R2: 0.2433 | RMSE: 2.6819 | LR: 0.000521\n",
      "浓度2D CNN Epoch 147/300 | 训练损失: 4.1522 | 验证损失: 4.2636 | R2: 0.2436 | RMSE: 2.6813 | LR: 0.000516\n",
      "浓度2D CNN Epoch 148/300 | 训练损失: 4.1518 | 验证损失: 4.2402 | R2: 0.2473 | RMSE: 2.6744 | LR: 0.000510\n",
      "浓度2D CNN Epoch 149/300 | 训练损失: 4.1559 | 验证损失: 4.2469 | R2: 0.2461 | RMSE: 2.6765 | LR: 0.000505\n",
      "浓度2D CNN Epoch 150/300 | 训练损失: 4.1418 | 验证损失: 4.2527 | R2: 0.2452 | RMSE: 2.6782 | LR: 0.000500\n",
      "浓度2D CNN Epoch 151/300 | 训练损失: 4.1511 | 验证损失: 4.2301 | R2: 0.2491 | RMSE: 2.6712 | LR: 0.000495\n",
      "保存基于R2的最佳2D CNN浓度模型，R2: 0.2491\n",
      "浓度2D CNN Epoch 152/300 | 训练损失: 4.3205 | 验证损失: 4.2818 | R2: 0.2394 | RMSE: 2.6879 | LR: 0.000490\n",
      "浓度2D CNN Epoch 153/300 | 训练损失: 4.1258 | 验证损失: 4.2323 | R2: 0.2487 | RMSE: 2.6719 | LR: 0.000484\n",
      "浓度2D CNN Epoch 154/300 | 训练损失: 4.1320 | 验证损失: 4.2478 | R2: 0.2462 | RMSE: 2.6766 | LR: 0.000479\n",
      "浓度2D CNN Epoch 155/300 | 训练损失: 4.1347 | 验证损失: 4.2571 | R2: 0.2447 | RMSE: 2.6794 | LR: 0.000474\n",
      "浓度2D CNN Epoch 156/300 | 训练损失: 4.1350 | 验证损失: 4.2594 | R2: 0.2437 | RMSE: 2.6806 | LR: 0.000469\n",
      "浓度2D CNN Epoch 157/300 | 训练损失: 4.1247 | 验证损失: 4.2728 | R2: 0.2411 | RMSE: 2.6849 | LR: 0.000463\n",
      "浓度2D CNN Epoch 158/300 | 训练损失: 4.1207 | 验证损失: 4.3049 | R2: 0.2363 | RMSE: 2.6944 | LR: 0.000458\n",
      "浓度2D CNN Epoch 159/300 | 训练损失: 4.1184 | 验证损失: 4.3119 | R2: 0.2350 | RMSE: 2.6966 | LR: 0.000453\n",
      "浓度2D CNN Epoch 160/300 | 训练损失: 4.1451 | 验证损失: 4.2335 | R2: 0.2486 | RMSE: 2.6722 | LR: 0.000448\n",
      "浓度2D CNN Epoch 161/300 | 训练损失: 4.1080 | 验证损失: 4.3440 | R2: 0.2292 | RMSE: 2.7067 | LR: 0.000443\n",
      "浓度2D CNN Epoch 162/300 | 训练损失: 4.1414 | 验证损失: 4.3026 | R2: 0.2358 | RMSE: 2.6944 | LR: 0.000437\n",
      "浓度2D CNN Epoch 163/300 | 训练损失: 4.1258 | 验证损失: 4.2594 | R2: 0.2440 | RMSE: 2.6804 | LR: 0.000432\n",
      "浓度2D CNN Epoch 164/300 | 训练损失: 4.1384 | 验证损失: 4.2235 | R2: 0.2503 | RMSE: 2.6691 | LR: 0.000427\n",
      "保存基于R2的最佳2D CNN浓度模型，R2: 0.2503\n",
      "浓度2D CNN Epoch 165/300 | 训练损失: 4.1053 | 验证损失: 4.2334 | R2: 0.2487 | RMSE: 2.6721 | LR: 0.000422\n",
      "浓度2D CNN Epoch 166/300 | 训练损失: 4.1423 | 验证损失: 4.2463 | R2: 0.2460 | RMSE: 2.6765 | LR: 0.000417\n",
      "浓度2D CNN Epoch 167/300 | 训练损失: 4.1151 | 验证损失: 4.2678 | R2: 0.2429 | RMSE: 2.6827 | LR: 0.000411\n",
      "浓度2D CNN Epoch 168/300 | 训练损失: 4.0934 | 验证损失: 4.2436 | R2: 0.2466 | RMSE: 2.6755 | LR: 0.000406\n",
      "浓度2D CNN Epoch 169/300 | 训练损失: 4.1171 | 验证损失: 4.2110 | R2: 0.2526 | RMSE: 2.6650 | LR: 0.000401\n",
      "保存基于R2的最佳2D CNN浓度模型，R2: 0.2526\n",
      "浓度2D CNN Epoch 170/300 | 训练损失: 4.1132 | 验证损失: 4.3636 | R2: 0.2247 | RMSE: 2.7135 | LR: 0.000396\n",
      "浓度2D CNN Epoch 171/300 | 训练损失: 4.1013 | 验证损失: 4.2269 | R2: 0.2497 | RMSE: 2.6701 | LR: 0.000391\n",
      "浓度2D CNN Epoch 172/300 | 训练损失: 4.2551 | 验证损失: 4.2305 | R2: 0.2492 | RMSE: 2.6712 | LR: 0.000386\n",
      "浓度2D CNN Epoch 173/300 | 训练损失: 4.1249 | 验证损失: 4.2231 | R2: 0.2506 | RMSE: 2.6689 | LR: 0.000381\n",
      "浓度2D CNN Epoch 174/300 | 训练损失: 4.1247 | 验证损失: 4.2699 | R2: 0.2415 | RMSE: 2.6841 | LR: 0.000376\n",
      "浓度2D CNN Epoch 175/300 | 训练损失: 4.2923 | 验证损失: 4.2856 | R2: 0.2387 | RMSE: 2.6891 | LR: 0.000371\n",
      "浓度2D CNN Epoch 176/300 | 训练损失: 4.1309 | 验证损失: 4.2774 | R2: 0.2404 | RMSE: 2.6863 | LR: 0.000366\n",
      "浓度2D CNN Epoch 177/300 | 训练损失: 4.1413 | 验证损失: 4.2708 | R2: 0.2423 | RMSE: 2.6837 | LR: 0.000361\n",
      "浓度2D CNN Epoch 178/300 | 训练损失: 4.1362 | 验证损失: 4.3093 | R2: 0.2345 | RMSE: 2.6964 | LR: 0.000355\n",
      "浓度2D CNN Epoch 179/300 | 训练损失: 4.1201 | 验证损失: 4.2700 | R2: 0.2416 | RMSE: 2.6841 | LR: 0.000350\n",
      "浓度2D CNN Epoch 180/300 | 训练损失: 4.1190 | 验证损失: 4.2702 | R2: 0.2416 | RMSE: 2.6841 | LR: 0.000345\n",
      "浓度2D CNN Epoch 181/300 | 训练损失: 4.2187 | 验证损失: 4.2236 | R2: 0.2503 | RMSE: 2.6691 | LR: 0.000341\n",
      "浓度2D CNN Epoch 182/300 | 训练损失: 4.0927 | 验证损失: 4.2468 | R2: 0.2462 | RMSE: 2.6764 | LR: 0.000336\n",
      "浓度2D CNN Epoch 183/300 | 训练损失: 4.1089 | 验证损失: 4.2241 | R2: 0.2503 | RMSE: 2.6692 | LR: 0.000331\n",
      "浓度2D CNN Epoch 184/300 | 训练损失: 4.1531 | 验证损失: 4.2696 | R2: 0.2425 | RMSE: 2.6833 | LR: 0.000326\n",
      "浓度2D CNN Epoch 185/300 | 训练损失: 4.1179 | 验证损失: 4.2296 | R2: 0.2491 | RMSE: 2.6710 | LR: 0.000321\n",
      "浓度2D CNN Epoch 186/300 | 训练损失: 4.1070 | 验证损失: 4.2337 | R2: 0.2486 | RMSE: 2.6723 | LR: 0.000316\n",
      "浓度2D CNN Epoch 187/300 | 训练损失: 4.1274 | 验证损失: 4.2378 | R2: 0.2478 | RMSE: 2.6736 | LR: 0.000311\n",
      "浓度2D CNN Epoch 188/300 | 训练损失: 4.1106 | 验证损失: 4.2274 | R2: 0.2496 | RMSE: 2.6703 | LR: 0.000306\n",
      "浓度2D CNN Epoch 189/300 | 训练损失: 4.2381 | 验证损失: 4.2844 | R2: 0.2397 | RMSE: 2.6881 | LR: 0.000301\n",
      "浓度2D CNN Epoch 190/300 | 训练损失: 4.1169 | 验证损失: 4.2250 | R2: 0.2499 | RMSE: 2.6697 | LR: 0.000297\n",
      "浓度2D CNN Epoch 191/300 | 训练损失: 4.0958 | 验证损失: 4.2310 | R2: 0.2488 | RMSE: 2.6716 | LR: 0.000292\n",
      "浓度2D CNN Epoch 192/300 | 训练损失: 4.0991 | 验证损失: 4.2208 | R2: 0.2505 | RMSE: 2.6684 | LR: 0.000287\n",
      "浓度2D CNN Epoch 193/300 | 训练损失: 4.0854 | 验证损失: 4.2271 | R2: 0.2498 | RMSE: 2.6701 | LR: 0.000282\n",
      "浓度2D CNN Epoch 194/300 | 训练损失: 4.1183 | 验证损失: 4.2290 | R2: 0.2495 | RMSE: 2.6707 | LR: 0.000278\n",
      "浓度2D CNN Epoch 195/300 | 训练损失: 4.0747 | 验证损失: 4.2297 | R2: 0.2493 | RMSE: 2.6710 | LR: 0.000273\n",
      "浓度2D CNN Epoch 196/300 | 训练损失: 4.1082 | 验证损失: 4.2106 | R2: 0.2527 | RMSE: 2.6649 | LR: 0.000268\n",
      "保存基于R2的最佳2D CNN浓度模型，R2: 0.2527\n",
      "浓度2D CNN Epoch 197/300 | 训练损失: 4.1050 | 验证损失: 4.3562 | R2: 0.2272 | RMSE: 2.7104 | LR: 0.000264\n",
      "浓度2D CNN Epoch 198/300 | 训练损失: 4.1153 | 验证损失: 4.2436 | R2: 0.2463 | RMSE: 2.6757 | LR: 0.000259\n",
      "浓度2D CNN Epoch 199/300 | 训练损失: 4.1092 | 验证损失: 4.2306 | R2: 0.2493 | RMSE: 2.6712 | LR: 0.000255\n",
      "浓度2D CNN Epoch 200/300 | 训练损失: 4.1281 | 验证损失: 4.2815 | R2: 0.2403 | RMSE: 2.6871 | LR: 0.000250\n",
      "浓度2D CNN Epoch 201/300 | 训练损失: 4.1156 | 验证损失: 4.2207 | R2: 0.2506 | RMSE: 2.6684 | LR: 0.000245\n",
      "浓度2D CNN Epoch 202/300 | 训练损失: 4.1034 | 验证损失: 4.2294 | R2: 0.2490 | RMSE: 2.6712 | LR: 0.000241\n",
      "浓度2D CNN Epoch 203/300 | 训练损失: 4.0952 | 验证损失: 4.2180 | R2: 0.2513 | RMSE: 2.6673 | LR: 0.000237\n",
      "浓度2D CNN Epoch 204/300 | 训练损失: 4.0936 | 验证损失: 4.2098 | R2: 0.2527 | RMSE: 2.6648 | LR: 0.000232\n",
      "浓度2D CNN Epoch 205/300 | 训练损失: 4.0823 | 验证损失: 4.2430 | R2: 0.2464 | RMSE: 2.6756 | LR: 0.000228\n",
      "浓度2D CNN Epoch 206/300 | 训练损失: 4.0924 | 验证损失: 4.2765 | R2: 0.2412 | RMSE: 2.6856 | LR: 0.000223\n",
      "浓度2D CNN Epoch 207/300 | 训练损失: 4.0889 | 验证损失: 4.2507 | R2: 0.2450 | RMSE: 2.6780 | LR: 0.000219\n",
      "浓度2D CNN Epoch 208/300 | 训练损失: 4.0922 | 验证损失: 4.2207 | R2: 0.2507 | RMSE: 2.6683 | LR: 0.000215\n",
      "浓度2D CNN Epoch 209/300 | 训练损失: 4.0938 | 验证损失: 4.2347 | R2: 0.2486 | RMSE: 2.6724 | LR: 0.000210\n",
      "浓度2D CNN Epoch 210/300 | 训练损失: 4.0987 | 验证损失: 4.2306 | R2: 0.2487 | RMSE: 2.6715 | LR: 0.000206\n",
      "浓度2D CNN Epoch 211/300 | 训练损失: 4.0875 | 验证损失: 4.2161 | R2: 0.2515 | RMSE: 2.6668 | LR: 0.000202\n",
      "浓度2D CNN Epoch 212/300 | 训练损失: 4.1224 | 验证损失: 4.2136 | R2: 0.2521 | RMSE: 2.6659 | LR: 0.000198\n",
      "浓度2D CNN Epoch 213/300 | 训练损失: 4.0760 | 验证损失: 4.2197 | R2: 0.2509 | RMSE: 2.6680 | LR: 0.000194\n",
      "浓度2D CNN Epoch 214/300 | 训练损失: 4.0800 | 验证损失: 4.2495 | R2: 0.2460 | RMSE: 2.6771 | LR: 0.000189\n",
      "浓度2D CNN Epoch 215/300 | 训练损失: 4.0847 | 验证损失: 4.2189 | R2: 0.2513 | RMSE: 2.6675 | LR: 0.000185\n",
      "浓度2D CNN Epoch 216/300 | 训练损失: 4.1012 | 验证损失: 4.2381 | R2: 0.2473 | RMSE: 2.6740 | LR: 0.000181\n",
      "浓度2D CNN Epoch 217/300 | 训练损失: 4.0990 | 验证损失: 4.2289 | R2: 0.2495 | RMSE: 2.6707 | LR: 0.000177\n",
      "浓度2D CNN Epoch 218/300 | 训练损失: 4.0847 | 验证损失: 4.2373 | R2: 0.2481 | RMSE: 2.6733 | LR: 0.000173\n",
      "浓度2D CNN Epoch 219/300 | 训练损失: 4.0647 | 验证损失: 4.2063 | R2: 0.2532 | RMSE: 2.6637 | LR: 0.000169\n",
      "保存基于R2的最佳2D CNN浓度模型，R2: 0.2532\n",
      "浓度2D CNN Epoch 220/300 | 训练损失: 4.0899 | 验证损失: 4.2117 | R2: 0.2525 | RMSE: 2.6653 | LR: 0.000165\n",
      "浓度2D CNN Epoch 221/300 | 训练损失: 4.1209 | 验证损失: 4.2122 | R2: 0.2524 | RMSE: 2.6654 | LR: 0.000162\n",
      "浓度2D CNN Epoch 222/300 | 训练损失: 4.2884 | 验证损失: 4.2232 | R2: 0.2500 | RMSE: 2.6692 | LR: 0.000158\n",
      "浓度2D CNN Epoch 223/300 | 训练损失: 4.0986 | 验证损失: 4.2090 | R2: 0.2526 | RMSE: 2.6647 | LR: 0.000154\n",
      "浓度2D CNN Epoch 224/300 | 训练损失: 4.0737 | 验证损失: 4.2302 | R2: 0.2493 | RMSE: 2.6711 | LR: 0.000150\n",
      "浓度2D CNN Epoch 225/300 | 训练损失: 4.0966 | 验证损失: 4.2162 | R2: 0.2517 | RMSE: 2.6667 | LR: 0.000146\n",
      "浓度2D CNN Epoch 226/300 | 训练损失: 4.0664 | 验证损失: 4.2241 | R2: 0.2503 | RMSE: 2.6692 | LR: 0.000143\n",
      "浓度2D CNN Epoch 227/300 | 训练损失: 4.0742 | 验证损失: 4.2155 | R2: 0.2518 | RMSE: 2.6665 | LR: 0.000139\n",
      "浓度2D CNN Epoch 228/300 | 训练损失: 4.1090 | 验证损失: 4.2328 | R2: 0.2488 | RMSE: 2.6719 | LR: 0.000136\n",
      "浓度2D CNN Epoch 229/300 | 训练损失: 4.0964 | 验证损失: 4.2109 | R2: 0.2525 | RMSE: 2.6651 | LR: 0.000132\n",
      "浓度2D CNN Epoch 230/300 | 训练损失: 4.0771 | 验证损失: 4.2228 | R2: 0.2505 | RMSE: 2.6688 | LR: 0.000128\n",
      "浓度2D CNN Epoch 231/300 | 训练损失: 4.0890 | 验证损失: 4.2097 | R2: 0.2528 | RMSE: 2.6647 | LR: 0.000125\n",
      "浓度2D CNN Epoch 232/300 | 训练损失: 4.0789 | 验证损失: 4.2070 | R2: 0.2531 | RMSE: 2.6639 | LR: 0.000122\n",
      "浓度2D CNN Epoch 233/300 | 训练损失: 4.0569 | 验证损失: 4.2215 | R2: 0.2508 | RMSE: 2.6684 | LR: 0.000118\n",
      "浓度2D CNN Epoch 234/300 | 训练损失: 4.0984 | 验证损失: 4.2235 | R2: 0.2505 | RMSE: 2.6690 | LR: 0.000115\n",
      "浓度2D CNN Epoch 235/300 | 训练损失: 4.1183 | 验证损失: 4.2122 | R2: 0.2524 | RMSE: 2.6655 | LR: 0.000111\n",
      "浓度2D CNN Epoch 236/300 | 训练损失: 4.0822 | 验证损失: 4.2316 | R2: 0.2484 | RMSE: 2.6719 | LR: 0.000108\n",
      "浓度2D CNN Epoch 237/300 | 训练损失: 4.0999 | 验证损失: 4.2200 | R2: 0.2506 | RMSE: 2.6682 | LR: 0.000105\n",
      "浓度2D CNN Epoch 238/300 | 训练损失: 4.0759 | 验证损失: 4.2064 | R2: 0.2533 | RMSE: 2.6637 | LR: 0.000102\n",
      "保存基于R2的最佳2D CNN浓度模型，R2: 0.2533\n",
      "浓度2D CNN Epoch 239/300 | 训练损失: 4.0722 | 验证损失: 4.2126 | R2: 0.2523 | RMSE: 2.6656 | LR: 0.000099\n",
      "浓度2D CNN Epoch 240/300 | 训练损失: 4.0887 | 验证损失: 4.2128 | R2: 0.2520 | RMSE: 2.6659 | LR: 0.000095\n",
      "浓度2D CNN Epoch 241/300 | 训练损失: 4.0767 | 验证损失: 4.2216 | R2: 0.2508 | RMSE: 2.6684 | LR: 0.000092\n",
      "浓度2D CNN Epoch 242/300 | 训练损失: 4.0863 | 验证损失: 4.2384 | R2: 0.2479 | RMSE: 2.6736 | LR: 0.000089\n",
      "浓度2D CNN Epoch 243/300 | 训练损失: 4.1337 | 验证损失: 4.2086 | R2: 0.2530 | RMSE: 2.6644 | LR: 0.000086\n",
      "浓度2D CNN Epoch 244/300 | 训练损失: 4.0810 | 验证损失: 4.2106 | R2: 0.2527 | RMSE: 2.6650 | LR: 0.000084\n",
      "浓度2D CNN Epoch 245/300 | 训练损失: 4.1142 | 验证损失: 4.2028 | R2: 0.2539 | RMSE: 2.6626 | LR: 0.000081\n",
      "保存基于R2的最佳2D CNN浓度模型，R2: 0.2539\n",
      "浓度2D CNN Epoch 246/300 | 训练损失: 4.0720 | 验证损失: 4.2095 | R2: 0.2528 | RMSE: 2.6646 | LR: 0.000078\n",
      "浓度2D CNN Epoch 247/300 | 训练损失: 4.0752 | 验证损失: 4.2101 | R2: 0.2525 | RMSE: 2.6650 | LR: 0.000075\n",
      "浓度2D CNN Epoch 248/300 | 训练损失: 4.0694 | 验证损失: 4.2131 | R2: 0.2520 | RMSE: 2.6659 | LR: 0.000072\n",
      "浓度2D CNN Epoch 249/300 | 训练损失: 4.0981 | 验证损失: 4.2033 | R2: 0.2537 | RMSE: 2.6628 | LR: 0.000070\n",
      "浓度2D CNN Epoch 250/300 | 训练损失: 4.0678 | 验证损失: 4.2291 | R2: 0.2496 | RMSE: 2.6707 | LR: 0.000067\n",
      "浓度2D CNN Epoch 251/300 | 训练损失: 4.0812 | 验证损失: 4.2033 | R2: 0.2537 | RMSE: 2.6628 | LR: 0.000064\n",
      "浓度2D CNN Epoch 252/300 | 训练损失: 4.0659 | 验证损失: 4.2056 | R2: 0.2535 | RMSE: 2.6634 | LR: 0.000062\n",
      "浓度2D CNN Epoch 253/300 | 训练损失: 4.2680 | 验证损失: 4.2042 | R2: 0.2537 | RMSE: 2.6630 | LR: 0.000059\n",
      "浓度2D CNN Epoch 254/300 | 训练损失: 4.0765 | 验证损失: 4.2023 | R2: 0.2540 | RMSE: 2.6624 | LR: 0.000057\n",
      "保存基于R2的最佳2D CNN浓度模型，R2: 0.2540\n",
      "浓度2D CNN Epoch 255/300 | 训练损失: 4.0667 | 验证损失: 4.2066 | R2: 0.2533 | RMSE: 2.6637 | LR: 0.000054\n",
      "浓度2D CNN Epoch 256/300 | 训练损失: 4.0659 | 验证损失: 4.2188 | R2: 0.2512 | RMSE: 2.6675 | LR: 0.000052\n",
      "浓度2D CNN Epoch 257/300 | 训练损失: 4.0753 | 验证损失: 4.2074 | R2: 0.2532 | RMSE: 2.6639 | LR: 0.000050\n",
      "浓度2D CNN Epoch 258/300 | 训练损失: 4.0821 | 验证损失: 4.2201 | R2: 0.2511 | RMSE: 2.6679 | LR: 0.000048\n",
      "浓度2D CNN Epoch 259/300 | 训练损失: 4.1257 | 验证损失: 4.2154 | R2: 0.2519 | RMSE: 2.6664 | LR: 0.000045\n",
      "浓度2D CNN Epoch 260/300 | 训练损失: 4.0803 | 验证损失: 4.1985 | R2: 0.2547 | RMSE: 2.6612 | LR: 0.000043\n",
      "保存基于R2的最佳2D CNN浓度模型，R2: 0.2547\n",
      "浓度2D CNN Epoch 261/300 | 训练损失: 4.0819 | 验证损失: 4.2022 | R2: 0.2539 | RMSE: 2.6625 | LR: 0.000041\n",
      "浓度2D CNN Epoch 262/300 | 训练损失: 4.1222 | 验证损失: 4.1984 | R2: 0.2547 | RMSE: 2.6612 | LR: 0.000039\n",
      "保存基于R2的最佳2D CNN浓度模型，R2: 0.2547\n",
      "浓度2D CNN Epoch 263/300 | 训练损失: 4.1976 | 验证损失: 4.2036 | R2: 0.2539 | RMSE: 2.6627 | LR: 0.000037\n",
      "浓度2D CNN Epoch 264/300 | 训练损失: 4.0877 | 验证损失: 4.1985 | R2: 0.2548 | RMSE: 2.6611 | LR: 0.000035\n",
      "保存基于R2的最佳2D CNN浓度模型，R2: 0.2548\n",
      "浓度2D CNN Epoch 265/300 | 训练损失: 4.0677 | 验证损失: 4.2024 | R2: 0.2538 | RMSE: 2.6626 | LR: 0.000033\n",
      "浓度2D CNN Epoch 266/300 | 训练损失: 4.0811 | 验证损失: 4.1971 | R2: 0.2549 | RMSE: 2.6608 | LR: 0.000031\n",
      "保存基于R2的最佳2D CNN浓度模型，R2: 0.2549\n",
      "浓度2D CNN Epoch 267/300 | 训练损失: 4.0661 | 验证损失: 4.1990 | R2: 0.2546 | RMSE: 2.6614 | LR: 0.000030\n",
      "浓度2D CNN Epoch 268/300 | 训练损失: 4.0897 | 验证损失: 4.1999 | R2: 0.2544 | RMSE: 2.6617 | LR: 0.000028\n",
      "浓度2D CNN Epoch 269/300 | 训练损失: 4.0772 | 验证损失: 4.2020 | R2: 0.2542 | RMSE: 2.6622 | LR: 0.000026\n",
      "浓度2D CNN Epoch 270/300 | 训练损失: 4.0680 | 验证损失: 4.2116 | R2: 0.2525 | RMSE: 2.6652 | LR: 0.000024\n",
      "浓度2D CNN Epoch 271/300 | 训练损失: 4.0987 | 验证损失: 4.1991 | R2: 0.2546 | RMSE: 2.6614 | LR: 0.000023\n",
      "浓度2D CNN Epoch 272/300 | 训练损失: 4.0655 | 验证损失: 4.2035 | R2: 0.2538 | RMSE: 2.6628 | LR: 0.000021\n",
      "浓度2D CNN Epoch 273/300 | 训练损失: 4.0964 | 验证损失: 4.2074 | R2: 0.2532 | RMSE: 2.6640 | LR: 0.000020\n",
      "浓度2D CNN Epoch 274/300 | 训练损失: 4.0547 | 验证损失: 4.2012 | R2: 0.2542 | RMSE: 2.6621 | LR: 0.000018\n",
      "浓度2D CNN Epoch 275/300 | 训练损失: 4.0757 | 验证损失: 4.2003 | R2: 0.2544 | RMSE: 2.6618 | LR: 0.000017\n",
      "浓度2D CNN Epoch 276/300 | 训练损失: 4.0886 | 验证损失: 4.2038 | R2: 0.2538 | RMSE: 2.6628 | LR: 0.000016\n",
      "浓度2D CNN Epoch 277/300 | 训练损失: 4.2496 | 验证损失: 4.2016 | R2: 0.2542 | RMSE: 2.6621 | LR: 0.000014\n",
      "浓度2D CNN Epoch 278/300 | 训练损失: 4.0668 | 验证损失: 4.2056 | R2: 0.2535 | RMSE: 2.6634 | LR: 0.000013\n",
      "浓度2D CNN Epoch 279/300 | 训练损失: 4.0869 | 验证损失: 4.1983 | R2: 0.2547 | RMSE: 2.6611 | LR: 0.000012\n",
      "浓度2D CNN Epoch 280/300 | 训练损失: 4.0582 | 验证损失: 4.2028 | R2: 0.2540 | RMSE: 2.6625 | LR: 0.000011\n",
      "浓度2D CNN Epoch 281/300 | 训练损失: 4.0823 | 验证损失: 4.1977 | R2: 0.2548 | RMSE: 2.6609 | LR: 0.000010\n",
      "浓度2D CNN Epoch 282/300 | 训练损失: 4.0793 | 验证损失: 4.2014 | R2: 0.2542 | RMSE: 2.6621 | LR: 0.000009\n",
      "浓度2D CNN Epoch 283/300 | 训练损失: 4.0680 | 验证损失: 4.1992 | R2: 0.2546 | RMSE: 2.6614 | LR: 0.000008\n",
      "浓度2D CNN Epoch 284/300 | 训练损失: 4.0678 | 验证损失: 4.2014 | R2: 0.2542 | RMSE: 2.6621 | LR: 0.000007\n",
      "浓度2D CNN Epoch 285/300 | 训练损失: 4.0922 | 验证损失: 4.2022 | R2: 0.2541 | RMSE: 2.6623 | LR: 0.000006\n",
      "浓度2D CNN Epoch 286/300 | 训练损失: 4.0656 | 验证损失: 4.2001 | R2: 0.2544 | RMSE: 2.6617 | LR: 0.000005\n",
      "浓度2D CNN Epoch 287/300 | 训练损失: 4.0556 | 验证损失: 4.2015 | R2: 0.2542 | RMSE: 2.6621 | LR: 0.000005\n",
      "浓度2D CNN Epoch 288/300 | 训练损失: 4.0736 | 验证损失: 4.1992 | R2: 0.2546 | RMSE: 2.6614 | LR: 0.000004\n",
      "浓度2D CNN Epoch 289/300 | 训练损失: 4.0921 | 验证损失: 4.2003 | R2: 0.2544 | RMSE: 2.6617 | LR: 0.000003\n",
      "浓度2D CNN Epoch 290/300 | 训练损失: 4.0581 | 验证损失: 4.1992 | R2: 0.2546 | RMSE: 2.6614 | LR: 0.000003\n",
      "浓度2D CNN Epoch 291/300 | 训练损失: 4.0895 | 验证损失: 4.1997 | R2: 0.2545 | RMSE: 2.6616 | LR: 0.000002\n",
      "浓度2D CNN Epoch 292/300 | 训练损失: 4.0660 | 验证损失: 4.2003 | R2: 0.2544 | RMSE: 2.6617 | LR: 0.000002\n",
      "浓度2D CNN Epoch 293/300 | 训练损失: 4.0774 | 验证损失: 4.2008 | R2: 0.2543 | RMSE: 2.6619 | LR: 0.000001\n",
      "浓度2D CNN Epoch 294/300 | 训练损失: 4.0726 | 验证损失: 4.2012 | R2: 0.2543 | RMSE: 2.6620 | LR: 0.000001\n",
      "浓度2D CNN Epoch 295/300 | 训练损失: 4.0506 | 验证损失: 4.2011 | R2: 0.2543 | RMSE: 2.6620 | LR: 0.000001\n",
      "浓度2D CNN Epoch 296/300 | 训练损失: 4.0656 | 验证损失: 4.1997 | R2: 0.2545 | RMSE: 2.6616 | LR: 0.000000\n",
      "浓度模型早停触发! 在第296个epoch停止训练\n",
      "\n",
      "🔹 2D CNN浓度模型训练完成！\n",
      "最佳验证损失: 4.1971\n",
      "最佳R2: 0.2549\n",
      "\n",
      "开始最终评估（使用验证集）...\n",
      "开始2D CNN模型评估...\n",
      "\n",
      "📊 经典2D CNN模型验证结果:\n",
      "\n",
      "🔹 水头指标:\n",
      "MSE  : 1.0678\n",
      "RMSE : 1.0263\n",
      "MAE  : 0.7344\n",
      "R2   : 0.9656\n",
      "\n",
      "🔹 浓度指标:\n",
      "MSE  : 7.0482\n",
      "RMSE : 2.6453\n",
      "MAE  : 0.4130\n",
      "R2   : 0.2538\n",
      "\n",
      "预测结果已保存到: ./saved_models/classic_2d_cnn_dual_original_preprocess/val_predictions_2d_cnn.csv\n",
      "\n",
      "🎉 经典2D CNN模型训练和评估完成！\n",
      "\n",
      "📊 最终结果总结:\n",
      "📈 水头模型 - R2: 0.9656, RMSE: 1.0263\n",
      "📈 浓度模型 - R2: 0.2538, RMSE: 2.6453\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score as sklearn_r2_score\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 经典2D CNN模型\n",
    "class Classic2DCNN(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_dim=64, dropout=0.3):\n",
    "        super(Classic2DCNN, self).__init__()\n",
    "        \n",
    "        # 第一层 - 使用更大的卷积核，减少感受野的精细度\n",
    "        self.conv1 = nn.Conv2d(input_channels, hidden_dim, kernel_size=5, padding=2, stride=2)  # 增加stride\n",
    "        self.bn1 = nn.BatchNorm2d(hidden_dim)\n",
    "        self.dropout1 = nn.Dropout2d(dropout)\n",
    "        \n",
    "        # 第二层 - 保持维度不变\n",
    "        self.conv2 = nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(hidden_dim)\n",
    "        self.dropout2 = nn.Dropout2d(dropout)\n",
    "        \n",
    "        # 第三层 - 新增层，继续保持维度\n",
    "        self.conv3 = nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(hidden_dim)\n",
    "        self.dropout3 = nn.Dropout2d(dropout)\n",
    "        \n",
    "        # 第四层 - 新增层，可以选择轻微改变维度或保持不变\n",
    "        self.conv4 = nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(hidden_dim)\n",
    "        self.dropout4 = nn.Dropout2d(dropout)\n",
    "        \n",
    "        # 反向上采样（可能破坏空间信息）\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='nearest')  # 简单最近邻上采样\n",
    "        \n",
    "        # 输出层\n",
    "        self.output_conv = nn.Conv2d(hidden_dim, 1, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (B, T, C, H, W)\n",
    "        B, T, C, H, W = x.shape\n",
    "        \n",
    "        # 将时间维度合并到batch维度\n",
    "        x = x.view(B * T, C, H, W)\n",
    "        \n",
    "        # 四层前向传播\n",
    "        x = self.dropout1(F.relu(self.bn1(self.conv1(x))))  # 下采样\n",
    "        x = self.dropout2(F.relu(self.bn2(self.conv2(x))))  # 保持维度\n",
    "        x = self.dropout3(F.relu(self.bn3(self.conv3(x))))  # 保持维度 (新增)\n",
    "        x = self.dropout4(F.relu(self.bn4(self.conv4(x))))  # 保持维度 (新增)\n",
    "        x = self.upsample(x)  # 上采样回原始尺寸\n",
    "        \n",
    "        # 输出层\n",
    "        x = F.relu(self.output_conv(x))\n",
    "        \n",
    "        # 恢复时间维度\n",
    "        output = x.view(B, T, 1, H, W)\n",
    "        return output\n",
    "\n",
    "# 水头模型 - 16维输入\n",
    "class HeadCNN2D(nn.Module):\n",
    "    def __init__(self, input_dim=16, hidden_dim=64, dropout=0.3):\n",
    "        super(HeadCNN2D, self).__init__()\n",
    "        self.cnn = Classic2DCNN(input_dim, hidden_dim, dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.cnn(x)\n",
    "\n",
    "# 浓度模型 - 19维输入\n",
    "class ConcCNN2D(nn.Module):\n",
    "    def __init__(self, input_dim=20, hidden_dim=64, dropout=0.3):\n",
    "        super(ConcCNN2D, self).__init__()\n",
    "        self.cnn = Classic2DCNN(input_dim, hidden_dim, dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.cnn(x)\n",
    "\n",
    "# Dataset Class - 修改预处理部分，使用您原来的历史特征计算方式\n",
    "class HydroCNNDataset(Dataset):\n",
    "    def __init__(self, data, grid_size, max_time_steps):\n",
    "        self.data = data.reset_index(drop=True).copy()\n",
    "        self.grid_size = grid_size\n",
    "        self.max_time_steps = max_time_steps\n",
    "        self.models = self.data['model_name'].unique()\n",
    "        self.cached_data = {}\n",
    "        \n",
    "        # 基础特征列 - 与GNN保持一致 (14维)\n",
    "        self.base_feature_cols = [\n",
    "            'x', 'y', 'top', 'bottom', 'K', 'recharge', 'ET',\n",
    "            'river_stage', 'river_cond', 'river_rbot', 'well_rate', 'well_mask',\n",
    "            'chd_mask', 'lytyp'\n",
    "        ]\n",
    "        \n",
    "        # 浓度模型额外的基础特征 (15维，增加conc_mask)\n",
    "        self.conc_base_feature_cols = self.base_feature_cols + ['conc_mask']\n",
    "        \n",
    "        self._normalize_features()\n",
    "        self._preprocess_data()\n",
    "\n",
    "    def _normalize_features(self):\n",
    "        \"\"\"标准化特征，与GNN保持一致\"\"\"\n",
    "        print(\"开始特征标准化...\")\n",
    "        \n",
    "        # 只对浮点数特征进行标准化\n",
    "        float_cols = [col for col in self.base_feature_cols if col not in ['well_mask', 'chd_mask', 'lytyp']]\n",
    "        \n",
    "        for model_name in self.models:\n",
    "            model_df = self.data[self.data['model_name'] == model_name].copy()\n",
    "            \n",
    "            # 标准化基础浮点特征\n",
    "            if len(model_df) > 0:\n",
    "                scaler = StandardScaler()\n",
    "                float_data = model_df[float_cols].values\n",
    "                if float_data.size > 0:\n",
    "                    scaled_data = scaler.fit_transform(float_data)\n",
    "                    mask = self.data['model_name'] == model_name\n",
    "                    self.data.loc[mask, float_cols] = scaled_data\n",
    "\n",
    "    def _preprocess_data(self):\n",
    "        \"\"\"预处理数据 - 使用您原来的历史特征计算方式\"\"\"\n",
    "        print(\"预处理CNN数据...\")\n",
    "        M, N = self.grid_size\n",
    "        T = self.max_time_steps\n",
    "        \n",
    "        for model_idx, model_name in enumerate(self.models):\n",
    "            print(f\"处理模型 {model_idx+1}/{len(self.models)}: {model_name}\")\n",
    "            \n",
    "            model_df = self.data[self.data['model_name'] == model_name].copy().reset_index(drop=True)\n",
    "            if len(model_df) == 0:\n",
    "                print(f\"警告: 模型 {model_name} 没有数据，跳过\")\n",
    "                continue\n",
    "            \n",
    "            # 时间步归一化\n",
    "            model_df['time_step'] = model_df['time_step'] - model_df['time_step'].min()\n",
    "            \n",
    "            # 初始化数组\n",
    "            # 水头模型：14个基础特征 + 2个历史水头 = 16维\n",
    "            X_head = np.zeros((T, len(self.base_feature_cols) + 2, M, N), dtype=np.float32)\n",
    "            # 浓度模型：15个基础特征 + 2个历史水头 + 2个历史浓度 = 19维（不包括预测水头）\n",
    "            X_conc_base = np.zeros((T, len(self.conc_base_feature_cols) + 4, M, N), dtype=np.float32)\n",
    "            Y_head = np.zeros((T, 1, M, N), dtype=np.float32)\n",
    "            Y_conc = np.zeros((T, 1, M, N), dtype=np.float32)\n",
    "            mask = np.zeros((M, N), dtype=np.float32)\n",
    "            \n",
    "            # 按时间步处理\n",
    "            max_t = min(T, model_df['time_step'].max() + 1)\n",
    "            for t in range(max_t):\n",
    "                if t % 50 == 0:  # 每50个时间步输出一次进度\n",
    "                    print(f\"    处理时间步 {t}/{max_t}\")\n",
    "                \n",
    "                t_df = model_df[model_df['time_step'] == t]\n",
    "                if len(t_df) == 0:\n",
    "                    continue\n",
    "                \n",
    "                rows = t_df['row'].values.astype(int)\n",
    "                cols = t_df['col'].values.astype(int)\n",
    "                \n",
    "                # 检查索引范围\n",
    "                valid_mask = (rows >= 0) & (rows < M) & (cols >= 0) & (cols < N)\n",
    "                if not np.any(valid_mask):\n",
    "                    continue\n",
    "                    \n",
    "                rows = rows[valid_mask]\n",
    "                cols = cols[valid_mask]\n",
    "                t_df_valid = t_df.iloc[valid_mask]\n",
    "                \n",
    "                # 填充基础特征\n",
    "                # 水头模型基础特征（前14维）\n",
    "                for feat_idx, feat_name in enumerate(self.base_feature_cols):\n",
    "                    feat_values = t_df_valid[feat_name].values\n",
    "                    X_head[t, feat_idx, rows, cols] = feat_values\n",
    "                \n",
    "                # 浓度模型基础特征（前15维）\n",
    "                for feat_idx, feat_name in enumerate(self.conc_base_feature_cols):\n",
    "                    feat_values = t_df_valid[feat_name].values\n",
    "                    X_conc_base[t, feat_idx, rows, cols] = feat_values\n",
    "                \n",
    "                # 填充目标值\n",
    "                Y_head[t, 0, rows, cols] = t_df_valid['head'].values\n",
    "                Y_conc[t, 0, rows, cols] = t_df_valid['concentration'].values\n",
    "                \n",
    "                # 更新掩码\n",
    "                mask[rows, cols] = 1\n",
    "                \n",
    "                # 计算历史特征 - 使用您原来的方式\n",
    "                # 前一个时间步 (t-1)\n",
    "                if t > 0:\n",
    "                    prev_df = model_df[model_df['time_step'] == t-1]\n",
    "                    if len(prev_df) > 0:\n",
    "                        # 创建前一时间步的映射\n",
    "                        prev_head_map = {(r, c): h for r, c, h in zip(\n",
    "                            prev_df['row'].values.astype(int),\n",
    "                            prev_df['col'].values.astype(int),\n",
    "                            prev_df['head'].values\n",
    "                        )}\n",
    "                        prev_conc_map = {(r, c): c for r, c, c in zip(\n",
    "                            prev_df['row'].values.astype(int),\n",
    "                            prev_df['col'].values.astype(int),\n",
    "                            prev_df['concentration'].values\n",
    "                        )}\n",
    "                        \n",
    "                        # 填充前一时间步的值\n",
    "                        for r, c in zip(rows, cols):\n",
    "                            if (r, c) in prev_head_map:\n",
    "                                # 水头模型的前一时间步水头 (第15维，索引14)\n",
    "                                X_head[t, len(self.base_feature_cols), r, c] = prev_head_map[(r, c)]\n",
    "                                # 浓度模型的前一时间步水头 (第16维，索引15)\n",
    "                                X_conc_base[t, len(self.conc_base_feature_cols), r, c] = prev_head_map[(r, c)]\n",
    "                            if (r, c) in prev_conc_map:\n",
    "                                # 浓度模型的前一时间步浓度 (第18维，索引17)\n",
    "                                X_conc_base[t, len(self.conc_base_feature_cols) + 2, r, c] = prev_conc_map[(r, c)]\n",
    "                \n",
    "                # 前两个时间步 (t-2)\n",
    "                if t > 1:\n",
    "                    prev2_df = model_df[model_df['time_step'] == t-2]\n",
    "                    if len(prev2_df) > 0:\n",
    "                        # 创建前两时间步的映射\n",
    "                        prev2_head_map = {(r, c): h for r, c, h in zip(\n",
    "                            prev2_df['row'].values.astype(int),\n",
    "                            prev2_df['col'].values.astype(int),\n",
    "                            prev2_df['head'].values\n",
    "                        )}\n",
    "                        prev2_conc_map = {(r, c): c for r, c, c in zip(\n",
    "                            prev2_df['row'].values.astype(int),\n",
    "                            prev2_df['col'].values.astype(int),\n",
    "                            prev2_df['concentration'].values\n",
    "                        )}\n",
    "                        \n",
    "                        # 填充前两时间步的值\n",
    "                        for r, c in zip(rows, cols):\n",
    "                            if (r, c) in prev2_head_map:\n",
    "                                # 水头模型的前两时间步水头 (第16维，索引15)\n",
    "                                X_head[t, len(self.base_feature_cols) + 1, r, c] = prev2_head_map[(r, c)]\n",
    "                                # 浓度模型的前两时间步水头 (第17维，索引16)\n",
    "                                X_conc_base[t, len(self.conc_base_feature_cols) + 1, r, c] = prev2_head_map[(r, c)]\n",
    "                            if (r, c) in prev2_conc_map:\n",
    "                                # 浓度模型的前两时间步浓度 (第19维，索引18)\n",
    "                                X_conc_base[t, len(self.conc_base_feature_cols) + 3, r, c] = prev2_conc_map[(r, c)]\n",
    "                \n",
    "                # 对于t=0和t=1，用当前值填充缺失的历史特征\n",
    "                if t == 0:\n",
    "                    # t=0时，前一和前两时间步都用当前值\n",
    "                    current_head = t_df_valid['head'].values\n",
    "                    current_conc = t_df_valid['concentration'].values\n",
    "                    \n",
    "                    # 水头模型历史特征\n",
    "                    X_head[t, len(self.base_feature_cols), rows, cols] = current_head      # prev_head\n",
    "                    X_head[t, len(self.base_feature_cols) + 1, rows, cols] = current_head  # prev2_head\n",
    "                    \n",
    "                    # 浓度模型历史特征\n",
    "                    X_conc_base[t, len(self.conc_base_feature_cols), rows, cols] = current_head      # prev_head\n",
    "                    X_conc_base[t, len(self.conc_base_feature_cols) + 1, rows, cols] = current_head  # prev2_head\n",
    "                    X_conc_base[t, len(self.conc_base_feature_cols) + 2, rows, cols] = current_conc  # prev_conc\n",
    "                    X_conc_base[t, len(self.conc_base_feature_cols) + 3, rows, cols] = current_conc  # prev2_conc\n",
    "                    \n",
    "                elif t == 1:\n",
    "                    # t=1时，前两时间步用前一时间步的值\n",
    "                    for r, c in zip(rows, cols):\n",
    "                        # 获取前一时间步的值\n",
    "                        prev_head_val = X_head[t, len(self.base_feature_cols), r, c]\n",
    "                        prev_conc_val = X_conc_base[t, len(self.conc_base_feature_cols) + 2, r, c]\n",
    "                        \n",
    "                        # 设置前两时间步\n",
    "                        X_head[t, len(self.base_feature_cols) + 1, r, c] = prev_head_val  # prev2_head = prev_head\n",
    "                        X_conc_base[t, len(self.conc_base_feature_cols) + 1, r, c] = prev_head_val  # prev2_head = prev_head\n",
    "                        X_conc_base[t, len(self.conc_base_feature_cols) + 3, r, c] = prev_conc_val  # prev2_conc = prev_conc\n",
    "            \n",
    "            # 缓存预处理后的数据\n",
    "            self.cached_data[model_name] = {\n",
    "                'X_head': torch.from_numpy(X_head),\n",
    "                'X_conc_base': torch.from_numpy(X_conc_base),\n",
    "                'Y_head': torch.from_numpy(Y_head),\n",
    "                'Y_conc': torch.from_numpy(Y_conc),\n",
    "                'mask': torch.from_numpy(mask),\n",
    "                'model_name': model_name\n",
    "            }\n",
    "            \n",
    "            print(f\"  模型 {model_name} 处理完成\")\n",
    "        \n",
    "        print(f\"预处理完成！处理了 {len(self.cached_data)} 个模型\")\n",
    "        if len(self.cached_data) > 0:\n",
    "            sample_data = list(self.cached_data.values())[0]\n",
    "            print(f\"特征维度 - 水头: {sample_data['X_head'].shape[1]}, 浓度基础: {sample_data['X_conc_base'].shape[1]}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.cached_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        model_name = list(self.cached_data.keys())[idx]\n",
    "        return self.cached_data[model_name]\n",
    "\n",
    "# Custom Collate Function\n",
    "def custom_collate_fn(batch):\n",
    "    fixed_keys = ['X_head', 'X_conc_base', 'Y_head', 'Y_conc', 'mask']\n",
    "    variable_keys = ['model_name']\n",
    "    collated = {}\n",
    "    for key in fixed_keys:\n",
    "        collated[key] = torch.stack([item[key] for item in batch])\n",
    "    for key in variable_keys:\n",
    "        collated[key] = [item[key] for item in batch]\n",
    "    return collated\n",
    "\n",
    "# Metrics Computation\n",
    "def compute_metrics(y_true, y_pred, mask, T):\n",
    "    \"\"\"计算指标，与GNN保持一致\"\"\"\n",
    "    if isinstance(y_true, torch.Tensor):\n",
    "        y_true = y_true.detach().cpu().numpy()\n",
    "    if isinstance(y_pred, torch.Tensor):\n",
    "        y_pred = y_pred.detach().cpu().numpy()\n",
    "    if isinstance(mask, torch.Tensor):\n",
    "        mask = mask.detach().cpu().numpy()\n",
    "\n",
    "    # 应用掩码\n",
    "    mask = mask[:, np.newaxis, np.newaxis, :, :]  # Shape: [B, 1, 1, M, N]\n",
    "    mask = np.repeat(mask, T, axis=1)  # Shape: [B, T, 1, M, N]\n",
    "\n",
    "    y_true = y_true[mask > 0]\n",
    "    y_pred = y_pred[mask > 0]\n",
    "\n",
    "    valid_mask = ~np.isnan(y_true) & ~np.isinf(y_true) & ~np.isnan(y_pred) & ~np.isinf(y_pred)\n",
    "    y_true = y_true[valid_mask]\n",
    "    y_pred = y_pred[valid_mask]\n",
    "\n",
    "    if len(y_true) == 0:\n",
    "        return {'mse': np.nan, 'rmse': np.nan, 'mae': np.nan, 'r2': np.nan}\n",
    "\n",
    "    mse = np.mean((y_true - y_pred) ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "    \n",
    "    # 计算R2\n",
    "    ss_res = np.sum((y_true - y_pred) ** 2)\n",
    "    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "    r2 = 1 - (ss_res / (ss_tot + 1e-8))\n",
    "\n",
    "    return {'mse': mse, 'rmse': rmse, 'mae': mae, 'r2': r2}\n",
    "\n",
    "# 训练函数 - 分步训练\n",
    "def train_dual_cnn_2d(train_loader, val_loader, config):\n",
    "    \"\"\"经典2D CNN训练函数 - 分步训练\"\"\"\n",
    "    \n",
    "    # 创建保存目录\n",
    "    os.makedirs(config['save_path'], exist_ok=True)\n",
    "    \n",
    "    print(\"🔹 开始训练经典2D CNN水头模型...\")\n",
    "    \n",
    "    # ==================== 第一阶段：训练水头模型 ====================\n",
    "    head_model = HeadCNN2D(input_dim=16, hidden_dim=config['hidden_dim']).to(device)\n",
    "    head_optimizer = torch.optim.AdamW(\n",
    "        head_model.parameters(),\n",
    "        lr=config['lr'],\n",
    "        weight_decay=config['weight_decay']\n",
    "    )\n",
    "    head_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(head_optimizer, T_max=config['num_epochs'])\n",
    "    \n",
    "    best_head_val_loss = float('inf')\n",
    "    head_early_stop_counter = 0\n",
    "    \n",
    "    for epoch in range(config['num_epochs']):\n",
    "        # 训练水头模型\n",
    "        head_model.train()\n",
    "        total_head_loss = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            X_head = batch['X_head'].to(device)\n",
    "            Y_head = batch['Y_head'].to(device)\n",
    "            mask = batch['mask'].to(device).unsqueeze(1).unsqueeze(1)  # [B, 1, 1, M, N]\n",
    "            \n",
    "            head_optimizer.zero_grad()\n",
    "            pred_head = head_model(X_head)\n",
    "            \n",
    "            # 应用掩码计算损失\n",
    "            loss_head = F.mse_loss(pred_head * mask, Y_head * mask)\n",
    "            loss_head.backward()\n",
    "            \n",
    "            # 梯度裁剪\n",
    "            torch.nn.utils.clip_grad_norm_(head_model.parameters(), max_norm=1.0)\n",
    "            head_optimizer.step()\n",
    "            \n",
    "            total_head_loss += loss_head.item()\n",
    "        \n",
    "        # 验证水头模型\n",
    "        head_model.eval()\n",
    "        total_head_val_loss = 0\n",
    "        all_head_metrics = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                X_head = batch['X_head'].to(device)\n",
    "                Y_head = batch['Y_head'].to(device)\n",
    "                mask = batch['mask'].to(device).unsqueeze(1).unsqueeze(1)\n",
    "                \n",
    "                pred_head = head_model(X_head)\n",
    "                loss_head = F.mse_loss(pred_head * mask, Y_head * mask)\n",
    "                total_head_val_loss += loss_head.item()\n",
    "                \n",
    "                # 计算指标\n",
    "                head_metrics = compute_metrics(Y_head, pred_head, batch['mask'], config['max_time_steps'])\n",
    "                all_head_metrics.append(head_metrics)\n",
    "        \n",
    "        avg_head_train_loss = total_head_loss / len(train_loader)\n",
    "        avg_head_val_loss = total_head_val_loss / len(val_loader)\n",
    "        \n",
    "        # 计算平均指标\n",
    "        avg_head_r2 = np.nanmean([m['r2'] for m in all_head_metrics])\n",
    "        avg_head_rmse = np.nanmean([m['rmse'] for m in all_head_metrics])\n",
    "        \n",
    "        head_scheduler.step()\n",
    "        current_lr = head_scheduler.get_last_lr()[0]\n",
    "        \n",
    "        print(f\"水头2D CNN Epoch {epoch+1:03d}/{config['num_epochs']} | \"\n",
    "              f\"训练损失: {avg_head_train_loss:.4f} | 验证损失: {avg_head_val_loss:.4f} | \"\n",
    "              f\"R2: {avg_head_r2:.4f} | RMSE: {avg_head_rmse:.4f} | LR: {current_lr:.6f}\")\n",
    "        \n",
    "        # 保存最佳水头模型\n",
    "        if avg_head_val_loss < best_head_val_loss:\n",
    "            best_head_val_loss = avg_head_val_loss\n",
    "            head_early_stop_counter = 0\n",
    "            torch.save({\n",
    "                'model_state_dict': head_model.state_dict(),\n",
    "                'epoch': epoch,\n",
    "                'train_loss': avg_head_train_loss,\n",
    "                'val_loss': avg_head_val_loss,\n",
    "                'r2': avg_head_r2,\n",
    "                'config': config\n",
    "            }, os.path.join(config['save_path'], 'best_head_model_2d.pth'))\n",
    "            print(f\"保存最佳2D CNN水头模型，验证损失: {best_head_val_loss:.4f}\")\n",
    "        else:\n",
    "            head_early_stop_counter += 1\n",
    "        \n",
    "        # 早停检查\n",
    "        if head_early_stop_counter >= config['patience']:\n",
    "            print(f\"水头模型早停触发! 在第{epoch+1}个epoch停止训练\")\n",
    "            break\n",
    "    \n",
    "    # 加载最佳水头模型\n",
    "    best_head_checkpoint = torch.load(os.path.join(config['save_path'], 'best_head_model_2d.pth'),weights_only=False)\n",
    "    head_model.load_state_dict(best_head_checkpoint['model_state_dict'])\n",
    "    head_model.eval()\n",
    "    \n",
    "    print(f\"\\n🔹 2D CNN水头模型训练完成！最佳验证损失: {best_head_val_loss:.4f}\")\n",
    "    print(\"🔹 开始训练2D CNN浓度模型...\")\n",
    "    \n",
    "    # ==================== 第二阶段：训练浓度模型 ====================\n",
    "    conc_model = ConcCNN2D(input_dim=20, hidden_dim=config['hidden_dim']).to(device)\n",
    "    conc_optimizer = torch.optim.AdamW(\n",
    "        conc_model.parameters(),\n",
    "        lr=config['lr'],\n",
    "        weight_decay=config['weight_decay']\n",
    "    )\n",
    "    conc_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(conc_optimizer, T_max=config['num_epochs'])\n",
    "    \n",
    "    best_conc_val_loss = float('inf')\n",
    "    best_conc_r2 = float('-inf')\n",
    "    conc_early_stop_counter = 0\n",
    "    \n",
    "    for epoch in range(config['num_epochs']):\n",
    "        # 训练浓度模型\n",
    "        conc_model.train()\n",
    "        total_conc_loss = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            X_head = batch['X_head'].to(device)\n",
    "            X_conc_base = batch['X_conc_base'].to(device)\n",
    "            Y_conc = batch['Y_conc'].to(device)\n",
    "            mask = batch['mask'].to(device).unsqueeze(1).unsqueeze(1)\n",
    "            \n",
    "            # 使用固定的水头模型预测水头\n",
    "            with torch.no_grad():\n",
    "                pred_head = head_model(X_head)\n",
    "            \n",
    "            # 构建浓度模型输入（19维）\n",
    "            X_conc = torch.cat([X_conc_base, pred_head], dim=2)  # [B, T, 19, M, N]\n",
    "            \n",
    "            conc_optimizer.zero_grad()\n",
    "            pred_conc = conc_model(X_conc)\n",
    "            \n",
    "            # 应用掩码计算损失\n",
    "            loss_conc = F.mse_loss(pred_conc * mask, Y_conc * mask)\n",
    "            loss_conc.backward()\n",
    "            \n",
    "            # 梯度裁剪\n",
    "            torch.nn.utils.clip_grad_norm_(conc_model.parameters(), max_norm=1.0)\n",
    "            conc_optimizer.step()\n",
    "            \n",
    "            total_conc_loss += loss_conc.item()\n",
    "        \n",
    "        # 验证浓度模型\n",
    "        conc_model.eval()\n",
    "        total_conc_val_loss = 0\n",
    "        all_conc_metrics = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                X_head = batch['X_head'].to(device)\n",
    "                X_conc_base = batch['X_conc_base'].to(device)\n",
    "                Y_conc = batch['Y_conc'].to(device)\n",
    "                mask = batch['mask'].to(device).unsqueeze(1).unsqueeze(1)\n",
    "                \n",
    "                pred_head = head_model(X_head)\n",
    "                X_conc = torch.cat([X_conc_base, pred_head], dim=2)\n",
    "                pred_conc = conc_model(X_conc)\n",
    "                \n",
    "                loss_conc = F.mse_loss(pred_conc * mask, Y_conc * mask)\n",
    "                total_conc_val_loss += loss_conc.item()\n",
    "                \n",
    "                # 计算指标\n",
    "                conc_metrics = compute_metrics(Y_conc, pred_conc, batch['mask'], config['max_time_steps'])\n",
    "                all_conc_metrics.append(conc_metrics)\n",
    "        \n",
    "        avg_conc_train_loss = total_conc_loss / len(train_loader)\n",
    "        avg_conc_val_loss = total_conc_val_loss / len(val_loader)\n",
    "        \n",
    "        # 计算平均指标\n",
    "        avg_conc_r2 = np.nanmean([m['r2'] for m in all_conc_metrics])\n",
    "        avg_conc_rmse = np.nanmean([m['rmse'] for m in all_conc_metrics])\n",
    "        \n",
    "        conc_scheduler.step()\n",
    "        current_lr = conc_scheduler.get_last_lr()[0]\n",
    "        \n",
    "        print(f\"浓度2D CNN Epoch {epoch+1:03d}/{config['num_epochs']} | \"\n",
    "              f\"训练损失: {avg_conc_train_loss:.4f} | 验证损失: {avg_conc_val_loss:.4f} | \"\n",
    "              f\"R2: {avg_conc_r2:.4f} | RMSE: {avg_conc_rmse:.4f} | LR: {current_lr:.6f}\")\n",
    "        \n",
    "        # 保存最佳浓度模型（基于验证损失）\n",
    "        if avg_conc_val_loss < best_conc_val_loss:\n",
    "            best_conc_val_loss = avg_conc_val_loss\n",
    "            torch.save({\n",
    "                'head_model_state_dict': head_model.state_dict(),\n",
    "                'conc_model_state_dict': conc_model.state_dict(),\n",
    "                'epoch': epoch,\n",
    "                'train_loss': avg_conc_train_loss,\n",
    "                'val_loss': avg_conc_val_loss,\n",
    "                'r2': avg_conc_r2,\n",
    "                'config': config,\n",
    "                'criterion': 'loss'\n",
    "            }, os.path.join(config['save_path'], 'best_conc_model_2d_loss.pth'))\n",
    "        \n",
    "        # 保存最佳浓度模型（基于R2）\n",
    "        if avg_conc_r2 > best_conc_r2:\n",
    "            best_conc_r2 = avg_conc_r2\n",
    "            conc_early_stop_counter = 0\n",
    "            torch.save({\n",
    "                'head_model_state_dict': head_model.state_dict(),\n",
    "                'conc_model_state_dict': conc_model.state_dict(),\n",
    "                'epoch': epoch,\n",
    "                'train_loss': avg_conc_train_loss,\n",
    "                'val_loss': avg_conc_val_loss,\n",
    "                'r2': avg_conc_r2,\n",
    "                'config': config,\n",
    "                'criterion': 'r2'\n",
    "            }, os.path.join(config['save_path'], 'best_conc_model_2d_r2.pth'))\n",
    "            print(f\"保存基于R2的最佳2D CNN浓度模型，R2: {best_conc_r2:.4f}\")\n",
    "        else:\n",
    "            conc_early_stop_counter += 1\n",
    "        \n",
    "        # 早停检查\n",
    "        if conc_early_stop_counter >= config['patience']:\n",
    "            print(f\"浓度模型早停触发! 在第{epoch+1}个epoch停止训练\")\n",
    "            break\n",
    "    \n",
    "    print(f\"\\n🔹 2D CNN浓度模型训练完成！\")\n",
    "    print(f\"最佳验证损失: {best_conc_val_loss:.4f}\")\n",
    "    print(f\"最佳R2: {best_conc_r2:.4f}\")\n",
    "    \n",
    "    return head_model, conc_model\n",
    "\n",
    "# 评估函数\n",
    "def evaluate_dual_cnn_2d(data_loader, config):\n",
    "    \"\"\"评估训练好的2D CNN双模型\"\"\"\n",
    "    \n",
    "    # 加载最佳模型\n",
    "    checkpoint = torch.load(os.path.join(config['save_path'], 'best_conc_model_2d_r2.pth'),weights_only=False)\n",
    "    \n",
    "    head_model = HeadCNN2D(input_dim=16, hidden_dim=config['hidden_dim']).to(device)\n",
    "    conc_model = ConcCNN2D(input_dim=20, hidden_dim=config['hidden_dim']).to(device)\n",
    "    \n",
    "    head_model.load_state_dict(checkpoint['head_model_state_dict'])\n",
    "    conc_model.load_state_dict(checkpoint['conc_model_state_dict'])\n",
    "    \n",
    "    head_model.eval()\n",
    "    conc_model.eval()\n",
    "    \n",
    "    all_head_metrics = []\n",
    "    all_conc_metrics = []\n",
    "    all_predictions = []\n",
    "    \n",
    "    print(\"开始2D CNN模型评估...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(data_loader):\n",
    "            X_head = batch['X_head'].to(device)\n",
    "            X_conc_base = batch['X_conc_base'].to(device)\n",
    "            Y_head = batch['Y_head'].to(device)\n",
    "            Y_conc = batch['Y_conc'].to(device)\n",
    "            mask = batch['mask'].to(device)\n",
    "            model_names = batch['model_name']\n",
    "            \n",
    "            # 预测水头\n",
    "            pred_head = head_model(X_head)\n",
    "            \n",
    "            # 预测浓度\n",
    "            X_conc = torch.cat([X_conc_base, pred_head], dim=2)\n",
    "            pred_conc = conc_model(X_conc)\n",
    "            \n",
    "            # 计算指标\n",
    "            for i in range(len(model_names)):\n",
    "                head_metrics = compute_metrics(Y_head[i:i+1], pred_head[i:i+1], mask[i:i+1], config['max_time_steps'])\n",
    "                conc_metrics = compute_metrics(Y_conc[i:i+1], pred_conc[i:i+1], mask[i:i+1], config['max_time_steps'])\n",
    "                \n",
    "                all_head_metrics.append(head_metrics)\n",
    "                all_conc_metrics.append(conc_metrics)\n",
    "                \n",
    "                # 保存预测结果\n",
    "                all_predictions.append({\n",
    "                    'model_name': model_names[i],\n",
    "                    'head_r2': head_metrics['r2'],\n",
    "                    'head_rmse': head_metrics['rmse'],\n",
    "                    'conc_r2': conc_metrics['r2'],\n",
    "                    'conc_rmse': conc_metrics['rmse']\n",
    "                })\n",
    "    \n",
    "    # 计算平均指标\n",
    "    avg_head_metrics = {\n",
    "        'mse': np.nanmean([m['mse'] for m in all_head_metrics]),\n",
    "        'rmse': np.nanmean([m['rmse'] for m in all_head_metrics]),\n",
    "        'mae': np.nanmean([m['mae'] for m in all_head_metrics]),\n",
    "        'r2': np.nanmean([m['r2'] for m in all_head_metrics])\n",
    "    }\n",
    "    \n",
    "    avg_conc_metrics = {\n",
    "        'mse': np.nanmean([m['mse'] for m in all_conc_metrics]),\n",
    "        'rmse': np.nanmean([m['rmse'] for m in all_conc_metrics]),\n",
    "        'mae': np.nanmean([m['mae'] for m in all_conc_metrics]),\n",
    "        'r2': np.nanmean([m['r2'] for m in all_conc_metrics])\n",
    "    }\n",
    "    \n",
    "    # 输出结果\n",
    "    print(\"\\n📊 经典2D CNN模型验证结果:\")\n",
    "    print(\"\\n🔹 水头指标:\")\n",
    "    for k, v in avg_head_metrics.items():\n",
    "        print(f\"{k.upper():<5}: {v:.4f}\")\n",
    "    print(\"\\n🔹 浓度指标:\")\n",
    "    for k, v in avg_conc_metrics.items():\n",
    "        print(f\"{k.upper():<5}: {v:.4f}\")\n",
    "    \n",
    "    # 保存预测结果\n",
    "    predictions_df = pd.DataFrame(all_predictions)\n",
    "    predictions_df.to_csv(os.path.join(config['save_path'], 'val_predictions_2d_cnn.csv'), index=False)\n",
    "    print(f\"\\n预测结果已保存到: {os.path.join(config['save_path'], 'val_predictions_2d_cnn.csv')}\")\n",
    "    \n",
    "    return avg_head_metrics, avg_conc_metrics\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    # 加载数据\n",
    "    cleaned_data = pd.read_csv('conc_dual_guass.csv')\n",
    "    print(\"数据统计:\")\n",
    "    print(cleaned_data[['head', 'concentration']].describe())\n",
    "    \n",
    "    # 检查必要的列\n",
    "    required_cols = [\n",
    "        'row', 'col', 'time_step', 'x', 'y', 'top', 'bottom', 'K', 'recharge', 'ET',\n",
    "        'river_stage', 'river_cond', 'river_rbot', 'well_rate', 'well_mask',\n",
    "        'chd_mask', 'lytyp', 'conc_mask', 'head', 'concentration', 'model_name'\n",
    "    ]\n",
    "    \n",
    "    missing_cols = [col for col in required_cols if col not in cleaned_data.columns]\n",
    "    if missing_cols:\n",
    "        raise KeyError(f\"缺少必要的列: {missing_cols}\")\n",
    "    \n",
    "    # 数据集参数\n",
    "    M = cleaned_data['row'].max() + 1\n",
    "    N = cleaned_data['col'].max() + 1\n",
    "    T = cleaned_data['time_step'].max() + 1 - cleaned_data['time_step'].min()\n",
    "    \n",
    "    print(f\"网格大小: {M} x {N}, 时间步数: {T}\")\n",
    "    \n",
    "    # 数据划分 - 与GNN保持一致的7:3划分\n",
    "    unique_models = cleaned_data['model_name'].unique()\n",
    "    print(f\"总模型数: {len(unique_models)}\")\n",
    "    \n",
    "    train_models, val_models = train_test_split(unique_models, test_size=0.3, random_state=42)\n",
    "    \n",
    "    train_data = cleaned_data[cleaned_data['model_name'].isin(train_models)]\n",
    "    val_data = cleaned_data[cleaned_data['model_name'].isin(val_models)]\n",
    "    \n",
    "    print(f\"训练集: {len(train_models)} 个模型 ({len(train_models)/len(unique_models)*100:.1f}%)\")\n",
    "    print(f\"验证集: {len(val_models)} 个模型 ({len(val_models)/len(unique_models)*100:.1f}%)\")\n",
    "    \n",
    "    # 创建数据集\n",
    "    train_dataset = HydroCNNDataset(train_data, (M, N), T)\n",
    "    val_dataset = HydroCNNDataset(val_data, (M, N), T)\n",
    "    \n",
    "    # 检查数据集是否为空\n",
    "    if len(train_dataset) == 0 or len(val_dataset) == 0:\n",
    "        print(\"错误: 某个数据集为空！\")\n",
    "        print(f\"训练集大小: {len(train_dataset)}\")\n",
    "        print(f\"验证集大小: {len(val_dataset)}\")\n",
    "        exit(1)\n",
    "    \n",
    "    # 创建数据加载器\n",
    "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=custom_collate_fn)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=4, collate_fn=custom_collate_fn)\n",
    "    \n",
    "    # 训练配置\n",
    "    config = {\n",
    "        'hidden_dim': 96,\n",
    "        'num_epochs': 300,\n",
    "        'lr': 1e-3,\n",
    "        'weight_decay': 1e-4,\n",
    "        'patience': 30,\n",
    "        'save_path': './saved_models/classic_2d_cnn_dual_original_preprocess',\n",
    "        'max_time_steps': T\n",
    "    }\n",
    "    \n",
    "    print(\"开始训练经典2D CNN模型...\")\n",
    "    print(f\"配置: {config}\")\n",
    "    \n",
    "    # 训练模型\n",
    "    head_model, conc_model = train_dual_cnn_2d(train_loader, val_loader, config)\n",
    "    \n",
    "    # 评估模型\n",
    "    print(\"\\n开始最终评估（使用验证集）...\")\n",
    "    head_metrics, conc_metrics = evaluate_dual_cnn_2d(val_loader, config)\n",
    "    \n",
    "    print(\"\\n🎉 经典2D CNN模型训练和评估完成！\")\n",
    "    print(\"\\n📊 最终结果总结:\")\n",
    "    print(f\"📈 水头模型 - R2: {head_metrics['r2']:.4f}, RMSE: {head_metrics['rmse']:.4f}\")\n",
    "    print(f\"📈 浓度模型 - R2: {conc_metrics['r2']:.4f}, RMSE: {conc_metrics['rmse']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e87af1-3cb5-4449-9a28-2a1eaa3adaae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
